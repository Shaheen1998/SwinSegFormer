{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afb02073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:51:07.484979Z",
     "iopub.status.busy": "2024-03-09T19:51:07.484608Z",
     "iopub.status.idle": "2024-03-09T19:51:08.515006Z",
     "shell.execute_reply": "2024-03-09T19:51:08.513780Z"
    },
    "papermill": {
     "duration": 1.046107,
     "end_time": "2024-03-09T19:51:08.517561",
     "exception": false,
     "start_time": "2024-03-09T19:51:07.471454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\r\n",
      "Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da446457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:51:08.542335Z",
     "iopub.status.busy": "2024-03-09T19:51:08.541918Z",
     "iopub.status.idle": "2024-03-09T19:51:09.586893Z",
     "shell.execute_reply": "2024-03-09T19:51:09.585647Z"
    },
    "papermill": {
     "duration": 1.060484,
     "end_time": "2024-03-09T19:51:09.589611",
     "exception": false,
     "start_time": "2024-03-09T19:51:08.529127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  9 19:51:09 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   35C    P0              25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fe52cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:51:09.615362Z",
     "iopub.status.busy": "2024-03-09T19:51:09.614545Z",
     "iopub.status.idle": "2024-03-09T19:51:10.615536Z",
     "shell.execute_reply": "2024-03-09T19:51:10.614354Z"
    },
    "papermill": {
     "duration": 1.016634,
     "end_time": "2024-03-09T19:51:10.618316",
     "exception": false,
     "start_time": "2024-03-09T19:51:09.601682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "606b28ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:51:10.644712Z",
     "iopub.status.busy": "2024-03-09T19:51:10.644344Z",
     "iopub.status.idle": "2024-03-09T19:51:10.650842Z",
     "shell.execute_reply": "2024-03-09T19:51:10.649893Z"
    },
    "papermill": {
     "duration": 0.023067,
     "end_time": "2024-03-09T19:51:10.653185",
     "exception": false,
     "start_time": "2024-03-09T19:51:10.630118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1c5392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:51:10.677816Z",
     "iopub.status.busy": "2024-03-09T19:51:10.677131Z",
     "iopub.status.idle": "2024-03-09T19:52:28.175987Z",
     "shell.execute_reply": "2024-03-09T19:52:28.174801Z"
    },
    "papermill": {
     "duration": 77.514526,
     "end_time": "2024-03-09T19:52:28.178922",
     "exception": false,
     "start_time": "2024-03-09T19:51:10.664396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.12.0\r\n",
      "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\r\n",
      "Collecting torchvision==0.13.0\r\n",
      "  Downloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting torchaudio==0.12.0\r\n",
      "  Downloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.12.0) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (2024.2.2)\r\n",
      "Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m908.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl (3.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.2.0.post0 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "stable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.12.0 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0 torchaudio-0.12.0 torchvision-0.13.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.7.0 torchvision==0.8.0\n",
    "!pip install torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131ecb70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:52:28.277864Z",
     "iopub.status.busy": "2024-03-09T19:52:28.277456Z",
     "iopub.status.idle": "2024-03-09T19:53:45.272889Z",
     "shell.execute_reply": "2024-03-09T19:53:45.271830Z"
    },
    "papermill": {
     "duration": 77.047058,
     "end_time": "2024-03-09T19:53:45.275492",
     "exception": false,
     "start_time": "2024-03-09T19:52:28.228434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.10/site-packages (from openmim) (8.1.7)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim) (0.4.6)\r\n",
      "Collecting model-index (from openmim)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from openmim) (2.1.4)\r\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.10/site-packages (from openmim) (23.3.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openmim) (2.31.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim) (13.7.0)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (6.0.1)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (3.5.2)\r\n",
      "Requirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (4.1.0)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (3.20.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (4.66.1)\r\n",
      "Collecting openxlab (from opendatalab->openmim)\r\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2024.2.2)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.4)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting requests (from openmim)\r\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting rich (from openmim)\r\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting tqdm (from opendatalab->openmim)\r\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\r\n",
      "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun-python-sdk-core-2.15.0.tar.gz (443 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.7)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\r\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading openxlab-0.0.34-py3-none-any.whl (299 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core\r\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=a5604ba2c13cf044a2f168a55664f474f6164a29a8b307fdfdadc0d676bf4489\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.0-py3-none-any.whl size=535312 sha256=2dde196a1171d1aea6149bb79aa363ded99aa29885c97bd0f028479194afdb45\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b7/28/7c/a888bb3c60c865d014c7ef5017c83fdbc1cb0f601b79c7794a\r\n",
      "Successfully built oss2 aliyun-python-sdk-core\r\n",
      "Installing collected packages: tqdm, setuptools, requests, model-index, jmespath, rich, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.1\r\n",
      "    Uninstalling tqdm-4.66.1:\r\n",
      "      Successfully uninstalled tqdm-4.66.1\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 69.0.3\r\n",
      "    Uninstalling setuptools-69.0.3:\r\n",
      "      Successfully uninstalled setuptools-69.0.3\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.31.0\r\n",
      "    Uninstalling requests-2.31.0:\r\n",
      "      Successfully uninstalled requests-2.31.0\r\n",
      "  Attempting uninstall: jmespath\r\n",
      "    Found existing installation: jmespath 1.0.1\r\n",
      "    Uninstalling jmespath-1.0.1:\r\n",
      "      Successfully uninstalled jmespath-1.0.1\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 13.7.0\r\n",
      "    Uninstalling rich-13.7.0:\r\n",
      "      Successfully uninstalled rich-13.7.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.8.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\r\n",
      "boto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.34.34 which is incompatible.\r\n",
      "gcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.2.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\r\n",
      "jupyterlab-server 2.25.2 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pytorch-lightning 2.2.0.post0 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.15.0 aliyun-python-sdk-kms-2.16.2 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.34 oss2-2.17.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmengine\r\n",
      "  Downloading mmengine-0.10.3-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting addict (from mmengine)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmengine) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmengine) (6.0.1)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine) (2.4.0)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmengine) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine) (4.9.0.80)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.17.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\r\n",
      "Downloading mmengine-0.10.3-py3-none-any.whl (451 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Installing collected packages: addict, mmengine\r\n",
      "Successfully installed addict-2.4.0 mmengine-0.10.3\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmcv>=2.0.0rc1\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (58.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.10.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (6.0.1)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (4.9.0.80)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.7.5)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.4.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv>=2.0.0rc1) (3.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc1) (3.17.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.4.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.16.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openmim\n",
    "# Install mmengine\n",
    "!mim install mmengine\n",
    "# Install MMCV\n",
    "!mim install 'mmcv >= 2.0.0rc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d474f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:53:45.398444Z",
     "iopub.status.busy": "2024-03-09T19:53:45.398029Z",
     "iopub.status.idle": "2024-03-09T19:53:45.402929Z",
     "shell.execute_reply": "2024-03-09T19:53:45.401984Z"
    },
    "papermill": {
     "duration": 0.067775,
     "end_time": "2024-03-09T19:53:45.405142",
     "exception": false,
     "start_time": "2024-03-09T19:53:45.337367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install mmcv>=2.0.0rc4 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b476e",
   "metadata": {
    "papermill": {
     "duration": 0.060641,
     "end_time": "2024-03-09T19:53:45.524719",
     "exception": false,
     "start_time": "2024-03-09T19:53:45.464078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **RESTART KERNEL BEFORE GOING FURTHER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab4df17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:53:45.647941Z",
     "iopub.status.busy": "2024-03-09T19:53:45.646927Z",
     "iopub.status.idle": "2024-03-09T19:53:46.643212Z",
     "shell.execute_reply": "2024-03-09T19:53:46.641869Z"
    },
    "papermill": {
     "duration": 1.059033,
     "end_time": "2024-03-09T19:53:46.645653",
     "exception": false,
     "start_time": "2024-03-09T19:53:45.586620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "0.13.0+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf91f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:53:46.810825Z",
     "iopub.status.busy": "2024-03-09T19:53:46.810354Z",
     "iopub.status.idle": "2024-03-09T19:54:17.185149Z",
     "shell.execute_reply": "2024-03-09T19:54:17.183843Z"
    },
    "papermill": {
     "duration": 30.502343,
     "end_time": "2024-03-09T19:54:17.252676",
     "exception": false,
     "start_time": "2024-03-09T19:53:46.750333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'mmsegmentation': No such file or directory\r\n",
      "Cloning into 'mmsegmentation'...\r\n",
      "remote: Enumerating objects: 16468, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (140/140), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (109/109), done.\u001b[K\r\n",
      "remote: Total 16468 (delta 51), reused 75 (delta 29), pack-reused 16328\u001b[K\r\n",
      "Receiving objects: 100% (16468/16468), 43.83 MiB | 37.47 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11434/11434), done.\r\n",
      "/kaggle/working/mmsegmentation\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools_scm/_integration/setuptools.py:30: RuntimeWarning: \r\n",
      "ERROR: setuptools==60.2.0 is used in combination with setuptools_scm>=8.x\r\n",
      "\r\n",
      "Your build configuration is incomplete and previously worked by accident!\r\n",
      "setuptools_scm requires setuptools>=61\r\n",
      "\r\n",
      "Suggested workaround if applicable:\r\n",
      " - migrating from the deprecated setup_requires mechanism to pep517/518\r\n",
      "   and using a pyproject.toml to declare build dependencies\r\n",
      "   which are reliably pre-installed before running the build tools\r\n",
      "\r\n",
      "  warnings.warn(\r\n",
      "running build\r\n",
      "running build_py\r\n",
      "creating build\r\n",
      "creating build/lib\r\n",
      "creating build/lib/mmseg\r\n",
      "copying mmseg/version.py -> build/lib/mmseg\r\n",
      "copying mmseg/__init__.py -> build/lib/mmseg\r\n",
      "creating build/lib/tests\r\n",
      "copying tests/test_digit_version.py -> build/lib/tests\r\n",
      "copying tests/__init__.py -> build/lib/tests\r\n",
      "copying tests/test_sampler.py -> build/lib/tests\r\n",
      "copying tests/test_config.py -> build/lib/tests\r\n",
      "creating build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dark_zurich.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/nyu.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/mapillary.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/voc.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/loveda.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/basesegdataset.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isaid.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/ade.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/synapse.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dsdl.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/cityscapes.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isprs.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/bdd100k.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hrf.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/coco_stuff.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/__init__.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/potsdam.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/levir.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/chase_db1.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/pascal_context.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hsi_drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/stare.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dataset_wrappers.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/night_driving.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/lip.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/decathlon.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/refuge.py -> build/lib/mmseg/datasets\r\n",
      "creating build/lib/mmseg/models\r\n",
      "copying mmseg/models/data_preprocessor.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/__init__.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/builder.py -> build/lib/mmseg/models\r\n",
      "creating build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/__init__.py -> build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/registry.py -> build/lib/mmseg/registry\r\n",
      "creating build/lib/mmseg/evaluation\r\n",
      "copying mmseg/evaluation/__init__.py -> build/lib/mmseg/evaluation\r\n",
      "creating build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/__init__.py -> build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/seg_data_sample.py -> build/lib/mmseg/structures\r\n",
      "creating build/lib/mmseg/engine\r\n",
      "copying mmseg/engine/__init__.py -> build/lib/mmseg/engine\r\n",
      "creating build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/local_visualizer.py -> build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/__init__.py -> build/lib/mmseg/visualization\r\n",
      "creating build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/inference.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/mmseg_inferencer.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/__init__.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/utils.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/remote_sense_inferencer.py -> build/lib/mmseg/apis\r\n",
      "creating build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/class_names.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/typing_utils.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/misc.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/__init__.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/get_templates.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/io.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/set_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/mask_classification.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/collect_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/tokenizer.py -> build/lib/mmseg/utils\r\n",
      "creating build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/__init__.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/loading.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/transforms.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/formatting.py -> build/lib/mmseg/datasets/transforms\r\n",
      "creating build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/__init__.py -> build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/clip_text_encoder.py -> build/lib/mmseg/models/text_encoder\r\n",
      "creating build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/tversky_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/lovasz_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/silog_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/dice_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/accuracy.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/huasdorff_distance_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/__init__.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/utils.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/boundary_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/focal_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/kldiv_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/ohem_cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "creating build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/base.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/__init__.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/multimodal_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/depth_estimator.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/cascade_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/seg_tta.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "creating build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/hungarian_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/base_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/__init__.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/match_cost.py -> build/lib/mmseg/models/assigners\r\n",
      "creating build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/ic_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/fpn.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/multilevel_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/__init__.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/mla_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/featurepyramid.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/jpu.py -> build/lib/mmseg/models/necks\r\n",
      "creating build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/fast_scnn.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/ddrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnest.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnext.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/erfnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vpd.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v3.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/cgnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mscan.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/icnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/hrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/__init__.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/pidnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/swin.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/twins.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/unet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/stdc.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv1.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mae.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/beit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/timm_backbone.py -> build/lib/mmseg/models/backbones\r\n",
      "creating build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/wrappers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/ppm.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/self_attention_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/embed.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/se_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/san_layers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/__init__.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/encoding.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/make_divisible.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/point_sample.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/shape_convert.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/up_conv_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/inverted_residual.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/basic_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/res_layer.py -> build/lib/mmseg/models/utils\r\n",
      "creating build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/gc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ema_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segmenter_mask_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/da_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/san_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/maskformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dm_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_up_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/point_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dpt_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ann_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/stdc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/enc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/nl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/__init__.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/knet_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cascade_decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/isa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/lraspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/vpd_depth_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ddr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/pid_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dnl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ocr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/mask2former_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fpn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/uper_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/apc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ham_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_mla_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "creating build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/depth_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/__init__.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/citys_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/iou_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "creating build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/base_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/__init__.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/ohem_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/builder.py -> build/lib/mmseg/structures/sampler\r\n",
      "creating build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/visualization_hook.py -> build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/__init__.py -> build/lib/mmseg/engine/hooks\r\n",
      "creating build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/poly_ratio_scheduler.py -> build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/__init__.py -> build/lib/mmseg/engine/schedulers\r\n",
      "creating build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/__init__.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/force_default_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/layer_decay_optimizer_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "creating build/lib/tests/test_models\r\n",
      "copying tests/test_models/__init__.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_data_preprocessor.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_forward.py -> build/lib/tests/test_models\r\n",
      "creating build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dnl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_mla_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ema_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_nl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dpt_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_apc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_lraspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_gc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_uper_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_maskformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_fcn_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/__init__.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_cc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_aspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ocr_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/utils.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dm_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_mask2former_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_up_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ham_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_vpd_depth_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_san_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segmenter_mask_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_pidnet_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_isa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ann_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_decode_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "creating build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_embed.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/__init__.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_shape_convert.py -> build/lib/tests/test_models/test_utils\r\n",
      "creating build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vpd.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mobilenet_v3.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv1.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_unet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_twins.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mscan.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_beit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnest.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_erfnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_clip_text_encoder.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_hrnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_cgnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mae.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/__init__.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnext.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_stdc.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/utils.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_blocks.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv2.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_icnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_fast_scnn.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_timm_backbone.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_pidnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_swin.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "creating build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_mla_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/__init__.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_feature2pyramid.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_multilevel_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_jpu.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_ic_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_fpn.py -> build/lib/tests/test_models/test_necks\r\n",
      "creating build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_multimodal_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/__init__.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/utils.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_depth_estimator.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_cascade_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_seg_tta_model.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "running egg_info\r\n",
      "creating mmsegmentation.egg-info\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "warning: no files found matching 'mmseg/.mim/model-index.yml'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.yaml' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/tools'\r\n",
      "warning: no files found matching '*.sh' under directory 'mmseg/.mim/tools'\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "creating build/lib/mmseg/configs\r\n",
      "creating build/lib/mmseg/configs/_base_\r\n",
      "copying mmseg/configs/_base_/default_runtime.py -> build/lib/mmseg/configs/_base_\r\n",
      "creating build/lib/mmseg/configs/_base_/datasets\r\n",
      "copying mmseg/configs/_base_/datasets/loveda.py -> build/lib/mmseg/configs/_base_/datasets\r\n",
      "copying mmseg/configs/_base_/datasets/potsdam.py -> build/lib/mmseg/configs/_base_/datasets\r\n",
      "creating build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_160k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_20k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_240k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_25k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_320k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_40k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_80k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "creating build/lib/tests/data\r\n",
      "copying tests/data/biomedical.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.npy -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.pkl -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical_ann.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/color.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/dataset.json -> build/lib/tests/data\r\n",
      "copying tests/data/gray.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/seg.png -> build/lib/tests/data\r\n",
      "creating build/lib/tests/data/dsdl_seg\r\n",
      "copying tests/data/dsdl_seg/config.py -> build/lib/tests/data/dsdl_seg\r\n",
      "creating build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/class-dom.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/segmentation-def.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "creating build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train.yaml -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train_samples.json -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/0004a4c0-d4dff0ad.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00054602-3bf57337.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00067cfb-e535423e.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d06fefd-f7be05a6.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d128593-0ccfea4c.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d15b18b-1e0d6e3f.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d2f7975-e0c1c5a7.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d06fefd-f7be05a6.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_instanceIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelTrainIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png -> build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_dataset\r\n",
      "creating build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00000_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00001_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00002_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00003_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00004_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "creating build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00000_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00001_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00002_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00003_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00004_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "creating build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/train.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/val.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/annotations\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1111_577_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1112_569_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1113_557_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1111_577_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1112_569_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1113_557_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1024_1920_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1536_2432_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1024_1920.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1536_2432.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/train.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/val.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "copying tests/data/pseudo_lip_dataset/train_images/684_2150041.jpg -> build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/train_segmentations/684_2150041.png -> build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "copying tests/data/pseudo_lip_dataset/val_images/86_185913.jpg -> build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/val_segmentations/86_185913.png -> build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "copying tests/data/pseudo_mapillary_dataset/images/__CRyFzoDOXn6unQ6a3DnQ.jpg -> build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v1.2/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v2.0/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "copying tests/data/pseudo_nyu_dataset/annotations/bookstore_0001d_00001.png -> build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "copying tests/data/pseudo_nyu_dataset/images/bookstore_0001d_00001.jpg -> build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/ann_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/img_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/ann_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/img_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice000.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice001.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice000.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice001.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/ann_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/img_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "creating build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_rs_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/utils.py -> build/lib/tests/test_apis\r\n",
      "creating build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset_builder.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_formatting.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_loading.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_transform.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_tta.py -> build/lib/tests/test_datasets\r\n",
      "creating build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_layer_decay_optimizer_constructor.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_optimizer.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_visualization_hook.py -> build/lib/tests/test_engine\r\n",
      "creating build/lib/tests/test_evaluation\r\n",
      "creating build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_citys_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_depth_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_iou_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "creating build/lib/tests/test_structures\r\n",
      "copying tests/test_structures/test_seg_data_sample.py -> build/lib/tests/test_structures\r\n",
      "creating build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_io.py -> build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_set_env.py -> build/lib/tests/test_utils\r\n",
      "creating build/lib/tests/test_visualization\r\n",
      "copying tests/test_visualization/test_local_visualizer.py -> build/lib/tests/test_visualization\r\n",
      "copying mmseg/utils/bpe_simple_vocab_16e6.txt.gz -> build/lib/mmseg/utils\r\n",
      "creating build/lib/tests/test_models/test_assigners\r\n",
      "copying tests/test_models/test_assigners/test_hungarian_assigner.py -> build/lib/tests/test_models/test_assigners\r\n",
      "creating build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_cross_entropy_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_dice_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_huasdorff_distance_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_kldiv_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_silog_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_tversky_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "Processing /kaggle/working/mmsegmentation\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (21.3)\r\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.9.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.11.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (2.8.2)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->mmsegmentation==1.2.2) (0.2.13)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.2.2) (1.16.0)\r\n",
      "Building wheels for collected packages: mmsegmentation\r\n",
      "  Building wheel for mmsegmentation (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmsegmentation: filename=mmsegmentation-1.2.2-py3-none-any.whl size=31509878 sha256=a2ef5d5a4fc9be70ba33e672280aa97d5ffd389190f7813168b23441f1b17794\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zhwe8ayp/wheels/43/47/68/4f234c90f5372e6bde61cb1d00ac67ba84723d1e9801de501d\r\n",
      "Successfully built mmsegmentation\r\n",
      "Installing collected packages: mmsegmentation\r\n",
      "Successfully installed mmsegmentation-1.2.2\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r mmsegmentation\n",
    "#!git clone https://github.com/alirafiqmalik/mmsegmentation.git \n",
    "!git clone -b main https://github.com/open-mmlab/mmsegmentation.git \n",
    "%cd mmsegmentation\n",
    "# !pip install -v -e .\n",
    "!python setup.py build\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff2f909",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:17.384892Z",
     "iopub.status.busy": "2024-03-09T19:54:17.384476Z",
     "iopub.status.idle": "2024-03-09T19:54:18.277552Z",
     "shell.execute_reply": "2024-03-09T19:54:18.276488Z"
    },
    "papermill": {
     "duration": 0.963201,
     "end_time": "2024-03-09T19:54:18.279856",
     "exception": false,
     "start_time": "2024-03-09T19:54:17.316655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8e9557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:18.409961Z",
     "iopub.status.busy": "2024-03-09T19:54:18.409608Z",
     "iopub.status.idle": "2024-03-09T19:54:18.415776Z",
     "shell.execute_reply": "2024-03-09T19:54:18.414524Z"
    },
    "papermill": {
     "duration": 0.074038,
     "end_time": "2024-03-09T19:54:18.417939",
     "exception": false,
     "start_time": "2024-03-09T19:54:18.343901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2 2.1.0 0.10.3\n"
     ]
    }
   ],
   "source": [
    "# Check MMSegmentation installation\n",
    "import mmseg,mmcv,mmengine\n",
    "print(mmseg.__version__,mmcv.__version__,mmengine.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee88b172",
   "metadata": {
    "papermill": {
     "duration": 0.067787,
     "end_time": "2024-03-09T19:54:18.552216",
     "exception": false,
     "start_time": "2024-03-09T19:54:18.484429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **DATASET LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c7bcf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:18.688230Z",
     "iopub.status.busy": "2024-03-09T19:54:18.687824Z",
     "iopub.status.idle": "2024-03-09T19:54:18.692451Z",
     "shell.execute_reply": "2024-03-09T19:54:18.691571Z"
    },
    "papermill": {
     "duration": 0.074786,
     "end_time": "2024-03-09T19:54:18.694584",
     "exception": false,
     "start_time": "2024-03-09T19:54:18.619798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import mmengine\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2273b5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:18.827154Z",
     "iopub.status.busy": "2024-03-09T19:54:18.826753Z",
     "iopub.status.idle": "2024-03-09T19:54:18.832835Z",
     "shell.execute_reply": "2024-03-09T19:54:18.831959Z"
    },
    "papermill": {
     "duration": 0.073863,
     "end_time": "2024-03-09T19:54:18.835223",
     "exception": false,
     "start_time": "2024-03-09T19:54:18.761360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db4116e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:18.966701Z",
     "iopub.status.busy": "2024-03-09T19:54:18.966287Z",
     "iopub.status.idle": "2024-03-09T19:54:18.970920Z",
     "shell.execute_reply": "2024-03-09T19:54:18.970052Z"
    },
    "papermill": {
     "duration": 0.073142,
     "end_time": "2024-03-09T19:54:18.972970",
     "exception": false,
     "start_time": "2024-03-09T19:54:18.899828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset root and directory for images and annotations\n",
    "data_root = '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fbb6b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:19.109509Z",
     "iopub.status.busy": "2024-03-09T19:54:19.109157Z",
     "iopub.status.idle": "2024-03-09T19:54:19.478714Z",
     "shell.execute_reply": "2024-03-09T19:54:19.477112Z"
    },
    "papermill": {
     "duration": 0.440174,
     "end_time": "2024-03-09T19:54:19.481166",
     "exception": false,
     "start_time": "2024-03-09T19:54:19.040992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes 10\n",
      "0         Background\n",
      "1    BuildingFlooded\n",
      "2        BNonFlooded\n",
      "3        RoadFlooded\n",
      "4        RNonFlooded\n",
      "5              Water\n",
      "6               Tree\n",
      "7             Vecile\n",
      "8               Pool\n",
      "9              Grass\n",
      "Name: name, dtype: object\n",
      "[[  0   0   0]\n",
      " [255   0   0]\n",
      " [181  72  72]\n",
      " [150 150   0]\n",
      " [135 135 135]\n",
      " [  0 224 224]\n",
      " [  0   0 225]\n",
      " [204   0 204]\n",
      " [237 237   0]\n",
      " [  0 225   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# define class and palette for better visualization\n",
    "df=pd.read_csv('/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/Now_class_dict_seg_10clss.csv')\n",
    "classes = df['name']\n",
    "palette = df[[' r', ' g', ' b']].values\n",
    "id2label = classes.to_dict()\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(\"classes\", len(id2label))\n",
    "print(classes)\n",
    "print(palette)\n",
    "classes=list(classes)\n",
    "palette=list(palette)\n",
    "num_classes=len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ea6eb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:19.626863Z",
     "iopub.status.busy": "2024-03-09T19:54:19.625947Z",
     "iopub.status.idle": "2024-03-09T19:54:21.764274Z",
     "shell.execute_reply": "2024-03-09T19:54:21.763110Z"
    },
    "papermill": {
     "duration": 2.210932,
     "end_time": "2024-03-09T19:54:21.766867",
     "exception": false,
     "start_time": "2024-03-09T19:54:19.555935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = Image.open('/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/annotations/training/10166_lab.png')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(8)]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "567d6658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:21.901791Z",
     "iopub.status.busy": "2024-03-09T19:54:21.901379Z",
     "iopub.status.idle": "2024-03-09T19:54:21.907999Z",
     "shell.execute_reply": "2024-03-09T19:54:21.907061Z"
    },
    "papermill": {
     "duration": 0.075862,
     "end_time": "2024-03-09T19:54:21.910117",
     "exception": false,
     "start_time": "2024-03-09T19:54:21.834255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Background',\n",
       " 'BuildingFlooded',\n",
       " 'BNonFlooded',\n",
       " 'RoadFlooded',\n",
       " 'RNonFlooded',\n",
       " 'Water',\n",
       " 'Tree',\n",
       " 'Vecile',\n",
       " 'Pool',\n",
       " 'Grass']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09f606b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:22.050706Z",
     "iopub.status.busy": "2024-03-09T19:54:22.049918Z",
     "iopub.status.idle": "2024-03-09T19:54:22.057616Z",
     "shell.execute_reply": "2024-03-09T19:54:22.056463Z"
    },
    "papermill": {
     "duration": 0.082813,
     "end_time": "2024-03-09T19:54:22.059920",
     "exception": false,
     "start_time": "2024-03-09T19:54:21.977107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0]),\n",
       " array([255,   0,   0]),\n",
       " array([181,  72,  72]),\n",
       " array([150, 150,   0]),\n",
       " array([135, 135, 135]),\n",
       " array([  0, 224, 224]),\n",
       " array([  0,   0, 225]),\n",
       " array([204,   0, 204]),\n",
       " array([237, 237,   0]),\n",
       " array([  0, 225,   0])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e94ae42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:22.207557Z",
     "iopub.status.busy": "2024-03-09T19:54:22.207155Z",
     "iopub.status.idle": "2024-03-09T19:54:36.382070Z",
     "shell.execute_reply": "2024-03-09T19:54:36.380964Z"
    },
    "papermill": {
     "duration": 14.251794,
     "end_time": "2024-03-09T19:54:36.384698",
     "exception": false,
     "start_time": "2024-03-09T19:54:22.132904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\r\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.13)\r\n",
      "Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ftfy\r\n",
      "Successfully installed ftfy-6.1.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b34009e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:36.526322Z",
     "iopub.status.busy": "2024-03-09T19:54:36.525299Z",
     "iopub.status.idle": "2024-03-09T19:54:40.483815Z",
     "shell.execute_reply": "2024-03-09T19:54:40.482814Z"
    },
    "papermill": {
     "duration": 4.036635,
     "end_time": "2024-03-09T19:54:40.486284",
     "exception": false,
     "start_time": "2024-03-09T19:54:36.449649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmseg.registry import DATASETS\n",
    "from mmseg.datasets import BaseSegDataset\n",
    "\n",
    "## should be run only once\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ImageSegmentationDataset(BaseSegDataset):\n",
    "    METAINFO = dict(classes = classes, palette = palette)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(img_suffix='.jpg', seg_map_suffix=\"_lab.png\", **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d760b34f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:40.629408Z",
     "iopub.status.busy": "2024-03-09T19:54:40.628727Z",
     "iopub.status.idle": "2024-03-09T19:54:40.636061Z",
     "shell.execute_reply": "2024-03-09T19:54:40.634851Z"
    },
    "papermill": {
     "duration": 0.081859,
     "end_time": "2024-03-09T19:54:40.638125",
     "exception": false,
     "start_time": "2024-03-09T19:54:40.556266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f32751",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:40.776300Z",
     "iopub.status.busy": "2024-03-09T19:54:40.775363Z",
     "iopub.status.idle": "2024-03-09T19:54:42.888791Z",
     "shell.execute_reply": "2024-03-09T19:54:42.887341Z"
    },
    "papermill": {
     "duration": 2.184808,
     "end_time": "2024-03-09T19:54:42.891622",
     "exception": false,
     "start_time": "2024-03-09T19:54:40.706814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'checkpoint': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r checkpoint\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae1835",
   "metadata": {
    "papermill": {
     "duration": 0.067549,
     "end_time": "2024-03-09T19:54:43.029361",
     "exception": false,
     "start_time": "2024-03-09T19:54:42.961812",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f330aa23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:43.166972Z",
     "iopub.status.busy": "2024-03-09T19:54:43.165936Z",
     "iopub.status.idle": "2024-03-09T19:54:43.859317Z",
     "shell.execute_reply": "2024-03-09T19:54:43.858309Z"
    },
    "papermill": {
     "duration": 0.768949,
     "end_time": "2024-03-09T19:54:43.864376",
     "exception": false,
     "start_time": "2024-03-09T19:54:43.095427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/ade/ADEChallengeData2016'\n",
      "dataset_type = 'ADE20KDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=150,\n",
      "        type='SegformerHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from mmengine import Config\n",
    "cfg = Config.fromfile('/kaggle/working/mmsegmentation/configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-512x512.py')\n",
    "#cfg = Config.fromfile('/kaggle/working/mmsegmentation/configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-640x640.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f467fb1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:44.004675Z",
     "iopub.status.busy": "2024-03-09T19:54:44.004259Z",
     "iopub.status.idle": "2024-03-09T19:54:44.011150Z",
     "shell.execute_reply": "2024-03-09T19:54:44.010019Z"
    },
    "papermill": {
     "duration": 0.078263,
     "end_time": "2024-03-09T19:54:44.013283",
     "exception": false,
     "start_time": "2024-03-09T19:54:43.935020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.decode_head.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e4fb50e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:44.152673Z",
     "iopub.status.busy": "2024-03-09T19:54:44.151803Z",
     "iopub.status.idle": "2024-03-09T19:54:44.157124Z",
     "shell.execute_reply": "2024-03-09T19:54:44.156204Z"
    },
    "papermill": {
     "duration": 0.077272,
     "end_time": "2024-03-09T19:54:44.159167",
     "exception": false,
     "start_time": "2024-03-09T19:54:44.081895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.model.pretrained None\n"
     ]
    }
   ],
   "source": [
    "#cfg.model.pretrained = True\n",
    "print(\"cfg.model.pretrained\", cfg.model.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edfd6dbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:44.294440Z",
     "iopub.status.busy": "2024-03-09T19:54:44.294090Z",
     "iopub.status.idle": "2024-03-09T19:54:44.311056Z",
     "shell.execute_reply": "2024-03-09T19:54:44.310024Z"
    },
    "papermill": {
     "duration": 0.086678,
     "end_time": "2024-03-09T19:54:44.312944",
     "exception": false,
     "start_time": "2024-03-09T19:54:44.226266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 10\n",
    "#cfg.model.auxiliary_head.num_classes = 10\n",
    "\n",
    "\n",
    "#cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_640x640_160k_ade20k/segformer_mit-b5_640x640_160k_ade20k_20210801_121243-41d2845b.pth'\n",
    "#cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth'\n",
    "cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'\n",
    "\n",
    "cfg.val_evaluator = dict(type='IoUMetric',\n",
    "                         iou_metrics=['mIoU', 'mDice', 'mFscore'],\n",
    "#                          format_only=True,\n",
    "#                          output_dir='/kaggle/working/results'\n",
    "                        )\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# # Modify dataset type and path\n",
    "cfg.dataset_type = 'ImageSegmentationDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "\n",
    "cfg.train_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.val_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.test_dataloader.dataset.type=cfg.dataset_type\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(\n",
    "        type='RandomResize',\n",
    "        scale=(\n",
    "            512,\n",
    "            512,\n",
    "        ),\n",
    "        ratio_range=(\n",
    "            0.5,\n",
    "            2.0,\n",
    "        ),\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomCrop', crop_size=(\n",
    "        512,\n",
    "        512,\n",
    "    ), cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='PackSegInputs'),\n",
    "]\n",
    "\n",
    "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
    "\n",
    "cfg.test_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "cfg.train_dataloader.dataset.data_root =data_root \n",
    "cfg.val_dataloader.dataset.data_root =data_root \n",
    "cfg.test_dataloader.dataset.data_root=data_root\n",
    "\n",
    "cfg.train_dataloader.num_workers=1\n",
    "cfg.train_dataloader.batch_size = 2\n",
    "cfg.train_dataloader.persistent_workers=False\n",
    "\n",
    "\n",
    "cfg.val_dataloader.batch_size = 1\n",
    "cfg.val_dataloader.num_workers=1\n",
    "cfg.val_dataloader.persistent_workers=False\n",
    "\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.test_dataloader.num_workers=1\n",
    "cfg.test_dataloader.persistent_workers=False\n",
    "\n",
    "#cfg.work_dir = './checkpoint'\n",
    "cfg.work_dir = '/kaggle/working/checkpoint'\n",
    "\n",
    "cfg.train_cfg.max_iters = 40000\n",
    "cfg.train_cfg.val_interval = 50000\n",
    "cfg.default_hooks.logger.interval =100\n",
    "cfg.default_hooks.checkpoint.interval = 0\n",
    "cfg.default_hooks.checkpoint.save_best='mIoU'\n",
    "\n",
    "# Set seed to facilitate reproducing the result\n",
    "cfg['randomness'] = dict(seed=0)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "#print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa7eee74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:44.449214Z",
     "iopub.status.busy": "2024-03-09T19:54:44.448805Z",
     "iopub.status.idle": "2024-03-09T19:54:44.458199Z",
     "shell.execute_reply": "2024-03-09T19:54:44.457101Z"
    },
    "papermill": {
     "duration": 0.081631,
     "end_time": "2024-03-09T19:54:44.460578",
     "exception": false,
     "start_time": "2024-03-09T19:54:44.378947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'EncoderDecoder',\n",
       " 'data_preprocessor': {'type': 'SegDataPreProcessor',\n",
       "  'mean': [123.675, 116.28, 103.53],\n",
       "  'std': [58.395, 57.12, 57.375],\n",
       "  'bgr_to_rgb': True,\n",
       "  'pad_val': 0,\n",
       "  'seg_pad_val': 255,\n",
       "  'size': (512, 512)},\n",
       " 'pretrained': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth',\n",
       " 'backbone': {'type': 'MixVisionTransformer',\n",
       "  'in_channels': 3,\n",
       "  'embed_dims': 64,\n",
       "  'num_stages': 4,\n",
       "  'num_layers': [3, 6, 40, 3],\n",
       "  'num_heads': [1, 2, 5, 8],\n",
       "  'patch_sizes': [7, 3, 3, 3],\n",
       "  'sr_ratios': [8, 4, 2, 1],\n",
       "  'out_indices': (0, 1, 2, 3),\n",
       "  'mlp_ratio': 4,\n",
       "  'qkv_bias': True,\n",
       "  'drop_rate': 0.0,\n",
       "  'attn_drop_rate': 0.0,\n",
       "  'drop_path_rate': 0.1,\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}},\n",
       " 'decode_head': {'type': 'SegformerHead',\n",
       "  'in_channels': [64, 128, 320, 512],\n",
       "  'in_index': [0, 1, 2, 3],\n",
       "  'channels': 256,\n",
       "  'dropout_ratio': 0.1,\n",
       "  'num_classes': 10,\n",
       "  'norm_cfg': {'type': 'SyncBN', 'requires_grad': True},\n",
       "  'align_corners': False,\n",
       "  'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "   'use_sigmoid': False,\n",
       "   'loss_weight': 1.0}},\n",
       " 'train_cfg': {},\n",
       " 'test_cfg': {'mode': 'whole'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73586c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:44.602753Z",
     "iopub.status.busy": "2024-03-09T19:54:44.601699Z",
     "iopub.status.idle": "2024-03-09T19:54:44.609366Z",
     "shell.execute_reply": "2024-03-09T19:54:44.608297Z"
    },
    "papermill": {
     "duration": 0.081785,
     "end_time": "2024-03-09T19:54:44.611563",
     "exception": false,
     "start_time": "2024-03-09T19:54:44.529778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncfg.model.decode_head=dict(\\n    type='UPerHead',\\n    in_channels=[64, 128, 320, 512],\\n    in_index=[0, 1, 2, 3],\\n    channels=256,\\n    dropout_ratio=0.1,\\n    num_classes=10,\\n    norm_cfg=cfg.norm_cfg,\\n    align_corners=False,\\n    loss_decode=dict(\\n        type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\\n    init_cfg=dict(\\n        type='Pretrained',\\n        checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth'\\n    ))\\ncfg.model.auxiliary_head=None\\n\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding Vit decoder\n",
    "\"\"\"\n",
    "cfg.model.decode_head=dict(\n",
    "    type='UPerHead',\n",
    "    in_channels=[64, 128, 320, 512],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=256,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=10,\n",
    "    norm_cfg=cfg.norm_cfg,\n",
    "    align_corners=False,\n",
    "    loss_decode=dict(\n",
    "        type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "    init_cfg=dict(\n",
    "        type='Pretrained',\n",
    "        checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth'\n",
    "    ))\n",
    "cfg.model.auxiliary_head=None\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "908ecc49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:44.753790Z",
     "iopub.status.busy": "2024-03-09T19:54:44.752846Z",
     "iopub.status.idle": "2024-03-09T19:54:44.759919Z",
     "shell.execute_reply": "2024-03-09T19:54:44.758968Z"
    },
    "papermill": {
     "duration": 0.080091,
     "end_time": "2024-03-09T19:54:44.762005",
     "exception": false,
     "start_time": "2024-03-09T19:54:44.681914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SwinT decoder adding\n",
    "\n",
    "\n",
    "cfg.model.decode_head=dict(\n",
    "    type='UPerHead',\n",
    "    in_channels=[64, 128, 320, 512],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=256,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=10,\n",
    "    norm_cfg=cfg.norm_cfg,\n",
    "    align_corners=False,\n",
    "    loss_decode=dict(\n",
    "        type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "    init_cfg=dict(\n",
    "        type='Pretrained',\n",
    "        checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth'\n",
    "    ))\n",
    "cfg.model.auxiliary_head=None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3387e4ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:44.897883Z",
     "iopub.status.busy": "2024-03-09T19:54:44.897466Z",
     "iopub.status.idle": "2024-03-09T19:54:44.903366Z",
     "shell.execute_reply": "2024-03-09T19:54:44.902201Z"
    },
    "papermill": {
     "duration": 0.07576,
     "end_time": "2024-03-09T19:54:44.905646",
     "exception": false,
     "start_time": "2024-03-09T19:54:44.829886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    }
   ],
   "source": [
    "print(cfg.model.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c803041e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:45.046413Z",
     "iopub.status.busy": "2024-03-09T19:54:45.046000Z",
     "iopub.status.idle": "2024-03-09T19:54:46.438884Z",
     "shell.execute_reply": "2024-03-09T19:54:46.438029Z"
    },
    "papermill": {
     "duration": 1.464785,
     "end_time": "2024-03-09T19:54:46.441411",
     "exception": false,
     "start_time": "2024-03-09T19:54:44.976626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.dump('/kaggle/working/my_config_file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee32c133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:46.582621Z",
     "iopub.status.busy": "2024-03-09T19:54:46.582220Z",
     "iopub.status.idle": "2024-03-09T19:54:46.592411Z",
     "shell.execute_reply": "2024-03-09T19:54:46.591463Z"
    },
    "papermill": {
     "duration": 0.084833,
     "end_time": "2024-03-09T19:54:46.594645",
     "exception": false,
     "start_time": "2024-03-09T19:54:46.509812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'EncoderDecoder',\n",
       " 'data_preprocessor': {'type': 'SegDataPreProcessor',\n",
       "  'mean': [123.675, 116.28, 103.53],\n",
       "  'std': [58.395, 57.12, 57.375],\n",
       "  'bgr_to_rgb': True,\n",
       "  'pad_val': 0,\n",
       "  'seg_pad_val': 255,\n",
       "  'size': (512, 512)},\n",
       " 'pretrained': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth',\n",
       " 'backbone': {'type': 'MixVisionTransformer',\n",
       "  'in_channels': 3,\n",
       "  'embed_dims': 64,\n",
       "  'num_stages': 4,\n",
       "  'num_layers': [3, 6, 40, 3],\n",
       "  'num_heads': [1, 2, 5, 8],\n",
       "  'patch_sizes': [7, 3, 3, 3],\n",
       "  'sr_ratios': [8, 4, 2, 1],\n",
       "  'out_indices': (0, 1, 2, 3),\n",
       "  'mlp_ratio': 4,\n",
       "  'qkv_bias': True,\n",
       "  'drop_rate': 0.0,\n",
       "  'attn_drop_rate': 0.0,\n",
       "  'drop_path_rate': 0.1,\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}},\n",
       " 'decode_head': {'type': 'UPerHead',\n",
       "  'in_channels': [64, 128, 320, 512],\n",
       "  'in_index': [0, 1, 2, 3],\n",
       "  'channels': 256,\n",
       "  'dropout_ratio': 0.1,\n",
       "  'num_classes': 10,\n",
       "  'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       "  'align_corners': False,\n",
       "  'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "   'use_sigmoid': False,\n",
       "   'loss_weight': 1.0},\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth'}},\n",
       " 'train_cfg': {},\n",
       " 'test_cfg': {'mode': 'whole'},\n",
       " 'auxiliary_head': None}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a0bf634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:46.744003Z",
     "iopub.status.busy": "2024-03-09T19:54:46.743602Z",
     "iopub.status.idle": "2024-03-09T19:54:46.750368Z",
     "shell.execute_reply": "2024-03-09T19:54:46.749456Z"
    },
    "papermill": {
     "duration": 0.084311,
     "end_time": "2024-03-09T19:54:46.752473",
     "exception": false,
     "start_time": "2024-03-09T19:54:46.668162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Pretrained',\n",
       " 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model['backbone'].pop('init_cfg', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e80b0cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:46.894474Z",
     "iopub.status.busy": "2024-03-09T19:54:46.893789Z",
     "iopub.status.idle": "2024-03-09T19:54:57.270598Z",
     "shell.execute_reply": "2024-03-09T19:54:57.269729Z"
    },
    "papermill": {
     "duration": 10.450642,
     "end_time": "2024-03-09T19:54:57.273167",
     "exception": false,
     "start_time": "2024-03-09T19:54:46.822525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 19:54:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0: Tesla P100-PCIE-16GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.0+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.0+cu102\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/09 19:54:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
      "dataset_type = 'ImageSegmentationDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False, interval=0, save_best='mIoU', type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=None,\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth',\n",
      "            type='Pretrained'),\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=10,\n",
      "        type='UPerHead'),\n",
      "    pretrained=\n",
      "    'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=40000, type='IterBasedTrainLoop', val_interval=50000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root=\n",
      "        '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/kaggle/working/checkpoint'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/backbones/mit.py:365: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 19:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/09 19:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d98dcf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:54:57.412235Z",
     "iopub.status.busy": "2024-03-09T19:54:57.411314Z",
     "iopub.status.idle": "2024-03-10T04:44:32.283904Z",
     "shell.execute_reply": "2024-03-10T04:44:32.282864Z"
    },
    "papermill": {
     "duration": 31774.945841,
     "end_time": "2024-03-10T04:44:32.288019",
     "exception": false,
     "start_time": "2024-03-09T19:54:57.342178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/datasets/transforms/loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:lr=6e-05\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.bias:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.conv.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.conv.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.conv.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.weight:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.weight:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.weight:lr_mult=10.0\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.bias:lr=0.0006000000000000001\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.bias:weight_decay=0.01\n",
      "03/09 19:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.bias:lr_mult=10.0\n",
      "03/09 19:55:01 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "03/09 19:55:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n",
      "03/09 19:55:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\" to /root/.cache/torch/hub/checkpoints/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 19:55:14 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.layers.0.0.projection.weight, backbone.layers.0.0.projection.bias, backbone.layers.0.0.norm.weight, backbone.layers.0.0.norm.bias, backbone.layers.0.1.0.norm1.weight, backbone.layers.0.1.0.norm1.bias, backbone.layers.0.1.0.attn.attn.in_proj_weight, backbone.layers.0.1.0.attn.attn.in_proj_bias, backbone.layers.0.1.0.attn.attn.out_proj.weight, backbone.layers.0.1.0.attn.attn.out_proj.bias, backbone.layers.0.1.0.attn.sr.weight, backbone.layers.0.1.0.attn.sr.bias, backbone.layers.0.1.0.attn.norm.weight, backbone.layers.0.1.0.attn.norm.bias, backbone.layers.0.1.0.norm2.weight, backbone.layers.0.1.0.norm2.bias, backbone.layers.0.1.0.ffn.layers.0.weight, backbone.layers.0.1.0.ffn.layers.0.bias, backbone.layers.0.1.0.ffn.layers.1.weight, backbone.layers.0.1.0.ffn.layers.1.bias, backbone.layers.0.1.0.ffn.layers.4.weight, backbone.layers.0.1.0.ffn.layers.4.bias, backbone.layers.0.1.1.norm1.weight, backbone.layers.0.1.1.norm1.bias, backbone.layers.0.1.1.attn.attn.in_proj_weight, backbone.layers.0.1.1.attn.attn.in_proj_bias, backbone.layers.0.1.1.attn.attn.out_proj.weight, backbone.layers.0.1.1.attn.attn.out_proj.bias, backbone.layers.0.1.1.attn.sr.weight, backbone.layers.0.1.1.attn.sr.bias, backbone.layers.0.1.1.attn.norm.weight, backbone.layers.0.1.1.attn.norm.bias, backbone.layers.0.1.1.norm2.weight, backbone.layers.0.1.1.norm2.bias, backbone.layers.0.1.1.ffn.layers.0.weight, backbone.layers.0.1.1.ffn.layers.0.bias, backbone.layers.0.1.1.ffn.layers.1.weight, backbone.layers.0.1.1.ffn.layers.1.bias, backbone.layers.0.1.1.ffn.layers.4.weight, backbone.layers.0.1.1.ffn.layers.4.bias, backbone.layers.0.1.2.norm1.weight, backbone.layers.0.1.2.norm1.bias, backbone.layers.0.1.2.attn.attn.in_proj_weight, backbone.layers.0.1.2.attn.attn.in_proj_bias, backbone.layers.0.1.2.attn.attn.out_proj.weight, backbone.layers.0.1.2.attn.attn.out_proj.bias, backbone.layers.0.1.2.attn.sr.weight, backbone.layers.0.1.2.attn.sr.bias, backbone.layers.0.1.2.attn.norm.weight, backbone.layers.0.1.2.attn.norm.bias, backbone.layers.0.1.2.norm2.weight, backbone.layers.0.1.2.norm2.bias, backbone.layers.0.1.2.ffn.layers.0.weight, backbone.layers.0.1.2.ffn.layers.0.bias, backbone.layers.0.1.2.ffn.layers.1.weight, backbone.layers.0.1.2.ffn.layers.1.bias, backbone.layers.0.1.2.ffn.layers.4.weight, backbone.layers.0.1.2.ffn.layers.4.bias, backbone.layers.0.2.weight, backbone.layers.0.2.bias, backbone.layers.1.0.projection.weight, backbone.layers.1.0.projection.bias, backbone.layers.1.0.norm.weight, backbone.layers.1.0.norm.bias, backbone.layers.1.1.0.norm1.weight, backbone.layers.1.1.0.norm1.bias, backbone.layers.1.1.0.attn.attn.in_proj_weight, backbone.layers.1.1.0.attn.attn.in_proj_bias, backbone.layers.1.1.0.attn.attn.out_proj.weight, backbone.layers.1.1.0.attn.attn.out_proj.bias, backbone.layers.1.1.0.attn.sr.weight, backbone.layers.1.1.0.attn.sr.bias, backbone.layers.1.1.0.attn.norm.weight, backbone.layers.1.1.0.attn.norm.bias, backbone.layers.1.1.0.norm2.weight, backbone.layers.1.1.0.norm2.bias, backbone.layers.1.1.0.ffn.layers.0.weight, backbone.layers.1.1.0.ffn.layers.0.bias, backbone.layers.1.1.0.ffn.layers.1.weight, backbone.layers.1.1.0.ffn.layers.1.bias, backbone.layers.1.1.0.ffn.layers.4.weight, backbone.layers.1.1.0.ffn.layers.4.bias, backbone.layers.1.1.1.norm1.weight, backbone.layers.1.1.1.norm1.bias, backbone.layers.1.1.1.attn.attn.in_proj_weight, backbone.layers.1.1.1.attn.attn.in_proj_bias, backbone.layers.1.1.1.attn.attn.out_proj.weight, backbone.layers.1.1.1.attn.attn.out_proj.bias, backbone.layers.1.1.1.attn.sr.weight, backbone.layers.1.1.1.attn.sr.bias, backbone.layers.1.1.1.attn.norm.weight, backbone.layers.1.1.1.attn.norm.bias, backbone.layers.1.1.1.norm2.weight, backbone.layers.1.1.1.norm2.bias, backbone.layers.1.1.1.ffn.layers.0.weight, backbone.layers.1.1.1.ffn.layers.0.bias, backbone.layers.1.1.1.ffn.layers.1.weight, backbone.layers.1.1.1.ffn.layers.1.bias, backbone.layers.1.1.1.ffn.layers.4.weight, backbone.layers.1.1.1.ffn.layers.4.bias, backbone.layers.1.1.2.norm1.weight, backbone.layers.1.1.2.norm1.bias, backbone.layers.1.1.2.attn.attn.in_proj_weight, backbone.layers.1.1.2.attn.attn.in_proj_bias, backbone.layers.1.1.2.attn.attn.out_proj.weight, backbone.layers.1.1.2.attn.attn.out_proj.bias, backbone.layers.1.1.2.attn.sr.weight, backbone.layers.1.1.2.attn.sr.bias, backbone.layers.1.1.2.attn.norm.weight, backbone.layers.1.1.2.attn.norm.bias, backbone.layers.1.1.2.norm2.weight, backbone.layers.1.1.2.norm2.bias, backbone.layers.1.1.2.ffn.layers.0.weight, backbone.layers.1.1.2.ffn.layers.0.bias, backbone.layers.1.1.2.ffn.layers.1.weight, backbone.layers.1.1.2.ffn.layers.1.bias, backbone.layers.1.1.2.ffn.layers.4.weight, backbone.layers.1.1.2.ffn.layers.4.bias, backbone.layers.1.1.3.norm1.weight, backbone.layers.1.1.3.norm1.bias, backbone.layers.1.1.3.attn.attn.in_proj_weight, backbone.layers.1.1.3.attn.attn.in_proj_bias, backbone.layers.1.1.3.attn.attn.out_proj.weight, backbone.layers.1.1.3.attn.attn.out_proj.bias, backbone.layers.1.1.3.attn.sr.weight, backbone.layers.1.1.3.attn.sr.bias, backbone.layers.1.1.3.attn.norm.weight, backbone.layers.1.1.3.attn.norm.bias, backbone.layers.1.1.3.norm2.weight, backbone.layers.1.1.3.norm2.bias, backbone.layers.1.1.3.ffn.layers.0.weight, backbone.layers.1.1.3.ffn.layers.0.bias, backbone.layers.1.1.3.ffn.layers.1.weight, backbone.layers.1.1.3.ffn.layers.1.bias, backbone.layers.1.1.3.ffn.layers.4.weight, backbone.layers.1.1.3.ffn.layers.4.bias, backbone.layers.1.1.4.norm1.weight, backbone.layers.1.1.4.norm1.bias, backbone.layers.1.1.4.attn.attn.in_proj_weight, backbone.layers.1.1.4.attn.attn.in_proj_bias, backbone.layers.1.1.4.attn.attn.out_proj.weight, backbone.layers.1.1.4.attn.attn.out_proj.bias, backbone.layers.1.1.4.attn.sr.weight, backbone.layers.1.1.4.attn.sr.bias, backbone.layers.1.1.4.attn.norm.weight, backbone.layers.1.1.4.attn.norm.bias, backbone.layers.1.1.4.norm2.weight, backbone.layers.1.1.4.norm2.bias, backbone.layers.1.1.4.ffn.layers.0.weight, backbone.layers.1.1.4.ffn.layers.0.bias, backbone.layers.1.1.4.ffn.layers.1.weight, backbone.layers.1.1.4.ffn.layers.1.bias, backbone.layers.1.1.4.ffn.layers.4.weight, backbone.layers.1.1.4.ffn.layers.4.bias, backbone.layers.1.1.5.norm1.weight, backbone.layers.1.1.5.norm1.bias, backbone.layers.1.1.5.attn.attn.in_proj_weight, backbone.layers.1.1.5.attn.attn.in_proj_bias, backbone.layers.1.1.5.attn.attn.out_proj.weight, backbone.layers.1.1.5.attn.attn.out_proj.bias, backbone.layers.1.1.5.attn.sr.weight, backbone.layers.1.1.5.attn.sr.bias, backbone.layers.1.1.5.attn.norm.weight, backbone.layers.1.1.5.attn.norm.bias, backbone.layers.1.1.5.norm2.weight, backbone.layers.1.1.5.norm2.bias, backbone.layers.1.1.5.ffn.layers.0.weight, backbone.layers.1.1.5.ffn.layers.0.bias, backbone.layers.1.1.5.ffn.layers.1.weight, backbone.layers.1.1.5.ffn.layers.1.bias, backbone.layers.1.1.5.ffn.layers.4.weight, backbone.layers.1.1.5.ffn.layers.4.bias, backbone.layers.1.2.weight, backbone.layers.1.2.bias, backbone.layers.2.0.projection.weight, backbone.layers.2.0.projection.bias, backbone.layers.2.0.norm.weight, backbone.layers.2.0.norm.bias, backbone.layers.2.1.0.norm1.weight, backbone.layers.2.1.0.norm1.bias, backbone.layers.2.1.0.attn.attn.in_proj_weight, backbone.layers.2.1.0.attn.attn.in_proj_bias, backbone.layers.2.1.0.attn.attn.out_proj.weight, backbone.layers.2.1.0.attn.attn.out_proj.bias, backbone.layers.2.1.0.attn.sr.weight, backbone.layers.2.1.0.attn.sr.bias, backbone.layers.2.1.0.attn.norm.weight, backbone.layers.2.1.0.attn.norm.bias, backbone.layers.2.1.0.norm2.weight, backbone.layers.2.1.0.norm2.bias, backbone.layers.2.1.0.ffn.layers.0.weight, backbone.layers.2.1.0.ffn.layers.0.bias, backbone.layers.2.1.0.ffn.layers.1.weight, backbone.layers.2.1.0.ffn.layers.1.bias, backbone.layers.2.1.0.ffn.layers.4.weight, backbone.layers.2.1.0.ffn.layers.4.bias, backbone.layers.2.1.1.norm1.weight, backbone.layers.2.1.1.norm1.bias, backbone.layers.2.1.1.attn.attn.in_proj_weight, backbone.layers.2.1.1.attn.attn.in_proj_bias, backbone.layers.2.1.1.attn.attn.out_proj.weight, backbone.layers.2.1.1.attn.attn.out_proj.bias, backbone.layers.2.1.1.attn.sr.weight, backbone.layers.2.1.1.attn.sr.bias, backbone.layers.2.1.1.attn.norm.weight, backbone.layers.2.1.1.attn.norm.bias, backbone.layers.2.1.1.norm2.weight, backbone.layers.2.1.1.norm2.bias, backbone.layers.2.1.1.ffn.layers.0.weight, backbone.layers.2.1.1.ffn.layers.0.bias, backbone.layers.2.1.1.ffn.layers.1.weight, backbone.layers.2.1.1.ffn.layers.1.bias, backbone.layers.2.1.1.ffn.layers.4.weight, backbone.layers.2.1.1.ffn.layers.4.bias, backbone.layers.2.1.2.norm1.weight, backbone.layers.2.1.2.norm1.bias, backbone.layers.2.1.2.attn.attn.in_proj_weight, backbone.layers.2.1.2.attn.attn.in_proj_bias, backbone.layers.2.1.2.attn.attn.out_proj.weight, backbone.layers.2.1.2.attn.attn.out_proj.bias, backbone.layers.2.1.2.attn.sr.weight, backbone.layers.2.1.2.attn.sr.bias, backbone.layers.2.1.2.attn.norm.weight, backbone.layers.2.1.2.attn.norm.bias, backbone.layers.2.1.2.norm2.weight, backbone.layers.2.1.2.norm2.bias, backbone.layers.2.1.2.ffn.layers.0.weight, backbone.layers.2.1.2.ffn.layers.0.bias, backbone.layers.2.1.2.ffn.layers.1.weight, backbone.layers.2.1.2.ffn.layers.1.bias, backbone.layers.2.1.2.ffn.layers.4.weight, backbone.layers.2.1.2.ffn.layers.4.bias, backbone.layers.2.1.3.norm1.weight, backbone.layers.2.1.3.norm1.bias, backbone.layers.2.1.3.attn.attn.in_proj_weight, backbone.layers.2.1.3.attn.attn.in_proj_bias, backbone.layers.2.1.3.attn.attn.out_proj.weight, backbone.layers.2.1.3.attn.attn.out_proj.bias, backbone.layers.2.1.3.attn.sr.weight, backbone.layers.2.1.3.attn.sr.bias, backbone.layers.2.1.3.attn.norm.weight, backbone.layers.2.1.3.attn.norm.bias, backbone.layers.2.1.3.norm2.weight, backbone.layers.2.1.3.norm2.bias, backbone.layers.2.1.3.ffn.layers.0.weight, backbone.layers.2.1.3.ffn.layers.0.bias, backbone.layers.2.1.3.ffn.layers.1.weight, backbone.layers.2.1.3.ffn.layers.1.bias, backbone.layers.2.1.3.ffn.layers.4.weight, backbone.layers.2.1.3.ffn.layers.4.bias, backbone.layers.2.1.4.norm1.weight, backbone.layers.2.1.4.norm1.bias, backbone.layers.2.1.4.attn.attn.in_proj_weight, backbone.layers.2.1.4.attn.attn.in_proj_bias, backbone.layers.2.1.4.attn.attn.out_proj.weight, backbone.layers.2.1.4.attn.attn.out_proj.bias, backbone.layers.2.1.4.attn.sr.weight, backbone.layers.2.1.4.attn.sr.bias, backbone.layers.2.1.4.attn.norm.weight, backbone.layers.2.1.4.attn.norm.bias, backbone.layers.2.1.4.norm2.weight, backbone.layers.2.1.4.norm2.bias, backbone.layers.2.1.4.ffn.layers.0.weight, backbone.layers.2.1.4.ffn.layers.0.bias, backbone.layers.2.1.4.ffn.layers.1.weight, backbone.layers.2.1.4.ffn.layers.1.bias, backbone.layers.2.1.4.ffn.layers.4.weight, backbone.layers.2.1.4.ffn.layers.4.bias, backbone.layers.2.1.5.norm1.weight, backbone.layers.2.1.5.norm1.bias, backbone.layers.2.1.5.attn.attn.in_proj_weight, backbone.layers.2.1.5.attn.attn.in_proj_bias, backbone.layers.2.1.5.attn.attn.out_proj.weight, backbone.layers.2.1.5.attn.attn.out_proj.bias, backbone.layers.2.1.5.attn.sr.weight, backbone.layers.2.1.5.attn.sr.bias, backbone.layers.2.1.5.attn.norm.weight, backbone.layers.2.1.5.attn.norm.bias, backbone.layers.2.1.5.norm2.weight, backbone.layers.2.1.5.norm2.bias, backbone.layers.2.1.5.ffn.layers.0.weight, backbone.layers.2.1.5.ffn.layers.0.bias, backbone.layers.2.1.5.ffn.layers.1.weight, backbone.layers.2.1.5.ffn.layers.1.bias, backbone.layers.2.1.5.ffn.layers.4.weight, backbone.layers.2.1.5.ffn.layers.4.bias, backbone.layers.2.1.6.norm1.weight, backbone.layers.2.1.6.norm1.bias, backbone.layers.2.1.6.attn.attn.in_proj_weight, backbone.layers.2.1.6.attn.attn.in_proj_bias, backbone.layers.2.1.6.attn.attn.out_proj.weight, backbone.layers.2.1.6.attn.attn.out_proj.bias, backbone.layers.2.1.6.attn.sr.weight, backbone.layers.2.1.6.attn.sr.bias, backbone.layers.2.1.6.attn.norm.weight, backbone.layers.2.1.6.attn.norm.bias, backbone.layers.2.1.6.norm2.weight, backbone.layers.2.1.6.norm2.bias, backbone.layers.2.1.6.ffn.layers.0.weight, backbone.layers.2.1.6.ffn.layers.0.bias, backbone.layers.2.1.6.ffn.layers.1.weight, backbone.layers.2.1.6.ffn.layers.1.bias, backbone.layers.2.1.6.ffn.layers.4.weight, backbone.layers.2.1.6.ffn.layers.4.bias, backbone.layers.2.1.7.norm1.weight, backbone.layers.2.1.7.norm1.bias, backbone.layers.2.1.7.attn.attn.in_proj_weight, backbone.layers.2.1.7.attn.attn.in_proj_bias, backbone.layers.2.1.7.attn.attn.out_proj.weight, backbone.layers.2.1.7.attn.attn.out_proj.bias, backbone.layers.2.1.7.attn.sr.weight, backbone.layers.2.1.7.attn.sr.bias, backbone.layers.2.1.7.attn.norm.weight, backbone.layers.2.1.7.attn.norm.bias, backbone.layers.2.1.7.norm2.weight, backbone.layers.2.1.7.norm2.bias, backbone.layers.2.1.7.ffn.layers.0.weight, backbone.layers.2.1.7.ffn.layers.0.bias, backbone.layers.2.1.7.ffn.layers.1.weight, backbone.layers.2.1.7.ffn.layers.1.bias, backbone.layers.2.1.7.ffn.layers.4.weight, backbone.layers.2.1.7.ffn.layers.4.bias, backbone.layers.2.1.8.norm1.weight, backbone.layers.2.1.8.norm1.bias, backbone.layers.2.1.8.attn.attn.in_proj_weight, backbone.layers.2.1.8.attn.attn.in_proj_bias, backbone.layers.2.1.8.attn.attn.out_proj.weight, backbone.layers.2.1.8.attn.attn.out_proj.bias, backbone.layers.2.1.8.attn.sr.weight, backbone.layers.2.1.8.attn.sr.bias, backbone.layers.2.1.8.attn.norm.weight, backbone.layers.2.1.8.attn.norm.bias, backbone.layers.2.1.8.norm2.weight, backbone.layers.2.1.8.norm2.bias, backbone.layers.2.1.8.ffn.layers.0.weight, backbone.layers.2.1.8.ffn.layers.0.bias, backbone.layers.2.1.8.ffn.layers.1.weight, backbone.layers.2.1.8.ffn.layers.1.bias, backbone.layers.2.1.8.ffn.layers.4.weight, backbone.layers.2.1.8.ffn.layers.4.bias, backbone.layers.2.1.9.norm1.weight, backbone.layers.2.1.9.norm1.bias, backbone.layers.2.1.9.attn.attn.in_proj_weight, backbone.layers.2.1.9.attn.attn.in_proj_bias, backbone.layers.2.1.9.attn.attn.out_proj.weight, backbone.layers.2.1.9.attn.attn.out_proj.bias, backbone.layers.2.1.9.attn.sr.weight, backbone.layers.2.1.9.attn.sr.bias, backbone.layers.2.1.9.attn.norm.weight, backbone.layers.2.1.9.attn.norm.bias, backbone.layers.2.1.9.norm2.weight, backbone.layers.2.1.9.norm2.bias, backbone.layers.2.1.9.ffn.layers.0.weight, backbone.layers.2.1.9.ffn.layers.0.bias, backbone.layers.2.1.9.ffn.layers.1.weight, backbone.layers.2.1.9.ffn.layers.1.bias, backbone.layers.2.1.9.ffn.layers.4.weight, backbone.layers.2.1.9.ffn.layers.4.bias, backbone.layers.2.1.10.norm1.weight, backbone.layers.2.1.10.norm1.bias, backbone.layers.2.1.10.attn.attn.in_proj_weight, backbone.layers.2.1.10.attn.attn.in_proj_bias, backbone.layers.2.1.10.attn.attn.out_proj.weight, backbone.layers.2.1.10.attn.attn.out_proj.bias, backbone.layers.2.1.10.attn.sr.weight, backbone.layers.2.1.10.attn.sr.bias, backbone.layers.2.1.10.attn.norm.weight, backbone.layers.2.1.10.attn.norm.bias, backbone.layers.2.1.10.norm2.weight, backbone.layers.2.1.10.norm2.bias, backbone.layers.2.1.10.ffn.layers.0.weight, backbone.layers.2.1.10.ffn.layers.0.bias, backbone.layers.2.1.10.ffn.layers.1.weight, backbone.layers.2.1.10.ffn.layers.1.bias, backbone.layers.2.1.10.ffn.layers.4.weight, backbone.layers.2.1.10.ffn.layers.4.bias, backbone.layers.2.1.11.norm1.weight, backbone.layers.2.1.11.norm1.bias, backbone.layers.2.1.11.attn.attn.in_proj_weight, backbone.layers.2.1.11.attn.attn.in_proj_bias, backbone.layers.2.1.11.attn.attn.out_proj.weight, backbone.layers.2.1.11.attn.attn.out_proj.bias, backbone.layers.2.1.11.attn.sr.weight, backbone.layers.2.1.11.attn.sr.bias, backbone.layers.2.1.11.attn.norm.weight, backbone.layers.2.1.11.attn.norm.bias, backbone.layers.2.1.11.norm2.weight, backbone.layers.2.1.11.norm2.bias, backbone.layers.2.1.11.ffn.layers.0.weight, backbone.layers.2.1.11.ffn.layers.0.bias, backbone.layers.2.1.11.ffn.layers.1.weight, backbone.layers.2.1.11.ffn.layers.1.bias, backbone.layers.2.1.11.ffn.layers.4.weight, backbone.layers.2.1.11.ffn.layers.4.bias, backbone.layers.2.1.12.norm1.weight, backbone.layers.2.1.12.norm1.bias, backbone.layers.2.1.12.attn.attn.in_proj_weight, backbone.layers.2.1.12.attn.attn.in_proj_bias, backbone.layers.2.1.12.attn.attn.out_proj.weight, backbone.layers.2.1.12.attn.attn.out_proj.bias, backbone.layers.2.1.12.attn.sr.weight, backbone.layers.2.1.12.attn.sr.bias, backbone.layers.2.1.12.attn.norm.weight, backbone.layers.2.1.12.attn.norm.bias, backbone.layers.2.1.12.norm2.weight, backbone.layers.2.1.12.norm2.bias, backbone.layers.2.1.12.ffn.layers.0.weight, backbone.layers.2.1.12.ffn.layers.0.bias, backbone.layers.2.1.12.ffn.layers.1.weight, backbone.layers.2.1.12.ffn.layers.1.bias, backbone.layers.2.1.12.ffn.layers.4.weight, backbone.layers.2.1.12.ffn.layers.4.bias, backbone.layers.2.1.13.norm1.weight, backbone.layers.2.1.13.norm1.bias, backbone.layers.2.1.13.attn.attn.in_proj_weight, backbone.layers.2.1.13.attn.attn.in_proj_bias, backbone.layers.2.1.13.attn.attn.out_proj.weight, backbone.layers.2.1.13.attn.attn.out_proj.bias, backbone.layers.2.1.13.attn.sr.weight, backbone.layers.2.1.13.attn.sr.bias, backbone.layers.2.1.13.attn.norm.weight, backbone.layers.2.1.13.attn.norm.bias, backbone.layers.2.1.13.norm2.weight, backbone.layers.2.1.13.norm2.bias, backbone.layers.2.1.13.ffn.layers.0.weight, backbone.layers.2.1.13.ffn.layers.0.bias, backbone.layers.2.1.13.ffn.layers.1.weight, backbone.layers.2.1.13.ffn.layers.1.bias, backbone.layers.2.1.13.ffn.layers.4.weight, backbone.layers.2.1.13.ffn.layers.4.bias, backbone.layers.2.1.14.norm1.weight, backbone.layers.2.1.14.norm1.bias, backbone.layers.2.1.14.attn.attn.in_proj_weight, backbone.layers.2.1.14.attn.attn.in_proj_bias, backbone.layers.2.1.14.attn.attn.out_proj.weight, backbone.layers.2.1.14.attn.attn.out_proj.bias, backbone.layers.2.1.14.attn.sr.weight, backbone.layers.2.1.14.attn.sr.bias, backbone.layers.2.1.14.attn.norm.weight, backbone.layers.2.1.14.attn.norm.bias, backbone.layers.2.1.14.norm2.weight, backbone.layers.2.1.14.norm2.bias, backbone.layers.2.1.14.ffn.layers.0.weight, backbone.layers.2.1.14.ffn.layers.0.bias, backbone.layers.2.1.14.ffn.layers.1.weight, backbone.layers.2.1.14.ffn.layers.1.bias, backbone.layers.2.1.14.ffn.layers.4.weight, backbone.layers.2.1.14.ffn.layers.4.bias, backbone.layers.2.1.15.norm1.weight, backbone.layers.2.1.15.norm1.bias, backbone.layers.2.1.15.attn.attn.in_proj_weight, backbone.layers.2.1.15.attn.attn.in_proj_bias, backbone.layers.2.1.15.attn.attn.out_proj.weight, backbone.layers.2.1.15.attn.attn.out_proj.bias, backbone.layers.2.1.15.attn.sr.weight, backbone.layers.2.1.15.attn.sr.bias, backbone.layers.2.1.15.attn.norm.weight, backbone.layers.2.1.15.attn.norm.bias, backbone.layers.2.1.15.norm2.weight, backbone.layers.2.1.15.norm2.bias, backbone.layers.2.1.15.ffn.layers.0.weight, backbone.layers.2.1.15.ffn.layers.0.bias, backbone.layers.2.1.15.ffn.layers.1.weight, backbone.layers.2.1.15.ffn.layers.1.bias, backbone.layers.2.1.15.ffn.layers.4.weight, backbone.layers.2.1.15.ffn.layers.4.bias, backbone.layers.2.1.16.norm1.weight, backbone.layers.2.1.16.norm1.bias, backbone.layers.2.1.16.attn.attn.in_proj_weight, backbone.layers.2.1.16.attn.attn.in_proj_bias, backbone.layers.2.1.16.attn.attn.out_proj.weight, backbone.layers.2.1.16.attn.attn.out_proj.bias, backbone.layers.2.1.16.attn.sr.weight, backbone.layers.2.1.16.attn.sr.bias, backbone.layers.2.1.16.attn.norm.weight, backbone.layers.2.1.16.attn.norm.bias, backbone.layers.2.1.16.norm2.weight, backbone.layers.2.1.16.norm2.bias, backbone.layers.2.1.16.ffn.layers.0.weight, backbone.layers.2.1.16.ffn.layers.0.bias, backbone.layers.2.1.16.ffn.layers.1.weight, backbone.layers.2.1.16.ffn.layers.1.bias, backbone.layers.2.1.16.ffn.layers.4.weight, backbone.layers.2.1.16.ffn.layers.4.bias, backbone.layers.2.1.17.norm1.weight, backbone.layers.2.1.17.norm1.bias, backbone.layers.2.1.17.attn.attn.in_proj_weight, backbone.layers.2.1.17.attn.attn.in_proj_bias, backbone.layers.2.1.17.attn.attn.out_proj.weight, backbone.layers.2.1.17.attn.attn.out_proj.bias, backbone.layers.2.1.17.attn.sr.weight, backbone.layers.2.1.17.attn.sr.bias, backbone.layers.2.1.17.attn.norm.weight, backbone.layers.2.1.17.attn.norm.bias, backbone.layers.2.1.17.norm2.weight, backbone.layers.2.1.17.norm2.bias, backbone.layers.2.1.17.ffn.layers.0.weight, backbone.layers.2.1.17.ffn.layers.0.bias, backbone.layers.2.1.17.ffn.layers.1.weight, backbone.layers.2.1.17.ffn.layers.1.bias, backbone.layers.2.1.17.ffn.layers.4.weight, backbone.layers.2.1.17.ffn.layers.4.bias, backbone.layers.2.1.18.norm1.weight, backbone.layers.2.1.18.norm1.bias, backbone.layers.2.1.18.attn.attn.in_proj_weight, backbone.layers.2.1.18.attn.attn.in_proj_bias, backbone.layers.2.1.18.attn.attn.out_proj.weight, backbone.layers.2.1.18.attn.attn.out_proj.bias, backbone.layers.2.1.18.attn.sr.weight, backbone.layers.2.1.18.attn.sr.bias, backbone.layers.2.1.18.attn.norm.weight, backbone.layers.2.1.18.attn.norm.bias, backbone.layers.2.1.18.norm2.weight, backbone.layers.2.1.18.norm2.bias, backbone.layers.2.1.18.ffn.layers.0.weight, backbone.layers.2.1.18.ffn.layers.0.bias, backbone.layers.2.1.18.ffn.layers.1.weight, backbone.layers.2.1.18.ffn.layers.1.bias, backbone.layers.2.1.18.ffn.layers.4.weight, backbone.layers.2.1.18.ffn.layers.4.bias, backbone.layers.2.1.19.norm1.weight, backbone.layers.2.1.19.norm1.bias, backbone.layers.2.1.19.attn.attn.in_proj_weight, backbone.layers.2.1.19.attn.attn.in_proj_bias, backbone.layers.2.1.19.attn.attn.out_proj.weight, backbone.layers.2.1.19.attn.attn.out_proj.bias, backbone.layers.2.1.19.attn.sr.weight, backbone.layers.2.1.19.attn.sr.bias, backbone.layers.2.1.19.attn.norm.weight, backbone.layers.2.1.19.attn.norm.bias, backbone.layers.2.1.19.norm2.weight, backbone.layers.2.1.19.norm2.bias, backbone.layers.2.1.19.ffn.layers.0.weight, backbone.layers.2.1.19.ffn.layers.0.bias, backbone.layers.2.1.19.ffn.layers.1.weight, backbone.layers.2.1.19.ffn.layers.1.bias, backbone.layers.2.1.19.ffn.layers.4.weight, backbone.layers.2.1.19.ffn.layers.4.bias, backbone.layers.2.1.20.norm1.weight, backbone.layers.2.1.20.norm1.bias, backbone.layers.2.1.20.attn.attn.in_proj_weight, backbone.layers.2.1.20.attn.attn.in_proj_bias, backbone.layers.2.1.20.attn.attn.out_proj.weight, backbone.layers.2.1.20.attn.attn.out_proj.bias, backbone.layers.2.1.20.attn.sr.weight, backbone.layers.2.1.20.attn.sr.bias, backbone.layers.2.1.20.attn.norm.weight, backbone.layers.2.1.20.attn.norm.bias, backbone.layers.2.1.20.norm2.weight, backbone.layers.2.1.20.norm2.bias, backbone.layers.2.1.20.ffn.layers.0.weight, backbone.layers.2.1.20.ffn.layers.0.bias, backbone.layers.2.1.20.ffn.layers.1.weight, backbone.layers.2.1.20.ffn.layers.1.bias, backbone.layers.2.1.20.ffn.layers.4.weight, backbone.layers.2.1.20.ffn.layers.4.bias, backbone.layers.2.1.21.norm1.weight, backbone.layers.2.1.21.norm1.bias, backbone.layers.2.1.21.attn.attn.in_proj_weight, backbone.layers.2.1.21.attn.attn.in_proj_bias, backbone.layers.2.1.21.attn.attn.out_proj.weight, backbone.layers.2.1.21.attn.attn.out_proj.bias, backbone.layers.2.1.21.attn.sr.weight, backbone.layers.2.1.21.attn.sr.bias, backbone.layers.2.1.21.attn.norm.weight, backbone.layers.2.1.21.attn.norm.bias, backbone.layers.2.1.21.norm2.weight, backbone.layers.2.1.21.norm2.bias, backbone.layers.2.1.21.ffn.layers.0.weight, backbone.layers.2.1.21.ffn.layers.0.bias, backbone.layers.2.1.21.ffn.layers.1.weight, backbone.layers.2.1.21.ffn.layers.1.bias, backbone.layers.2.1.21.ffn.layers.4.weight, backbone.layers.2.1.21.ffn.layers.4.bias, backbone.layers.2.1.22.norm1.weight, backbone.layers.2.1.22.norm1.bias, backbone.layers.2.1.22.attn.attn.in_proj_weight, backbone.layers.2.1.22.attn.attn.in_proj_bias, backbone.layers.2.1.22.attn.attn.out_proj.weight, backbone.layers.2.1.22.attn.attn.out_proj.bias, backbone.layers.2.1.22.attn.sr.weight, backbone.layers.2.1.22.attn.sr.bias, backbone.layers.2.1.22.attn.norm.weight, backbone.layers.2.1.22.attn.norm.bias, backbone.layers.2.1.22.norm2.weight, backbone.layers.2.1.22.norm2.bias, backbone.layers.2.1.22.ffn.layers.0.weight, backbone.layers.2.1.22.ffn.layers.0.bias, backbone.layers.2.1.22.ffn.layers.1.weight, backbone.layers.2.1.22.ffn.layers.1.bias, backbone.layers.2.1.22.ffn.layers.4.weight, backbone.layers.2.1.22.ffn.layers.4.bias, backbone.layers.2.1.23.norm1.weight, backbone.layers.2.1.23.norm1.bias, backbone.layers.2.1.23.attn.attn.in_proj_weight, backbone.layers.2.1.23.attn.attn.in_proj_bias, backbone.layers.2.1.23.attn.attn.out_proj.weight, backbone.layers.2.1.23.attn.attn.out_proj.bias, backbone.layers.2.1.23.attn.sr.weight, backbone.layers.2.1.23.attn.sr.bias, backbone.layers.2.1.23.attn.norm.weight, backbone.layers.2.1.23.attn.norm.bias, backbone.layers.2.1.23.norm2.weight, backbone.layers.2.1.23.norm2.bias, backbone.layers.2.1.23.ffn.layers.0.weight, backbone.layers.2.1.23.ffn.layers.0.bias, backbone.layers.2.1.23.ffn.layers.1.weight, backbone.layers.2.1.23.ffn.layers.1.bias, backbone.layers.2.1.23.ffn.layers.4.weight, backbone.layers.2.1.23.ffn.layers.4.bias, backbone.layers.2.1.24.norm1.weight, backbone.layers.2.1.24.norm1.bias, backbone.layers.2.1.24.attn.attn.in_proj_weight, backbone.layers.2.1.24.attn.attn.in_proj_bias, backbone.layers.2.1.24.attn.attn.out_proj.weight, backbone.layers.2.1.24.attn.attn.out_proj.bias, backbone.layers.2.1.24.attn.sr.weight, backbone.layers.2.1.24.attn.sr.bias, backbone.layers.2.1.24.attn.norm.weight, backbone.layers.2.1.24.attn.norm.bias, backbone.layers.2.1.24.norm2.weight, backbone.layers.2.1.24.norm2.bias, backbone.layers.2.1.24.ffn.layers.0.weight, backbone.layers.2.1.24.ffn.layers.0.bias, backbone.layers.2.1.24.ffn.layers.1.weight, backbone.layers.2.1.24.ffn.layers.1.bias, backbone.layers.2.1.24.ffn.layers.4.weight, backbone.layers.2.1.24.ffn.layers.4.bias, backbone.layers.2.1.25.norm1.weight, backbone.layers.2.1.25.norm1.bias, backbone.layers.2.1.25.attn.attn.in_proj_weight, backbone.layers.2.1.25.attn.attn.in_proj_bias, backbone.layers.2.1.25.attn.attn.out_proj.weight, backbone.layers.2.1.25.attn.attn.out_proj.bias, backbone.layers.2.1.25.attn.sr.weight, backbone.layers.2.1.25.attn.sr.bias, backbone.layers.2.1.25.attn.norm.weight, backbone.layers.2.1.25.attn.norm.bias, backbone.layers.2.1.25.norm2.weight, backbone.layers.2.1.25.norm2.bias, backbone.layers.2.1.25.ffn.layers.0.weight, backbone.layers.2.1.25.ffn.layers.0.bias, backbone.layers.2.1.25.ffn.layers.1.weight, backbone.layers.2.1.25.ffn.layers.1.bias, backbone.layers.2.1.25.ffn.layers.4.weight, backbone.layers.2.1.25.ffn.layers.4.bias, backbone.layers.2.1.26.norm1.weight, backbone.layers.2.1.26.norm1.bias, backbone.layers.2.1.26.attn.attn.in_proj_weight, backbone.layers.2.1.26.attn.attn.in_proj_bias, backbone.layers.2.1.26.attn.attn.out_proj.weight, backbone.layers.2.1.26.attn.attn.out_proj.bias, backbone.layers.2.1.26.attn.sr.weight, backbone.layers.2.1.26.attn.sr.bias, backbone.layers.2.1.26.attn.norm.weight, backbone.layers.2.1.26.attn.norm.bias, backbone.layers.2.1.26.norm2.weight, backbone.layers.2.1.26.norm2.bias, backbone.layers.2.1.26.ffn.layers.0.weight, backbone.layers.2.1.26.ffn.layers.0.bias, backbone.layers.2.1.26.ffn.layers.1.weight, backbone.layers.2.1.26.ffn.layers.1.bias, backbone.layers.2.1.26.ffn.layers.4.weight, backbone.layers.2.1.26.ffn.layers.4.bias, backbone.layers.2.1.27.norm1.weight, backbone.layers.2.1.27.norm1.bias, backbone.layers.2.1.27.attn.attn.in_proj_weight, backbone.layers.2.1.27.attn.attn.in_proj_bias, backbone.layers.2.1.27.attn.attn.out_proj.weight, backbone.layers.2.1.27.attn.attn.out_proj.bias, backbone.layers.2.1.27.attn.sr.weight, backbone.layers.2.1.27.attn.sr.bias, backbone.layers.2.1.27.attn.norm.weight, backbone.layers.2.1.27.attn.norm.bias, backbone.layers.2.1.27.norm2.weight, backbone.layers.2.1.27.norm2.bias, backbone.layers.2.1.27.ffn.layers.0.weight, backbone.layers.2.1.27.ffn.layers.0.bias, backbone.layers.2.1.27.ffn.layers.1.weight, backbone.layers.2.1.27.ffn.layers.1.bias, backbone.layers.2.1.27.ffn.layers.4.weight, backbone.layers.2.1.27.ffn.layers.4.bias, backbone.layers.2.1.28.norm1.weight, backbone.layers.2.1.28.norm1.bias, backbone.layers.2.1.28.attn.attn.in_proj_weight, backbone.layers.2.1.28.attn.attn.in_proj_bias, backbone.layers.2.1.28.attn.attn.out_proj.weight, backbone.layers.2.1.28.attn.attn.out_proj.bias, backbone.layers.2.1.28.attn.sr.weight, backbone.layers.2.1.28.attn.sr.bias, backbone.layers.2.1.28.attn.norm.weight, backbone.layers.2.1.28.attn.norm.bias, backbone.layers.2.1.28.norm2.weight, backbone.layers.2.1.28.norm2.bias, backbone.layers.2.1.28.ffn.layers.0.weight, backbone.layers.2.1.28.ffn.layers.0.bias, backbone.layers.2.1.28.ffn.layers.1.weight, backbone.layers.2.1.28.ffn.layers.1.bias, backbone.layers.2.1.28.ffn.layers.4.weight, backbone.layers.2.1.28.ffn.layers.4.bias, backbone.layers.2.1.29.norm1.weight, backbone.layers.2.1.29.norm1.bias, backbone.layers.2.1.29.attn.attn.in_proj_weight, backbone.layers.2.1.29.attn.attn.in_proj_bias, backbone.layers.2.1.29.attn.attn.out_proj.weight, backbone.layers.2.1.29.attn.attn.out_proj.bias, backbone.layers.2.1.29.attn.sr.weight, backbone.layers.2.1.29.attn.sr.bias, backbone.layers.2.1.29.attn.norm.weight, backbone.layers.2.1.29.attn.norm.bias, backbone.layers.2.1.29.norm2.weight, backbone.layers.2.1.29.norm2.bias, backbone.layers.2.1.29.ffn.layers.0.weight, backbone.layers.2.1.29.ffn.layers.0.bias, backbone.layers.2.1.29.ffn.layers.1.weight, backbone.layers.2.1.29.ffn.layers.1.bias, backbone.layers.2.1.29.ffn.layers.4.weight, backbone.layers.2.1.29.ffn.layers.4.bias, backbone.layers.2.1.30.norm1.weight, backbone.layers.2.1.30.norm1.bias, backbone.layers.2.1.30.attn.attn.in_proj_weight, backbone.layers.2.1.30.attn.attn.in_proj_bias, backbone.layers.2.1.30.attn.attn.out_proj.weight, backbone.layers.2.1.30.attn.attn.out_proj.bias, backbone.layers.2.1.30.attn.sr.weight, backbone.layers.2.1.30.attn.sr.bias, backbone.layers.2.1.30.attn.norm.weight, backbone.layers.2.1.30.attn.norm.bias, backbone.layers.2.1.30.norm2.weight, backbone.layers.2.1.30.norm2.bias, backbone.layers.2.1.30.ffn.layers.0.weight, backbone.layers.2.1.30.ffn.layers.0.bias, backbone.layers.2.1.30.ffn.layers.1.weight, backbone.layers.2.1.30.ffn.layers.1.bias, backbone.layers.2.1.30.ffn.layers.4.weight, backbone.layers.2.1.30.ffn.layers.4.bias, backbone.layers.2.1.31.norm1.weight, backbone.layers.2.1.31.norm1.bias, backbone.layers.2.1.31.attn.attn.in_proj_weight, backbone.layers.2.1.31.attn.attn.in_proj_bias, backbone.layers.2.1.31.attn.attn.out_proj.weight, backbone.layers.2.1.31.attn.attn.out_proj.bias, backbone.layers.2.1.31.attn.sr.weight, backbone.layers.2.1.31.attn.sr.bias, backbone.layers.2.1.31.attn.norm.weight, backbone.layers.2.1.31.attn.norm.bias, backbone.layers.2.1.31.norm2.weight, backbone.layers.2.1.31.norm2.bias, backbone.layers.2.1.31.ffn.layers.0.weight, backbone.layers.2.1.31.ffn.layers.0.bias, backbone.layers.2.1.31.ffn.layers.1.weight, backbone.layers.2.1.31.ffn.layers.1.bias, backbone.layers.2.1.31.ffn.layers.4.weight, backbone.layers.2.1.31.ffn.layers.4.bias, backbone.layers.2.1.32.norm1.weight, backbone.layers.2.1.32.norm1.bias, backbone.layers.2.1.32.attn.attn.in_proj_weight, backbone.layers.2.1.32.attn.attn.in_proj_bias, backbone.layers.2.1.32.attn.attn.out_proj.weight, backbone.layers.2.1.32.attn.attn.out_proj.bias, backbone.layers.2.1.32.attn.sr.weight, backbone.layers.2.1.32.attn.sr.bias, backbone.layers.2.1.32.attn.norm.weight, backbone.layers.2.1.32.attn.norm.bias, backbone.layers.2.1.32.norm2.weight, backbone.layers.2.1.32.norm2.bias, backbone.layers.2.1.32.ffn.layers.0.weight, backbone.layers.2.1.32.ffn.layers.0.bias, backbone.layers.2.1.32.ffn.layers.1.weight, backbone.layers.2.1.32.ffn.layers.1.bias, backbone.layers.2.1.32.ffn.layers.4.weight, backbone.layers.2.1.32.ffn.layers.4.bias, backbone.layers.2.1.33.norm1.weight, backbone.layers.2.1.33.norm1.bias, backbone.layers.2.1.33.attn.attn.in_proj_weight, backbone.layers.2.1.33.attn.attn.in_proj_bias, backbone.layers.2.1.33.attn.attn.out_proj.weight, backbone.layers.2.1.33.attn.attn.out_proj.bias, backbone.layers.2.1.33.attn.sr.weight, backbone.layers.2.1.33.attn.sr.bias, backbone.layers.2.1.33.attn.norm.weight, backbone.layers.2.1.33.attn.norm.bias, backbone.layers.2.1.33.norm2.weight, backbone.layers.2.1.33.norm2.bias, backbone.layers.2.1.33.ffn.layers.0.weight, backbone.layers.2.1.33.ffn.layers.0.bias, backbone.layers.2.1.33.ffn.layers.1.weight, backbone.layers.2.1.33.ffn.layers.1.bias, backbone.layers.2.1.33.ffn.layers.4.weight, backbone.layers.2.1.33.ffn.layers.4.bias, backbone.layers.2.1.34.norm1.weight, backbone.layers.2.1.34.norm1.bias, backbone.layers.2.1.34.attn.attn.in_proj_weight, backbone.layers.2.1.34.attn.attn.in_proj_bias, backbone.layers.2.1.34.attn.attn.out_proj.weight, backbone.layers.2.1.34.attn.attn.out_proj.bias, backbone.layers.2.1.34.attn.sr.weight, backbone.layers.2.1.34.attn.sr.bias, backbone.layers.2.1.34.attn.norm.weight, backbone.layers.2.1.34.attn.norm.bias, backbone.layers.2.1.34.norm2.weight, backbone.layers.2.1.34.norm2.bias, backbone.layers.2.1.34.ffn.layers.0.weight, backbone.layers.2.1.34.ffn.layers.0.bias, backbone.layers.2.1.34.ffn.layers.1.weight, backbone.layers.2.1.34.ffn.layers.1.bias, backbone.layers.2.1.34.ffn.layers.4.weight, backbone.layers.2.1.34.ffn.layers.4.bias, backbone.layers.2.1.35.norm1.weight, backbone.layers.2.1.35.norm1.bias, backbone.layers.2.1.35.attn.attn.in_proj_weight, backbone.layers.2.1.35.attn.attn.in_proj_bias, backbone.layers.2.1.35.attn.attn.out_proj.weight, backbone.layers.2.1.35.attn.attn.out_proj.bias, backbone.layers.2.1.35.attn.sr.weight, backbone.layers.2.1.35.attn.sr.bias, backbone.layers.2.1.35.attn.norm.weight, backbone.layers.2.1.35.attn.norm.bias, backbone.layers.2.1.35.norm2.weight, backbone.layers.2.1.35.norm2.bias, backbone.layers.2.1.35.ffn.layers.0.weight, backbone.layers.2.1.35.ffn.layers.0.bias, backbone.layers.2.1.35.ffn.layers.1.weight, backbone.layers.2.1.35.ffn.layers.1.bias, backbone.layers.2.1.35.ffn.layers.4.weight, backbone.layers.2.1.35.ffn.layers.4.bias, backbone.layers.2.1.36.norm1.weight, backbone.layers.2.1.36.norm1.bias, backbone.layers.2.1.36.attn.attn.in_proj_weight, backbone.layers.2.1.36.attn.attn.in_proj_bias, backbone.layers.2.1.36.attn.attn.out_proj.weight, backbone.layers.2.1.36.attn.attn.out_proj.bias, backbone.layers.2.1.36.attn.sr.weight, backbone.layers.2.1.36.attn.sr.bias, backbone.layers.2.1.36.attn.norm.weight, backbone.layers.2.1.36.attn.norm.bias, backbone.layers.2.1.36.norm2.weight, backbone.layers.2.1.36.norm2.bias, backbone.layers.2.1.36.ffn.layers.0.weight, backbone.layers.2.1.36.ffn.layers.0.bias, backbone.layers.2.1.36.ffn.layers.1.weight, backbone.layers.2.1.36.ffn.layers.1.bias, backbone.layers.2.1.36.ffn.layers.4.weight, backbone.layers.2.1.36.ffn.layers.4.bias, backbone.layers.2.1.37.norm1.weight, backbone.layers.2.1.37.norm1.bias, backbone.layers.2.1.37.attn.attn.in_proj_weight, backbone.layers.2.1.37.attn.attn.in_proj_bias, backbone.layers.2.1.37.attn.attn.out_proj.weight, backbone.layers.2.1.37.attn.attn.out_proj.bias, backbone.layers.2.1.37.attn.sr.weight, backbone.layers.2.1.37.attn.sr.bias, backbone.layers.2.1.37.attn.norm.weight, backbone.layers.2.1.37.attn.norm.bias, backbone.layers.2.1.37.norm2.weight, backbone.layers.2.1.37.norm2.bias, backbone.layers.2.1.37.ffn.layers.0.weight, backbone.layers.2.1.37.ffn.layers.0.bias, backbone.layers.2.1.37.ffn.layers.1.weight, backbone.layers.2.1.37.ffn.layers.1.bias, backbone.layers.2.1.37.ffn.layers.4.weight, backbone.layers.2.1.37.ffn.layers.4.bias, backbone.layers.2.1.38.norm1.weight, backbone.layers.2.1.38.norm1.bias, backbone.layers.2.1.38.attn.attn.in_proj_weight, backbone.layers.2.1.38.attn.attn.in_proj_bias, backbone.layers.2.1.38.attn.attn.out_proj.weight, backbone.layers.2.1.38.attn.attn.out_proj.bias, backbone.layers.2.1.38.attn.sr.weight, backbone.layers.2.1.38.attn.sr.bias, backbone.layers.2.1.38.attn.norm.weight, backbone.layers.2.1.38.attn.norm.bias, backbone.layers.2.1.38.norm2.weight, backbone.layers.2.1.38.norm2.bias, backbone.layers.2.1.38.ffn.layers.0.weight, backbone.layers.2.1.38.ffn.layers.0.bias, backbone.layers.2.1.38.ffn.layers.1.weight, backbone.layers.2.1.38.ffn.layers.1.bias, backbone.layers.2.1.38.ffn.layers.4.weight, backbone.layers.2.1.38.ffn.layers.4.bias, backbone.layers.2.1.39.norm1.weight, backbone.layers.2.1.39.norm1.bias, backbone.layers.2.1.39.attn.attn.in_proj_weight, backbone.layers.2.1.39.attn.attn.in_proj_bias, backbone.layers.2.1.39.attn.attn.out_proj.weight, backbone.layers.2.1.39.attn.attn.out_proj.bias, backbone.layers.2.1.39.attn.sr.weight, backbone.layers.2.1.39.attn.sr.bias, backbone.layers.2.1.39.attn.norm.weight, backbone.layers.2.1.39.attn.norm.bias, backbone.layers.2.1.39.norm2.weight, backbone.layers.2.1.39.norm2.bias, backbone.layers.2.1.39.ffn.layers.0.weight, backbone.layers.2.1.39.ffn.layers.0.bias, backbone.layers.2.1.39.ffn.layers.1.weight, backbone.layers.2.1.39.ffn.layers.1.bias, backbone.layers.2.1.39.ffn.layers.4.weight, backbone.layers.2.1.39.ffn.layers.4.bias, backbone.layers.2.2.weight, backbone.layers.2.2.bias, backbone.layers.3.0.projection.weight, backbone.layers.3.0.projection.bias, backbone.layers.3.0.norm.weight, backbone.layers.3.0.norm.bias, backbone.layers.3.1.0.norm1.weight, backbone.layers.3.1.0.norm1.bias, backbone.layers.3.1.0.attn.attn.in_proj_weight, backbone.layers.3.1.0.attn.attn.in_proj_bias, backbone.layers.3.1.0.attn.attn.out_proj.weight, backbone.layers.3.1.0.attn.attn.out_proj.bias, backbone.layers.3.1.0.norm2.weight, backbone.layers.3.1.0.norm2.bias, backbone.layers.3.1.0.ffn.layers.0.weight, backbone.layers.3.1.0.ffn.layers.0.bias, backbone.layers.3.1.0.ffn.layers.1.weight, backbone.layers.3.1.0.ffn.layers.1.bias, backbone.layers.3.1.0.ffn.layers.4.weight, backbone.layers.3.1.0.ffn.layers.4.bias, backbone.layers.3.1.1.norm1.weight, backbone.layers.3.1.1.norm1.bias, backbone.layers.3.1.1.attn.attn.in_proj_weight, backbone.layers.3.1.1.attn.attn.in_proj_bias, backbone.layers.3.1.1.attn.attn.out_proj.weight, backbone.layers.3.1.1.attn.attn.out_proj.bias, backbone.layers.3.1.1.norm2.weight, backbone.layers.3.1.1.norm2.bias, backbone.layers.3.1.1.ffn.layers.0.weight, backbone.layers.3.1.1.ffn.layers.0.bias, backbone.layers.3.1.1.ffn.layers.1.weight, backbone.layers.3.1.1.ffn.layers.1.bias, backbone.layers.3.1.1.ffn.layers.4.weight, backbone.layers.3.1.1.ffn.layers.4.bias, backbone.layers.3.1.2.norm1.weight, backbone.layers.3.1.2.norm1.bias, backbone.layers.3.1.2.attn.attn.in_proj_weight, backbone.layers.3.1.2.attn.attn.in_proj_bias, backbone.layers.3.1.2.attn.attn.out_proj.weight, backbone.layers.3.1.2.attn.attn.out_proj.bias, backbone.layers.3.1.2.norm2.weight, backbone.layers.3.1.2.norm2.bias, backbone.layers.3.1.2.ffn.layers.0.weight, backbone.layers.3.1.2.ffn.layers.0.bias, backbone.layers.3.1.2.ffn.layers.1.weight, backbone.layers.3.1.2.ffn.layers.1.bias, backbone.layers.3.1.2.ffn.layers.4.weight, backbone.layers.3.1.2.ffn.layers.4.bias, backbone.layers.3.2.weight, backbone.layers.3.2.bias, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.convs.0.conv.weight, decode_head.convs.0.bn.weight, decode_head.convs.0.bn.bias, decode_head.convs.0.bn.running_mean, decode_head.convs.0.bn.running_var, decode_head.convs.0.bn.num_batches_tracked, decode_head.convs.1.conv.weight, decode_head.convs.1.bn.weight, decode_head.convs.1.bn.bias, decode_head.convs.1.bn.running_mean, decode_head.convs.1.bn.running_var, decode_head.convs.1.bn.num_batches_tracked, decode_head.convs.2.conv.weight, decode_head.convs.2.bn.weight, decode_head.convs.2.bn.bias, decode_head.convs.2.bn.running_mean, decode_head.convs.2.bn.running_var, decode_head.convs.2.bn.num_batches_tracked, decode_head.convs.3.conv.weight, decode_head.convs.3.bn.weight, decode_head.convs.3.bn.bias, decode_head.convs.3.bn.running_mean, decode_head.convs.3.bn.running_var, decode_head.convs.3.bn.num_batches_tracked, decode_head.fusion_conv.conv.weight, decode_head.fusion_conv.bn.weight, decode_head.fusion_conv.bn.bias, decode_head.fusion_conv.bn.running_mean, decode_head.fusion_conv.bn.running_var, decode_head.fusion_conv.bn.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: layers.0.0.projection.weight, layers.0.0.projection.bias, layers.0.0.norm.weight, layers.0.0.norm.bias, layers.0.1.0.norm1.weight, layers.0.1.0.norm1.bias, layers.0.1.0.attn.attn.in_proj_weight, layers.0.1.0.attn.attn.in_proj_bias, layers.0.1.0.attn.attn.out_proj.weight, layers.0.1.0.attn.attn.out_proj.bias, layers.0.1.0.attn.sr.weight, layers.0.1.0.attn.sr.bias, layers.0.1.0.attn.norm.weight, layers.0.1.0.attn.norm.bias, layers.0.1.0.norm2.weight, layers.0.1.0.norm2.bias, layers.0.1.0.ffn.layers.0.weight, layers.0.1.0.ffn.layers.0.bias, layers.0.1.0.ffn.layers.1.weight, layers.0.1.0.ffn.layers.1.bias, layers.0.1.0.ffn.layers.4.weight, layers.0.1.0.ffn.layers.4.bias, layers.0.1.1.norm1.weight, layers.0.1.1.norm1.bias, layers.0.1.1.attn.attn.in_proj_weight, layers.0.1.1.attn.attn.in_proj_bias, layers.0.1.1.attn.attn.out_proj.weight, layers.0.1.1.attn.attn.out_proj.bias, layers.0.1.1.attn.sr.weight, layers.0.1.1.attn.sr.bias, layers.0.1.1.attn.norm.weight, layers.0.1.1.attn.norm.bias, layers.0.1.1.norm2.weight, layers.0.1.1.norm2.bias, layers.0.1.1.ffn.layers.0.weight, layers.0.1.1.ffn.layers.0.bias, layers.0.1.1.ffn.layers.1.weight, layers.0.1.1.ffn.layers.1.bias, layers.0.1.1.ffn.layers.4.weight, layers.0.1.1.ffn.layers.4.bias, layers.0.1.2.norm1.weight, layers.0.1.2.norm1.bias, layers.0.1.2.attn.attn.in_proj_weight, layers.0.1.2.attn.attn.in_proj_bias, layers.0.1.2.attn.attn.out_proj.weight, layers.0.1.2.attn.attn.out_proj.bias, layers.0.1.2.attn.sr.weight, layers.0.1.2.attn.sr.bias, layers.0.1.2.attn.norm.weight, layers.0.1.2.attn.norm.bias, layers.0.1.2.norm2.weight, layers.0.1.2.norm2.bias, layers.0.1.2.ffn.layers.0.weight, layers.0.1.2.ffn.layers.0.bias, layers.0.1.2.ffn.layers.1.weight, layers.0.1.2.ffn.layers.1.bias, layers.0.1.2.ffn.layers.4.weight, layers.0.1.2.ffn.layers.4.bias, layers.0.2.weight, layers.0.2.bias, layers.1.0.projection.weight, layers.1.0.projection.bias, layers.1.0.norm.weight, layers.1.0.norm.bias, layers.1.1.0.norm1.weight, layers.1.1.0.norm1.bias, layers.1.1.0.attn.attn.in_proj_weight, layers.1.1.0.attn.attn.in_proj_bias, layers.1.1.0.attn.attn.out_proj.weight, layers.1.1.0.attn.attn.out_proj.bias, layers.1.1.0.attn.sr.weight, layers.1.1.0.attn.sr.bias, layers.1.1.0.attn.norm.weight, layers.1.1.0.attn.norm.bias, layers.1.1.0.norm2.weight, layers.1.1.0.norm2.bias, layers.1.1.0.ffn.layers.0.weight, layers.1.1.0.ffn.layers.0.bias, layers.1.1.0.ffn.layers.1.weight, layers.1.1.0.ffn.layers.1.bias, layers.1.1.0.ffn.layers.4.weight, layers.1.1.0.ffn.layers.4.bias, layers.1.1.1.norm1.weight, layers.1.1.1.norm1.bias, layers.1.1.1.attn.attn.in_proj_weight, layers.1.1.1.attn.attn.in_proj_bias, layers.1.1.1.attn.attn.out_proj.weight, layers.1.1.1.attn.attn.out_proj.bias, layers.1.1.1.attn.sr.weight, layers.1.1.1.attn.sr.bias, layers.1.1.1.attn.norm.weight, layers.1.1.1.attn.norm.bias, layers.1.1.1.norm2.weight, layers.1.1.1.norm2.bias, layers.1.1.1.ffn.layers.0.weight, layers.1.1.1.ffn.layers.0.bias, layers.1.1.1.ffn.layers.1.weight, layers.1.1.1.ffn.layers.1.bias, layers.1.1.1.ffn.layers.4.weight, layers.1.1.1.ffn.layers.4.bias, layers.1.1.2.norm1.weight, layers.1.1.2.norm1.bias, layers.1.1.2.attn.attn.in_proj_weight, layers.1.1.2.attn.attn.in_proj_bias, layers.1.1.2.attn.attn.out_proj.weight, layers.1.1.2.attn.attn.out_proj.bias, layers.1.1.2.attn.sr.weight, layers.1.1.2.attn.sr.bias, layers.1.1.2.attn.norm.weight, layers.1.1.2.attn.norm.bias, layers.1.1.2.norm2.weight, layers.1.1.2.norm2.bias, layers.1.1.2.ffn.layers.0.weight, layers.1.1.2.ffn.layers.0.bias, layers.1.1.2.ffn.layers.1.weight, layers.1.1.2.ffn.layers.1.bias, layers.1.1.2.ffn.layers.4.weight, layers.1.1.2.ffn.layers.4.bias, layers.1.1.3.norm1.weight, layers.1.1.3.norm1.bias, layers.1.1.3.attn.attn.in_proj_weight, layers.1.1.3.attn.attn.in_proj_bias, layers.1.1.3.attn.attn.out_proj.weight, layers.1.1.3.attn.attn.out_proj.bias, layers.1.1.3.attn.sr.weight, layers.1.1.3.attn.sr.bias, layers.1.1.3.attn.norm.weight, layers.1.1.3.attn.norm.bias, layers.1.1.3.norm2.weight, layers.1.1.3.norm2.bias, layers.1.1.3.ffn.layers.0.weight, layers.1.1.3.ffn.layers.0.bias, layers.1.1.3.ffn.layers.1.weight, layers.1.1.3.ffn.layers.1.bias, layers.1.1.3.ffn.layers.4.weight, layers.1.1.3.ffn.layers.4.bias, layers.1.1.4.norm1.weight, layers.1.1.4.norm1.bias, layers.1.1.4.attn.attn.in_proj_weight, layers.1.1.4.attn.attn.in_proj_bias, layers.1.1.4.attn.attn.out_proj.weight, layers.1.1.4.attn.attn.out_proj.bias, layers.1.1.4.attn.sr.weight, layers.1.1.4.attn.sr.bias, layers.1.1.4.attn.norm.weight, layers.1.1.4.attn.norm.bias, layers.1.1.4.norm2.weight, layers.1.1.4.norm2.bias, layers.1.1.4.ffn.layers.0.weight, layers.1.1.4.ffn.layers.0.bias, layers.1.1.4.ffn.layers.1.weight, layers.1.1.4.ffn.layers.1.bias, layers.1.1.4.ffn.layers.4.weight, layers.1.1.4.ffn.layers.4.bias, layers.1.1.5.norm1.weight, layers.1.1.5.norm1.bias, layers.1.1.5.attn.attn.in_proj_weight, layers.1.1.5.attn.attn.in_proj_bias, layers.1.1.5.attn.attn.out_proj.weight, layers.1.1.5.attn.attn.out_proj.bias, layers.1.1.5.attn.sr.weight, layers.1.1.5.attn.sr.bias, layers.1.1.5.attn.norm.weight, layers.1.1.5.attn.norm.bias, layers.1.1.5.norm2.weight, layers.1.1.5.norm2.bias, layers.1.1.5.ffn.layers.0.weight, layers.1.1.5.ffn.layers.0.bias, layers.1.1.5.ffn.layers.1.weight, layers.1.1.5.ffn.layers.1.bias, layers.1.1.5.ffn.layers.4.weight, layers.1.1.5.ffn.layers.4.bias, layers.1.2.weight, layers.1.2.bias, layers.2.0.projection.weight, layers.2.0.projection.bias, layers.2.0.norm.weight, layers.2.0.norm.bias, layers.2.1.0.norm1.weight, layers.2.1.0.norm1.bias, layers.2.1.0.attn.attn.in_proj_weight, layers.2.1.0.attn.attn.in_proj_bias, layers.2.1.0.attn.attn.out_proj.weight, layers.2.1.0.attn.attn.out_proj.bias, layers.2.1.0.attn.sr.weight, layers.2.1.0.attn.sr.bias, layers.2.1.0.attn.norm.weight, layers.2.1.0.attn.norm.bias, layers.2.1.0.norm2.weight, layers.2.1.0.norm2.bias, layers.2.1.0.ffn.layers.0.weight, layers.2.1.0.ffn.layers.0.bias, layers.2.1.0.ffn.layers.1.weight, layers.2.1.0.ffn.layers.1.bias, layers.2.1.0.ffn.layers.4.weight, layers.2.1.0.ffn.layers.4.bias, layers.2.1.1.norm1.weight, layers.2.1.1.norm1.bias, layers.2.1.1.attn.attn.in_proj_weight, layers.2.1.1.attn.attn.in_proj_bias, layers.2.1.1.attn.attn.out_proj.weight, layers.2.1.1.attn.attn.out_proj.bias, layers.2.1.1.attn.sr.weight, layers.2.1.1.attn.sr.bias, layers.2.1.1.attn.norm.weight, layers.2.1.1.attn.norm.bias, layers.2.1.1.norm2.weight, layers.2.1.1.norm2.bias, layers.2.1.1.ffn.layers.0.weight, layers.2.1.1.ffn.layers.0.bias, layers.2.1.1.ffn.layers.1.weight, layers.2.1.1.ffn.layers.1.bias, layers.2.1.1.ffn.layers.4.weight, layers.2.1.1.ffn.layers.4.bias, layers.2.1.2.norm1.weight, layers.2.1.2.norm1.bias, layers.2.1.2.attn.attn.in_proj_weight, layers.2.1.2.attn.attn.in_proj_bias, layers.2.1.2.attn.attn.out_proj.weight, layers.2.1.2.attn.attn.out_proj.bias, layers.2.1.2.attn.sr.weight, layers.2.1.2.attn.sr.bias, layers.2.1.2.attn.norm.weight, layers.2.1.2.attn.norm.bias, layers.2.1.2.norm2.weight, layers.2.1.2.norm2.bias, layers.2.1.2.ffn.layers.0.weight, layers.2.1.2.ffn.layers.0.bias, layers.2.1.2.ffn.layers.1.weight, layers.2.1.2.ffn.layers.1.bias, layers.2.1.2.ffn.layers.4.weight, layers.2.1.2.ffn.layers.4.bias, layers.2.1.3.norm1.weight, layers.2.1.3.norm1.bias, layers.2.1.3.attn.attn.in_proj_weight, layers.2.1.3.attn.attn.in_proj_bias, layers.2.1.3.attn.attn.out_proj.weight, layers.2.1.3.attn.attn.out_proj.bias, layers.2.1.3.attn.sr.weight, layers.2.1.3.attn.sr.bias, layers.2.1.3.attn.norm.weight, layers.2.1.3.attn.norm.bias, layers.2.1.3.norm2.weight, layers.2.1.3.norm2.bias, layers.2.1.3.ffn.layers.0.weight, layers.2.1.3.ffn.layers.0.bias, layers.2.1.3.ffn.layers.1.weight, layers.2.1.3.ffn.layers.1.bias, layers.2.1.3.ffn.layers.4.weight, layers.2.1.3.ffn.layers.4.bias, layers.2.1.4.norm1.weight, layers.2.1.4.norm1.bias, layers.2.1.4.attn.attn.in_proj_weight, layers.2.1.4.attn.attn.in_proj_bias, layers.2.1.4.attn.attn.out_proj.weight, layers.2.1.4.attn.attn.out_proj.bias, layers.2.1.4.attn.sr.weight, layers.2.1.4.attn.sr.bias, layers.2.1.4.attn.norm.weight, layers.2.1.4.attn.norm.bias, layers.2.1.4.norm2.weight, layers.2.1.4.norm2.bias, layers.2.1.4.ffn.layers.0.weight, layers.2.1.4.ffn.layers.0.bias, layers.2.1.4.ffn.layers.1.weight, layers.2.1.4.ffn.layers.1.bias, layers.2.1.4.ffn.layers.4.weight, layers.2.1.4.ffn.layers.4.bias, layers.2.1.5.norm1.weight, layers.2.1.5.norm1.bias, layers.2.1.5.attn.attn.in_proj_weight, layers.2.1.5.attn.attn.in_proj_bias, layers.2.1.5.attn.attn.out_proj.weight, layers.2.1.5.attn.attn.out_proj.bias, layers.2.1.5.attn.sr.weight, layers.2.1.5.attn.sr.bias, layers.2.1.5.attn.norm.weight, layers.2.1.5.attn.norm.bias, layers.2.1.5.norm2.weight, layers.2.1.5.norm2.bias, layers.2.1.5.ffn.layers.0.weight, layers.2.1.5.ffn.layers.0.bias, layers.2.1.5.ffn.layers.1.weight, layers.2.1.5.ffn.layers.1.bias, layers.2.1.5.ffn.layers.4.weight, layers.2.1.5.ffn.layers.4.bias, layers.2.1.6.norm1.weight, layers.2.1.6.norm1.bias, layers.2.1.6.attn.attn.in_proj_weight, layers.2.1.6.attn.attn.in_proj_bias, layers.2.1.6.attn.attn.out_proj.weight, layers.2.1.6.attn.attn.out_proj.bias, layers.2.1.6.attn.sr.weight, layers.2.1.6.attn.sr.bias, layers.2.1.6.attn.norm.weight, layers.2.1.6.attn.norm.bias, layers.2.1.6.norm2.weight, layers.2.1.6.norm2.bias, layers.2.1.6.ffn.layers.0.weight, layers.2.1.6.ffn.layers.0.bias, layers.2.1.6.ffn.layers.1.weight, layers.2.1.6.ffn.layers.1.bias, layers.2.1.6.ffn.layers.4.weight, layers.2.1.6.ffn.layers.4.bias, layers.2.1.7.norm1.weight, layers.2.1.7.norm1.bias, layers.2.1.7.attn.attn.in_proj_weight, layers.2.1.7.attn.attn.in_proj_bias, layers.2.1.7.attn.attn.out_proj.weight, layers.2.1.7.attn.attn.out_proj.bias, layers.2.1.7.attn.sr.weight, layers.2.1.7.attn.sr.bias, layers.2.1.7.attn.norm.weight, layers.2.1.7.attn.norm.bias, layers.2.1.7.norm2.weight, layers.2.1.7.norm2.bias, layers.2.1.7.ffn.layers.0.weight, layers.2.1.7.ffn.layers.0.bias, layers.2.1.7.ffn.layers.1.weight, layers.2.1.7.ffn.layers.1.bias, layers.2.1.7.ffn.layers.4.weight, layers.2.1.7.ffn.layers.4.bias, layers.2.1.8.norm1.weight, layers.2.1.8.norm1.bias, layers.2.1.8.attn.attn.in_proj_weight, layers.2.1.8.attn.attn.in_proj_bias, layers.2.1.8.attn.attn.out_proj.weight, layers.2.1.8.attn.attn.out_proj.bias, layers.2.1.8.attn.sr.weight, layers.2.1.8.attn.sr.bias, layers.2.1.8.attn.norm.weight, layers.2.1.8.attn.norm.bias, layers.2.1.8.norm2.weight, layers.2.1.8.norm2.bias, layers.2.1.8.ffn.layers.0.weight, layers.2.1.8.ffn.layers.0.bias, layers.2.1.8.ffn.layers.1.weight, layers.2.1.8.ffn.layers.1.bias, layers.2.1.8.ffn.layers.4.weight, layers.2.1.8.ffn.layers.4.bias, layers.2.1.9.norm1.weight, layers.2.1.9.norm1.bias, layers.2.1.9.attn.attn.in_proj_weight, layers.2.1.9.attn.attn.in_proj_bias, layers.2.1.9.attn.attn.out_proj.weight, layers.2.1.9.attn.attn.out_proj.bias, layers.2.1.9.attn.sr.weight, layers.2.1.9.attn.sr.bias, layers.2.1.9.attn.norm.weight, layers.2.1.9.attn.norm.bias, layers.2.1.9.norm2.weight, layers.2.1.9.norm2.bias, layers.2.1.9.ffn.layers.0.weight, layers.2.1.9.ffn.layers.0.bias, layers.2.1.9.ffn.layers.1.weight, layers.2.1.9.ffn.layers.1.bias, layers.2.1.9.ffn.layers.4.weight, layers.2.1.9.ffn.layers.4.bias, layers.2.1.10.norm1.weight, layers.2.1.10.norm1.bias, layers.2.1.10.attn.attn.in_proj_weight, layers.2.1.10.attn.attn.in_proj_bias, layers.2.1.10.attn.attn.out_proj.weight, layers.2.1.10.attn.attn.out_proj.bias, layers.2.1.10.attn.sr.weight, layers.2.1.10.attn.sr.bias, layers.2.1.10.attn.norm.weight, layers.2.1.10.attn.norm.bias, layers.2.1.10.norm2.weight, layers.2.1.10.norm2.bias, layers.2.1.10.ffn.layers.0.weight, layers.2.1.10.ffn.layers.0.bias, layers.2.1.10.ffn.layers.1.weight, layers.2.1.10.ffn.layers.1.bias, layers.2.1.10.ffn.layers.4.weight, layers.2.1.10.ffn.layers.4.bias, layers.2.1.11.norm1.weight, layers.2.1.11.norm1.bias, layers.2.1.11.attn.attn.in_proj_weight, layers.2.1.11.attn.attn.in_proj_bias, layers.2.1.11.attn.attn.out_proj.weight, layers.2.1.11.attn.attn.out_proj.bias, layers.2.1.11.attn.sr.weight, layers.2.1.11.attn.sr.bias, layers.2.1.11.attn.norm.weight, layers.2.1.11.attn.norm.bias, layers.2.1.11.norm2.weight, layers.2.1.11.norm2.bias, layers.2.1.11.ffn.layers.0.weight, layers.2.1.11.ffn.layers.0.bias, layers.2.1.11.ffn.layers.1.weight, layers.2.1.11.ffn.layers.1.bias, layers.2.1.11.ffn.layers.4.weight, layers.2.1.11.ffn.layers.4.bias, layers.2.1.12.norm1.weight, layers.2.1.12.norm1.bias, layers.2.1.12.attn.attn.in_proj_weight, layers.2.1.12.attn.attn.in_proj_bias, layers.2.1.12.attn.attn.out_proj.weight, layers.2.1.12.attn.attn.out_proj.bias, layers.2.1.12.attn.sr.weight, layers.2.1.12.attn.sr.bias, layers.2.1.12.attn.norm.weight, layers.2.1.12.attn.norm.bias, layers.2.1.12.norm2.weight, layers.2.1.12.norm2.bias, layers.2.1.12.ffn.layers.0.weight, layers.2.1.12.ffn.layers.0.bias, layers.2.1.12.ffn.layers.1.weight, layers.2.1.12.ffn.layers.1.bias, layers.2.1.12.ffn.layers.4.weight, layers.2.1.12.ffn.layers.4.bias, layers.2.1.13.norm1.weight, layers.2.1.13.norm1.bias, layers.2.1.13.attn.attn.in_proj_weight, layers.2.1.13.attn.attn.in_proj_bias, layers.2.1.13.attn.attn.out_proj.weight, layers.2.1.13.attn.attn.out_proj.bias, layers.2.1.13.attn.sr.weight, layers.2.1.13.attn.sr.bias, layers.2.1.13.attn.norm.weight, layers.2.1.13.attn.norm.bias, layers.2.1.13.norm2.weight, layers.2.1.13.norm2.bias, layers.2.1.13.ffn.layers.0.weight, layers.2.1.13.ffn.layers.0.bias, layers.2.1.13.ffn.layers.1.weight, layers.2.1.13.ffn.layers.1.bias, layers.2.1.13.ffn.layers.4.weight, layers.2.1.13.ffn.layers.4.bias, layers.2.1.14.norm1.weight, layers.2.1.14.norm1.bias, layers.2.1.14.attn.attn.in_proj_weight, layers.2.1.14.attn.attn.in_proj_bias, layers.2.1.14.attn.attn.out_proj.weight, layers.2.1.14.attn.attn.out_proj.bias, layers.2.1.14.attn.sr.weight, layers.2.1.14.attn.sr.bias, layers.2.1.14.attn.norm.weight, layers.2.1.14.attn.norm.bias, layers.2.1.14.norm2.weight, layers.2.1.14.norm2.bias, layers.2.1.14.ffn.layers.0.weight, layers.2.1.14.ffn.layers.0.bias, layers.2.1.14.ffn.layers.1.weight, layers.2.1.14.ffn.layers.1.bias, layers.2.1.14.ffn.layers.4.weight, layers.2.1.14.ffn.layers.4.bias, layers.2.1.15.norm1.weight, layers.2.1.15.norm1.bias, layers.2.1.15.attn.attn.in_proj_weight, layers.2.1.15.attn.attn.in_proj_bias, layers.2.1.15.attn.attn.out_proj.weight, layers.2.1.15.attn.attn.out_proj.bias, layers.2.1.15.attn.sr.weight, layers.2.1.15.attn.sr.bias, layers.2.1.15.attn.norm.weight, layers.2.1.15.attn.norm.bias, layers.2.1.15.norm2.weight, layers.2.1.15.norm2.bias, layers.2.1.15.ffn.layers.0.weight, layers.2.1.15.ffn.layers.0.bias, layers.2.1.15.ffn.layers.1.weight, layers.2.1.15.ffn.layers.1.bias, layers.2.1.15.ffn.layers.4.weight, layers.2.1.15.ffn.layers.4.bias, layers.2.1.16.norm1.weight, layers.2.1.16.norm1.bias, layers.2.1.16.attn.attn.in_proj_weight, layers.2.1.16.attn.attn.in_proj_bias, layers.2.1.16.attn.attn.out_proj.weight, layers.2.1.16.attn.attn.out_proj.bias, layers.2.1.16.attn.sr.weight, layers.2.1.16.attn.sr.bias, layers.2.1.16.attn.norm.weight, layers.2.1.16.attn.norm.bias, layers.2.1.16.norm2.weight, layers.2.1.16.norm2.bias, layers.2.1.16.ffn.layers.0.weight, layers.2.1.16.ffn.layers.0.bias, layers.2.1.16.ffn.layers.1.weight, layers.2.1.16.ffn.layers.1.bias, layers.2.1.16.ffn.layers.4.weight, layers.2.1.16.ffn.layers.4.bias, layers.2.1.17.norm1.weight, layers.2.1.17.norm1.bias, layers.2.1.17.attn.attn.in_proj_weight, layers.2.1.17.attn.attn.in_proj_bias, layers.2.1.17.attn.attn.out_proj.weight, layers.2.1.17.attn.attn.out_proj.bias, layers.2.1.17.attn.sr.weight, layers.2.1.17.attn.sr.bias, layers.2.1.17.attn.norm.weight, layers.2.1.17.attn.norm.bias, layers.2.1.17.norm2.weight, layers.2.1.17.norm2.bias, layers.2.1.17.ffn.layers.0.weight, layers.2.1.17.ffn.layers.0.bias, layers.2.1.17.ffn.layers.1.weight, layers.2.1.17.ffn.layers.1.bias, layers.2.1.17.ffn.layers.4.weight, layers.2.1.17.ffn.layers.4.bias, layers.2.1.18.norm1.weight, layers.2.1.18.norm1.bias, layers.2.1.18.attn.attn.in_proj_weight, layers.2.1.18.attn.attn.in_proj_bias, layers.2.1.18.attn.attn.out_proj.weight, layers.2.1.18.attn.attn.out_proj.bias, layers.2.1.18.attn.sr.weight, layers.2.1.18.attn.sr.bias, layers.2.1.18.attn.norm.weight, layers.2.1.18.attn.norm.bias, layers.2.1.18.norm2.weight, layers.2.1.18.norm2.bias, layers.2.1.18.ffn.layers.0.weight, layers.2.1.18.ffn.layers.0.bias, layers.2.1.18.ffn.layers.1.weight, layers.2.1.18.ffn.layers.1.bias, layers.2.1.18.ffn.layers.4.weight, layers.2.1.18.ffn.layers.4.bias, layers.2.1.19.norm1.weight, layers.2.1.19.norm1.bias, layers.2.1.19.attn.attn.in_proj_weight, layers.2.1.19.attn.attn.in_proj_bias, layers.2.1.19.attn.attn.out_proj.weight, layers.2.1.19.attn.attn.out_proj.bias, layers.2.1.19.attn.sr.weight, layers.2.1.19.attn.sr.bias, layers.2.1.19.attn.norm.weight, layers.2.1.19.attn.norm.bias, layers.2.1.19.norm2.weight, layers.2.1.19.norm2.bias, layers.2.1.19.ffn.layers.0.weight, layers.2.1.19.ffn.layers.0.bias, layers.2.1.19.ffn.layers.1.weight, layers.2.1.19.ffn.layers.1.bias, layers.2.1.19.ffn.layers.4.weight, layers.2.1.19.ffn.layers.4.bias, layers.2.1.20.norm1.weight, layers.2.1.20.norm1.bias, layers.2.1.20.attn.attn.in_proj_weight, layers.2.1.20.attn.attn.in_proj_bias, layers.2.1.20.attn.attn.out_proj.weight, layers.2.1.20.attn.attn.out_proj.bias, layers.2.1.20.attn.sr.weight, layers.2.1.20.attn.sr.bias, layers.2.1.20.attn.norm.weight, layers.2.1.20.attn.norm.bias, layers.2.1.20.norm2.weight, layers.2.1.20.norm2.bias, layers.2.1.20.ffn.layers.0.weight, layers.2.1.20.ffn.layers.0.bias, layers.2.1.20.ffn.layers.1.weight, layers.2.1.20.ffn.layers.1.bias, layers.2.1.20.ffn.layers.4.weight, layers.2.1.20.ffn.layers.4.bias, layers.2.1.21.norm1.weight, layers.2.1.21.norm1.bias, layers.2.1.21.attn.attn.in_proj_weight, layers.2.1.21.attn.attn.in_proj_bias, layers.2.1.21.attn.attn.out_proj.weight, layers.2.1.21.attn.attn.out_proj.bias, layers.2.1.21.attn.sr.weight, layers.2.1.21.attn.sr.bias, layers.2.1.21.attn.norm.weight, layers.2.1.21.attn.norm.bias, layers.2.1.21.norm2.weight, layers.2.1.21.norm2.bias, layers.2.1.21.ffn.layers.0.weight, layers.2.1.21.ffn.layers.0.bias, layers.2.1.21.ffn.layers.1.weight, layers.2.1.21.ffn.layers.1.bias, layers.2.1.21.ffn.layers.4.weight, layers.2.1.21.ffn.layers.4.bias, layers.2.1.22.norm1.weight, layers.2.1.22.norm1.bias, layers.2.1.22.attn.attn.in_proj_weight, layers.2.1.22.attn.attn.in_proj_bias, layers.2.1.22.attn.attn.out_proj.weight, layers.2.1.22.attn.attn.out_proj.bias, layers.2.1.22.attn.sr.weight, layers.2.1.22.attn.sr.bias, layers.2.1.22.attn.norm.weight, layers.2.1.22.attn.norm.bias, layers.2.1.22.norm2.weight, layers.2.1.22.norm2.bias, layers.2.1.22.ffn.layers.0.weight, layers.2.1.22.ffn.layers.0.bias, layers.2.1.22.ffn.layers.1.weight, layers.2.1.22.ffn.layers.1.bias, layers.2.1.22.ffn.layers.4.weight, layers.2.1.22.ffn.layers.4.bias, layers.2.1.23.norm1.weight, layers.2.1.23.norm1.bias, layers.2.1.23.attn.attn.in_proj_weight, layers.2.1.23.attn.attn.in_proj_bias, layers.2.1.23.attn.attn.out_proj.weight, layers.2.1.23.attn.attn.out_proj.bias, layers.2.1.23.attn.sr.weight, layers.2.1.23.attn.sr.bias, layers.2.1.23.attn.norm.weight, layers.2.1.23.attn.norm.bias, layers.2.1.23.norm2.weight, layers.2.1.23.norm2.bias, layers.2.1.23.ffn.layers.0.weight, layers.2.1.23.ffn.layers.0.bias, layers.2.1.23.ffn.layers.1.weight, layers.2.1.23.ffn.layers.1.bias, layers.2.1.23.ffn.layers.4.weight, layers.2.1.23.ffn.layers.4.bias, layers.2.1.24.norm1.weight, layers.2.1.24.norm1.bias, layers.2.1.24.attn.attn.in_proj_weight, layers.2.1.24.attn.attn.in_proj_bias, layers.2.1.24.attn.attn.out_proj.weight, layers.2.1.24.attn.attn.out_proj.bias, layers.2.1.24.attn.sr.weight, layers.2.1.24.attn.sr.bias, layers.2.1.24.attn.norm.weight, layers.2.1.24.attn.norm.bias, layers.2.1.24.norm2.weight, layers.2.1.24.norm2.bias, layers.2.1.24.ffn.layers.0.weight, layers.2.1.24.ffn.layers.0.bias, layers.2.1.24.ffn.layers.1.weight, layers.2.1.24.ffn.layers.1.bias, layers.2.1.24.ffn.layers.4.weight, layers.2.1.24.ffn.layers.4.bias, layers.2.1.25.norm1.weight, layers.2.1.25.norm1.bias, layers.2.1.25.attn.attn.in_proj_weight, layers.2.1.25.attn.attn.in_proj_bias, layers.2.1.25.attn.attn.out_proj.weight, layers.2.1.25.attn.attn.out_proj.bias, layers.2.1.25.attn.sr.weight, layers.2.1.25.attn.sr.bias, layers.2.1.25.attn.norm.weight, layers.2.1.25.attn.norm.bias, layers.2.1.25.norm2.weight, layers.2.1.25.norm2.bias, layers.2.1.25.ffn.layers.0.weight, layers.2.1.25.ffn.layers.0.bias, layers.2.1.25.ffn.layers.1.weight, layers.2.1.25.ffn.layers.1.bias, layers.2.1.25.ffn.layers.4.weight, layers.2.1.25.ffn.layers.4.bias, layers.2.1.26.norm1.weight, layers.2.1.26.norm1.bias, layers.2.1.26.attn.attn.in_proj_weight, layers.2.1.26.attn.attn.in_proj_bias, layers.2.1.26.attn.attn.out_proj.weight, layers.2.1.26.attn.attn.out_proj.bias, layers.2.1.26.attn.sr.weight, layers.2.1.26.attn.sr.bias, layers.2.1.26.attn.norm.weight, layers.2.1.26.attn.norm.bias, layers.2.1.26.norm2.weight, layers.2.1.26.norm2.bias, layers.2.1.26.ffn.layers.0.weight, layers.2.1.26.ffn.layers.0.bias, layers.2.1.26.ffn.layers.1.weight, layers.2.1.26.ffn.layers.1.bias, layers.2.1.26.ffn.layers.4.weight, layers.2.1.26.ffn.layers.4.bias, layers.2.1.27.norm1.weight, layers.2.1.27.norm1.bias, layers.2.1.27.attn.attn.in_proj_weight, layers.2.1.27.attn.attn.in_proj_bias, layers.2.1.27.attn.attn.out_proj.weight, layers.2.1.27.attn.attn.out_proj.bias, layers.2.1.27.attn.sr.weight, layers.2.1.27.attn.sr.bias, layers.2.1.27.attn.norm.weight, layers.2.1.27.attn.norm.bias, layers.2.1.27.norm2.weight, layers.2.1.27.norm2.bias, layers.2.1.27.ffn.layers.0.weight, layers.2.1.27.ffn.layers.0.bias, layers.2.1.27.ffn.layers.1.weight, layers.2.1.27.ffn.layers.1.bias, layers.2.1.27.ffn.layers.4.weight, layers.2.1.27.ffn.layers.4.bias, layers.2.1.28.norm1.weight, layers.2.1.28.norm1.bias, layers.2.1.28.attn.attn.in_proj_weight, layers.2.1.28.attn.attn.in_proj_bias, layers.2.1.28.attn.attn.out_proj.weight, layers.2.1.28.attn.attn.out_proj.bias, layers.2.1.28.attn.sr.weight, layers.2.1.28.attn.sr.bias, layers.2.1.28.attn.norm.weight, layers.2.1.28.attn.norm.bias, layers.2.1.28.norm2.weight, layers.2.1.28.norm2.bias, layers.2.1.28.ffn.layers.0.weight, layers.2.1.28.ffn.layers.0.bias, layers.2.1.28.ffn.layers.1.weight, layers.2.1.28.ffn.layers.1.bias, layers.2.1.28.ffn.layers.4.weight, layers.2.1.28.ffn.layers.4.bias, layers.2.1.29.norm1.weight, layers.2.1.29.norm1.bias, layers.2.1.29.attn.attn.in_proj_weight, layers.2.1.29.attn.attn.in_proj_bias, layers.2.1.29.attn.attn.out_proj.weight, layers.2.1.29.attn.attn.out_proj.bias, layers.2.1.29.attn.sr.weight, layers.2.1.29.attn.sr.bias, layers.2.1.29.attn.norm.weight, layers.2.1.29.attn.norm.bias, layers.2.1.29.norm2.weight, layers.2.1.29.norm2.bias, layers.2.1.29.ffn.layers.0.weight, layers.2.1.29.ffn.layers.0.bias, layers.2.1.29.ffn.layers.1.weight, layers.2.1.29.ffn.layers.1.bias, layers.2.1.29.ffn.layers.4.weight, layers.2.1.29.ffn.layers.4.bias, layers.2.1.30.norm1.weight, layers.2.1.30.norm1.bias, layers.2.1.30.attn.attn.in_proj_weight, layers.2.1.30.attn.attn.in_proj_bias, layers.2.1.30.attn.attn.out_proj.weight, layers.2.1.30.attn.attn.out_proj.bias, layers.2.1.30.attn.sr.weight, layers.2.1.30.attn.sr.bias, layers.2.1.30.attn.norm.weight, layers.2.1.30.attn.norm.bias, layers.2.1.30.norm2.weight, layers.2.1.30.norm2.bias, layers.2.1.30.ffn.layers.0.weight, layers.2.1.30.ffn.layers.0.bias, layers.2.1.30.ffn.layers.1.weight, layers.2.1.30.ffn.layers.1.bias, layers.2.1.30.ffn.layers.4.weight, layers.2.1.30.ffn.layers.4.bias, layers.2.1.31.norm1.weight, layers.2.1.31.norm1.bias, layers.2.1.31.attn.attn.in_proj_weight, layers.2.1.31.attn.attn.in_proj_bias, layers.2.1.31.attn.attn.out_proj.weight, layers.2.1.31.attn.attn.out_proj.bias, layers.2.1.31.attn.sr.weight, layers.2.1.31.attn.sr.bias, layers.2.1.31.attn.norm.weight, layers.2.1.31.attn.norm.bias, layers.2.1.31.norm2.weight, layers.2.1.31.norm2.bias, layers.2.1.31.ffn.layers.0.weight, layers.2.1.31.ffn.layers.0.bias, layers.2.1.31.ffn.layers.1.weight, layers.2.1.31.ffn.layers.1.bias, layers.2.1.31.ffn.layers.4.weight, layers.2.1.31.ffn.layers.4.bias, layers.2.1.32.norm1.weight, layers.2.1.32.norm1.bias, layers.2.1.32.attn.attn.in_proj_weight, layers.2.1.32.attn.attn.in_proj_bias, layers.2.1.32.attn.attn.out_proj.weight, layers.2.1.32.attn.attn.out_proj.bias, layers.2.1.32.attn.sr.weight, layers.2.1.32.attn.sr.bias, layers.2.1.32.attn.norm.weight, layers.2.1.32.attn.norm.bias, layers.2.1.32.norm2.weight, layers.2.1.32.norm2.bias, layers.2.1.32.ffn.layers.0.weight, layers.2.1.32.ffn.layers.0.bias, layers.2.1.32.ffn.layers.1.weight, layers.2.1.32.ffn.layers.1.bias, layers.2.1.32.ffn.layers.4.weight, layers.2.1.32.ffn.layers.4.bias, layers.2.1.33.norm1.weight, layers.2.1.33.norm1.bias, layers.2.1.33.attn.attn.in_proj_weight, layers.2.1.33.attn.attn.in_proj_bias, layers.2.1.33.attn.attn.out_proj.weight, layers.2.1.33.attn.attn.out_proj.bias, layers.2.1.33.attn.sr.weight, layers.2.1.33.attn.sr.bias, layers.2.1.33.attn.norm.weight, layers.2.1.33.attn.norm.bias, layers.2.1.33.norm2.weight, layers.2.1.33.norm2.bias, layers.2.1.33.ffn.layers.0.weight, layers.2.1.33.ffn.layers.0.bias, layers.2.1.33.ffn.layers.1.weight, layers.2.1.33.ffn.layers.1.bias, layers.2.1.33.ffn.layers.4.weight, layers.2.1.33.ffn.layers.4.bias, layers.2.1.34.norm1.weight, layers.2.1.34.norm1.bias, layers.2.1.34.attn.attn.in_proj_weight, layers.2.1.34.attn.attn.in_proj_bias, layers.2.1.34.attn.attn.out_proj.weight, layers.2.1.34.attn.attn.out_proj.bias, layers.2.1.34.attn.sr.weight, layers.2.1.34.attn.sr.bias, layers.2.1.34.attn.norm.weight, layers.2.1.34.attn.norm.bias, layers.2.1.34.norm2.weight, layers.2.1.34.norm2.bias, layers.2.1.34.ffn.layers.0.weight, layers.2.1.34.ffn.layers.0.bias, layers.2.1.34.ffn.layers.1.weight, layers.2.1.34.ffn.layers.1.bias, layers.2.1.34.ffn.layers.4.weight, layers.2.1.34.ffn.layers.4.bias, layers.2.1.35.norm1.weight, layers.2.1.35.norm1.bias, layers.2.1.35.attn.attn.in_proj_weight, layers.2.1.35.attn.attn.in_proj_bias, layers.2.1.35.attn.attn.out_proj.weight, layers.2.1.35.attn.attn.out_proj.bias, layers.2.1.35.attn.sr.weight, layers.2.1.35.attn.sr.bias, layers.2.1.35.attn.norm.weight, layers.2.1.35.attn.norm.bias, layers.2.1.35.norm2.weight, layers.2.1.35.norm2.bias, layers.2.1.35.ffn.layers.0.weight, layers.2.1.35.ffn.layers.0.bias, layers.2.1.35.ffn.layers.1.weight, layers.2.1.35.ffn.layers.1.bias, layers.2.1.35.ffn.layers.4.weight, layers.2.1.35.ffn.layers.4.bias, layers.2.1.36.norm1.weight, layers.2.1.36.norm1.bias, layers.2.1.36.attn.attn.in_proj_weight, layers.2.1.36.attn.attn.in_proj_bias, layers.2.1.36.attn.attn.out_proj.weight, layers.2.1.36.attn.attn.out_proj.bias, layers.2.1.36.attn.sr.weight, layers.2.1.36.attn.sr.bias, layers.2.1.36.attn.norm.weight, layers.2.1.36.attn.norm.bias, layers.2.1.36.norm2.weight, layers.2.1.36.norm2.bias, layers.2.1.36.ffn.layers.0.weight, layers.2.1.36.ffn.layers.0.bias, layers.2.1.36.ffn.layers.1.weight, layers.2.1.36.ffn.layers.1.bias, layers.2.1.36.ffn.layers.4.weight, layers.2.1.36.ffn.layers.4.bias, layers.2.1.37.norm1.weight, layers.2.1.37.norm1.bias, layers.2.1.37.attn.attn.in_proj_weight, layers.2.1.37.attn.attn.in_proj_bias, layers.2.1.37.attn.attn.out_proj.weight, layers.2.1.37.attn.attn.out_proj.bias, layers.2.1.37.attn.sr.weight, layers.2.1.37.attn.sr.bias, layers.2.1.37.attn.norm.weight, layers.2.1.37.attn.norm.bias, layers.2.1.37.norm2.weight, layers.2.1.37.norm2.bias, layers.2.1.37.ffn.layers.0.weight, layers.2.1.37.ffn.layers.0.bias, layers.2.1.37.ffn.layers.1.weight, layers.2.1.37.ffn.layers.1.bias, layers.2.1.37.ffn.layers.4.weight, layers.2.1.37.ffn.layers.4.bias, layers.2.1.38.norm1.weight, layers.2.1.38.norm1.bias, layers.2.1.38.attn.attn.in_proj_weight, layers.2.1.38.attn.attn.in_proj_bias, layers.2.1.38.attn.attn.out_proj.weight, layers.2.1.38.attn.attn.out_proj.bias, layers.2.1.38.attn.sr.weight, layers.2.1.38.attn.sr.bias, layers.2.1.38.attn.norm.weight, layers.2.1.38.attn.norm.bias, layers.2.1.38.norm2.weight, layers.2.1.38.norm2.bias, layers.2.1.38.ffn.layers.0.weight, layers.2.1.38.ffn.layers.0.bias, layers.2.1.38.ffn.layers.1.weight, layers.2.1.38.ffn.layers.1.bias, layers.2.1.38.ffn.layers.4.weight, layers.2.1.38.ffn.layers.4.bias, layers.2.1.39.norm1.weight, layers.2.1.39.norm1.bias, layers.2.1.39.attn.attn.in_proj_weight, layers.2.1.39.attn.attn.in_proj_bias, layers.2.1.39.attn.attn.out_proj.weight, layers.2.1.39.attn.attn.out_proj.bias, layers.2.1.39.attn.sr.weight, layers.2.1.39.attn.sr.bias, layers.2.1.39.attn.norm.weight, layers.2.1.39.attn.norm.bias, layers.2.1.39.norm2.weight, layers.2.1.39.norm2.bias, layers.2.1.39.ffn.layers.0.weight, layers.2.1.39.ffn.layers.0.bias, layers.2.1.39.ffn.layers.1.weight, layers.2.1.39.ffn.layers.1.bias, layers.2.1.39.ffn.layers.4.weight, layers.2.1.39.ffn.layers.4.bias, layers.2.2.weight, layers.2.2.bias, layers.3.0.projection.weight, layers.3.0.projection.bias, layers.3.0.norm.weight, layers.3.0.norm.bias, layers.3.1.0.norm1.weight, layers.3.1.0.norm1.bias, layers.3.1.0.attn.attn.in_proj_weight, layers.3.1.0.attn.attn.in_proj_bias, layers.3.1.0.attn.attn.out_proj.weight, layers.3.1.0.attn.attn.out_proj.bias, layers.3.1.0.norm2.weight, layers.3.1.0.norm2.bias, layers.3.1.0.ffn.layers.0.weight, layers.3.1.0.ffn.layers.0.bias, layers.3.1.0.ffn.layers.1.weight, layers.3.1.0.ffn.layers.1.bias, layers.3.1.0.ffn.layers.4.weight, layers.3.1.0.ffn.layers.4.bias, layers.3.1.1.norm1.weight, layers.3.1.1.norm1.bias, layers.3.1.1.attn.attn.in_proj_weight, layers.3.1.1.attn.attn.in_proj_bias, layers.3.1.1.attn.attn.out_proj.weight, layers.3.1.1.attn.attn.out_proj.bias, layers.3.1.1.norm2.weight, layers.3.1.1.norm2.bias, layers.3.1.1.ffn.layers.0.weight, layers.3.1.1.ffn.layers.0.bias, layers.3.1.1.ffn.layers.1.weight, layers.3.1.1.ffn.layers.1.bias, layers.3.1.1.ffn.layers.4.weight, layers.3.1.1.ffn.layers.4.bias, layers.3.1.2.norm1.weight, layers.3.1.2.norm1.bias, layers.3.1.2.attn.attn.in_proj_weight, layers.3.1.2.attn.attn.in_proj_bias, layers.3.1.2.attn.attn.out_proj.weight, layers.3.1.2.attn.attn.out_proj.bias, layers.3.1.2.norm2.weight, layers.3.1.2.norm2.bias, layers.3.1.2.ffn.layers.0.weight, layers.3.1.2.ffn.layers.0.bias, layers.3.1.2.ffn.layers.1.weight, layers.3.1.2.ffn.layers.1.bias, layers.3.1.2.ffn.layers.4.weight, layers.3.1.2.ffn.layers.4.bias, layers.3.2.weight, layers.3.2.bias\n",
      "\n",
      "03/09 19:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth\n",
      "03/09 19:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth\" to /root/.cache/torch/hub/checkpoints/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 19:55:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.patch_embed.projection.weight, backbone.patch_embed.projection.bias, backbone.patch_embed.norm.weight, backbone.patch_embed.norm.bias, backbone.stages.0.blocks.0.norm1.weight, backbone.stages.0.blocks.0.norm1.bias, backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.0.attn.w_msa.relative_position_index, backbone.stages.0.blocks.0.attn.w_msa.qkv.weight, backbone.stages.0.blocks.0.attn.w_msa.qkv.bias, backbone.stages.0.blocks.0.attn.w_msa.proj.weight, backbone.stages.0.blocks.0.attn.w_msa.proj.bias, backbone.stages.0.blocks.0.norm2.weight, backbone.stages.0.blocks.0.norm2.bias, backbone.stages.0.blocks.0.ffn.layers.0.0.weight, backbone.stages.0.blocks.0.ffn.layers.0.0.bias, backbone.stages.0.blocks.0.ffn.layers.1.weight, backbone.stages.0.blocks.0.ffn.layers.1.bias, backbone.stages.0.blocks.1.norm1.weight, backbone.stages.0.blocks.1.norm1.bias, backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.0.blocks.1.attn.w_msa.relative_position_index, backbone.stages.0.blocks.1.attn.w_msa.qkv.weight, backbone.stages.0.blocks.1.attn.w_msa.qkv.bias, backbone.stages.0.blocks.1.attn.w_msa.proj.weight, backbone.stages.0.blocks.1.attn.w_msa.proj.bias, backbone.stages.0.blocks.1.norm2.weight, backbone.stages.0.blocks.1.norm2.bias, backbone.stages.0.blocks.1.ffn.layers.0.0.weight, backbone.stages.0.blocks.1.ffn.layers.0.0.bias, backbone.stages.0.blocks.1.ffn.layers.1.weight, backbone.stages.0.blocks.1.ffn.layers.1.bias, backbone.stages.0.downsample.reduction.weight, backbone.stages.0.downsample.norm.weight, backbone.stages.0.downsample.norm.bias, backbone.stages.1.blocks.0.norm1.weight, backbone.stages.1.blocks.0.norm1.bias, backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.0.attn.w_msa.relative_position_index, backbone.stages.1.blocks.0.attn.w_msa.qkv.weight, backbone.stages.1.blocks.0.attn.w_msa.qkv.bias, backbone.stages.1.blocks.0.attn.w_msa.proj.weight, backbone.stages.1.blocks.0.attn.w_msa.proj.bias, backbone.stages.1.blocks.0.norm2.weight, backbone.stages.1.blocks.0.norm2.bias, backbone.stages.1.blocks.0.ffn.layers.0.0.weight, backbone.stages.1.blocks.0.ffn.layers.0.0.bias, backbone.stages.1.blocks.0.ffn.layers.1.weight, backbone.stages.1.blocks.0.ffn.layers.1.bias, backbone.stages.1.blocks.1.norm1.weight, backbone.stages.1.blocks.1.norm1.bias, backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.1.blocks.1.attn.w_msa.relative_position_index, backbone.stages.1.blocks.1.attn.w_msa.qkv.weight, backbone.stages.1.blocks.1.attn.w_msa.qkv.bias, backbone.stages.1.blocks.1.attn.w_msa.proj.weight, backbone.stages.1.blocks.1.attn.w_msa.proj.bias, backbone.stages.1.blocks.1.norm2.weight, backbone.stages.1.blocks.1.norm2.bias, backbone.stages.1.blocks.1.ffn.layers.0.0.weight, backbone.stages.1.blocks.1.ffn.layers.0.0.bias, backbone.stages.1.blocks.1.ffn.layers.1.weight, backbone.stages.1.blocks.1.ffn.layers.1.bias, backbone.stages.1.downsample.reduction.weight, backbone.stages.1.downsample.norm.weight, backbone.stages.1.downsample.norm.bias, backbone.stages.2.blocks.0.norm1.weight, backbone.stages.2.blocks.0.norm1.bias, backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.0.attn.w_msa.relative_position_index, backbone.stages.2.blocks.0.attn.w_msa.qkv.weight, backbone.stages.2.blocks.0.attn.w_msa.qkv.bias, backbone.stages.2.blocks.0.attn.w_msa.proj.weight, backbone.stages.2.blocks.0.attn.w_msa.proj.bias, backbone.stages.2.blocks.0.norm2.weight, backbone.stages.2.blocks.0.norm2.bias, backbone.stages.2.blocks.0.ffn.layers.0.0.weight, backbone.stages.2.blocks.0.ffn.layers.0.0.bias, backbone.stages.2.blocks.0.ffn.layers.1.weight, backbone.stages.2.blocks.0.ffn.layers.1.bias, backbone.stages.2.blocks.1.norm1.weight, backbone.stages.2.blocks.1.norm1.bias, backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.1.attn.w_msa.relative_position_index, backbone.stages.2.blocks.1.attn.w_msa.qkv.weight, backbone.stages.2.blocks.1.attn.w_msa.qkv.bias, backbone.stages.2.blocks.1.attn.w_msa.proj.weight, backbone.stages.2.blocks.1.attn.w_msa.proj.bias, backbone.stages.2.blocks.1.norm2.weight, backbone.stages.2.blocks.1.norm2.bias, backbone.stages.2.blocks.1.ffn.layers.0.0.weight, backbone.stages.2.blocks.1.ffn.layers.0.0.bias, backbone.stages.2.blocks.1.ffn.layers.1.weight, backbone.stages.2.blocks.1.ffn.layers.1.bias, backbone.stages.2.blocks.2.norm1.weight, backbone.stages.2.blocks.2.norm1.bias, backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.2.attn.w_msa.relative_position_index, backbone.stages.2.blocks.2.attn.w_msa.qkv.weight, backbone.stages.2.blocks.2.attn.w_msa.qkv.bias, backbone.stages.2.blocks.2.attn.w_msa.proj.weight, backbone.stages.2.blocks.2.attn.w_msa.proj.bias, backbone.stages.2.blocks.2.norm2.weight, backbone.stages.2.blocks.2.norm2.bias, backbone.stages.2.blocks.2.ffn.layers.0.0.weight, backbone.stages.2.blocks.2.ffn.layers.0.0.bias, backbone.stages.2.blocks.2.ffn.layers.1.weight, backbone.stages.2.blocks.2.ffn.layers.1.bias, backbone.stages.2.blocks.3.norm1.weight, backbone.stages.2.blocks.3.norm1.bias, backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.3.attn.w_msa.relative_position_index, backbone.stages.2.blocks.3.attn.w_msa.qkv.weight, backbone.stages.2.blocks.3.attn.w_msa.qkv.bias, backbone.stages.2.blocks.3.attn.w_msa.proj.weight, backbone.stages.2.blocks.3.attn.w_msa.proj.bias, backbone.stages.2.blocks.3.norm2.weight, backbone.stages.2.blocks.3.norm2.bias, backbone.stages.2.blocks.3.ffn.layers.0.0.weight, backbone.stages.2.blocks.3.ffn.layers.0.0.bias, backbone.stages.2.blocks.3.ffn.layers.1.weight, backbone.stages.2.blocks.3.ffn.layers.1.bias, backbone.stages.2.blocks.4.norm1.weight, backbone.stages.2.blocks.4.norm1.bias, backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.4.attn.w_msa.relative_position_index, backbone.stages.2.blocks.4.attn.w_msa.qkv.weight, backbone.stages.2.blocks.4.attn.w_msa.qkv.bias, backbone.stages.2.blocks.4.attn.w_msa.proj.weight, backbone.stages.2.blocks.4.attn.w_msa.proj.bias, backbone.stages.2.blocks.4.norm2.weight, backbone.stages.2.blocks.4.norm2.bias, backbone.stages.2.blocks.4.ffn.layers.0.0.weight, backbone.stages.2.blocks.4.ffn.layers.0.0.bias, backbone.stages.2.blocks.4.ffn.layers.1.weight, backbone.stages.2.blocks.4.ffn.layers.1.bias, backbone.stages.2.blocks.5.norm1.weight, backbone.stages.2.blocks.5.norm1.bias, backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.5.attn.w_msa.relative_position_index, backbone.stages.2.blocks.5.attn.w_msa.qkv.weight, backbone.stages.2.blocks.5.attn.w_msa.qkv.bias, backbone.stages.2.blocks.5.attn.w_msa.proj.weight, backbone.stages.2.blocks.5.attn.w_msa.proj.bias, backbone.stages.2.blocks.5.norm2.weight, backbone.stages.2.blocks.5.norm2.bias, backbone.stages.2.blocks.5.ffn.layers.0.0.weight, backbone.stages.2.blocks.5.ffn.layers.0.0.bias, backbone.stages.2.blocks.5.ffn.layers.1.weight, backbone.stages.2.blocks.5.ffn.layers.1.bias, backbone.stages.2.blocks.6.norm1.weight, backbone.stages.2.blocks.6.norm1.bias, backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.6.attn.w_msa.relative_position_index, backbone.stages.2.blocks.6.attn.w_msa.qkv.weight, backbone.stages.2.blocks.6.attn.w_msa.qkv.bias, backbone.stages.2.blocks.6.attn.w_msa.proj.weight, backbone.stages.2.blocks.6.attn.w_msa.proj.bias, backbone.stages.2.blocks.6.norm2.weight, backbone.stages.2.blocks.6.norm2.bias, backbone.stages.2.blocks.6.ffn.layers.0.0.weight, backbone.stages.2.blocks.6.ffn.layers.0.0.bias, backbone.stages.2.blocks.6.ffn.layers.1.weight, backbone.stages.2.blocks.6.ffn.layers.1.bias, backbone.stages.2.blocks.7.norm1.weight, backbone.stages.2.blocks.7.norm1.bias, backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.7.attn.w_msa.relative_position_index, backbone.stages.2.blocks.7.attn.w_msa.qkv.weight, backbone.stages.2.blocks.7.attn.w_msa.qkv.bias, backbone.stages.2.blocks.7.attn.w_msa.proj.weight, backbone.stages.2.blocks.7.attn.w_msa.proj.bias, backbone.stages.2.blocks.7.norm2.weight, backbone.stages.2.blocks.7.norm2.bias, backbone.stages.2.blocks.7.ffn.layers.0.0.weight, backbone.stages.2.blocks.7.ffn.layers.0.0.bias, backbone.stages.2.blocks.7.ffn.layers.1.weight, backbone.stages.2.blocks.7.ffn.layers.1.bias, backbone.stages.2.blocks.8.norm1.weight, backbone.stages.2.blocks.8.norm1.bias, backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.8.attn.w_msa.relative_position_index, backbone.stages.2.blocks.8.attn.w_msa.qkv.weight, backbone.stages.2.blocks.8.attn.w_msa.qkv.bias, backbone.stages.2.blocks.8.attn.w_msa.proj.weight, backbone.stages.2.blocks.8.attn.w_msa.proj.bias, backbone.stages.2.blocks.8.norm2.weight, backbone.stages.2.blocks.8.norm2.bias, backbone.stages.2.blocks.8.ffn.layers.0.0.weight, backbone.stages.2.blocks.8.ffn.layers.0.0.bias, backbone.stages.2.blocks.8.ffn.layers.1.weight, backbone.stages.2.blocks.8.ffn.layers.1.bias, backbone.stages.2.blocks.9.norm1.weight, backbone.stages.2.blocks.9.norm1.bias, backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.9.attn.w_msa.relative_position_index, backbone.stages.2.blocks.9.attn.w_msa.qkv.weight, backbone.stages.2.blocks.9.attn.w_msa.qkv.bias, backbone.stages.2.blocks.9.attn.w_msa.proj.weight, backbone.stages.2.blocks.9.attn.w_msa.proj.bias, backbone.stages.2.blocks.9.norm2.weight, backbone.stages.2.blocks.9.norm2.bias, backbone.stages.2.blocks.9.ffn.layers.0.0.weight, backbone.stages.2.blocks.9.ffn.layers.0.0.bias, backbone.stages.2.blocks.9.ffn.layers.1.weight, backbone.stages.2.blocks.9.ffn.layers.1.bias, backbone.stages.2.blocks.10.norm1.weight, backbone.stages.2.blocks.10.norm1.bias, backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.10.attn.w_msa.relative_position_index, backbone.stages.2.blocks.10.attn.w_msa.qkv.weight, backbone.stages.2.blocks.10.attn.w_msa.qkv.bias, backbone.stages.2.blocks.10.attn.w_msa.proj.weight, backbone.stages.2.blocks.10.attn.w_msa.proj.bias, backbone.stages.2.blocks.10.norm2.weight, backbone.stages.2.blocks.10.norm2.bias, backbone.stages.2.blocks.10.ffn.layers.0.0.weight, backbone.stages.2.blocks.10.ffn.layers.0.0.bias, backbone.stages.2.blocks.10.ffn.layers.1.weight, backbone.stages.2.blocks.10.ffn.layers.1.bias, backbone.stages.2.blocks.11.norm1.weight, backbone.stages.2.blocks.11.norm1.bias, backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.11.attn.w_msa.relative_position_index, backbone.stages.2.blocks.11.attn.w_msa.qkv.weight, backbone.stages.2.blocks.11.attn.w_msa.qkv.bias, backbone.stages.2.blocks.11.attn.w_msa.proj.weight, backbone.stages.2.blocks.11.attn.w_msa.proj.bias, backbone.stages.2.blocks.11.norm2.weight, backbone.stages.2.blocks.11.norm2.bias, backbone.stages.2.blocks.11.ffn.layers.0.0.weight, backbone.stages.2.blocks.11.ffn.layers.0.0.bias, backbone.stages.2.blocks.11.ffn.layers.1.weight, backbone.stages.2.blocks.11.ffn.layers.1.bias, backbone.stages.2.blocks.12.norm1.weight, backbone.stages.2.blocks.12.norm1.bias, backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.12.attn.w_msa.relative_position_index, backbone.stages.2.blocks.12.attn.w_msa.qkv.weight, backbone.stages.2.blocks.12.attn.w_msa.qkv.bias, backbone.stages.2.blocks.12.attn.w_msa.proj.weight, backbone.stages.2.blocks.12.attn.w_msa.proj.bias, backbone.stages.2.blocks.12.norm2.weight, backbone.stages.2.blocks.12.norm2.bias, backbone.stages.2.blocks.12.ffn.layers.0.0.weight, backbone.stages.2.blocks.12.ffn.layers.0.0.bias, backbone.stages.2.blocks.12.ffn.layers.1.weight, backbone.stages.2.blocks.12.ffn.layers.1.bias, backbone.stages.2.blocks.13.norm1.weight, backbone.stages.2.blocks.13.norm1.bias, backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.13.attn.w_msa.relative_position_index, backbone.stages.2.blocks.13.attn.w_msa.qkv.weight, backbone.stages.2.blocks.13.attn.w_msa.qkv.bias, backbone.stages.2.blocks.13.attn.w_msa.proj.weight, backbone.stages.2.blocks.13.attn.w_msa.proj.bias, backbone.stages.2.blocks.13.norm2.weight, backbone.stages.2.blocks.13.norm2.bias, backbone.stages.2.blocks.13.ffn.layers.0.0.weight, backbone.stages.2.blocks.13.ffn.layers.0.0.bias, backbone.stages.2.blocks.13.ffn.layers.1.weight, backbone.stages.2.blocks.13.ffn.layers.1.bias, backbone.stages.2.blocks.14.norm1.weight, backbone.stages.2.blocks.14.norm1.bias, backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.14.attn.w_msa.relative_position_index, backbone.stages.2.blocks.14.attn.w_msa.qkv.weight, backbone.stages.2.blocks.14.attn.w_msa.qkv.bias, backbone.stages.2.blocks.14.attn.w_msa.proj.weight, backbone.stages.2.blocks.14.attn.w_msa.proj.bias, backbone.stages.2.blocks.14.norm2.weight, backbone.stages.2.blocks.14.norm2.bias, backbone.stages.2.blocks.14.ffn.layers.0.0.weight, backbone.stages.2.blocks.14.ffn.layers.0.0.bias, backbone.stages.2.blocks.14.ffn.layers.1.weight, backbone.stages.2.blocks.14.ffn.layers.1.bias, backbone.stages.2.blocks.15.norm1.weight, backbone.stages.2.blocks.15.norm1.bias, backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.15.attn.w_msa.relative_position_index, backbone.stages.2.blocks.15.attn.w_msa.qkv.weight, backbone.stages.2.blocks.15.attn.w_msa.qkv.bias, backbone.stages.2.blocks.15.attn.w_msa.proj.weight, backbone.stages.2.blocks.15.attn.w_msa.proj.bias, backbone.stages.2.blocks.15.norm2.weight, backbone.stages.2.blocks.15.norm2.bias, backbone.stages.2.blocks.15.ffn.layers.0.0.weight, backbone.stages.2.blocks.15.ffn.layers.0.0.bias, backbone.stages.2.blocks.15.ffn.layers.1.weight, backbone.stages.2.blocks.15.ffn.layers.1.bias, backbone.stages.2.blocks.16.norm1.weight, backbone.stages.2.blocks.16.norm1.bias, backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.16.attn.w_msa.relative_position_index, backbone.stages.2.blocks.16.attn.w_msa.qkv.weight, backbone.stages.2.blocks.16.attn.w_msa.qkv.bias, backbone.stages.2.blocks.16.attn.w_msa.proj.weight, backbone.stages.2.blocks.16.attn.w_msa.proj.bias, backbone.stages.2.blocks.16.norm2.weight, backbone.stages.2.blocks.16.norm2.bias, backbone.stages.2.blocks.16.ffn.layers.0.0.weight, backbone.stages.2.blocks.16.ffn.layers.0.0.bias, backbone.stages.2.blocks.16.ffn.layers.1.weight, backbone.stages.2.blocks.16.ffn.layers.1.bias, backbone.stages.2.blocks.17.norm1.weight, backbone.stages.2.blocks.17.norm1.bias, backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table, backbone.stages.2.blocks.17.attn.w_msa.relative_position_index, backbone.stages.2.blocks.17.attn.w_msa.qkv.weight, backbone.stages.2.blocks.17.attn.w_msa.qkv.bias, backbone.stages.2.blocks.17.attn.w_msa.proj.weight, backbone.stages.2.blocks.17.attn.w_msa.proj.bias, backbone.stages.2.blocks.17.norm2.weight, backbone.stages.2.blocks.17.norm2.bias, backbone.stages.2.blocks.17.ffn.layers.0.0.weight, backbone.stages.2.blocks.17.ffn.layers.0.0.bias, backbone.stages.2.blocks.17.ffn.layers.1.weight, backbone.stages.2.blocks.17.ffn.layers.1.bias, backbone.stages.2.downsample.reduction.weight, backbone.stages.2.downsample.norm.weight, backbone.stages.2.downsample.norm.bias, backbone.stages.3.blocks.0.norm1.weight, backbone.stages.3.blocks.0.norm1.bias, backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.0.attn.w_msa.relative_position_index, backbone.stages.3.blocks.0.attn.w_msa.qkv.weight, backbone.stages.3.blocks.0.attn.w_msa.qkv.bias, backbone.stages.3.blocks.0.attn.w_msa.proj.weight, backbone.stages.3.blocks.0.attn.w_msa.proj.bias, backbone.stages.3.blocks.0.norm2.weight, backbone.stages.3.blocks.0.norm2.bias, backbone.stages.3.blocks.0.ffn.layers.0.0.weight, backbone.stages.3.blocks.0.ffn.layers.0.0.bias, backbone.stages.3.blocks.0.ffn.layers.1.weight, backbone.stages.3.blocks.0.ffn.layers.1.bias, backbone.stages.3.blocks.1.norm1.weight, backbone.stages.3.blocks.1.norm1.bias, backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table, backbone.stages.3.blocks.1.attn.w_msa.relative_position_index, backbone.stages.3.blocks.1.attn.w_msa.qkv.weight, backbone.stages.3.blocks.1.attn.w_msa.qkv.bias, backbone.stages.3.blocks.1.attn.w_msa.proj.weight, backbone.stages.3.blocks.1.attn.w_msa.proj.bias, backbone.stages.3.blocks.1.norm2.weight, backbone.stages.3.blocks.1.norm2.bias, backbone.stages.3.blocks.1.ffn.layers.0.0.weight, backbone.stages.3.blocks.1.ffn.layers.0.0.bias, backbone.stages.3.blocks.1.ffn.layers.1.weight, backbone.stages.3.blocks.1.ffn.layers.1.bias, backbone.norm0.weight, backbone.norm0.bias, backbone.norm1.weight, backbone.norm1.bias, backbone.norm2.weight, backbone.norm2.bias, backbone.norm3.weight, backbone.norm3.bias, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.psp_modules.0.1.conv.weight, decode_head.psp_modules.0.1.bn.weight, decode_head.psp_modules.0.1.bn.bias, decode_head.psp_modules.0.1.bn.running_mean, decode_head.psp_modules.0.1.bn.running_var, decode_head.psp_modules.0.1.bn.num_batches_tracked, decode_head.psp_modules.1.1.conv.weight, decode_head.psp_modules.1.1.bn.weight, decode_head.psp_modules.1.1.bn.bias, decode_head.psp_modules.1.1.bn.running_mean, decode_head.psp_modules.1.1.bn.running_var, decode_head.psp_modules.1.1.bn.num_batches_tracked, decode_head.psp_modules.2.1.conv.weight, decode_head.psp_modules.2.1.bn.weight, decode_head.psp_modules.2.1.bn.bias, decode_head.psp_modules.2.1.bn.running_mean, decode_head.psp_modules.2.1.bn.running_var, decode_head.psp_modules.2.1.bn.num_batches_tracked, decode_head.psp_modules.3.1.conv.weight, decode_head.psp_modules.3.1.bn.weight, decode_head.psp_modules.3.1.bn.bias, decode_head.psp_modules.3.1.bn.running_mean, decode_head.psp_modules.3.1.bn.running_var, decode_head.psp_modules.3.1.bn.num_batches_tracked, decode_head.bottleneck.conv.weight, decode_head.bottleneck.bn.weight, decode_head.bottleneck.bn.bias, decode_head.bottleneck.bn.running_mean, decode_head.bottleneck.bn.running_var, decode_head.bottleneck.bn.num_batches_tracked, decode_head.lateral_convs.0.conv.weight, decode_head.lateral_convs.0.bn.weight, decode_head.lateral_convs.0.bn.bias, decode_head.lateral_convs.0.bn.running_mean, decode_head.lateral_convs.0.bn.running_var, decode_head.lateral_convs.0.bn.num_batches_tracked, decode_head.lateral_convs.1.conv.weight, decode_head.lateral_convs.1.bn.weight, decode_head.lateral_convs.1.bn.bias, decode_head.lateral_convs.1.bn.running_mean, decode_head.lateral_convs.1.bn.running_var, decode_head.lateral_convs.1.bn.num_batches_tracked, decode_head.lateral_convs.2.conv.weight, decode_head.lateral_convs.2.bn.weight, decode_head.lateral_convs.2.bn.bias, decode_head.lateral_convs.2.bn.running_mean, decode_head.lateral_convs.2.bn.running_var, decode_head.lateral_convs.2.bn.num_batches_tracked, decode_head.fpn_convs.0.conv.weight, decode_head.fpn_convs.0.bn.weight, decode_head.fpn_convs.0.bn.bias, decode_head.fpn_convs.0.bn.running_mean, decode_head.fpn_convs.0.bn.running_var, decode_head.fpn_convs.0.bn.num_batches_tracked, decode_head.fpn_convs.1.conv.weight, decode_head.fpn_convs.1.bn.weight, decode_head.fpn_convs.1.bn.bias, decode_head.fpn_convs.1.bn.running_mean, decode_head.fpn_convs.1.bn.running_var, decode_head.fpn_convs.1.bn.num_batches_tracked, decode_head.fpn_convs.2.conv.weight, decode_head.fpn_convs.2.bn.weight, decode_head.fpn_convs.2.bn.bias, decode_head.fpn_convs.2.bn.running_mean, decode_head.fpn_convs.2.bn.running_var, decode_head.fpn_convs.2.bn.num_batches_tracked, decode_head.fpn_bottleneck.conv.weight, decode_head.fpn_bottleneck.bn.weight, decode_head.fpn_bottleneck.bn.bias, decode_head.fpn_bottleneck.bn.running_mean, decode_head.fpn_bottleneck.bn.running_var, decode_head.fpn_bottleneck.bn.num_batches_tracked, auxiliary_head.conv_seg.weight, auxiliary_head.conv_seg.bias, auxiliary_head.convs.0.conv.weight, auxiliary_head.convs.0.bn.weight, auxiliary_head.convs.0.bn.bias, auxiliary_head.convs.0.bn.running_mean, auxiliary_head.convs.0.bn.running_var, auxiliary_head.convs.0.bn.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: conv_seg.weight, conv_seg.bias, psp_modules.0.1.conv.weight, psp_modules.0.1.bn.weight, psp_modules.0.1.bn.bias, psp_modules.0.1.bn.running_mean, psp_modules.0.1.bn.running_var, psp_modules.1.1.conv.weight, psp_modules.1.1.bn.weight, psp_modules.1.1.bn.bias, psp_modules.1.1.bn.running_mean, psp_modules.1.1.bn.running_var, psp_modules.2.1.conv.weight, psp_modules.2.1.bn.weight, psp_modules.2.1.bn.bias, psp_modules.2.1.bn.running_mean, psp_modules.2.1.bn.running_var, psp_modules.3.1.conv.weight, psp_modules.3.1.bn.weight, psp_modules.3.1.bn.bias, psp_modules.3.1.bn.running_mean, psp_modules.3.1.bn.running_var, bottleneck.conv.weight, bottleneck.bn.weight, bottleneck.bn.bias, bottleneck.bn.running_mean, bottleneck.bn.running_var, lateral_convs.0.conv.weight, lateral_convs.0.bn.weight, lateral_convs.0.bn.bias, lateral_convs.0.bn.running_mean, lateral_convs.0.bn.running_var, lateral_convs.1.conv.weight, lateral_convs.1.bn.weight, lateral_convs.1.bn.bias, lateral_convs.1.bn.running_mean, lateral_convs.1.bn.running_var, lateral_convs.2.conv.weight, lateral_convs.2.bn.weight, lateral_convs.2.bn.bias, lateral_convs.2.bn.running_mean, lateral_convs.2.bn.running_var, fpn_convs.0.conv.weight, fpn_convs.0.bn.weight, fpn_convs.0.bn.bias, fpn_convs.0.bn.running_mean, fpn_convs.0.bn.running_var, fpn_convs.1.conv.weight, fpn_convs.1.bn.weight, fpn_convs.1.bn.bias, fpn_convs.1.bn.running_mean, fpn_convs.1.bn.running_var, fpn_convs.2.conv.weight, fpn_convs.2.bn.weight, fpn_convs.2.bn.bias, fpn_convs.2.bn.running_mean, fpn_convs.2.bn.running_var, fpn_bottleneck.conv.weight, fpn_bottleneck.bn.weight, fpn_bottleneck.bn.bias, fpn_bottleneck.bn.running_mean, fpn_bottleneck.bn.running_var\n",
      "\n",
      "03/09 19:55:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/09 19:55:36 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/09 19:55:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /kaggle/working/checkpoint.\n",
      "03/09 19:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  100/40000]  base_lr: 3.9627e-06 lr: 3.9627e-06  eta: 9:12:47  time: 0.8014  data_time: 0.0248  memory: 5632  loss: 1.2928  decode.loss_ce: 1.2928  decode.acc_seg: 24.6639\n",
      "03/09 19:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  200/40000]  base_lr: 7.9654e-06 lr: 7.9654e-06  eta: 9:10:00  time: 0.8030  data_time: 0.0236  memory: 5632  loss: 1.2123  decode.loss_ce: 1.2123  decode.acc_seg: 48.1575\n",
      "03/09 19:59:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  300/40000]  base_lr: 1.1968e-05 lr: 1.1968e-05  eta: 9:07:57  time: 0.8191  data_time: 0.0448  memory: 5632  loss: 1.1384  decode.loss_ce: 1.1384  decode.acc_seg: 18.6866\n",
      "03/09 20:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  400/40000]  base_lr: 1.5971e-05 lr: 1.5971e-05  eta: 9:03:10  time: 0.8036  data_time: 0.0239  memory: 5634  loss: 1.0460  decode.loss_ce: 1.0460  decode.acc_seg: 94.0815\n",
      "03/09 20:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  500/40000]  base_lr: 1.9973e-05 lr: 1.9973e-05  eta: 9:01:25  time: 0.8414  data_time: 0.0662  memory: 5634  loss: 1.0728  decode.loss_ce: 1.0728  decode.acc_seg: 52.4359\n",
      "03/09 20:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  600/40000]  base_lr: 2.3976e-05 lr: 2.3976e-05  eta: 9:00:45  time: 0.8177  data_time: 0.0426  memory: 5634  loss: 0.9771  decode.loss_ce: 0.9771  decode.acc_seg: 51.7088\n",
      "03/09 20:05:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  700/40000]  base_lr: 2.7979e-05 lr: 2.7979e-05  eta: 8:59:29  time: 0.7998  data_time: 0.0236  memory: 5634  loss: 1.0148  decode.loss_ce: 1.0148  decode.acc_seg: 43.2918\n",
      "03/09 20:05:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 20:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  800/40000]  base_lr: 3.1981e-05 lr: 3.1981e-05  eta: 8:55:58  time: 0.7984  data_time: 0.0235  memory: 5634  loss: 0.7218  decode.loss_ce: 0.7218  decode.acc_seg: 81.3124\n",
      "03/09 20:07:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  900/40000]  base_lr: 3.5984e-05 lr: 3.5984e-05  eta: 8:52:57  time: 0.7941  data_time: 0.0233  memory: 5633  loss: 0.7462  decode.loss_ce: 0.7462  decode.acc_seg: 26.3488\n",
      "03/09 20:09:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 20:09:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1000/40000]  base_lr: 3.9987e-05 lr: 3.9987e-05  eta: 8:50:11  time: 0.8036  data_time: 0.0245  memory: 5634  loss: 0.8572  decode.loss_ce: 0.8572  decode.acc_seg: 73.1041\n",
      "03/09 20:10:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1100/40000]  base_lr: 4.3989e-05 lr: 4.3989e-05  eta: 8:47:43  time: 0.7952  data_time: 0.0231  memory: 5632  loss: 0.8540  decode.loss_ce: 0.8540  decode.acc_seg: 63.9683\n",
      "03/09 20:11:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1200/40000]  base_lr: 4.7992e-05 lr: 4.7992e-05  eta: 8:45:27  time: 0.8015  data_time: 0.0244  memory: 5634  loss: 0.7557  decode.loss_ce: 0.7557  decode.acc_seg: 75.9756\n",
      "03/09 20:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1300/40000]  base_lr: 5.1995e-05 lr: 5.1995e-05  eta: 8:43:16  time: 0.7937  data_time: 0.0229  memory: 5634  loss: 0.8595  decode.loss_ce: 0.8595  decode.acc_seg: 68.5050\n",
      "03/09 20:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1400/40000]  base_lr: 5.5997e-05 lr: 5.5997e-05  eta: 8:41:17  time: 0.7970  data_time: 0.0239  memory: 5632  loss: 0.9047  decode.loss_ce: 0.9047  decode.acc_seg: 93.6748\n",
      "03/09 20:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1500/40000]  base_lr: 6.0000e-05 lr: 6.0000e-05  eta: 8:39:21  time: 0.7937  data_time: 0.0236  memory: 5634  loss: 0.6870  decode.loss_ce: 0.6870  decode.acc_seg: 66.9480\n",
      "03/09 20:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1600/40000]  base_lr: 5.9963e-05 lr: 5.9963e-05  eta: 8:37:33  time: 0.8000  data_time: 0.0248  memory: 5634  loss: 1.1618  decode.loss_ce: 1.1618  decode.acc_seg: 24.0117\n",
      "03/09 20:18:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1700/40000]  base_lr: 5.9925e-05 lr: 5.9925e-05  eta: 8:35:45  time: 0.7924  data_time: 0.0230  memory: 5634  loss: 0.8527  decode.loss_ce: 0.8527  decode.acc_seg: 83.6568\n",
      "03/09 20:19:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1800/40000]  base_lr: 5.9887e-05 lr: 5.9887e-05  eta: 8:34:06  time: 0.8124  data_time: 0.0241  memory: 5632  loss: 0.6858  decode.loss_ce: 0.6858  decode.acc_seg: 78.7624\n",
      "03/09 20:21:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1900/40000]  base_lr: 5.9849e-05 lr: 5.9849e-05  eta: 8:32:24  time: 0.7968  data_time: 0.0234  memory: 5632  loss: 0.7066  decode.loss_ce: 0.7066  decode.acc_seg: 72.3021\n",
      "03/09 20:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 20:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2000/40000]  base_lr: 5.9811e-05 lr: 5.9811e-05  eta: 8:30:48  time: 0.7982  data_time: 0.0243  memory: 5634  loss: 0.8528  decode.loss_ce: 0.8528  decode.acc_seg: 30.4068\n",
      "03/09 20:23:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2100/40000]  base_lr: 5.9773e-05 lr: 5.9773e-05  eta: 8:29:09  time: 0.7938  data_time: 0.0244  memory: 5632  loss: 0.8585  decode.loss_ce: 0.8585  decode.acc_seg: 85.7729\n",
      "03/09 20:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2200/40000]  base_lr: 5.9735e-05 lr: 5.9735e-05  eta: 8:27:33  time: 0.7935  data_time: 0.0231  memory: 5632  loss: 0.9134  decode.loss_ce: 0.9134  decode.acc_seg: 64.3437\n",
      "03/09 20:26:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2300/40000]  base_lr: 5.9698e-05 lr: 5.9698e-05  eta: 8:25:58  time: 0.7990  data_time: 0.0241  memory: 5632  loss: 0.7056  decode.loss_ce: 0.7056  decode.acc_seg: 46.0950\n",
      "03/09 20:27:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2400/40000]  base_lr: 5.9660e-05 lr: 5.9660e-05  eta: 8:24:28  time: 0.7983  data_time: 0.0231  memory: 5632  loss: 0.8190  decode.loss_ce: 0.8190  decode.acc_seg: 53.9021\n",
      "03/09 20:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2500/40000]  base_lr: 5.9622e-05 lr: 5.9622e-05  eta: 8:22:55  time: 0.7940  data_time: 0.0238  memory: 5633  loss: 0.6357  decode.loss_ce: 0.6357  decode.acc_seg: 72.5583\n",
      "03/09 20:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2600/40000]  base_lr: 5.9584e-05 lr: 5.9584e-05  eta: 8:21:21  time: 0.7968  data_time: 0.0235  memory: 5634  loss: 0.9034  decode.loss_ce: 0.9034  decode.acc_seg: 37.0581\n",
      "03/09 20:31:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2700/40000]  base_lr: 5.9546e-05 lr: 5.9546e-05  eta: 8:19:50  time: 0.7943  data_time: 0.0236  memory: 5632  loss: 0.6762  decode.loss_ce: 0.6762  decode.acc_seg: 64.8649\n",
      "03/09 20:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2800/40000]  base_lr: 5.9508e-05 lr: 5.9508e-05  eta: 8:18:24  time: 0.7985  data_time: 0.0246  memory: 5633  loss: 0.7110  decode.loss_ce: 0.7110  decode.acc_seg: 87.4909\n",
      "03/09 20:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2900/40000]  base_lr: 5.9470e-05 lr: 5.9470e-05  eta: 8:16:58  time: 0.7976  data_time: 0.0241  memory: 5634  loss: 0.5781  decode.loss_ce: 0.5781  decode.acc_seg: 54.3411\n",
      "03/09 20:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 20:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3000/40000]  base_lr: 5.9433e-05 lr: 5.9433e-05  eta: 8:15:25  time: 0.7941  data_time: 0.0233  memory: 5634  loss: 0.6898  decode.loss_ce: 0.6898  decode.acc_seg: 85.0563\n",
      "03/09 20:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3100/40000]  base_lr: 5.9395e-05 lr: 5.9395e-05  eta: 8:13:56  time: 0.7971  data_time: 0.0241  memory: 5634  loss: 0.7320  decode.loss_ce: 0.7320  decode.acc_seg: 53.4322\n",
      "03/09 20:38:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3200/40000]  base_lr: 5.9357e-05 lr: 5.9357e-05  eta: 8:12:29  time: 0.7992  data_time: 0.0253  memory: 5632  loss: 0.8535  decode.loss_ce: 0.8535  decode.acc_seg: 41.2590\n",
      "03/09 20:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3300/40000]  base_lr: 5.9319e-05 lr: 5.9319e-05  eta: 8:11:03  time: 0.8060  data_time: 0.0261  memory: 5634  loss: 0.6528  decode.loss_ce: 0.6528  decode.acc_seg: 90.0534\n",
      "03/09 20:41:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3400/40000]  base_lr: 5.9281e-05 lr: 5.9281e-05  eta: 8:09:36  time: 0.7938  data_time: 0.0233  memory: 5632  loss: 0.6625  decode.loss_ce: 0.6625  decode.acc_seg: 76.4914\n",
      "03/09 20:42:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3500/40000]  base_lr: 5.9243e-05 lr: 5.9243e-05  eta: 8:08:11  time: 0.8018  data_time: 0.0246  memory: 5632  loss: 0.8768  decode.loss_ce: 0.8768  decode.acc_seg: 80.5334\n",
      "03/09 20:43:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3600/40000]  base_lr: 5.9205e-05 lr: 5.9205e-05  eta: 8:06:50  time: 0.8153  data_time: 0.0244  memory: 5633  loss: 0.6262  decode.loss_ce: 0.6262  decode.acc_seg: 68.5725\n",
      "03/09 20:45:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3700/40000]  base_lr: 5.9168e-05 lr: 5.9168e-05  eta: 8:05:27  time: 0.8088  data_time: 0.0244  memory: 5634  loss: 0.6661  decode.loss_ce: 0.6661  decode.acc_seg: 67.3895\n",
      "03/09 20:46:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3800/40000]  base_lr: 5.9130e-05 lr: 5.9130e-05  eta: 8:04:04  time: 0.8013  data_time: 0.0240  memory: 5634  loss: 1.0465  decode.loss_ce: 1.0465  decode.acc_seg: 65.3399\n",
      "03/09 20:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3900/40000]  base_lr: 5.9092e-05 lr: 5.9092e-05  eta: 8:02:42  time: 0.8000  data_time: 0.0246  memory: 5632  loss: 0.5883  decode.loss_ce: 0.5883  decode.acc_seg: 62.8090\n",
      "03/09 20:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 20:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4000/40000]  base_lr: 5.9054e-05 lr: 5.9054e-05  eta: 8:01:19  time: 0.7988  data_time: 0.0238  memory: 5634  loss: 0.7180  decode.loss_ce: 0.7180  decode.acc_seg: 77.3310\n",
      "03/09 20:50:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4100/40000]  base_lr: 5.9016e-05 lr: 5.9016e-05  eta: 7:59:57  time: 0.7990  data_time: 0.0238  memory: 5632  loss: 0.7976  decode.loss_ce: 0.7976  decode.acc_seg: 76.9273\n",
      "03/09 20:51:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4200/40000]  base_lr: 5.8978e-05 lr: 5.8978e-05  eta: 7:58:34  time: 0.7969  data_time: 0.0248  memory: 5632  loss: 0.6359  decode.loss_ce: 0.6359  decode.acc_seg: 70.0208\n",
      "03/09 20:53:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4300/40000]  base_lr: 5.8940e-05 lr: 5.8940e-05  eta: 7:57:11  time: 0.7967  data_time: 0.0245  memory: 5632  loss: 0.6280  decode.loss_ce: 0.6280  decode.acc_seg: 72.4714\n",
      "03/09 20:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4400/40000]  base_lr: 5.8903e-05 lr: 5.8903e-05  eta: 7:55:49  time: 0.8030  data_time: 0.0248  memory: 5634  loss: 0.5727  decode.loss_ce: 0.5727  decode.acc_seg: 59.7483\n",
      "03/09 20:55:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4500/40000]  base_lr: 5.8865e-05 lr: 5.8865e-05  eta: 7:54:29  time: 0.7992  data_time: 0.0240  memory: 5634  loss: 0.9736  decode.loss_ce: 0.9736  decode.acc_seg: 32.7717\n",
      "03/09 20:57:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4600/40000]  base_lr: 5.8827e-05 lr: 5.8827e-05  eta: 7:53:06  time: 0.7994  data_time: 0.0251  memory: 5634  loss: 0.9159  decode.loss_ce: 0.9159  decode.acc_seg: 65.1367\n",
      "03/09 20:58:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4700/40000]  base_lr: 5.8789e-05 lr: 5.8789e-05  eta: 7:51:44  time: 0.7994  data_time: 0.0240  memory: 5634  loss: 0.7784  decode.loss_ce: 0.7784  decode.acc_seg: 71.7025\n",
      "03/09 20:59:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4800/40000]  base_lr: 5.8751e-05 lr: 5.8751e-05  eta: 7:50:23  time: 0.7980  data_time: 0.0241  memory: 5634  loss: 0.7018  decode.loss_ce: 0.7018  decode.acc_seg: 93.6078\n",
      "03/09 21:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4900/40000]  base_lr: 5.8713e-05 lr: 5.8713e-05  eta: 7:49:02  time: 0.7994  data_time: 0.0242  memory: 5634  loss: 0.6706  decode.loss_ce: 0.6706  decode.acc_seg: 80.4627\n",
      "03/09 21:02:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 21:02:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5000/40000]  base_lr: 5.8675e-05 lr: 5.8675e-05  eta: 7:47:41  time: 0.8026  data_time: 0.0243  memory: 5632  loss: 0.6408  decode.loss_ce: 0.6408  decode.acc_seg: 66.5489\n",
      "03/09 21:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5100/40000]  base_lr: 5.8638e-05 lr: 5.8638e-05  eta: 7:46:19  time: 0.7983  data_time: 0.0235  memory: 5633  loss: 0.6358  decode.loss_ce: 0.6358  decode.acc_seg: 75.8619\n",
      "03/09 21:05:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5200/40000]  base_lr: 5.8600e-05 lr: 5.8600e-05  eta: 7:44:59  time: 0.8088  data_time: 0.0251  memory: 5634  loss: 0.7679  decode.loss_ce: 0.7679  decode.acc_seg: 66.8215\n",
      "03/09 21:06:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5300/40000]  base_lr: 5.8562e-05 lr: 5.8562e-05  eta: 7:43:38  time: 0.7993  data_time: 0.0250  memory: 5634  loss: 0.5965  decode.loss_ce: 0.5965  decode.acc_seg: 80.7645\n",
      "03/09 21:07:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5400/40000]  base_lr: 5.8524e-05 lr: 5.8524e-05  eta: 7:42:18  time: 0.8036  data_time: 0.0251  memory: 5632  loss: 0.4902  decode.loss_ce: 0.4902  decode.acc_seg: 69.0657\n",
      "03/09 21:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5500/40000]  base_lr: 5.8486e-05 lr: 5.8486e-05  eta: 7:40:57  time: 0.8000  data_time: 0.0245  memory: 5632  loss: 0.6442  decode.loss_ce: 0.6442  decode.acc_seg: 45.4584\n",
      "03/09 21:10:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5600/40000]  base_lr: 5.8448e-05 lr: 5.8448e-05  eta: 7:39:36  time: 0.8010  data_time: 0.0246  memory: 5633  loss: 0.4034  decode.loss_ce: 0.4034  decode.acc_seg: 88.5213\n",
      "03/09 21:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5700/40000]  base_lr: 5.8410e-05 lr: 5.8410e-05  eta: 7:38:14  time: 0.7972  data_time: 0.0237  memory: 5634  loss: 0.7030  decode.loss_ce: 0.7030  decode.acc_seg: 91.5452\n",
      "03/09 21:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5800/40000]  base_lr: 5.8373e-05 lr: 5.8373e-05  eta: 7:36:54  time: 0.8080  data_time: 0.0253  memory: 5634  loss: 0.5976  decode.loss_ce: 0.5976  decode.acc_seg: 71.3659\n",
      "03/09 21:14:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5900/40000]  base_lr: 5.8335e-05 lr: 5.8335e-05  eta: 7:35:35  time: 0.7992  data_time: 0.0243  memory: 5634  loss: 0.5324  decode.loss_ce: 0.5324  decode.acc_seg: 86.9077\n",
      "03/09 21:15:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 21:15:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6000/40000]  base_lr: 5.8297e-05 lr: 5.8297e-05  eta: 7:34:14  time: 0.7941  data_time: 0.0235  memory: 5632  loss: 0.9986  decode.loss_ce: 0.9986  decode.acc_seg: 76.8365\n",
      "03/09 21:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6100/40000]  base_lr: 5.8259e-05 lr: 5.8259e-05  eta: 7:32:54  time: 0.8011  data_time: 0.0251  memory: 5634  loss: 0.6416  decode.loss_ce: 0.6416  decode.acc_seg: 76.2348\n",
      "03/09 21:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6200/40000]  base_lr: 5.8221e-05 lr: 5.8221e-05  eta: 7:31:35  time: 0.7980  data_time: 0.0249  memory: 5632  loss: 0.5384  decode.loss_ce: 0.5384  decode.acc_seg: 59.1315\n",
      "03/09 21:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6300/40000]  base_lr: 5.8183e-05 lr: 5.8183e-05  eta: 7:30:15  time: 0.8040  data_time: 0.0248  memory: 5634  loss: 0.4648  decode.loss_ce: 0.4648  decode.acc_seg: 86.4043\n",
      "03/09 21:21:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6400/40000]  base_lr: 5.8145e-05 lr: 5.8145e-05  eta: 7:28:56  time: 0.7969  data_time: 0.0240  memory: 5632  loss: 0.4331  decode.loss_ce: 0.4331  decode.acc_seg: 79.9942\n",
      "03/09 21:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6500/40000]  base_lr: 5.8108e-05 lr: 5.8108e-05  eta: 7:27:36  time: 0.8054  data_time: 0.0244  memory: 5634  loss: 0.7324  decode.loss_ce: 0.7324  decode.acc_seg: 83.4358\n",
      "03/09 21:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6600/40000]  base_lr: 5.8070e-05 lr: 5.8070e-05  eta: 7:26:16  time: 0.7984  data_time: 0.0239  memory: 5634  loss: 0.6932  decode.loss_ce: 0.6932  decode.acc_seg: 89.2620\n",
      "03/09 21:25:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6700/40000]  base_lr: 5.8032e-05 lr: 5.8032e-05  eta: 7:24:55  time: 0.8044  data_time: 0.0242  memory: 5632  loss: 0.5299  decode.loss_ce: 0.5299  decode.acc_seg: 95.3272\n",
      "03/09 21:26:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6800/40000]  base_lr: 5.7994e-05 lr: 5.7994e-05  eta: 7:23:34  time: 0.7971  data_time: 0.0242  memory: 5632  loss: 0.6731  decode.loss_ce: 0.6731  decode.acc_seg: 57.4083\n",
      "03/09 21:27:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6900/40000]  base_lr: 5.7956e-05 lr: 5.7956e-05  eta: 7:22:13  time: 0.8050  data_time: 0.0240  memory: 5632  loss: 0.5667  decode.loss_ce: 0.5667  decode.acc_seg: 74.7289\n",
      "03/09 21:29:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 21:29:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7000/40000]  base_lr: 5.7918e-05 lr: 5.7918e-05  eta: 7:20:52  time: 0.8000  data_time: 0.0240  memory: 5632  loss: 0.5925  decode.loss_ce: 0.5925  decode.acc_seg: 55.8425\n",
      "03/09 21:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7100/40000]  base_lr: 5.7880e-05 lr: 5.7880e-05  eta: 7:19:31  time: 0.8053  data_time: 0.0262  memory: 5634  loss: 0.6850  decode.loss_ce: 0.6850  decode.acc_seg: 80.9056\n",
      "03/09 21:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7200/40000]  base_lr: 5.7843e-05 lr: 5.7843e-05  eta: 7:18:12  time: 0.7992  data_time: 0.0242  memory: 5634  loss: 0.7126  decode.loss_ce: 0.7126  decode.acc_seg: 88.0144\n",
      "03/09 21:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7300/40000]  base_lr: 5.7805e-05 lr: 5.7805e-05  eta: 7:16:52  time: 0.8075  data_time: 0.0252  memory: 5632  loss: 0.4900  decode.loss_ce: 0.4900  decode.acc_seg: 80.5577\n",
      "03/09 21:34:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7400/40000]  base_lr: 5.7767e-05 lr: 5.7767e-05  eta: 7:15:30  time: 0.7979  data_time: 0.0246  memory: 5632  loss: 0.4000  decode.loss_ce: 0.4000  decode.acc_seg: 85.9554\n",
      "03/09 21:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7500/40000]  base_lr: 5.7729e-05 lr: 5.7729e-05  eta: 7:14:10  time: 0.8004  data_time: 0.0257  memory: 5632  loss: 0.7249  decode.loss_ce: 0.7249  decode.acc_seg: 62.0701\n",
      "03/09 21:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7600/40000]  base_lr: 5.7691e-05 lr: 5.7691e-05  eta: 7:12:49  time: 0.7979  data_time: 0.0243  memory: 5634  loss: 0.4420  decode.loss_ce: 0.4420  decode.acc_seg: 92.6589\n",
      "03/09 21:38:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7700/40000]  base_lr: 5.7653e-05 lr: 5.7653e-05  eta: 7:11:28  time: 0.7990  data_time: 0.0246  memory: 5632  loss: 0.8473  decode.loss_ce: 0.8473  decode.acc_seg: 84.8583\n",
      "03/09 21:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7800/40000]  base_lr: 5.7616e-05 lr: 5.7616e-05  eta: 7:10:07  time: 0.7952  data_time: 0.0242  memory: 5634  loss: 0.4527  decode.loss_ce: 0.4527  decode.acc_seg: 81.3498\n",
      "03/09 21:41:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7900/40000]  base_lr: 5.7578e-05 lr: 5.7578e-05  eta: 7:08:50  time: 0.7956  data_time: 0.0237  memory: 5634  loss: 0.3311  decode.loss_ce: 0.3311  decode.acc_seg: 94.9694\n",
      "03/09 21:42:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 21:42:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8000/40000]  base_lr: 5.7540e-05 lr: 5.7540e-05  eta: 7:07:29  time: 0.7979  data_time: 0.0242  memory: 5634  loss: 0.4963  decode.loss_ce: 0.4963  decode.acc_seg: 75.8582\n",
      "03/09 21:43:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8100/40000]  base_lr: 5.7502e-05 lr: 5.7502e-05  eta: 7:06:08  time: 0.7982  data_time: 0.0242  memory: 5634  loss: 0.5376  decode.loss_ce: 0.5376  decode.acc_seg: 69.0073\n",
      "03/09 21:45:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8200/40000]  base_lr: 5.7464e-05 lr: 5.7464e-05  eta: 7:04:47  time: 0.7980  data_time: 0.0242  memory: 5633  loss: 0.6451  decode.loss_ce: 0.6451  decode.acc_seg: 49.6560\n",
      "03/09 21:46:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8300/40000]  base_lr: 5.7426e-05 lr: 5.7426e-05  eta: 7:03:27  time: 0.7972  data_time: 0.0243  memory: 5634  loss: 0.8388  decode.loss_ce: 0.8388  decode.acc_seg: 57.0162\n",
      "03/09 21:47:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8400/40000]  base_lr: 5.7388e-05 lr: 5.7388e-05  eta: 7:02:06  time: 0.8029  data_time: 0.0254  memory: 5634  loss: 0.5220  decode.loss_ce: 0.5220  decode.acc_seg: 71.9570\n",
      "03/09 21:49:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8500/40000]  base_lr: 5.7351e-05 lr: 5.7351e-05  eta: 7:00:46  time: 0.7984  data_time: 0.0247  memory: 5634  loss: 0.3453  decode.loss_ce: 0.3453  decode.acc_seg: 84.4715\n",
      "03/09 21:50:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8600/40000]  base_lr: 5.7313e-05 lr: 5.7313e-05  eta: 6:59:25  time: 0.8075  data_time: 0.0260  memory: 5634  loss: 0.5642  decode.loss_ce: 0.5642  decode.acc_seg: 71.2332\n",
      "03/09 21:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8700/40000]  base_lr: 5.7275e-05 lr: 5.7275e-05  eta: 6:58:05  time: 0.7998  data_time: 0.0252  memory: 5633  loss: 0.7366  decode.loss_ce: 0.7366  decode.acc_seg: 46.7674\n",
      "03/09 21:53:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8800/40000]  base_lr: 5.7237e-05 lr: 5.7237e-05  eta: 6:56:45  time: 0.8027  data_time: 0.0256  memory: 5634  loss: 0.4225  decode.loss_ce: 0.4225  decode.acc_seg: 80.5481\n",
      "03/09 21:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8900/40000]  base_lr: 5.7199e-05 lr: 5.7199e-05  eta: 6:55:24  time: 0.8005  data_time: 0.0248  memory: 5634  loss: 0.3390  decode.loss_ce: 0.3390  decode.acc_seg: 89.6189\n",
      "03/09 21:55:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 21:55:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9000/40000]  base_lr: 5.7161e-05 lr: 5.7161e-05  eta: 6:54:05  time: 0.7999  data_time: 0.0251  memory: 5632  loss: 0.4736  decode.loss_ce: 0.4736  decode.acc_seg: 65.9715\n",
      "03/09 21:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9100/40000]  base_lr: 5.7123e-05 lr: 5.7123e-05  eta: 6:52:45  time: 0.7947  data_time: 0.0238  memory: 5634  loss: 0.6242  decode.loss_ce: 0.6242  decode.acc_seg: 71.8987\n",
      "03/09 21:58:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9200/40000]  base_lr: 5.7086e-05 lr: 5.7086e-05  eta: 6:51:25  time: 0.8006  data_time: 0.0267  memory: 5633  loss: 0.5161  decode.loss_ce: 0.5161  decode.acc_seg: 64.3093\n",
      "03/09 21:59:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9300/40000]  base_lr: 5.7048e-05 lr: 5.7048e-05  eta: 6:50:04  time: 0.7965  data_time: 0.0241  memory: 5634  loss: 0.6280  decode.loss_ce: 0.6280  decode.acc_seg: 96.0393\n",
      "03/09 22:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9400/40000]  base_lr: 5.7010e-05 lr: 5.7010e-05  eta: 6:48:44  time: 0.7983  data_time: 0.0247  memory: 5634  loss: 0.4486  decode.loss_ce: 0.4486  decode.acc_seg: 80.2711\n",
      "03/09 22:02:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9500/40000]  base_lr: 5.6972e-05 lr: 5.6972e-05  eta: 6:47:23  time: 0.7960  data_time: 0.0242  memory: 5632  loss: 0.4824  decode.loss_ce: 0.4824  decode.acc_seg: 68.7805\n",
      "03/09 22:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9600/40000]  base_lr: 5.6934e-05 lr: 5.6934e-05  eta: 6:46:02  time: 0.7967  data_time: 0.0243  memory: 5632  loss: 0.5620  decode.loss_ce: 0.5620  decode.acc_seg: 78.6742\n",
      "03/09 22:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9700/40000]  base_lr: 5.6896e-05 lr: 5.6896e-05  eta: 6:44:42  time: 0.7971  data_time: 0.0246  memory: 5632  loss: 0.4869  decode.loss_ce: 0.4869  decode.acc_seg: 87.3509\n",
      "03/09 22:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9800/40000]  base_lr: 5.6858e-05 lr: 5.6858e-05  eta: 6:43:22  time: 0.8003  data_time: 0.0249  memory: 5632  loss: 0.4109  decode.loss_ce: 0.4109  decode.acc_seg: 77.5175\n",
      "03/09 22:07:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9900/40000]  base_lr: 5.6821e-05 lr: 5.6821e-05  eta: 6:42:01  time: 0.7997  data_time: 0.0246  memory: 5633  loss: 0.6962  decode.loss_ce: 0.6962  decode.acc_seg: 81.3267\n",
      "03/09 22:09:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 22:09:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10000/40000]  base_lr: 5.6783e-05 lr: 5.6783e-05  eta: 6:40:42  time: 0.7976  data_time: 0.0245  memory: 5632  loss: 0.5305  decode.loss_ce: 0.5305  decode.acc_seg: 90.5540\n",
      "03/09 22:10:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10100/40000]  base_lr: 5.6745e-05 lr: 5.6745e-05  eta: 6:39:22  time: 0.8101  data_time: 0.0256  memory: 5634  loss: 0.9070  decode.loss_ce: 0.9070  decode.acc_seg: 89.2173\n",
      "03/09 22:11:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10200/40000]  base_lr: 5.6707e-05 lr: 5.6707e-05  eta: 6:38:01  time: 0.8001  data_time: 0.0241  memory: 5634  loss: 0.5436  decode.loss_ce: 0.5436  decode.acc_seg: 89.8240\n",
      "03/09 22:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10300/40000]  base_lr: 5.6669e-05 lr: 5.6669e-05  eta: 6:36:41  time: 0.8025  data_time: 0.0247  memory: 5634  loss: 0.5708  decode.loss_ce: 0.5708  decode.acc_seg: 68.4948\n",
      "03/09 22:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10400/40000]  base_lr: 5.6631e-05 lr: 5.6631e-05  eta: 6:35:20  time: 0.7964  data_time: 0.0246  memory: 5634  loss: 0.6528  decode.loss_ce: 0.6528  decode.acc_seg: 68.2226\n",
      "03/09 22:15:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10500/40000]  base_lr: 5.6593e-05 lr: 5.6593e-05  eta: 6:34:00  time: 0.8054  data_time: 0.0241  memory: 5634  loss: 0.4363  decode.loss_ce: 0.4363  decode.acc_seg: 56.4506\n",
      "03/09 22:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10600/40000]  base_lr: 5.6556e-05 lr: 5.6556e-05  eta: 6:32:39  time: 0.8001  data_time: 0.0238  memory: 5634  loss: 0.7117  decode.loss_ce: 0.7117  decode.acc_seg: 66.5522\n",
      "03/09 22:18:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10700/40000]  base_lr: 5.6518e-05 lr: 5.6518e-05  eta: 6:31:19  time: 0.8132  data_time: 0.0264  memory: 5634  loss: 0.7040  decode.loss_ce: 0.7040  decode.acc_seg: 61.7468\n",
      "03/09 22:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10800/40000]  base_lr: 5.6480e-05 lr: 5.6480e-05  eta: 6:29:59  time: 0.7977  data_time: 0.0243  memory: 5632  loss: 0.6356  decode.loss_ce: 0.6356  decode.acc_seg: 77.2704\n",
      "03/09 22:21:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10900/40000]  base_lr: 5.6442e-05 lr: 5.6442e-05  eta: 6:28:38  time: 0.7997  data_time: 0.0245  memory: 5632  loss: 0.7006  decode.loss_ce: 0.7006  decode.acc_seg: 75.2713\n",
      "03/09 22:22:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 22:22:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11000/40000]  base_lr: 5.6404e-05 lr: 5.6404e-05  eta: 6:27:18  time: 0.8000  data_time: 0.0249  memory: 5632  loss: 0.5143  decode.loss_ce: 0.5143  decode.acc_seg: 73.8282\n",
      "03/09 22:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11100/40000]  base_lr: 5.6366e-05 lr: 5.6366e-05  eta: 6:25:58  time: 0.7986  data_time: 0.0243  memory: 5632  loss: 0.4727  decode.loss_ce: 0.4727  decode.acc_seg: 77.9811\n",
      "03/09 22:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11200/40000]  base_lr: 5.6328e-05 lr: 5.6328e-05  eta: 6:24:37  time: 0.8025  data_time: 0.0247  memory: 5634  loss: 0.4786  decode.loss_ce: 0.4786  decode.acc_seg: 90.8146\n",
      "03/09 22:26:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11300/40000]  base_lr: 5.6291e-05 lr: 5.6291e-05  eta: 6:23:18  time: 0.8023  data_time: 0.0252  memory: 5634  loss: 0.5524  decode.loss_ce: 0.5524  decode.acc_seg: 77.7875\n",
      "03/09 22:27:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11400/40000]  base_lr: 5.6253e-05 lr: 5.6253e-05  eta: 6:21:57  time: 0.7987  data_time: 0.0244  memory: 5632  loss: 0.5593  decode.loss_ce: 0.5593  decode.acc_seg: 68.2444\n",
      "03/09 22:29:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11500/40000]  base_lr: 5.6215e-05 lr: 5.6215e-05  eta: 6:20:37  time: 0.8001  data_time: 0.0246  memory: 5634  loss: 0.6083  decode.loss_ce: 0.6083  decode.acc_seg: 50.9246\n",
      "03/09 22:30:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11600/40000]  base_lr: 5.6177e-05 lr: 5.6177e-05  eta: 6:19:17  time: 0.8021  data_time: 0.0244  memory: 5632  loss: 0.6086  decode.loss_ce: 0.6086  decode.acc_seg: 68.0168\n",
      "03/09 22:31:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11700/40000]  base_lr: 5.6139e-05 lr: 5.6139e-05  eta: 6:17:58  time: 0.7998  data_time: 0.0252  memory: 5632  loss: 0.3586  decode.loss_ce: 0.3586  decode.acc_seg: 89.6149\n",
      "03/09 22:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11800/40000]  base_lr: 5.6101e-05 lr: 5.6101e-05  eta: 6:16:38  time: 0.8097  data_time: 0.0241  memory: 5634  loss: 0.3719  decode.loss_ce: 0.3719  decode.acc_seg: 72.8291\n",
      "03/09 22:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11900/40000]  base_lr: 5.6063e-05 lr: 5.6063e-05  eta: 6:15:17  time: 0.8018  data_time: 0.0249  memory: 5633  loss: 0.4923  decode.loss_ce: 0.4923  decode.acc_seg: 75.3303\n",
      "03/09 22:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 22:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12000/40000]  base_lr: 5.6026e-05 lr: 5.6026e-05  eta: 6:13:57  time: 0.8032  data_time: 0.0249  memory: 5632  loss: 0.3887  decode.loss_ce: 0.3887  decode.acc_seg: 60.8105\n",
      "03/09 22:37:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12100/40000]  base_lr: 5.5988e-05 lr: 5.5988e-05  eta: 6:12:37  time: 0.8011  data_time: 0.0246  memory: 5632  loss: 0.5926  decode.loss_ce: 0.5926  decode.acc_seg: 83.9149\n",
      "03/09 22:38:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12200/40000]  base_lr: 5.5950e-05 lr: 5.5950e-05  eta: 6:11:16  time: 0.8009  data_time: 0.0248  memory: 5634  loss: 0.4566  decode.loss_ce: 0.4566  decode.acc_seg: 67.3968\n",
      "03/09 22:39:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12300/40000]  base_lr: 5.5912e-05 lr: 5.5912e-05  eta: 6:09:56  time: 0.7981  data_time: 0.0242  memory: 5633  loss: 0.7253  decode.loss_ce: 0.7253  decode.acc_seg: 85.9130\n",
      "03/09 22:41:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12400/40000]  base_lr: 5.5874e-05 lr: 5.5874e-05  eta: 6:08:35  time: 0.8061  data_time: 0.0242  memory: 5633  loss: 0.6135  decode.loss_ce: 0.6135  decode.acc_seg: 67.9168\n",
      "03/09 22:42:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12500/40000]  base_lr: 5.5836e-05 lr: 5.5836e-05  eta: 6:07:15  time: 0.8000  data_time: 0.0246  memory: 5634  loss: 0.4844  decode.loss_ce: 0.4844  decode.acc_seg: 87.5145\n",
      "03/09 22:43:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12600/40000]  base_lr: 5.5798e-05 lr: 5.5798e-05  eta: 6:05:55  time: 0.8037  data_time: 0.0247  memory: 5632  loss: 0.6347  decode.loss_ce: 0.6347  decode.acc_seg: 92.1961\n",
      "03/09 22:45:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12700/40000]  base_lr: 5.5761e-05 lr: 5.5761e-05  eta: 6:04:34  time: 0.7967  data_time: 0.0241  memory: 5632  loss: 0.3387  decode.loss_ce: 0.3387  decode.acc_seg: 90.6970\n",
      "03/09 22:46:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12800/40000]  base_lr: 5.5723e-05 lr: 5.5723e-05  eta: 6:03:14  time: 0.8029  data_time: 0.0250  memory: 5632  loss: 0.3011  decode.loss_ce: 0.3011  decode.acc_seg: 84.7507\n",
      "03/09 22:47:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12900/40000]  base_lr: 5.5685e-05 lr: 5.5685e-05  eta: 6:01:53  time: 0.8003  data_time: 0.0252  memory: 5634  loss: 0.3868  decode.loss_ce: 0.3868  decode.acc_seg: 75.5566\n",
      "03/09 22:49:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 22:49:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13000/40000]  base_lr: 5.5647e-05 lr: 5.5647e-05  eta: 6:00:33  time: 0.7984  data_time: 0.0246  memory: 5634  loss: 0.4488  decode.loss_ce: 0.4488  decode.acc_seg: 98.9565\n",
      "03/09 22:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13100/40000]  base_lr: 5.5609e-05 lr: 5.5609e-05  eta: 5:59:12  time: 0.7954  data_time: 0.0242  memory: 5634  loss: 0.3458  decode.loss_ce: 0.3458  decode.acc_seg: 89.0734\n",
      "03/09 22:51:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13200/40000]  base_lr: 5.5571e-05 lr: 5.5571e-05  eta: 5:57:51  time: 0.7962  data_time: 0.0243  memory: 5634  loss: 0.3354  decode.loss_ce: 0.3354  decode.acc_seg: 87.2139\n",
      "03/09 22:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13300/40000]  base_lr: 5.5533e-05 lr: 5.5533e-05  eta: 5:56:31  time: 0.7966  data_time: 0.0242  memory: 5632  loss: 0.3249  decode.loss_ce: 0.3249  decode.acc_seg: 86.3355\n",
      "03/09 22:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13400/40000]  base_lr: 5.5496e-05 lr: 5.5496e-05  eta: 5:55:10  time: 0.7966  data_time: 0.0247  memory: 5632  loss: 0.5766  decode.loss_ce: 0.5766  decode.acc_seg: 75.5560\n",
      "03/09 22:55:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13500/40000]  base_lr: 5.5458e-05 lr: 5.5458e-05  eta: 5:53:49  time: 0.7964  data_time: 0.0236  memory: 5634  loss: 0.6153  decode.loss_ce: 0.6153  decode.acc_seg: 34.3807\n",
      "03/09 22:57:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13600/40000]  base_lr: 5.5420e-05 lr: 5.5420e-05  eta: 5:52:29  time: 0.8001  data_time: 0.0244  memory: 5633  loss: 0.6818  decode.loss_ce: 0.6818  decode.acc_seg: 92.5506\n",
      "03/09 22:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13700/40000]  base_lr: 5.5382e-05 lr: 5.5382e-05  eta: 5:51:09  time: 0.7987  data_time: 0.0238  memory: 5632  loss: 0.5328  decode.loss_ce: 0.5328  decode.acc_seg: 40.8972\n",
      "03/09 22:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13800/40000]  base_lr: 5.5344e-05 lr: 5.5344e-05  eta: 5:49:48  time: 0.7988  data_time: 0.0236  memory: 5632  loss: 0.3055  decode.loss_ce: 0.3055  decode.acc_seg: 84.8949\n",
      "03/09 23:01:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13900/40000]  base_lr: 5.5306e-05 lr: 5.5306e-05  eta: 5:48:28  time: 0.8056  data_time: 0.0254  memory: 5632  loss: 0.5260  decode.loss_ce: 0.5260  decode.acc_seg: 84.9771\n",
      "03/09 23:02:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 23:02:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14000/40000]  base_lr: 5.5268e-05 lr: 5.5268e-05  eta: 5:47:07  time: 0.7954  data_time: 0.0248  memory: 5634  loss: 0.6840  decode.loss_ce: 0.6840  decode.acc_seg: 60.9145\n",
      "03/09 23:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14100/40000]  base_lr: 5.5231e-05 lr: 5.5231e-05  eta: 5:45:46  time: 0.7998  data_time: 0.0250  memory: 5634  loss: 0.5357  decode.loss_ce: 0.5357  decode.acc_seg: 82.0379\n",
      "03/09 23:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14200/40000]  base_lr: 5.5193e-05 lr: 5.5193e-05  eta: 5:44:26  time: 0.7958  data_time: 0.0239  memory: 5632  loss: 0.4819  decode.loss_ce: 0.4819  decode.acc_seg: 80.4729\n",
      "03/09 23:06:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14300/40000]  base_lr: 5.5155e-05 lr: 5.5155e-05  eta: 5:43:06  time: 0.8052  data_time: 0.0248  memory: 5634  loss: 0.5872  decode.loss_ce: 0.5872  decode.acc_seg: 75.7341\n",
      "03/09 23:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14400/40000]  base_lr: 5.5117e-05 lr: 5.5117e-05  eta: 5:41:46  time: 0.7921  data_time: 0.0233  memory: 5632  loss: 0.3414  decode.loss_ce: 0.3414  decode.acc_seg: 74.3900\n",
      "03/09 23:09:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14500/40000]  base_lr: 5.5079e-05 lr: 5.5079e-05  eta: 5:40:25  time: 0.8039  data_time: 0.0251  memory: 5632  loss: 0.4735  decode.loss_ce: 0.4735  decode.acc_seg: 67.7248\n",
      "03/09 23:10:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14600/40000]  base_lr: 5.5041e-05 lr: 5.5041e-05  eta: 5:39:04  time: 0.7947  data_time: 0.0239  memory: 5634  loss: 0.5414  decode.loss_ce: 0.5414  decode.acc_seg: 81.7906\n",
      "03/09 23:11:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14700/40000]  base_lr: 5.5004e-05 lr: 5.5004e-05  eta: 5:37:44  time: 0.7996  data_time: 0.0248  memory: 5632  loss: 0.3444  decode.loss_ce: 0.3444  decode.acc_seg: 69.1941\n",
      "03/09 23:13:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14800/40000]  base_lr: 5.4966e-05 lr: 5.4966e-05  eta: 5:36:23  time: 0.7936  data_time: 0.0236  memory: 5633  loss: 0.4791  decode.loss_ce: 0.4791  decode.acc_seg: 77.3250\n",
      "03/09 23:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14900/40000]  base_lr: 5.4928e-05 lr: 5.4928e-05  eta: 5:35:03  time: 0.7942  data_time: 0.0243  memory: 5634  loss: 0.4851  decode.loss_ce: 0.4851  decode.acc_seg: 80.5402\n",
      "03/09 23:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 23:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15000/40000]  base_lr: 5.4890e-05 lr: 5.4890e-05  eta: 5:33:42  time: 0.7933  data_time: 0.0242  memory: 5634  loss: 0.4664  decode.loss_ce: 0.4664  decode.acc_seg: 92.8277\n",
      "03/09 23:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15100/40000]  base_lr: 5.4852e-05 lr: 5.4852e-05  eta: 5:32:21  time: 0.7926  data_time: 0.0236  memory: 5632  loss: 0.4392  decode.loss_ce: 0.4392  decode.acc_seg: 76.4803\n",
      "03/09 23:18:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15200/40000]  base_lr: 5.4814e-05 lr: 5.4814e-05  eta: 5:31:00  time: 0.7949  data_time: 0.0240  memory: 5633  loss: 0.3807  decode.loss_ce: 0.3807  decode.acc_seg: 57.0914\n",
      "03/09 23:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15300/40000]  base_lr: 5.4776e-05 lr: 5.4776e-05  eta: 5:29:39  time: 0.7938  data_time: 0.0242  memory: 5634  loss: 0.3611  decode.loss_ce: 0.3611  decode.acc_seg: 92.0900\n",
      "03/09 23:21:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15400/40000]  base_lr: 5.4739e-05 lr: 5.4739e-05  eta: 5:28:18  time: 0.7938  data_time: 0.0240  memory: 5633  loss: 0.5323  decode.loss_ce: 0.5323  decode.acc_seg: 79.1872\n",
      "03/09 23:22:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15500/40000]  base_lr: 5.4701e-05 lr: 5.4701e-05  eta: 5:26:58  time: 0.7958  data_time: 0.0233  memory: 5634  loss: 0.4200  decode.loss_ce: 0.4200  decode.acc_seg: 68.9382\n",
      "03/09 23:23:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15600/40000]  base_lr: 5.4663e-05 lr: 5.4663e-05  eta: 5:25:37  time: 0.7895  data_time: 0.0233  memory: 5632  loss: 0.2952  decode.loss_ce: 0.2952  decode.acc_seg: 92.9605\n",
      "03/09 23:25:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15700/40000]  base_lr: 5.4625e-05 lr: 5.4625e-05  eta: 5:24:15  time: 0.7915  data_time: 0.0230  memory: 5634  loss: 0.3759  decode.loss_ce: 0.3759  decode.acc_seg: 56.9856\n",
      "03/09 23:26:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15800/40000]  base_lr: 5.4587e-05 lr: 5.4587e-05  eta: 5:22:54  time: 0.7932  data_time: 0.0235  memory: 5633  loss: 0.4997  decode.loss_ce: 0.4997  decode.acc_seg: 58.6448\n",
      "03/09 23:27:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15900/40000]  base_lr: 5.4549e-05 lr: 5.4549e-05  eta: 5:21:34  time: 0.7906  data_time: 0.0233  memory: 5634  loss: 0.3863  decode.loss_ce: 0.3863  decode.acc_seg: 84.4895\n",
      "03/09 23:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 23:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16000/40000]  base_lr: 5.4511e-05 lr: 5.4511e-05  eta: 5:20:13  time: 0.7953  data_time: 0.0244  memory: 5633  loss: 0.6648  decode.loss_ce: 0.6648  decode.acc_seg: 84.1026\n",
      "03/09 23:30:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16100/40000]  base_lr: 5.4474e-05 lr: 5.4474e-05  eta: 5:18:52  time: 0.7913  data_time: 0.0240  memory: 5634  loss: 0.5993  decode.loss_ce: 0.5993  decode.acc_seg: 86.1742\n",
      "03/09 23:31:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16200/40000]  base_lr: 5.4436e-05 lr: 5.4436e-05  eta: 5:17:32  time: 0.7945  data_time: 0.0237  memory: 5632  loss: 0.3183  decode.loss_ce: 0.3183  decode.acc_seg: 65.9729\n",
      "03/09 23:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16300/40000]  base_lr: 5.4398e-05 lr: 5.4398e-05  eta: 5:16:11  time: 0.7931  data_time: 0.0238  memory: 5634  loss: 0.6396  decode.loss_ce: 0.6396  decode.acc_seg: 98.0781\n",
      "03/09 23:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16400/40000]  base_lr: 5.4360e-05 lr: 5.4360e-05  eta: 5:14:50  time: 0.7948  data_time: 0.0248  memory: 5632  loss: 0.4728  decode.loss_ce: 0.4728  decode.acc_seg: 97.0604\n",
      "03/09 23:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16500/40000]  base_lr: 5.4322e-05 lr: 5.4322e-05  eta: 5:13:30  time: 0.7920  data_time: 0.0234  memory: 5632  loss: 0.3940  decode.loss_ce: 0.3940  decode.acc_seg: 80.0264\n",
      "03/09 23:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16600/40000]  base_lr: 5.4284e-05 lr: 5.4284e-05  eta: 5:12:09  time: 0.7974  data_time: 0.0231  memory: 5632  loss: 0.4796  decode.loss_ce: 0.4796  decode.acc_seg: 94.0496\n",
      "03/09 23:38:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16700/40000]  base_lr: 5.4246e-05 lr: 5.4246e-05  eta: 5:10:48  time: 0.7913  data_time: 0.0232  memory: 5634  loss: 0.5083  decode.loss_ce: 0.5083  decode.acc_seg: 76.9565\n",
      "03/09 23:39:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16800/40000]  base_lr: 5.4209e-05 lr: 5.4209e-05  eta: 5:09:27  time: 0.7956  data_time: 0.0249  memory: 5634  loss: 0.3924  decode.loss_ce: 0.3924  decode.acc_seg: 86.7409\n",
      "03/09 23:41:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16900/40000]  base_lr: 5.4171e-05 lr: 5.4171e-05  eta: 5:08:06  time: 0.7929  data_time: 0.0234  memory: 5634  loss: 0.2772  decode.loss_ce: 0.2772  decode.acc_seg: 80.4701\n",
      "03/09 23:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 23:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17000/40000]  base_lr: 5.4133e-05 lr: 5.4133e-05  eta: 5:06:46  time: 0.7941  data_time: 0.0243  memory: 5634  loss: 0.3884  decode.loss_ce: 0.3884  decode.acc_seg: 65.9412\n",
      "03/09 23:43:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17100/40000]  base_lr: 5.4095e-05 lr: 5.4095e-05  eta: 5:05:25  time: 0.7970  data_time: 0.0243  memory: 5632  loss: 0.4871  decode.loss_ce: 0.4871  decode.acc_seg: 26.1478\n",
      "03/09 23:45:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17200/40000]  base_lr: 5.4057e-05 lr: 5.4057e-05  eta: 5:04:05  time: 0.8022  data_time: 0.0247  memory: 5634  loss: 0.4161  decode.loss_ce: 0.4161  decode.acc_seg: 86.3666\n",
      "03/09 23:46:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17300/40000]  base_lr: 5.4019e-05 lr: 5.4019e-05  eta: 5:02:44  time: 0.7933  data_time: 0.0237  memory: 5634  loss: 0.5284  decode.loss_ce: 0.5284  decode.acc_seg: 93.8560\n",
      "03/09 23:47:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17400/40000]  base_lr: 5.3981e-05 lr: 5.3981e-05  eta: 5:01:23  time: 0.7934  data_time: 0.0250  memory: 5632  loss: 0.3515  decode.loss_ce: 0.3515  decode.acc_seg: 77.8618\n",
      "03/09 23:48:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17500/40000]  base_lr: 5.3944e-05 lr: 5.3944e-05  eta: 5:00:03  time: 0.7947  data_time: 0.0240  memory: 5634  loss: 0.3821  decode.loss_ce: 0.3821  decode.acc_seg: 85.0019\n",
      "03/09 23:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17600/40000]  base_lr: 5.3906e-05 lr: 5.3906e-05  eta: 4:58:42  time: 0.7959  data_time: 0.0253  memory: 5632  loss: 0.3437  decode.loss_ce: 0.3437  decode.acc_seg: 89.0120\n",
      "03/09 23:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17700/40000]  base_lr: 5.3868e-05 lr: 5.3868e-05  eta: 4:57:22  time: 0.7954  data_time: 0.0237  memory: 5632  loss: 0.3186  decode.loss_ce: 0.3186  decode.acc_seg: 82.4043\n",
      "03/09 23:52:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17800/40000]  base_lr: 5.3830e-05 lr: 5.3830e-05  eta: 4:56:01  time: 0.7947  data_time: 0.0238  memory: 5632  loss: 0.3093  decode.loss_ce: 0.3093  decode.acc_seg: 72.9356\n",
      "03/09 23:54:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17900/40000]  base_lr: 5.3792e-05 lr: 5.3792e-05  eta: 4:54:41  time: 0.7918  data_time: 0.0230  memory: 5634  loss: 0.4016  decode.loss_ce: 0.4016  decode.acc_seg: 86.5433\n",
      "03/09 23:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/09 23:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18000/40000]  base_lr: 5.3754e-05 lr: 5.3754e-05  eta: 4:53:20  time: 0.7984  data_time: 0.0233  memory: 5632  loss: 0.4897  decode.loss_ce: 0.4897  decode.acc_seg: 81.2531\n",
      "03/09 23:56:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18100/40000]  base_lr: 5.3716e-05 lr: 5.3716e-05  eta: 4:51:59  time: 0.7907  data_time: 0.0231  memory: 5632  loss: 0.2805  decode.loss_ce: 0.2805  decode.acc_seg: 96.0784\n",
      "03/09 23:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18200/40000]  base_lr: 5.3679e-05 lr: 5.3679e-05  eta: 4:50:38  time: 0.7917  data_time: 0.0232  memory: 5633  loss: 0.3653  decode.loss_ce: 0.3653  decode.acc_seg: 81.1100\n",
      "03/09 23:59:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18300/40000]  base_lr: 5.3641e-05 lr: 5.3641e-05  eta: 4:49:18  time: 0.7930  data_time: 0.0239  memory: 5632  loss: 0.3547  decode.loss_ce: 0.3547  decode.acc_seg: 84.1137\n",
      "03/10 00:00:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18400/40000]  base_lr: 5.3603e-05 lr: 5.3603e-05  eta: 4:47:57  time: 0.7939  data_time: 0.0239  memory: 5633  loss: 0.5542  decode.loss_ce: 0.5542  decode.acc_seg: 85.6870\n",
      "03/10 00:02:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18500/40000]  base_lr: 5.3565e-05 lr: 5.3565e-05  eta: 4:46:36  time: 0.7927  data_time: 0.0245  memory: 5632  loss: 0.4189  decode.loss_ce: 0.4189  decode.acc_seg: 85.2249\n",
      "03/10 00:03:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18600/40000]  base_lr: 5.3527e-05 lr: 5.3527e-05  eta: 4:45:16  time: 0.7936  data_time: 0.0234  memory: 5634  loss: 0.6898  decode.loss_ce: 0.6898  decode.acc_seg: 72.0575\n",
      "03/10 00:04:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18700/40000]  base_lr: 5.3489e-05 lr: 5.3489e-05  eta: 4:43:55  time: 0.7916  data_time: 0.0236  memory: 5634  loss: 0.5419  decode.loss_ce: 0.5419  decode.acc_seg: 63.7999\n",
      "03/10 00:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18800/40000]  base_lr: 5.3451e-05 lr: 5.3451e-05  eta: 4:42:34  time: 0.7950  data_time: 0.0236  memory: 5632  loss: 0.4365  decode.loss_ce: 0.4365  decode.acc_seg: 80.4093\n",
      "03/10 00:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18900/40000]  base_lr: 5.3414e-05 lr: 5.3414e-05  eta: 4:41:14  time: 0.7909  data_time: 0.0227  memory: 5634  loss: 0.4103  decode.loss_ce: 0.4103  decode.acc_seg: 81.0186\n",
      "03/10 00:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 00:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19000/40000]  base_lr: 5.3376e-05 lr: 5.3376e-05  eta: 4:39:53  time: 0.7891  data_time: 0.0228  memory: 5634  loss: 0.6701  decode.loss_ce: 0.6701  decode.acc_seg: 72.8895\n",
      "03/10 00:10:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19100/40000]  base_lr: 5.3338e-05 lr: 5.3338e-05  eta: 4:38:32  time: 0.7916  data_time: 0.0230  memory: 5632  loss: 0.3864  decode.loss_ce: 0.3864  decode.acc_seg: 89.4303\n",
      "03/10 00:11:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19200/40000]  base_lr: 5.3300e-05 lr: 5.3300e-05  eta: 4:37:12  time: 0.7903  data_time: 0.0235  memory: 5633  loss: 0.2483  decode.loss_ce: 0.2483  decode.acc_seg: 90.1570\n",
      "03/10 00:12:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19300/40000]  base_lr: 5.3262e-05 lr: 5.3262e-05  eta: 4:35:51  time: 0.7906  data_time: 0.0232  memory: 5632  loss: 0.3814  decode.loss_ce: 0.3814  decode.acc_seg: 85.3662\n",
      "03/10 00:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19400/40000]  base_lr: 5.3224e-05 lr: 5.3224e-05  eta: 4:34:31  time: 0.7895  data_time: 0.0232  memory: 5632  loss: 0.4292  decode.loss_ce: 0.4292  decode.acc_seg: 95.1273\n",
      "03/10 00:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19500/40000]  base_lr: 5.3186e-05 lr: 5.3186e-05  eta: 4:33:10  time: 0.7934  data_time: 0.0239  memory: 5634  loss: 0.3905  decode.loss_ce: 0.3905  decode.acc_seg: 91.6371\n",
      "03/10 00:16:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19600/40000]  base_lr: 5.3149e-05 lr: 5.3149e-05  eta: 4:31:49  time: 0.7877  data_time: 0.0232  memory: 5632  loss: 0.3370  decode.loss_ce: 0.3370  decode.acc_seg: 95.8727\n",
      "03/10 00:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19700/40000]  base_lr: 5.3111e-05 lr: 5.3111e-05  eta: 4:30:29  time: 0.7957  data_time: 0.0242  memory: 5632  loss: 0.3789  decode.loss_ce: 0.3789  decode.acc_seg: 72.1667\n",
      "03/10 00:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19800/40000]  base_lr: 5.3073e-05 lr: 5.3073e-05  eta: 4:29:08  time: 0.7908  data_time: 0.0236  memory: 5632  loss: 0.5314  decode.loss_ce: 0.5314  decode.acc_seg: 83.3987\n",
      "03/10 00:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19900/40000]  base_lr: 5.3035e-05 lr: 5.3035e-05  eta: 4:27:48  time: 0.7952  data_time: 0.0238  memory: 5633  loss: 0.2822  decode.loss_ce: 0.2822  decode.acc_seg: 77.4717\n",
      "03/10 00:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 00:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20000/40000]  base_lr: 5.2997e-05 lr: 5.2997e-05  eta: 4:26:27  time: 0.7881  data_time: 0.0230  memory: 5634  loss: 0.2715  decode.loss_ce: 0.2715  decode.acc_seg: 86.5863\n",
      "03/10 00:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20100/40000]  base_lr: 5.2959e-05 lr: 5.2959e-05  eta: 4:25:07  time: 0.7909  data_time: 0.0228  memory: 5634  loss: 0.4148  decode.loss_ce: 0.4148  decode.acc_seg: 70.4093\n",
      "03/10 00:24:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20200/40000]  base_lr: 5.2921e-05 lr: 5.2921e-05  eta: 4:23:46  time: 0.7896  data_time: 0.0232  memory: 5632  loss: 0.4273  decode.loss_ce: 0.4273  decode.acc_seg: 55.0823\n",
      "03/10 00:26:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20300/40000]  base_lr: 5.2884e-05 lr: 5.2884e-05  eta: 4:22:25  time: 0.7916  data_time: 0.0226  memory: 5632  loss: 0.3185  decode.loss_ce: 0.3185  decode.acc_seg: 98.0610\n",
      "03/10 00:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20400/40000]  base_lr: 5.2846e-05 lr: 5.2846e-05  eta: 4:21:04  time: 0.7895  data_time: 0.0231  memory: 5633  loss: 0.3107  decode.loss_ce: 0.3107  decode.acc_seg: 86.7403\n",
      "03/10 00:28:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20500/40000]  base_lr: 5.2808e-05 lr: 5.2808e-05  eta: 4:19:44  time: 0.7848  data_time: 0.0228  memory: 5632  loss: 0.3618  decode.loss_ce: 0.3618  decode.acc_seg: 96.9325\n",
      "03/10 00:30:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20600/40000]  base_lr: 5.2770e-05 lr: 5.2770e-05  eta: 4:18:23  time: 0.7895  data_time: 0.0232  memory: 5634  loss: 0.4890  decode.loss_ce: 0.4890  decode.acc_seg: 87.2919\n",
      "03/10 00:31:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20700/40000]  base_lr: 5.2732e-05 lr: 5.2732e-05  eta: 4:17:02  time: 0.7874  data_time: 0.0233  memory: 5632  loss: 0.4885  decode.loss_ce: 0.4885  decode.acc_seg: 85.1653\n",
      "03/10 00:32:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20800/40000]  base_lr: 5.2694e-05 lr: 5.2694e-05  eta: 4:15:42  time: 0.7916  data_time: 0.0231  memory: 5634  loss: 0.5788  decode.loss_ce: 0.5788  decode.acc_seg: 89.2224\n",
      "03/10 00:33:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20900/40000]  base_lr: 5.2656e-05 lr: 5.2656e-05  eta: 4:14:21  time: 0.7907  data_time: 0.0237  memory: 5634  loss: 0.3886  decode.loss_ce: 0.3886  decode.acc_seg: 84.9780\n",
      "03/10 00:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 00:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21000/40000]  base_lr: 5.2619e-05 lr: 5.2619e-05  eta: 4:13:01  time: 0.7912  data_time: 0.0241  memory: 5634  loss: 0.3457  decode.loss_ce: 0.3457  decode.acc_seg: 82.0663\n",
      "03/10 00:36:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21100/40000]  base_lr: 5.2581e-05 lr: 5.2581e-05  eta: 4:11:40  time: 0.7897  data_time: 0.0227  memory: 5632  loss: 0.2539  decode.loss_ce: 0.2539  decode.acc_seg: 80.9062\n",
      "03/10 00:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21200/40000]  base_lr: 5.2543e-05 lr: 5.2543e-05  eta: 4:10:20  time: 0.7907  data_time: 0.0229  memory: 5634  loss: 0.4367  decode.loss_ce: 0.4367  decode.acc_seg: 92.0817\n",
      "03/10 00:39:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21300/40000]  base_lr: 5.2505e-05 lr: 5.2505e-05  eta: 4:08:59  time: 0.7916  data_time: 0.0237  memory: 5632  loss: 0.2994  decode.loss_ce: 0.2994  decode.acc_seg: 82.5457\n",
      "03/10 00:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21400/40000]  base_lr: 5.2467e-05 lr: 5.2467e-05  eta: 4:07:39  time: 0.7916  data_time: 0.0236  memory: 5634  loss: 0.5025  decode.loss_ce: 0.5025  decode.acc_seg: 71.1975\n",
      "03/10 00:41:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21500/40000]  base_lr: 5.2429e-05 lr: 5.2429e-05  eta: 4:06:19  time: 0.8111  data_time: 0.0232  memory: 5634  loss: 0.5137  decode.loss_ce: 0.5137  decode.acc_seg: 70.4231\n",
      "03/10 00:43:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21600/40000]  base_lr: 5.2391e-05 lr: 5.2391e-05  eta: 4:04:58  time: 0.7884  data_time: 0.0234  memory: 5634  loss: 0.3921  decode.loss_ce: 0.3921  decode.acc_seg: 84.4866\n",
      "03/10 00:44:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21700/40000]  base_lr: 5.2354e-05 lr: 5.2354e-05  eta: 4:03:38  time: 0.7922  data_time: 0.0227  memory: 5632  loss: 0.3399  decode.loss_ce: 0.3399  decode.acc_seg: 83.2930\n",
      "03/10 00:45:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21800/40000]  base_lr: 5.2316e-05 lr: 5.2316e-05  eta: 4:02:17  time: 0.7892  data_time: 0.0225  memory: 5632  loss: 0.2700  decode.loss_ce: 0.2700  decode.acc_seg: 73.0911\n",
      "03/10 00:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21900/40000]  base_lr: 5.2278e-05 lr: 5.2278e-05  eta: 4:00:57  time: 0.8014  data_time: 0.0235  memory: 5634  loss: 0.5526  decode.loss_ce: 0.5526  decode.acc_seg: 93.0374\n",
      "03/10 00:48:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 00:48:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22000/40000]  base_lr: 5.2240e-05 lr: 5.2240e-05  eta: 3:59:37  time: 0.7897  data_time: 0.0233  memory: 5634  loss: 0.4318  decode.loss_ce: 0.4318  decode.acc_seg: 68.7820\n",
      "03/10 00:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22100/40000]  base_lr: 5.2202e-05 lr: 5.2202e-05  eta: 3:58:16  time: 0.7992  data_time: 0.0234  memory: 5632  loss: 0.2730  decode.loss_ce: 0.2730  decode.acc_seg: 93.6457\n",
      "03/10 00:51:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22200/40000]  base_lr: 5.2164e-05 lr: 5.2164e-05  eta: 3:56:56  time: 0.7934  data_time: 0.0228  memory: 5634  loss: 0.3776  decode.loss_ce: 0.3776  decode.acc_seg: 89.8849\n",
      "03/10 00:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22300/40000]  base_lr: 5.2127e-05 lr: 5.2127e-05  eta: 3:55:35  time: 0.7917  data_time: 0.0234  memory: 5634  loss: 0.3649  decode.loss_ce: 0.3649  decode.acc_seg: 60.2339\n",
      "03/10 00:53:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22400/40000]  base_lr: 5.2089e-05 lr: 5.2089e-05  eta: 3:54:15  time: 0.7882  data_time: 0.0230  memory: 5634  loss: 0.3160  decode.loss_ce: 0.3160  decode.acc_seg: 66.8208\n",
      "03/10 00:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22500/40000]  base_lr: 5.2051e-05 lr: 5.2051e-05  eta: 3:52:54  time: 0.7928  data_time: 0.0228  memory: 5632  loss: 0.3679  decode.loss_ce: 0.3679  decode.acc_seg: 75.0304\n",
      "03/10 00:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22600/40000]  base_lr: 5.2013e-05 lr: 5.2013e-05  eta: 3:51:34  time: 0.7889  data_time: 0.0237  memory: 5633  loss: 0.4789  decode.loss_ce: 0.4789  decode.acc_seg: 74.9773\n",
      "03/10 00:57:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22700/40000]  base_lr: 5.1975e-05 lr: 5.1975e-05  eta: 3:50:13  time: 0.7945  data_time: 0.0240  memory: 5634  loss: 0.4414  decode.loss_ce: 0.4414  decode.acc_seg: 78.0106\n",
      "03/10 00:59:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22800/40000]  base_lr: 5.1937e-05 lr: 5.1937e-05  eta: 3:48:53  time: 0.7895  data_time: 0.0236  memory: 5632  loss: 0.3577  decode.loss_ce: 0.3577  decode.acc_seg: 92.3199\n",
      "03/10 01:00:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22900/40000]  base_lr: 5.1899e-05 lr: 5.1899e-05  eta: 3:47:32  time: 0.7933  data_time: 0.0237  memory: 5633  loss: 0.5801  decode.loss_ce: 0.5801  decode.acc_seg: 96.4930\n",
      "03/10 01:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 01:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23000/40000]  base_lr: 5.1862e-05 lr: 5.1862e-05  eta: 3:46:12  time: 0.7882  data_time: 0.0227  memory: 5632  loss: 0.3740  decode.loss_ce: 0.3740  decode.acc_seg: 90.9588\n",
      "03/10 01:02:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23100/40000]  base_lr: 5.1824e-05 lr: 5.1824e-05  eta: 3:44:52  time: 0.7950  data_time: 0.0233  memory: 5632  loss: 0.4805  decode.loss_ce: 0.4805  decode.acc_seg: 63.3801\n",
      "03/10 01:04:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23200/40000]  base_lr: 5.1786e-05 lr: 5.1786e-05  eta: 3:43:31  time: 0.7871  data_time: 0.0227  memory: 5632  loss: 0.3353  decode.loss_ce: 0.3353  decode.acc_seg: 76.8587\n",
      "03/10 01:05:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23300/40000]  base_lr: 5.1748e-05 lr: 5.1748e-05  eta: 3:42:11  time: 0.7918  data_time: 0.0241  memory: 5632  loss: 0.3200  decode.loss_ce: 0.3200  decode.acc_seg: 93.8637\n",
      "03/10 01:06:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23400/40000]  base_lr: 5.1710e-05 lr: 5.1710e-05  eta: 3:40:51  time: 0.7922  data_time: 0.0232  memory: 5633  loss: 0.4163  decode.loss_ce: 0.4163  decode.acc_seg: 43.6524\n",
      "03/10 01:08:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23500/40000]  base_lr: 5.1672e-05 lr: 5.1672e-05  eta: 3:39:30  time: 0.7954  data_time: 0.0232  memory: 5633  loss: 0.3760  decode.loss_ce: 0.3760  decode.acc_seg: 61.5257\n",
      "03/10 01:09:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23600/40000]  base_lr: 5.1634e-05 lr: 5.1634e-05  eta: 3:38:10  time: 0.7914  data_time: 0.0237  memory: 5634  loss: 0.2604  decode.loss_ce: 0.2604  decode.acc_seg: 80.8751\n",
      "03/10 01:10:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23700/40000]  base_lr: 5.1597e-05 lr: 5.1597e-05  eta: 3:36:50  time: 0.7949  data_time: 0.0236  memory: 5634  loss: 0.3537  decode.loss_ce: 0.3537  decode.acc_seg: 51.6297\n",
      "03/10 01:12:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23800/40000]  base_lr: 5.1559e-05 lr: 5.1559e-05  eta: 3:35:29  time: 0.7903  data_time: 0.0229  memory: 5634  loss: 0.4441  decode.loss_ce: 0.4441  decode.acc_seg: 85.0272\n",
      "03/10 01:13:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23900/40000]  base_lr: 5.1521e-05 lr: 5.1521e-05  eta: 3:34:09  time: 0.7941  data_time: 0.0239  memory: 5634  loss: 0.3659  decode.loss_ce: 0.3659  decode.acc_seg: 78.5431\n",
      "03/10 01:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 01:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24000/40000]  base_lr: 5.1483e-05 lr: 5.1483e-05  eta: 3:32:49  time: 0.7877  data_time: 0.0230  memory: 5633  loss: 0.2896  decode.loss_ce: 0.2896  decode.acc_seg: 96.3297\n",
      "03/10 01:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24100/40000]  base_lr: 5.1445e-05 lr: 5.1445e-05  eta: 3:31:28  time: 0.7892  data_time: 0.0229  memory: 5632  loss: 0.5371  decode.loss_ce: 0.5371  decode.acc_seg: 37.5989\n",
      "03/10 01:17:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24200/40000]  base_lr: 5.1407e-05 lr: 5.1407e-05  eta: 3:30:08  time: 0.7898  data_time: 0.0230  memory: 5634  loss: 0.4249  decode.loss_ce: 0.4249  decode.acc_seg: 97.9678\n",
      "03/10 01:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24300/40000]  base_lr: 5.1369e-05 lr: 5.1369e-05  eta: 3:28:47  time: 0.7933  data_time: 0.0226  memory: 5634  loss: 0.4257  decode.loss_ce: 0.4257  decode.acc_seg: 54.5056\n",
      "03/10 01:20:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24400/40000]  base_lr: 5.1332e-05 lr: 5.1332e-05  eta: 3:27:27  time: 0.7868  data_time: 0.0226  memory: 5632  loss: 0.7876  decode.loss_ce: 0.7876  decode.acc_seg: 57.0216\n",
      "03/10 01:21:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24500/40000]  base_lr: 5.1294e-05 lr: 5.1294e-05  eta: 3:26:07  time: 0.7919  data_time: 0.0232  memory: 5634  loss: 0.3214  decode.loss_ce: 0.3214  decode.acc_seg: 87.5641\n",
      "03/10 01:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24600/40000]  base_lr: 5.1256e-05 lr: 5.1256e-05  eta: 3:24:46  time: 0.7856  data_time: 0.0221  memory: 5634  loss: 0.2503  decode.loss_ce: 0.2503  decode.acc_seg: 90.0458\n",
      "03/10 01:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24700/40000]  base_lr: 5.1218e-05 lr: 5.1218e-05  eta: 3:23:26  time: 0.7920  data_time: 0.0224  memory: 5634  loss: 0.3502  decode.loss_ce: 0.3502  decode.acc_seg: 88.4827\n",
      "03/10 01:25:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24800/40000]  base_lr: 5.1180e-05 lr: 5.1180e-05  eta: 3:22:05  time: 0.7834  data_time: 0.0218  memory: 5634  loss: 0.6684  decode.loss_ce: 0.6684  decode.acc_seg: 83.0870\n",
      "03/10 01:26:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24900/40000]  base_lr: 5.1142e-05 lr: 5.1142e-05  eta: 3:20:45  time: 0.7933  data_time: 0.0223  memory: 5634  loss: 0.4672  decode.loss_ce: 0.4672  decode.acc_seg: 88.2207\n",
      "03/10 01:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 01:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25000/40000]  base_lr: 5.1104e-05 lr: 5.1104e-05  eta: 3:19:24  time: 0.7839  data_time: 0.0221  memory: 5634  loss: 0.4173  decode.loss_ce: 0.4173  decode.acc_seg: 70.5625\n",
      "03/10 01:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25100/40000]  base_lr: 5.1067e-05 lr: 5.1067e-05  eta: 3:18:04  time: 0.7901  data_time: 0.0229  memory: 5634  loss: 0.3520  decode.loss_ce: 0.3520  decode.acc_seg: 82.5416\n",
      "03/10 01:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25200/40000]  base_lr: 5.1029e-05 lr: 5.1029e-05  eta: 3:16:44  time: 0.7858  data_time: 0.0224  memory: 5634  loss: 0.4611  decode.loss_ce: 0.4611  decode.acc_seg: 69.5428\n",
      "03/10 01:31:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25300/40000]  base_lr: 5.0991e-05 lr: 5.0991e-05  eta: 3:15:23  time: 0.7866  data_time: 0.0229  memory: 5634  loss: 0.2783  decode.loss_ce: 0.2783  decode.acc_seg: 84.1858\n",
      "03/10 01:33:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25400/40000]  base_lr: 5.0953e-05 lr: 5.0953e-05  eta: 3:14:03  time: 0.7835  data_time: 0.0220  memory: 5632  loss: 0.2736  decode.loss_ce: 0.2736  decode.acc_seg: 97.7143\n",
      "03/10 01:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25500/40000]  base_lr: 5.0915e-05 lr: 5.0915e-05  eta: 3:12:42  time: 0.7836  data_time: 0.0222  memory: 5634  loss: 0.3131  decode.loss_ce: 0.3131  decode.acc_seg: 88.2142\n",
      "03/10 01:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25600/40000]  base_lr: 5.0877e-05 lr: 5.0877e-05  eta: 3:11:22  time: 0.7839  data_time: 0.0224  memory: 5634  loss: 0.3257  decode.loss_ce: 0.3257  decode.acc_seg: 73.1336\n",
      "03/10 01:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25700/40000]  base_lr: 5.0839e-05 lr: 5.0839e-05  eta: 3:10:02  time: 0.7835  data_time: 0.0218  memory: 5632  loss: 0.3303  decode.loss_ce: 0.3303  decode.acc_seg: 97.6334\n",
      "03/10 01:38:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25800/40000]  base_lr: 5.0802e-05 lr: 5.0802e-05  eta: 3:08:41  time: 0.7851  data_time: 0.0229  memory: 5632  loss: 0.3237  decode.loss_ce: 0.3237  decode.acc_seg: 95.1421\n",
      "03/10 01:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25900/40000]  base_lr: 5.0764e-05 lr: 5.0764e-05  eta: 3:07:21  time: 0.7856  data_time: 0.0224  memory: 5632  loss: 0.4324  decode.loss_ce: 0.4324  decode.acc_seg: 66.0165\n",
      "03/10 01:41:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 01:41:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26000/40000]  base_lr: 5.0726e-05 lr: 5.0726e-05  eta: 3:06:00  time: 0.7838  data_time: 0.0223  memory: 5634  loss: 0.1853  decode.loss_ce: 0.1853  decode.acc_seg: 92.4789\n",
      "03/10 01:42:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26100/40000]  base_lr: 5.0688e-05 lr: 5.0688e-05  eta: 3:04:40  time: 0.7887  data_time: 0.0222  memory: 5634  loss: 0.2617  decode.loss_ce: 0.2617  decode.acc_seg: 96.3575\n",
      "03/10 01:43:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26200/40000]  base_lr: 5.0650e-05 lr: 5.0650e-05  eta: 3:03:20  time: 0.7850  data_time: 0.0223  memory: 5633  loss: 0.4810  decode.loss_ce: 0.4810  decode.acc_seg: 85.9076\n",
      "03/10 01:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26300/40000]  base_lr: 5.0612e-05 lr: 5.0612e-05  eta: 3:01:59  time: 0.7816  data_time: 0.0220  memory: 5632  loss: 0.2700  decode.loss_ce: 0.2700  decode.acc_seg: 74.1822\n",
      "03/10 01:46:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26400/40000]  base_lr: 5.0574e-05 lr: 5.0574e-05  eta: 3:00:39  time: 0.7820  data_time: 0.0218  memory: 5632  loss: 0.2569  decode.loss_ce: 0.2569  decode.acc_seg: 87.8420\n",
      "03/10 01:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26500/40000]  base_lr: 5.0537e-05 lr: 5.0537e-05  eta: 2:59:19  time: 0.7812  data_time: 0.0218  memory: 5634  loss: 0.3432  decode.loss_ce: 0.3432  decode.acc_seg: 91.5209\n",
      "03/10 01:48:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26600/40000]  base_lr: 5.0499e-05 lr: 5.0499e-05  eta: 2:57:58  time: 0.7835  data_time: 0.0219  memory: 5634  loss: 0.4542  decode.loss_ce: 0.4542  decode.acc_seg: 90.8310\n",
      "03/10 01:50:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26700/40000]  base_lr: 5.0461e-05 lr: 5.0461e-05  eta: 2:56:38  time: 0.7822  data_time: 0.0224  memory: 5634  loss: 0.7782  decode.loss_ce: 0.7782  decode.acc_seg: 44.8820\n",
      "03/10 01:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26800/40000]  base_lr: 5.0423e-05 lr: 5.0423e-05  eta: 2:55:18  time: 0.7832  data_time: 0.0224  memory: 5634  loss: 0.3202  decode.loss_ce: 0.3202  decode.acc_seg: 80.5668\n",
      "03/10 01:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26900/40000]  base_lr: 5.0385e-05 lr: 5.0385e-05  eta: 2:53:58  time: 0.7837  data_time: 0.0218  memory: 5632  loss: 0.2901  decode.loss_ce: 0.2901  decode.acc_seg: 98.3950\n",
      "03/10 01:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 01:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27000/40000]  base_lr: 5.0347e-05 lr: 5.0347e-05  eta: 2:52:37  time: 0.7833  data_time: 0.0219  memory: 5634  loss: 0.3615  decode.loss_ce: 0.3615  decode.acc_seg: 93.8289\n",
      "03/10 01:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27100/40000]  base_lr: 5.0309e-05 lr: 5.0309e-05  eta: 2:51:17  time: 0.7859  data_time: 0.0229  memory: 5632  loss: 0.3950  decode.loss_ce: 0.3950  decode.acc_seg: 86.2129\n",
      "03/10 01:56:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27200/40000]  base_lr: 5.0272e-05 lr: 5.0272e-05  eta: 2:49:57  time: 0.7865  data_time: 0.0229  memory: 5634  loss: 0.2855  decode.loss_ce: 0.2855  decode.acc_seg: 95.5357\n",
      "03/10 01:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27300/40000]  base_lr: 5.0234e-05 lr: 5.0234e-05  eta: 2:48:37  time: 0.7847  data_time: 0.0218  memory: 5632  loss: 0.3517  decode.loss_ce: 0.3517  decode.acc_seg: 61.7899\n",
      "03/10 01:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27400/40000]  base_lr: 5.0196e-05 lr: 5.0196e-05  eta: 2:47:17  time: 0.7846  data_time: 0.0226  memory: 5633  loss: 0.4923  decode.loss_ce: 0.4923  decode.acc_seg: 74.3897\n",
      "03/10 02:00:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27500/40000]  base_lr: 5.0158e-05 lr: 5.0158e-05  eta: 2:45:56  time: 0.7860  data_time: 0.0221  memory: 5634  loss: 0.3833  decode.loss_ce: 0.3833  decode.acc_seg: 66.9556\n",
      "03/10 02:02:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27600/40000]  base_lr: 5.0120e-05 lr: 5.0120e-05  eta: 2:44:36  time: 0.7841  data_time: 0.0223  memory: 5632  loss: 0.3289  decode.loss_ce: 0.3289  decode.acc_seg: 91.6981\n",
      "03/10 02:03:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27700/40000]  base_lr: 5.0082e-05 lr: 5.0082e-05  eta: 2:43:16  time: 0.7845  data_time: 0.0225  memory: 5634  loss: 0.2981  decode.loss_ce: 0.2981  decode.acc_seg: 90.4104\n",
      "03/10 02:04:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27800/40000]  base_lr: 5.0044e-05 lr: 5.0044e-05  eta: 2:41:56  time: 0.7913  data_time: 0.0228  memory: 5632  loss: 0.3601  decode.loss_ce: 0.3601  decode.acc_seg: 93.2656\n",
      "03/10 02:05:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27900/40000]  base_lr: 5.0007e-05 lr: 5.0007e-05  eta: 2:40:36  time: 0.7840  data_time: 0.0219  memory: 5632  loss: 0.4414  decode.loss_ce: 0.4414  decode.acc_seg: 92.4923\n",
      "03/10 02:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 02:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28000/40000]  base_lr: 4.9969e-05 lr: 4.9969e-05  eta: 2:39:16  time: 0.7900  data_time: 0.0242  memory: 5632  loss: 0.6231  decode.loss_ce: 0.6231  decode.acc_seg: 88.6253\n",
      "03/10 02:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28100/40000]  base_lr: 4.9931e-05 lr: 4.9931e-05  eta: 2:37:56  time: 0.7854  data_time: 0.0215  memory: 5634  loss: 0.3264  decode.loss_ce: 0.3264  decode.acc_seg: 87.1344\n",
      "03/10 02:09:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28200/40000]  base_lr: 4.9893e-05 lr: 4.9893e-05  eta: 2:36:36  time: 0.7911  data_time: 0.0222  memory: 5632  loss: 0.2825  decode.loss_ce: 0.2825  decode.acc_seg: 74.7190\n",
      "03/10 02:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28300/40000]  base_lr: 4.9855e-05 lr: 4.9855e-05  eta: 2:35:15  time: 0.7832  data_time: 0.0220  memory: 5634  loss: 0.4161  decode.loss_ce: 0.4161  decode.acc_seg: 63.9134\n",
      "03/10 02:12:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28400/40000]  base_lr: 4.9817e-05 lr: 4.9817e-05  eta: 2:33:55  time: 0.7902  data_time: 0.0227  memory: 5632  loss: 0.5178  decode.loss_ce: 0.5178  decode.acc_seg: 98.0928\n",
      "03/10 02:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28500/40000]  base_lr: 4.9779e-05 lr: 4.9779e-05  eta: 2:32:35  time: 0.7845  data_time: 0.0229  memory: 5632  loss: 0.3606  decode.loss_ce: 0.3606  decode.acc_seg: 91.2098\n",
      "03/10 02:15:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28600/40000]  base_lr: 4.9742e-05 lr: 4.9742e-05  eta: 2:31:15  time: 0.7879  data_time: 0.0228  memory: 5632  loss: 0.3743  decode.loss_ce: 0.3743  decode.acc_seg: 90.8499\n",
      "03/10 02:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28700/40000]  base_lr: 4.9704e-05 lr: 4.9704e-05  eta: 2:29:55  time: 0.7821  data_time: 0.0217  memory: 5632  loss: 0.2928  decode.loss_ce: 0.2928  decode.acc_seg: 80.8252\n",
      "03/10 02:17:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28800/40000]  base_lr: 4.9666e-05 lr: 4.9666e-05  eta: 2:28:35  time: 0.7863  data_time: 0.0225  memory: 5634  loss: 0.2499  decode.loss_ce: 0.2499  decode.acc_seg: 81.4975\n",
      "03/10 02:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28900/40000]  base_lr: 4.9628e-05 lr: 4.9628e-05  eta: 2:27:15  time: 0.7829  data_time: 0.0219  memory: 5632  loss: 0.3901  decode.loss_ce: 0.3901  decode.acc_seg: 97.0768\n",
      "03/10 02:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 02:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29000/40000]  base_lr: 4.9590e-05 lr: 4.9590e-05  eta: 2:25:55  time: 0.7893  data_time: 0.0236  memory: 5634  loss: 0.7823  decode.loss_ce: 0.7823  decode.acc_seg: 48.0142\n",
      "03/10 02:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29100/40000]  base_lr: 4.9552e-05 lr: 4.9552e-05  eta: 2:24:35  time: 0.7833  data_time: 0.0219  memory: 5634  loss: 0.2510  decode.loss_ce: 0.2510  decode.acc_seg: 95.4168\n",
      "03/10 02:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29200/40000]  base_lr: 4.9515e-05 lr: 4.9515e-05  eta: 2:23:15  time: 0.7843  data_time: 0.0223  memory: 5632  loss: 0.2899  decode.loss_ce: 0.2899  decode.acc_seg: 92.0754\n",
      "03/10 02:24:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29300/40000]  base_lr: 4.9477e-05 lr: 4.9477e-05  eta: 2:21:55  time: 0.7826  data_time: 0.0218  memory: 5633  loss: 0.2484  decode.loss_ce: 0.2484  decode.acc_seg: 67.3562\n",
      "03/10 02:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29400/40000]  base_lr: 4.9439e-05 lr: 4.9439e-05  eta: 2:20:35  time: 0.7922  data_time: 0.0232  memory: 5634  loss: 0.6523  decode.loss_ce: 0.6523  decode.acc_seg: 73.4251\n",
      "03/10 02:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29500/40000]  base_lr: 4.9401e-05 lr: 4.9401e-05  eta: 2:19:15  time: 0.7809  data_time: 0.0218  memory: 5634  loss: 0.3668  decode.loss_ce: 0.3668  decode.acc_seg: 87.0901\n",
      "03/10 02:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29600/40000]  base_lr: 4.9363e-05 lr: 4.9363e-05  eta: 2:17:55  time: 0.7900  data_time: 0.0231  memory: 5634  loss: 0.2880  decode.loss_ce: 0.2880  decode.acc_seg: 94.3907\n",
      "03/10 02:29:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29700/40000]  base_lr: 4.9325e-05 lr: 4.9325e-05  eta: 2:16:35  time: 0.7832  data_time: 0.0223  memory: 5634  loss: 0.3574  decode.loss_ce: 0.3574  decode.acc_seg: 80.7490\n",
      "03/10 02:30:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29800/40000]  base_lr: 4.9287e-05 lr: 4.9287e-05  eta: 2:15:15  time: 0.7853  data_time: 0.0233  memory: 5632  loss: 0.3127  decode.loss_ce: 0.3127  decode.acc_seg: 89.7362\n",
      "03/10 02:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29900/40000]  base_lr: 4.9250e-05 lr: 4.9250e-05  eta: 2:13:55  time: 0.7827  data_time: 0.0222  memory: 5634  loss: 0.2639  decode.loss_ce: 0.2639  decode.acc_seg: 90.1979\n",
      "03/10 02:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 02:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30000/40000]  base_lr: 4.9212e-05 lr: 4.9212e-05  eta: 2:12:36  time: 0.7855  data_time: 0.0218  memory: 5632  loss: 0.3103  decode.loss_ce: 0.3103  decode.acc_seg: 93.1448\n",
      "03/10 02:34:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30100/40000]  base_lr: 4.9174e-05 lr: 4.9174e-05  eta: 2:11:16  time: 0.7837  data_time: 0.0219  memory: 5634  loss: 0.2954  decode.loss_ce: 0.2954  decode.acc_seg: 90.4102\n",
      "03/10 02:36:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30200/40000]  base_lr: 4.9136e-05 lr: 4.9136e-05  eta: 2:09:56  time: 0.7895  data_time: 0.0220  memory: 5634  loss: 0.3241  decode.loss_ce: 0.3241  decode.acc_seg: 86.4977\n",
      "03/10 02:37:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30300/40000]  base_lr: 4.9098e-05 lr: 4.9098e-05  eta: 2:08:36  time: 0.7836  data_time: 0.0218  memory: 5632  loss: 0.3406  decode.loss_ce: 0.3406  decode.acc_seg: 84.3311\n",
      "03/10 02:38:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30400/40000]  base_lr: 4.9060e-05 lr: 4.9060e-05  eta: 2:07:16  time: 0.7841  data_time: 0.0219  memory: 5634  loss: 0.3555  decode.loss_ce: 0.3555  decode.acc_seg: 96.3118\n",
      "03/10 02:39:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30500/40000]  base_lr: 4.9022e-05 lr: 4.9022e-05  eta: 2:05:56  time: 0.7820  data_time: 0.0221  memory: 5634  loss: 0.3288  decode.loss_ce: 0.3288  decode.acc_seg: 78.1218\n",
      "03/10 02:41:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30600/40000]  base_lr: 4.8985e-05 lr: 4.8985e-05  eta: 2:04:36  time: 0.7911  data_time: 0.0224  memory: 5634  loss: 0.2018  decode.loss_ce: 0.2018  decode.acc_seg: 95.5522\n",
      "03/10 02:42:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30700/40000]  base_lr: 4.8947e-05 lr: 4.8947e-05  eta: 2:03:16  time: 0.7846  data_time: 0.0228  memory: 5634  loss: 0.3675  decode.loss_ce: 0.3675  decode.acc_seg: 70.2097\n",
      "03/10 02:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30800/40000]  base_lr: 4.8909e-05 lr: 4.8909e-05  eta: 2:01:57  time: 0.7851  data_time: 0.0220  memory: 5634  loss: 0.3168  decode.loss_ce: 0.3168  decode.acc_seg: 83.5131\n",
      "03/10 02:45:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30900/40000]  base_lr: 4.8871e-05 lr: 4.8871e-05  eta: 2:00:37  time: 0.7846  data_time: 0.0224  memory: 5632  loss: 0.3223  decode.loss_ce: 0.3223  decode.acc_seg: 84.4990\n",
      "03/10 02:46:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 02:46:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31000/40000]  base_lr: 4.8833e-05 lr: 4.8833e-05  eta: 1:59:17  time: 0.7819  data_time: 0.0218  memory: 5632  loss: 0.2785  decode.loss_ce: 0.2785  decode.acc_seg: 78.2068\n",
      "03/10 02:47:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31100/40000]  base_lr: 4.8795e-05 lr: 4.8795e-05  eta: 1:57:57  time: 0.7833  data_time: 0.0220  memory: 5632  loss: 0.1645  decode.loss_ce: 0.1645  decode.acc_seg: 87.7819\n",
      "03/10 02:49:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31200/40000]  base_lr: 4.8757e-05 lr: 4.8757e-05  eta: 1:56:37  time: 0.7823  data_time: 0.0215  memory: 5632  loss: 0.3233  decode.loss_ce: 0.3233  decode.acc_seg: 92.3295\n",
      "03/10 02:50:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31300/40000]  base_lr: 4.8720e-05 lr: 4.8720e-05  eta: 1:55:18  time: 0.7827  data_time: 0.0216  memory: 5633  loss: 0.2361  decode.loss_ce: 0.2361  decode.acc_seg: 90.3906\n",
      "03/10 02:51:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31400/40000]  base_lr: 4.8682e-05 lr: 4.8682e-05  eta: 1:53:58  time: 0.7812  data_time: 0.0218  memory: 5632  loss: 0.3106  decode.loss_ce: 0.3106  decode.acc_seg: 77.9071\n",
      "03/10 02:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31500/40000]  base_lr: 4.8644e-05 lr: 4.8644e-05  eta: 1:52:38  time: 0.7837  data_time: 0.0218  memory: 5634  loss: 0.3939  decode.loss_ce: 0.3939  decode.acc_seg: 76.0563\n",
      "03/10 02:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31600/40000]  base_lr: 4.8606e-05 lr: 4.8606e-05  eta: 1:51:18  time: 0.7832  data_time: 0.0220  memory: 5632  loss: 0.3947  decode.loss_ce: 0.3947  decode.acc_seg: 75.2025\n",
      "03/10 02:55:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31700/40000]  base_lr: 4.8568e-05 lr: 4.8568e-05  eta: 1:49:58  time: 0.7817  data_time: 0.0220  memory: 5634  loss: 0.4299  decode.loss_ce: 0.4299  decode.acc_seg: 83.7834\n",
      "03/10 02:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31800/40000]  base_lr: 4.8530e-05 lr: 4.8530e-05  eta: 1:48:39  time: 0.7815  data_time: 0.0218  memory: 5633  loss: 0.2719  decode.loss_ce: 0.2719  decode.acc_seg: 91.5295\n",
      "03/10 02:58:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31900/40000]  base_lr: 4.8492e-05 lr: 4.8492e-05  eta: 1:47:19  time: 0.7819  data_time: 0.0218  memory: 5634  loss: 0.3632  decode.loss_ce: 0.3632  decode.acc_seg: 89.1348\n",
      "03/10 02:59:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 02:59:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32000/40000]  base_lr: 4.8455e-05 lr: 4.8455e-05  eta: 1:45:59  time: 0.7845  data_time: 0.0225  memory: 5633  loss: 0.2072  decode.loss_ce: 0.2072  decode.acc_seg: 86.7327\n",
      "03/10 03:00:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32100/40000]  base_lr: 4.8417e-05 lr: 4.8417e-05  eta: 1:44:39  time: 0.7827  data_time: 0.0217  memory: 5632  loss: 0.4061  decode.loss_ce: 0.4061  decode.acc_seg: 70.4903\n",
      "03/10 03:02:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32200/40000]  base_lr: 4.8379e-05 lr: 4.8379e-05  eta: 1:43:20  time: 0.7827  data_time: 0.0219  memory: 5634  loss: 0.2270  decode.loss_ce: 0.2270  decode.acc_seg: 98.1808\n",
      "03/10 03:03:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32300/40000]  base_lr: 4.8341e-05 lr: 4.8341e-05  eta: 1:42:00  time: 0.7866  data_time: 0.0218  memory: 5632  loss: 0.5452  decode.loss_ce: 0.5452  decode.acc_seg: 86.0276\n",
      "03/10 03:04:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32400/40000]  base_lr: 4.8303e-05 lr: 4.8303e-05  eta: 1:40:40  time: 0.7806  data_time: 0.0217  memory: 5634  loss: 0.3731  decode.loss_ce: 0.3731  decode.acc_seg: 79.1730\n",
      "03/10 03:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32500/40000]  base_lr: 4.8265e-05 lr: 4.8265e-05  eta: 1:39:20  time: 0.7821  data_time: 0.0220  memory: 5632  loss: 0.2234  decode.loss_ce: 0.2234  decode.acc_seg: 76.3233\n",
      "03/10 03:07:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32600/40000]  base_lr: 4.8227e-05 lr: 4.8227e-05  eta: 1:38:01  time: 0.7825  data_time: 0.0224  memory: 5632  loss: 0.3910  decode.loss_ce: 0.3910  decode.acc_seg: 95.7116\n",
      "03/10 03:08:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32700/40000]  base_lr: 4.8190e-05 lr: 4.8190e-05  eta: 1:36:41  time: 0.7841  data_time: 0.0222  memory: 5633  loss: 0.3367  decode.loss_ce: 0.3367  decode.acc_seg: 81.6113\n",
      "03/10 03:10:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32800/40000]  base_lr: 4.8152e-05 lr: 4.8152e-05  eta: 1:35:21  time: 0.7829  data_time: 0.0220  memory: 5632  loss: 0.3041  decode.loss_ce: 0.3041  decode.acc_seg: 82.9681\n",
      "03/10 03:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32900/40000]  base_lr: 4.8114e-05 lr: 4.8114e-05  eta: 1:34:02  time: 0.7844  data_time: 0.0230  memory: 5634  loss: 0.4116  decode.loss_ce: 0.4116  decode.acc_seg: 87.7898\n",
      "03/10 03:12:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 03:12:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33000/40000]  base_lr: 4.8076e-05 lr: 4.8076e-05  eta: 1:32:42  time: 0.7831  data_time: 0.0219  memory: 5634  loss: 0.3482  decode.loss_ce: 0.3482  decode.acc_seg: 93.9068\n",
      "03/10 03:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33100/40000]  base_lr: 4.8038e-05 lr: 4.8038e-05  eta: 1:31:22  time: 0.7861  data_time: 0.0231  memory: 5632  loss: 0.2625  decode.loss_ce: 0.2625  decode.acc_seg: 95.8303\n",
      "03/10 03:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33200/40000]  base_lr: 4.8000e-05 lr: 4.8000e-05  eta: 1:30:03  time: 0.7833  data_time: 0.0220  memory: 5634  loss: 0.4546  decode.loss_ce: 0.4546  decode.acc_seg: 85.6447\n",
      "03/10 03:16:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33300/40000]  base_lr: 4.7962e-05 lr: 4.7962e-05  eta: 1:28:43  time: 0.7902  data_time: 0.0225  memory: 5633  loss: 0.2664  decode.loss_ce: 0.2664  decode.acc_seg: 88.9514\n",
      "03/10 03:17:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33400/40000]  base_lr: 4.7925e-05 lr: 4.7925e-05  eta: 1:27:23  time: 0.7814  data_time: 0.0227  memory: 5634  loss: 0.2933  decode.loss_ce: 0.2933  decode.acc_seg: 60.7963\n",
      "03/10 03:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33500/40000]  base_lr: 4.7887e-05 lr: 4.7887e-05  eta: 1:26:04  time: 0.7939  data_time: 0.0243  memory: 5634  loss: 0.3374  decode.loss_ce: 0.3374  decode.acc_seg: 89.2264\n",
      "03/10 03:20:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33600/40000]  base_lr: 4.7849e-05 lr: 4.7849e-05  eta: 1:24:44  time: 0.7801  data_time: 0.0217  memory: 5634  loss: 0.2493  decode.loss_ce: 0.2493  decode.acc_seg: 64.0319\n",
      "03/10 03:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33700/40000]  base_lr: 4.7811e-05 lr: 4.7811e-05  eta: 1:23:24  time: 0.7876  data_time: 0.0221  memory: 5634  loss: 0.5486  decode.loss_ce: 0.5486  decode.acc_seg: 85.3719\n",
      "03/10 03:23:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33800/40000]  base_lr: 4.7773e-05 lr: 4.7773e-05  eta: 1:22:05  time: 0.7819  data_time: 0.0220  memory: 5634  loss: 0.3314  decode.loss_ce: 0.3314  decode.acc_seg: 83.3741\n",
      "03/10 03:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33900/40000]  base_lr: 4.7735e-05 lr: 4.7735e-05  eta: 1:20:45  time: 0.7901  data_time: 0.0224  memory: 5634  loss: 0.2635  decode.loss_ce: 0.2635  decode.acc_seg: 78.9652\n",
      "03/10 03:25:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 03:25:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34000/40000]  base_lr: 4.7697e-05 lr: 4.7697e-05  eta: 1:19:25  time: 0.7811  data_time: 0.0215  memory: 5632  loss: 0.3421  decode.loss_ce: 0.3421  decode.acc_seg: 75.2490\n",
      "03/10 03:27:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34100/40000]  base_lr: 4.7660e-05 lr: 4.7660e-05  eta: 1:18:06  time: 0.7847  data_time: 0.0221  memory: 5634  loss: 0.1301  decode.loss_ce: 0.1301  decode.acc_seg: 88.0033\n",
      "03/10 03:28:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34200/40000]  base_lr: 4.7622e-05 lr: 4.7622e-05  eta: 1:16:46  time: 0.7851  data_time: 0.0217  memory: 5632  loss: 0.4074  decode.loss_ce: 0.4074  decode.acc_seg: 80.4466\n",
      "03/10 03:29:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34300/40000]  base_lr: 4.7584e-05 lr: 4.7584e-05  eta: 1:15:27  time: 0.7891  data_time: 0.0230  memory: 5632  loss: 0.2904  decode.loss_ce: 0.2904  decode.acc_seg: 82.6293\n",
      "03/10 03:30:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34400/40000]  base_lr: 4.7546e-05 lr: 4.7546e-05  eta: 1:14:07  time: 0.7821  data_time: 0.0217  memory: 5632  loss: 0.2612  decode.loss_ce: 0.2612  decode.acc_seg: 97.2378\n",
      "03/10 03:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34500/40000]  base_lr: 4.7508e-05 lr: 4.7508e-05  eta: 1:12:47  time: 0.7836  data_time: 0.0219  memory: 5633  loss: 0.4053  decode.loss_ce: 0.4053  decode.acc_seg: 76.5341\n",
      "03/10 03:33:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34600/40000]  base_lr: 4.7470e-05 lr: 4.7470e-05  eta: 1:11:28  time: 0.7831  data_time: 0.0222  memory: 5634  loss: 0.4696  decode.loss_ce: 0.4696  decode.acc_seg: 72.3487\n",
      "03/10 03:34:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34700/40000]  base_lr: 4.7432e-05 lr: 4.7432e-05  eta: 1:10:08  time: 0.7820  data_time: 0.0218  memory: 5632  loss: 0.2907  decode.loss_ce: 0.2907  decode.acc_seg: 88.0984\n",
      "03/10 03:36:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34800/40000]  base_lr: 4.7395e-05 lr: 4.7395e-05  eta: 1:08:49  time: 0.7803  data_time: 0.0222  memory: 5634  loss: 0.3183  decode.loss_ce: 0.3183  decode.acc_seg: 90.7649\n",
      "03/10 03:37:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34900/40000]  base_lr: 4.7357e-05 lr: 4.7357e-05  eta: 1:07:29  time: 0.7820  data_time: 0.0223  memory: 5632  loss: 0.5618  decode.loss_ce: 0.5618  decode.acc_seg: 60.9458\n",
      "03/10 03:38:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 03:38:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35000/40000]  base_lr: 4.7319e-05 lr: 4.7319e-05  eta: 1:06:10  time: 0.7900  data_time: 0.0227  memory: 5632  loss: 0.3097  decode.loss_ce: 0.3097  decode.acc_seg: 88.6215\n",
      "03/10 03:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35100/40000]  base_lr: 4.7281e-05 lr: 4.7281e-05  eta: 1:04:50  time: 0.7940  data_time: 0.0234  memory: 5634  loss: 0.2537  decode.loss_ce: 0.2537  decode.acc_seg: 87.8235\n",
      "03/10 03:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35200/40000]  base_lr: 4.7243e-05 lr: 4.7243e-05  eta: 1:03:31  time: 0.7884  data_time: 0.0225  memory: 5634  loss: 0.3920  decode.loss_ce: 0.3920  decode.acc_seg: 79.0899\n",
      "03/10 03:42:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35300/40000]  base_lr: 4.7205e-05 lr: 4.7205e-05  eta: 1:02:11  time: 0.7895  data_time: 0.0229  memory: 5634  loss: 0.1413  decode.loss_ce: 0.1413  decode.acc_seg: 87.4353\n",
      "03/10 03:44:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35400/40000]  base_lr: 4.7167e-05 lr: 4.7167e-05  eta: 1:00:52  time: 0.7908  data_time: 0.0234  memory: 5634  loss: 0.3455  decode.loss_ce: 0.3455  decode.acc_seg: 82.4997\n",
      "03/10 03:45:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35500/40000]  base_lr: 4.7130e-05 lr: 4.7130e-05  eta: 0:59:33  time: 0.7895  data_time: 0.0229  memory: 5632  loss: 0.2173  decode.loss_ce: 0.2173  decode.acc_seg: 93.7971\n",
      "03/10 03:46:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35600/40000]  base_lr: 4.7092e-05 lr: 4.7092e-05  eta: 0:58:13  time: 0.7881  data_time: 0.0227  memory: 5634  loss: 0.6773  decode.loss_ce: 0.6773  decode.acc_seg: 69.7863\n",
      "03/10 03:48:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35700/40000]  base_lr: 4.7054e-05 lr: 4.7054e-05  eta: 0:56:54  time: 0.7859  data_time: 0.0225  memory: 5632  loss: 0.3177  decode.loss_ce: 0.3177  decode.acc_seg: 96.1868\n",
      "03/10 03:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35800/40000]  base_lr: 4.7016e-05 lr: 4.7016e-05  eta: 0:55:34  time: 0.7883  data_time: 0.0233  memory: 5632  loss: 0.3635  decode.loss_ce: 0.3635  decode.acc_seg: 95.6567\n",
      "03/10 03:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35900/40000]  base_lr: 4.6978e-05 lr: 4.6978e-05  eta: 0:54:15  time: 0.7885  data_time: 0.0230  memory: 5632  loss: 0.3387  decode.loss_ce: 0.3387  decode.acc_seg: 93.0373\n",
      "03/10 03:52:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 03:52:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36000/40000]  base_lr: 4.6940e-05 lr: 4.6940e-05  eta: 0:52:55  time: 0.7844  data_time: 0.0224  memory: 5634  loss: 0.4086  decode.loss_ce: 0.4086  decode.acc_seg: 91.9020\n",
      "03/10 03:53:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36100/40000]  base_lr: 4.6903e-05 lr: 4.6903e-05  eta: 0:51:36  time: 0.7868  data_time: 0.0230  memory: 5634  loss: 0.2895  decode.loss_ce: 0.2895  decode.acc_seg: 82.5357\n",
      "03/10 03:54:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36200/40000]  base_lr: 4.6865e-05 lr: 4.6865e-05  eta: 0:50:16  time: 0.7868  data_time: 0.0229  memory: 5634  loss: 0.3811  decode.loss_ce: 0.3811  decode.acc_seg: 80.5415\n",
      "03/10 03:55:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36300/40000]  base_lr: 4.6827e-05 lr: 4.6827e-05  eta: 0:48:57  time: 0.7847  data_time: 0.0222  memory: 5634  loss: 0.2261  decode.loss_ce: 0.2261  decode.acc_seg: 96.8887\n",
      "03/10 03:57:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36400/40000]  base_lr: 4.6789e-05 lr: 4.6789e-05  eta: 0:47:37  time: 0.7824  data_time: 0.0221  memory: 5632  loss: 0.3460  decode.loss_ce: 0.3460  decode.acc_seg: 38.6554\n",
      "03/10 03:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36500/40000]  base_lr: 4.6751e-05 lr: 4.6751e-05  eta: 0:46:18  time: 0.7839  data_time: 0.0219  memory: 5634  loss: 0.4162  decode.loss_ce: 0.4162  decode.acc_seg: 81.4110\n",
      "03/10 03:59:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36600/40000]  base_lr: 4.6713e-05 lr: 4.6713e-05  eta: 0:44:58  time: 0.7825  data_time: 0.0218  memory: 5632  loss: 0.2530  decode.loss_ce: 0.2530  decode.acc_seg: 83.1996\n",
      "03/10 04:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36700/40000]  base_lr: 4.6675e-05 lr: 4.6675e-05  eta: 0:43:39  time: 0.7821  data_time: 0.0222  memory: 5634  loss: 0.3704  decode.loss_ce: 0.3704  decode.acc_seg: 55.9972\n",
      "03/10 04:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36800/40000]  base_lr: 4.6638e-05 lr: 4.6638e-05  eta: 0:42:20  time: 0.7842  data_time: 0.0223  memory: 5634  loss: 0.2413  decode.loss_ce: 0.2413  decode.acc_seg: 97.1064\n",
      "03/10 04:03:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36900/40000]  base_lr: 4.6600e-05 lr: 4.6600e-05  eta: 0:41:00  time: 0.7836  data_time: 0.0226  memory: 5632  loss: 0.2745  decode.loss_ce: 0.2745  decode.acc_seg: 84.4400\n",
      "03/10 04:05:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 04:05:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37000/40000]  base_lr: 4.6562e-05 lr: 4.6562e-05  eta: 0:39:41  time: 0.7839  data_time: 0.0223  memory: 5634  loss: 0.3026  decode.loss_ce: 0.3026  decode.acc_seg: 83.3019\n",
      "03/10 04:06:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37100/40000]  base_lr: 4.6524e-05 lr: 4.6524e-05  eta: 0:38:21  time: 0.7834  data_time: 0.0219  memory: 5633  loss: 0.3198  decode.loss_ce: 0.3198  decode.acc_seg: 95.2488\n",
      "03/10 04:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37200/40000]  base_lr: 4.6486e-05 lr: 4.6486e-05  eta: 0:37:02  time: 0.7841  data_time: 0.0226  memory: 5633  loss: 0.2977  decode.loss_ce: 0.2977  decode.acc_seg: 86.6363\n",
      "03/10 04:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37300/40000]  base_lr: 4.6448e-05 lr: 4.6448e-05  eta: 0:35:42  time: 0.7874  data_time: 0.0219  memory: 5634  loss: 0.2989  decode.loss_ce: 0.2989  decode.acc_seg: 82.1995\n",
      "03/10 04:10:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37400/40000]  base_lr: 4.6410e-05 lr: 4.6410e-05  eta: 0:34:23  time: 0.7836  data_time: 0.0220  memory: 5634  loss: 0.2888  decode.loss_ce: 0.2888  decode.acc_seg: 91.5016\n",
      "03/10 04:11:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37500/40000]  base_lr: 4.6373e-05 lr: 4.6373e-05  eta: 0:33:04  time: 0.7865  data_time: 0.0221  memory: 5634  loss: 0.2337  decode.loss_ce: 0.2337  decode.acc_seg: 89.5330\n",
      "03/10 04:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37600/40000]  base_lr: 4.6335e-05 lr: 4.6335e-05  eta: 0:31:44  time: 0.7867  data_time: 0.0222  memory: 5632  loss: 0.2850  decode.loss_ce: 0.2850  decode.acc_seg: 92.9470\n",
      "03/10 04:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37700/40000]  base_lr: 4.6297e-05 lr: 4.6297e-05  eta: 0:30:25  time: 0.7846  data_time: 0.0227  memory: 5632  loss: 0.3467  decode.loss_ce: 0.3467  decode.acc_seg: 93.6463\n",
      "03/10 04:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37800/40000]  base_lr: 4.6259e-05 lr: 4.6259e-05  eta: 0:29:05  time: 0.7849  data_time: 0.0221  memory: 5632  loss: 0.2970  decode.loss_ce: 0.2970  decode.acc_seg: 85.8291\n",
      "03/10 04:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37900/40000]  base_lr: 4.6221e-05 lr: 4.6221e-05  eta: 0:27:46  time: 0.7852  data_time: 0.0219  memory: 5633  loss: 0.2872  decode.loss_ce: 0.2872  decode.acc_seg: 89.8747\n",
      "03/10 04:18:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 04:18:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38000/40000]  base_lr: 4.6183e-05 lr: 4.6183e-05  eta: 0:26:27  time: 0.7833  data_time: 0.0218  memory: 5634  loss: 0.5838  decode.loss_ce: 0.5838  decode.acc_seg: 94.1873\n",
      "03/10 04:19:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38100/40000]  base_lr: 4.6145e-05 lr: 4.6145e-05  eta: 0:25:07  time: 0.7841  data_time: 0.0224  memory: 5634  loss: 0.2625  decode.loss_ce: 0.2625  decode.acc_seg: 78.3576\n",
      "03/10 04:20:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38200/40000]  base_lr: 4.6108e-05 lr: 4.6108e-05  eta: 0:23:48  time: 0.7857  data_time: 0.0226  memory: 5634  loss: 0.2879  decode.loss_ce: 0.2879  decode.acc_seg: 77.4978\n",
      "03/10 04:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38300/40000]  base_lr: 4.6070e-05 lr: 4.6070e-05  eta: 0:22:28  time: 0.7850  data_time: 0.0227  memory: 5634  loss: 0.3525  decode.loss_ce: 0.3525  decode.acc_seg: 69.6375\n",
      "03/10 04:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38400/40000]  base_lr: 4.6032e-05 lr: 4.6032e-05  eta: 0:21:09  time: 0.7886  data_time: 0.0225  memory: 5632  loss: 0.4942  decode.loss_ce: 0.4942  decode.acc_seg: 87.9819\n",
      "03/10 04:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38500/40000]  base_lr: 4.5994e-05 lr: 4.5994e-05  eta: 0:19:50  time: 0.7846  data_time: 0.0219  memory: 5632  loss: 0.4986  decode.loss_ce: 0.4986  decode.acc_seg: 90.4192\n",
      "03/10 04:26:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38600/40000]  base_lr: 4.5956e-05 lr: 4.5956e-05  eta: 0:18:30  time: 0.7851  data_time: 0.0222  memory: 5632  loss: 0.4278  decode.loss_ce: 0.4278  decode.acc_seg: 78.8630\n",
      "03/10 04:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38700/40000]  base_lr: 4.5918e-05 lr: 4.5918e-05  eta: 0:17:11  time: 0.7816  data_time: 0.0215  memory: 5634  loss: 0.3077  decode.loss_ce: 0.3077  decode.acc_seg: 74.4458\n",
      "03/10 04:28:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38800/40000]  base_lr: 4.5880e-05 lr: 4.5880e-05  eta: 0:15:52  time: 0.7829  data_time: 0.0216  memory: 5634  loss: 0.3210  decode.loss_ce: 0.3210  decode.acc_seg: 97.0454\n",
      "03/10 04:30:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38900/40000]  base_lr: 4.5843e-05 lr: 4.5843e-05  eta: 0:14:32  time: 0.7827  data_time: 0.0222  memory: 5633  loss: 0.2689  decode.loss_ce: 0.2689  decode.acc_seg: 96.9839\n",
      "03/10 04:31:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 04:31:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39000/40000]  base_lr: 4.5805e-05 lr: 4.5805e-05  eta: 0:13:13  time: 0.7820  data_time: 0.0220  memory: 5634  loss: 0.3313  decode.loss_ce: 0.3313  decode.acc_seg: 91.0151\n",
      "03/10 04:32:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39100/40000]  base_lr: 4.5767e-05 lr: 4.5767e-05  eta: 0:11:53  time: 0.7822  data_time: 0.0220  memory: 5634  loss: 0.2344  decode.loss_ce: 0.2344  decode.acc_seg: 88.9983\n",
      "03/10 04:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39200/40000]  base_lr: 4.5729e-05 lr: 4.5729e-05  eta: 0:10:34  time: 0.7896  data_time: 0.0229  memory: 5632  loss: 0.3579  decode.loss_ce: 0.3579  decode.acc_seg: 87.2364\n",
      "03/10 04:35:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39300/40000]  base_lr: 4.5691e-05 lr: 4.5691e-05  eta: 0:09:15  time: 0.7875  data_time: 0.0226  memory: 5632  loss: 0.3219  decode.loss_ce: 0.3219  decode.acc_seg: 76.2027\n",
      "03/10 04:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39400/40000]  base_lr: 4.5653e-05 lr: 4.5653e-05  eta: 0:07:55  time: 0.8117  data_time: 0.0233  memory: 5632  loss: 0.5435  decode.loss_ce: 0.5435  decode.acc_seg: 90.8872\n",
      "03/10 04:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39500/40000]  base_lr: 4.5615e-05 lr: 4.5615e-05  eta: 0:06:36  time: 0.7888  data_time: 0.0229  memory: 5634  loss: 0.1908  decode.loss_ce: 0.1908  decode.acc_seg: 85.6983\n",
      "03/10 04:39:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39600/40000]  base_lr: 4.5578e-05 lr: 4.5578e-05  eta: 0:05:17  time: 0.7891  data_time: 0.0226  memory: 5634  loss: 0.2243  decode.loss_ce: 0.2243  decode.acc_seg: 86.1681\n",
      "03/10 04:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39700/40000]  base_lr: 4.5540e-05 lr: 4.5540e-05  eta: 0:03:57  time: 0.7861  data_time: 0.0225  memory: 5632  loss: 0.4541  decode.loss_ce: 0.4541  decode.acc_seg: 59.9659\n",
      "03/10 04:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39800/40000]  base_lr: 4.5502e-05 lr: 4.5502e-05  eta: 0:02:38  time: 0.7873  data_time: 0.0230  memory: 5634  loss: 0.3168  decode.loss_ce: 0.3168  decode.acc_seg: 81.9258\n",
      "03/10 04:43:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39900/40000]  base_lr: 4.5464e-05 lr: 4.5464e-05  eta: 0:01:19  time: 0.7859  data_time: 0.0225  memory: 5634  loss: 0.1949  decode.loss_ce: 0.1949  decode.acc_seg: 94.7706\n",
      "03/10 04:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_195446\n",
      "03/10 04:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40000/40000]  base_lr: 4.5426e-05 lr: 4.5426e-05  eta: 0:00:00  time: 0.7884  data_time: 0.0232  memory: 5634  loss: 0.2841  decode.loss_ce: 0.2841  decode.acc_seg: 89.0982\n",
      "03/10 04:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40000 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (data_preprocessor): SegDataPreProcessor()\n",
       "  (backbone): MixVisionTransformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (12): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (13): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (14): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (15): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (16): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (17): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (18): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (19): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (20): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (21): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (22): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (23): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (24): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (25): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (26): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (27): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (28): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (29): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (30): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (31): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (32): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (33): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (34): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (35): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (36): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (37): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (38): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (39): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'}\n",
       "  (decode_head): UPerHead(\n",
       "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (conv_seg): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (psp_modules): PPM(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=3)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=6)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): ConvModule(\n",
       "      (conv): Conv2d(1536, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_bottleneck): ConvModule(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K/upernet_swin_base_patch4_window7_512x512_160k_ade20k_pretrain_224x224_22K_20210526_211650-762e2178.pth'}\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e33ac7cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T04:44:32.675671Z",
     "iopub.status.busy": "2024-03-10T04:44:32.674872Z",
     "iopub.status.idle": "2024-03-10T04:48:10.164004Z",
     "shell.execute_reply": "2024-03-10T04:48:10.162938Z"
    },
    "papermill": {
     "duration": 217.689884,
     "end_time": "2024-03-10T04:48:10.166191",
     "exception": false,
     "start_time": "2024-03-10T04:44:32.476307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/datasets/transforms/loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/10 04:45:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/450]    eta: 0:02:51  time: 0.4795  data_time: 0.2870  memory: 9967  \n",
      "03/10 04:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/450]    eta: 0:02:03  time: 0.5756  data_time: 0.3899  memory: 2668  \n",
      "03/10 04:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/450]    eta: 0:01:13  time: 0.4815  data_time: 0.2729  memory: 2666  \n",
      "03/10 04:47:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/450]    eta: 0:00:24  time: 0.4508  data_time: 0.2459  memory: 2499  \n",
      "03/10 04:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "03/10 04:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   |  23.3 | 29.27 |  37.8 |  37.8  |   53.33   | 29.27  |\n",
      "| BuildingFlooded | 65.35 | 93.81 | 79.05 | 79.05  |    68.3   | 93.81  |\n",
      "|   BNonFlooded   | 61.95 | 74.54 | 76.51 | 76.51  |   78.58   | 74.54  |\n",
      "|   RoadFlooded   | 50.33 | 64.16 | 66.96 | 66.96  |   70.02   | 64.16  |\n",
      "|   RNonFlooded   | 71.65 | 77.65 | 83.48 | 83.48  |   90.26   | 77.65  |\n",
      "|      Water      | 61.06 | 74.53 | 75.82 | 75.82  |   77.16   | 74.53  |\n",
      "|       Tree      |  75.5 | 83.37 | 86.04 | 86.04  |   88.89   | 83.37  |\n",
      "|      Vecile     | 15.81 | 17.62 | 27.31 | 27.31  |   60.68   | 17.62  |\n",
      "|       Pool      | 40.87 |  43.8 | 58.03 | 58.03  |   85.95   |  43.8  |\n",
      "|      Grass      | 83.91 | 93.99 | 91.25 | 91.25  |   88.66   | 93.99  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "03/10 04:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/450]    aAcc: 85.7500  mIoU: 54.9700  mAcc: 65.2800  mDice: 68.2200  mFscore: 68.2200  mPrecision: 76.1800  mRecall: 65.2800  data_time: 0.2787  time: 0.4801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aAcc': 85.75,\n",
       " 'mIoU': 54.97,\n",
       " 'mAcc': 65.28,\n",
       " 'mDice': 68.22,\n",
       " 'mFscore': 68.22,\n",
       " 'mPrecision': 76.18,\n",
       " 'mRecall': 65.28}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158d54c",
   "metadata": {
    "papermill": {
     "duration": 0.182545,
     "end_time": "2024-03-10T04:48:10.538235",
     "exception": false,
     "start_time": "2024-03-10T04:48:10.355690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2963587,
     "sourceId": 5104516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32229.109704,
   "end_time": "2024-03-10T04:48:13.609678",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-09T19:51:04.499974",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
