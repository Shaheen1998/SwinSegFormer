{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d63b1bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:13:12.843792Z",
     "iopub.status.busy": "2024-03-09T10:13:12.843449Z",
     "iopub.status.idle": "2024-03-09T10:13:13.814106Z",
     "shell.execute_reply": "2024-03-09T10:13:13.812873Z"
    },
    "papermill": {
     "duration": 0.984958,
     "end_time": "2024-03-09T10:13:13.816542",
     "exception": false,
     "start_time": "2024-03-09T10:13:12.831584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\r\n",
      "Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075547c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:13:13.839337Z",
     "iopub.status.busy": "2024-03-09T10:13:13.838918Z",
     "iopub.status.idle": "2024-03-09T10:13:14.833320Z",
     "shell.execute_reply": "2024-03-09T10:13:14.832349Z"
    },
    "papermill": {
     "duration": 1.008614,
     "end_time": "2024-03-09T10:13:14.835771",
     "exception": false,
     "start_time": "2024-03-09T10:13:13.827157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  9 10:13:14 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   32C    P0              25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0308c4f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:13:14.858350Z",
     "iopub.status.busy": "2024-03-09T10:13:14.857962Z",
     "iopub.status.idle": "2024-03-09T10:13:15.808918Z",
     "shell.execute_reply": "2024-03-09T10:13:15.807798Z"
    },
    "papermill": {
     "duration": 0.965102,
     "end_time": "2024-03-09T10:13:15.811381",
     "exception": false,
     "start_time": "2024-03-09T10:13:14.846279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e24602b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:13:15.833652Z",
     "iopub.status.busy": "2024-03-09T10:13:15.833316Z",
     "iopub.status.idle": "2024-03-09T10:13:15.840283Z",
     "shell.execute_reply": "2024-03-09T10:13:15.839257Z"
    },
    "papermill": {
     "duration": 0.020318,
     "end_time": "2024-03-09T10:13:15.842304",
     "exception": false,
     "start_time": "2024-03-09T10:13:15.821986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f10f4f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:13:15.864288Z",
     "iopub.status.busy": "2024-03-09T10:13:15.863993Z",
     "iopub.status.idle": "2024-03-09T10:14:40.017512Z",
     "shell.execute_reply": "2024-03-09T10:14:40.016455Z"
    },
    "papermill": {
     "duration": 84.167587,
     "end_time": "2024-03-09T10:14:40.020026",
     "exception": false,
     "start_time": "2024-03-09T10:13:15.852439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.12.0\r\n",
      "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\r\n",
      "Collecting torchvision==0.13.0\r\n",
      "  Downloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting torchaudio==0.12.0\r\n",
      "  Downloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.12.0) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (2024.2.2)\r\n",
      "Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m934.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl (3.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.2.0.post0 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "stable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.12.0 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0 torchaudio-0.12.0 torchvision-0.13.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.7.0 torchvision==0.8.0\n",
    "!pip install torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120403f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:14:40.143683Z",
     "iopub.status.busy": "2024-03-09T10:14:40.143270Z",
     "iopub.status.idle": "2024-03-09T10:15:52.476626Z",
     "shell.execute_reply": "2024-03-09T10:15:52.475392Z"
    },
    "papermill": {
     "duration": 72.399489,
     "end_time": "2024-03-09T10:15:52.479122",
     "exception": false,
     "start_time": "2024-03-09T10:14:40.079633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.10/site-packages (from openmim) (8.1.7)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim) (0.4.6)\r\n",
      "Collecting model-index (from openmim)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from openmim) (2.1.4)\r\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.10/site-packages (from openmim) (23.3.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openmim) (2.31.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim) (13.7.0)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (6.0.1)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (3.5.2)\r\n",
      "Requirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (4.1.0)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (3.20.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (4.66.1)\r\n",
      "Collecting openxlab (from opendatalab->openmim)\r\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2024.2.2)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.4)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting requests (from openmim)\r\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting rich (from openmim)\r\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting tqdm (from opendatalab->openmim)\r\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\r\n",
      "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun-python-sdk-core-2.15.0.tar.gz (443 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.7)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\r\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading openxlab-0.0.34-py3-none-any.whl (299 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core\r\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=0b138a93a9943991aa122b51b52f3285244e406551fffd72245ccf08e1b0475d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.0-py3-none-any.whl size=535312 sha256=2b5ac598c14ba6a1c561ff1acd14e8a46eda27e3bf7946977309a1a300271dc5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b7/28/7c/a888bb3c60c865d014c7ef5017c83fdbc1cb0f601b79c7794a\r\n",
      "Successfully built oss2 aliyun-python-sdk-core\r\n",
      "Installing collected packages: tqdm, setuptools, requests, model-index, jmespath, rich, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.1\r\n",
      "    Uninstalling tqdm-4.66.1:\r\n",
      "      Successfully uninstalled tqdm-4.66.1\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 69.0.3\r\n",
      "    Uninstalling setuptools-69.0.3:\r\n",
      "      Successfully uninstalled setuptools-69.0.3\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.31.0\r\n",
      "    Uninstalling requests-2.31.0:\r\n",
      "      Successfully uninstalled requests-2.31.0\r\n",
      "  Attempting uninstall: jmespath\r\n",
      "    Found existing installation: jmespath 1.0.1\r\n",
      "    Uninstalling jmespath-1.0.1:\r\n",
      "      Successfully uninstalled jmespath-1.0.1\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 13.7.0\r\n",
      "    Uninstalling rich-13.7.0:\r\n",
      "      Successfully uninstalled rich-13.7.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.8.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\r\n",
      "boto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.34.34 which is incompatible.\r\n",
      "gcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.2.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\r\n",
      "jupyterlab-server 2.25.2 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pytorch-lightning 2.2.0.post0 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.15.0 aliyun-python-sdk-kms-2.16.2 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.34 oss2-2.17.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmengine\r\n",
      "  Downloading mmengine-0.10.3-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting addict (from mmengine)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmengine) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmengine) (6.0.1)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine) (2.4.0)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmengine) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine) (4.9.0.80)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.17.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\r\n",
      "Downloading mmengine-0.10.3-py3-none-any.whl (451 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Installing collected packages: addict, mmengine\r\n",
      "Successfully installed addict-2.4.0 mmengine-0.10.3\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmcv>=2.0.0rc1\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (58.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.10.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (6.0.1)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (4.9.0.80)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.7.5)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.4.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv>=2.0.0rc1) (3.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc1) (3.17.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.4.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.16.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openmim\n",
    "# Install mmengine\n",
    "!mim install mmengine\n",
    "# Install MMCV\n",
    "!mim install 'mmcv >= 2.0.0rc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b2835d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:15:52.623264Z",
     "iopub.status.busy": "2024-03-09T10:15:52.622458Z",
     "iopub.status.idle": "2024-03-09T10:15:52.627402Z",
     "shell.execute_reply": "2024-03-09T10:15:52.626522Z"
    },
    "papermill": {
     "duration": 0.079598,
     "end_time": "2024-03-09T10:15:52.629352",
     "exception": false,
     "start_time": "2024-03-09T10:15:52.549754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install mmcv>=2.0.0rc4 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc928e64",
   "metadata": {
    "papermill": {
     "duration": 0.069081,
     "end_time": "2024-03-09T10:15:52.810689",
     "exception": false,
     "start_time": "2024-03-09T10:15:52.741608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **RESTART KERNEL BEFORE GOING FURTHER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeaaff4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:15:52.951253Z",
     "iopub.status.busy": "2024-03-09T10:15:52.950531Z",
     "iopub.status.idle": "2024-03-09T10:15:53.887819Z",
     "shell.execute_reply": "2024-03-09T10:15:53.886479Z"
    },
    "papermill": {
     "duration": 1.009627,
     "end_time": "2024-03-09T10:15:53.890306",
     "exception": false,
     "start_time": "2024-03-09T10:15:52.880679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "0.13.0+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7211592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:15:54.031499Z",
     "iopub.status.busy": "2024-03-09T10:15:54.030632Z",
     "iopub.status.idle": "2024-03-09T10:16:24.311729Z",
     "shell.execute_reply": "2024-03-09T10:16:24.310578Z"
    },
    "papermill": {
     "duration": 30.42914,
     "end_time": "2024-03-09T10:16:24.389433",
     "exception": false,
     "start_time": "2024-03-09T10:15:53.960293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'mmsegmentation': No such file or directory\r\n",
      "Cloning into 'mmsegmentation'...\r\n",
      "remote: Enumerating objects: 16468, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (140/140), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (109/109), done.\u001b[K\r\n",
      "remote: Total 16468 (delta 51), reused 75 (delta 29), pack-reused 16328\u001b[K\r\n",
      "Receiving objects: 100% (16468/16468), 43.83 MiB | 15.13 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11434/11434), done.\r\n",
      "/kaggle/working/mmsegmentation\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools_scm/_integration/setuptools.py:30: RuntimeWarning: \r\n",
      "ERROR: setuptools==60.2.0 is used in combination with setuptools_scm>=8.x\r\n",
      "\r\n",
      "Your build configuration is incomplete and previously worked by accident!\r\n",
      "setuptools_scm requires setuptools>=61\r\n",
      "\r\n",
      "Suggested workaround if applicable:\r\n",
      " - migrating from the deprecated setup_requires mechanism to pep517/518\r\n",
      "   and using a pyproject.toml to declare build dependencies\r\n",
      "   which are reliably pre-installed before running the build tools\r\n",
      "\r\n",
      "  warnings.warn(\r\n",
      "running build\r\n",
      "running build_py\r\n",
      "creating build\r\n",
      "creating build/lib\r\n",
      "creating build/lib/tests\r\n",
      "copying tests/__init__.py -> build/lib/tests\r\n",
      "copying tests/test_sampler.py -> build/lib/tests\r\n",
      "copying tests/test_config.py -> build/lib/tests\r\n",
      "copying tests/test_digit_version.py -> build/lib/tests\r\n",
      "creating build/lib/mmseg\r\n",
      "copying mmseg/__init__.py -> build/lib/mmseg\r\n",
      "copying mmseg/version.py -> build/lib/mmseg\r\n",
      "creating build/lib/tests/test_models\r\n",
      "copying tests/test_models/__init__.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_forward.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_data_preprocessor.py -> build/lib/tests/test_models\r\n",
      "creating build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/utils.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mobilenet_v3.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_timm_backbone.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mae.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv1.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/__init__.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_swin.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_beit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnest.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_pidnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mscan.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_erfnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_fast_scnn.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_hrnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_stdc.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_clip_text_encoder.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv2.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_cgnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vpd.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_twins.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_icnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_unet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_blocks.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnext.py -> build/lib/tests/test_models/test_backbones\r\n",
      "creating build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/utils.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/__init__.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dpt_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_gc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ham_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_san_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ema_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_up_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ocr_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dm_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_vpd_depth_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_pidnet_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_fcn_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_aspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ann_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dnl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_apc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_cc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_uper_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_nl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_maskformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_isa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_mask2former_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_decode_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_mla_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segmenter_mask_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_lraspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "creating build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_jpu.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/__init__.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_fpn.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_ic_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_feature2pyramid.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_multilevel_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_mla_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "creating build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/utils.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/__init__.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_depth_estimator.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_multimodal_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_seg_tta_model.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_cascade_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "creating build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_shape_convert.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/__init__.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_embed.py -> build/lib/tests/test_models/test_utils\r\n",
      "creating build/lib/mmseg/models\r\n",
      "copying mmseg/models/builder.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/__init__.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/data_preprocessor.py -> build/lib/mmseg/models\r\n",
      "creating build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/seg_data_sample.py -> build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/__init__.py -> build/lib/mmseg/structures\r\n",
      "creating build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/utils.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/remote_sense_inferencer.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/__init__.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/mmseg_inferencer.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/inference.py -> build/lib/mmseg/apis\r\n",
      "creating build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/misc.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/class_names.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/set_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/mask_classification.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/__init__.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/io.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/get_templates.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/typing_utils.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/collect_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/tokenizer.py -> build/lib/mmseg/utils\r\n",
      "creating build/lib/mmseg/engine\r\n",
      "copying mmseg/engine/__init__.py -> build/lib/mmseg/engine\r\n",
      "creating build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/registry.py -> build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/__init__.py -> build/lib/mmseg/registry\r\n",
      "creating build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dark_zurich.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/pascal_context.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/mapillary.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/bdd100k.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/basesegdataset.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/stare.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/refuge.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/__init__.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isaid.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/decathlon.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/levir.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hsi_drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/chase_db1.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/lip.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isprs.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/ade.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/cityscapes.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dsdl.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/night_driving.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/coco_stuff.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/potsdam.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/voc.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/nyu.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hrf.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dataset_wrappers.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/synapse.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/loveda.py -> build/lib/mmseg/datasets\r\n",
      "creating build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/local_visualizer.py -> build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/__init__.py -> build/lib/mmseg/visualization\r\n",
      "creating build/lib/mmseg/evaluation\r\n",
      "copying mmseg/evaluation/__init__.py -> build/lib/mmseg/evaluation\r\n",
      "creating build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/hrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/stdc.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/twins.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/beit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnest.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/cgnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv1.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/__init__.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/fast_scnn.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mscan.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/timm_backbone.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnext.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/icnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/erfnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vpd.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/ddrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/swin.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v3.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/pidnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mae.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/unet.py -> build/lib/mmseg/models/backbones\r\n",
      "creating build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/__init__.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/mla_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/fpn.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/jpu.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/multilevel_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/ic_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/featurepyramid.py -> build/lib/mmseg/models/necks\r\n",
      "creating build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/san_layers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/basic_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/up_conv_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/point_sample.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/se_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/self_attention_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/inverted_residual.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/__init__.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/ppm.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/wrappers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/make_divisible.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/encoding.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/res_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/embed.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/shape_convert.py -> build/lib/mmseg/models/utils\r\n",
      "creating build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/depth_estimator.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/cascade_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/__init__.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/base.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/seg_tta.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/multimodal_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "creating build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/__init__.py -> build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/clip_text_encoder.py -> build/lib/mmseg/models/text_encoder\r\n",
      "creating build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/accuracy.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/utils.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/silog_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/ohem_cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/focal_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/__init__.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/kldiv_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/tversky_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/boundary_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/lovasz_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/dice_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/huasdorff_distance_loss.py -> build/lib/mmseg/models/losses\r\n",
      "creating build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/isa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/stdc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segmenter_mask_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/nl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/knet_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cascade_decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fpn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_mla_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/mask2former_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/vpd_depth_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dm_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_up_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/__init__.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/san_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/pid_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ema_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ddr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/enc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/lraspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/gc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ann_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ocr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/uper_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ham_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dnl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/maskformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/da_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/point_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dpt_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/apc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "creating build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/__init__.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/hungarian_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/base_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/match_cost.py -> build/lib/mmseg/models/assigners\r\n",
      "creating build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/base_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/builder.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/__init__.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/ohem_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "creating build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/__init__.py -> build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/visualization_hook.py -> build/lib/mmseg/engine/hooks\r\n",
      "creating build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/__init__.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/layer_decay_optimizer_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/force_default_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "creating build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/__init__.py -> build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/poly_ratio_scheduler.py -> build/lib/mmseg/engine/schedulers\r\n",
      "creating build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/loading.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/__init__.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/transforms.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/formatting.py -> build/lib/mmseg/datasets/transforms\r\n",
      "creating build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/depth_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/citys_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/__init__.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/iou_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "running egg_info\r\n",
      "creating mmsegmentation.egg-info\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "warning: no files found matching 'mmseg/.mim/model-index.yml'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.yaml' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/tools'\r\n",
      "warning: no files found matching '*.sh' under directory 'mmseg/.mim/tools'\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "creating build/lib/tests/data\r\n",
      "copying tests/data/biomedical.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.npy -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.pkl -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical_ann.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/color.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/dataset.json -> build/lib/tests/data\r\n",
      "copying tests/data/gray.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/seg.png -> build/lib/tests/data\r\n",
      "creating build/lib/tests/data/dsdl_seg\r\n",
      "copying tests/data/dsdl_seg/config.py -> build/lib/tests/data/dsdl_seg\r\n",
      "creating build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/class-dom.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/segmentation-def.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "creating build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train.yaml -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train_samples.json -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/0004a4c0-d4dff0ad.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00054602-3bf57337.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00067cfb-e535423e.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d06fefd-f7be05a6.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d128593-0ccfea4c.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d15b18b-1e0d6e3f.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d2f7975-e0c1c5a7.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d06fefd-f7be05a6.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_instanceIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelTrainIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png -> build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_dataset\r\n",
      "creating build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00000_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00001_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00002_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00003_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00004_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "creating build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00000_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00001_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00002_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00003_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00004_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "creating build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/train.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/val.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/annotations\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1111_577_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1112_569_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1113_557_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1111_577_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1112_569_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1113_557_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1024_1920_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1536_2432_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1024_1920.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1536_2432.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/train.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/val.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "copying tests/data/pseudo_lip_dataset/train_images/684_2150041.jpg -> build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/train_segmentations/684_2150041.png -> build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "copying tests/data/pseudo_lip_dataset/val_images/86_185913.jpg -> build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/val_segmentations/86_185913.png -> build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "copying tests/data/pseudo_mapillary_dataset/images/__CRyFzoDOXn6unQ6a3DnQ.jpg -> build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v1.2/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v2.0/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "copying tests/data/pseudo_nyu_dataset/annotations/bookstore_0001d_00001.png -> build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "copying tests/data/pseudo_nyu_dataset/images/bookstore_0001d_00001.jpg -> build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/ann_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/img_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/ann_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/img_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice000.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice001.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice000.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice001.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/ann_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/img_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "creating build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_rs_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/utils.py -> build/lib/tests/test_apis\r\n",
      "creating build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset_builder.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_formatting.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_loading.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_transform.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_tta.py -> build/lib/tests/test_datasets\r\n",
      "creating build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_layer_decay_optimizer_constructor.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_optimizer.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_visualization_hook.py -> build/lib/tests/test_engine\r\n",
      "creating build/lib/tests/test_evaluation\r\n",
      "creating build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_citys_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_depth_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_iou_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "creating build/lib/tests/test_structures\r\n",
      "copying tests/test_structures/test_seg_data_sample.py -> build/lib/tests/test_structures\r\n",
      "creating build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_io.py -> build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_set_env.py -> build/lib/tests/test_utils\r\n",
      "creating build/lib/tests/test_visualization\r\n",
      "copying tests/test_visualization/test_local_visualizer.py -> build/lib/tests/test_visualization\r\n",
      "creating build/lib/mmseg/configs\r\n",
      "creating build/lib/mmseg/configs/_base_\r\n",
      "copying mmseg/configs/_base_/default_runtime.py -> build/lib/mmseg/configs/_base_\r\n",
      "creating build/lib/mmseg/configs/_base_/datasets\r\n",
      "copying mmseg/configs/_base_/datasets/loveda.py -> build/lib/mmseg/configs/_base_/datasets\r\n",
      "copying mmseg/configs/_base_/datasets/potsdam.py -> build/lib/mmseg/configs/_base_/datasets\r\n",
      "creating build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_160k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_20k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_240k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_25k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_320k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_40k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_80k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "creating build/lib/tests/test_models/test_assigners\r\n",
      "copying tests/test_models/test_assigners/test_hungarian_assigner.py -> build/lib/tests/test_models/test_assigners\r\n",
      "creating build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_cross_entropy_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_dice_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_huasdorff_distance_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_kldiv_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_silog_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_tversky_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying mmseg/utils/bpe_simple_vocab_16e6.txt.gz -> build/lib/mmseg/utils\r\n",
      "Processing /kaggle/working/mmsegmentation\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (21.3)\r\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.9.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.11.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (2.8.2)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->mmsegmentation==1.2.2) (0.2.13)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.2.2) (1.16.0)\r\n",
      "Building wheels for collected packages: mmsegmentation\r\n",
      "  Building wheel for mmsegmentation (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmsegmentation: filename=mmsegmentation-1.2.2-py3-none-any.whl size=31509878 sha256=4212a8c2d0b510f75d22669110e29d9ea9f3d25f2caf615d3548ddd6b4830bb3\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-xdmdk4od/wheels/43/47/68/4f234c90f5372e6bde61cb1d00ac67ba84723d1e9801de501d\r\n",
      "Successfully built mmsegmentation\r\n",
      "Installing collected packages: mmsegmentation\r\n",
      "Successfully installed mmsegmentation-1.2.2\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r mmsegmentation\n",
    "#!git clone https://github.com/alirafiqmalik/mmsegmentation.git \n",
    "!git clone -b main https://github.com/open-mmlab/mmsegmentation.git \n",
    "%cd mmsegmentation\n",
    "# !pip install -v -e .\n",
    "!python setup.py build\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08f7923e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:24.541517Z",
     "iopub.status.busy": "2024-03-09T10:16:24.541122Z",
     "iopub.status.idle": "2024-03-09T10:16:25.370546Z",
     "shell.execute_reply": "2024-03-09T10:16:25.369490Z"
    },
    "papermill": {
     "duration": 0.90749,
     "end_time": "2024-03-09T10:16:25.372636",
     "exception": false,
     "start_time": "2024-03-09T10:16:24.465146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626e3cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:25.529147Z",
     "iopub.status.busy": "2024-03-09T10:16:25.528329Z",
     "iopub.status.idle": "2024-03-09T10:16:25.533973Z",
     "shell.execute_reply": "2024-03-09T10:16:25.532939Z"
    },
    "papermill": {
     "duration": 0.086829,
     "end_time": "2024-03-09T10:16:25.536061",
     "exception": false,
     "start_time": "2024-03-09T10:16:25.449232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2 2.1.0 0.10.3\n"
     ]
    }
   ],
   "source": [
    "# Check MMSegmentation installation\n",
    "import mmseg,mmcv,mmengine\n",
    "print(mmseg.__version__,mmcv.__version__,mmengine.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bb0c9",
   "metadata": {
    "papermill": {
     "duration": 0.078255,
     "end_time": "2024-03-09T10:16:25.700888",
     "exception": false,
     "start_time": "2024-03-09T10:16:25.622633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **DATASET LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baec1325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:25.855071Z",
     "iopub.status.busy": "2024-03-09T10:16:25.854401Z",
     "iopub.status.idle": "2024-03-09T10:16:25.858960Z",
     "shell.execute_reply": "2024-03-09T10:16:25.857965Z"
    },
    "papermill": {
     "duration": 0.084444,
     "end_time": "2024-03-09T10:16:25.860998",
     "exception": false,
     "start_time": "2024-03-09T10:16:25.776554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import mmengine\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fdcf223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:26.016255Z",
     "iopub.status.busy": "2024-03-09T10:16:26.015832Z",
     "iopub.status.idle": "2024-03-09T10:16:26.022140Z",
     "shell.execute_reply": "2024-03-09T10:16:26.021278Z"
    },
    "papermill": {
     "duration": 0.086161,
     "end_time": "2024-03-09T10:16:26.024195",
     "exception": false,
     "start_time": "2024-03-09T10:16:25.938034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ddd1e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:26.180885Z",
     "iopub.status.busy": "2024-03-09T10:16:26.180042Z",
     "iopub.status.idle": "2024-03-09T10:16:26.184677Z",
     "shell.execute_reply": "2024-03-09T10:16:26.183773Z"
    },
    "papermill": {
     "duration": 0.082971,
     "end_time": "2024-03-09T10:16:26.186480",
     "exception": false,
     "start_time": "2024-03-09T10:16:26.103509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset root and directory for images and annotations\n",
    "data_root = '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc83804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:26.341388Z",
     "iopub.status.busy": "2024-03-09T10:16:26.340757Z",
     "iopub.status.idle": "2024-03-09T10:16:26.729463Z",
     "shell.execute_reply": "2024-03-09T10:16:26.728375Z"
    },
    "papermill": {
     "duration": 0.46982,
     "end_time": "2024-03-09T10:16:26.732073",
     "exception": false,
     "start_time": "2024-03-09T10:16:26.262253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes 10\n",
      "0         Background\n",
      "1    BuildingFlooded\n",
      "2        BNonFlooded\n",
      "3        RoadFlooded\n",
      "4        RNonFlooded\n",
      "5              Water\n",
      "6               Tree\n",
      "7             Vecile\n",
      "8               Pool\n",
      "9              Grass\n",
      "Name: name, dtype: object\n",
      "[[  0   0   0]\n",
      " [255   0   0]\n",
      " [181  72  72]\n",
      " [150 150   0]\n",
      " [135 135 135]\n",
      " [  0 224 224]\n",
      " [  0   0 225]\n",
      " [204   0 204]\n",
      " [237 237   0]\n",
      " [  0 225   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# define class and palette for better visualization\n",
    "df=pd.read_csv('/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/Now_class_dict_seg_10clss.csv')\n",
    "classes = df['name']\n",
    "palette = df[[' r', ' g', ' b']].values\n",
    "id2label = classes.to_dict()\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(\"classes\", len(id2label))\n",
    "print(classes)\n",
    "print(palette)\n",
    "classes=list(classes)\n",
    "palette=list(palette)\n",
    "num_classes=len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62b57fde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:26.889104Z",
     "iopub.status.busy": "2024-03-09T10:16:26.888723Z",
     "iopub.status.idle": "2024-03-09T10:16:28.880004Z",
     "shell.execute_reply": "2024-03-09T10:16:28.878577Z"
    },
    "papermill": {
     "duration": 2.073147,
     "end_time": "2024-03-09T10:16:28.882922",
     "exception": false,
     "start_time": "2024-03-09T10:16:26.809775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAH/CAYAAAAVCPOeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoY0lEQVR4nO3deVxWZd7H8e8NyKYCKpskKKLivqRpuKQoLqiZ1eS4VOC4p6Zpbi1uOeGWS+YyTiVWWpM9apor7mlom2SaMWouZSKiAW4oy3n+CM54C5goCsLn/Xrdr/G+znXO+Z3rAR+/Xedcx2IYhiEAAAAAQLFnU9AFAAAAAAAKBwIiAAAAAEASAREAAAAAkImACAAAAACQREAEAAAAAGQiIAIAAAAAJBEQAQAAAACZCIgAAAAAAEkERAAAAABAJgIiAAAAAEBSIQ+I8+fPV6VKleTo6KgmTZro66+/LuiSAAAAAKDIKrQB8T//+Y9GjBihCRMm6Pvvv1e9evXUvn17xcfHF3RpAAAAAFAkWQzDMAq6iJw0adJEjzzyiN555x1JUkZGhnx9fTV06FCNHTu2gKsDAAAAgKLHrqALyMn169f13Xffady4cWabjY2NQkJCFB0dneM+165d07Vr18zvGRkZunDhgsqVKyeLxXLPawYAAMCtGYahixcvysfHRzY2BXcjW3p6ulJTUwvs/MD9ZGtrqxIlStx2/0IZEBMSEpSeni4vLy+rdi8vL/3888857hMREaFJkybdj/IAAABwF3799VdVqFDhvp/XMAzFxcUpKSlJhfQmOuCecHBwkLu7u1xcXP6yb6EMiHdi3LhxGjFihPk9KSlJfn5+srW1ZQYRAACgEDAMQ+np6SpdunSBnD8pKUmJiYny8PBQyZIl+TciijzDMJSamqqkpCSdPn1akv4yJBbKgOju7i5bW1udPXvWqv3s2bPy9vbOcR8HBwc5ODhka7dYLPzyAwAAFCIF8W8zwzAUHx8vFxcXubu73/fzAwXFyclJpUuX1m+//aaEhIS/DIiFchVTe3t7NWzYUFu3bjXbMjIytHXrVgUFBRVgZQAAAHgQpaenKz09/bZusQOKGovFIldXV127du0vn78tlDOIkjRixAiFhYWpUaNGaty4sebMmaPLly+rd+/eBV0aAAAAHjBpaWmSJDu7QvvPX+CeylqoJj09/ZaL1hTa35C///3vOnfunMaPH6+4uDjVr19fGzduzLZwDQAAAHC7ePQIxdXt/uwX2oAoSUOGDNGQIUMKugwAAAAAKBYK5TOIAAAAAAq/SpUqqXPnzgVdRoGxWCyaOHFiQZeRrwr1DCIAAABwr506dUoJCQkFXYbc3d3l5+d3R/tGRkZmW6vDw8NDtWrV0ujRoxUaGpofJaIYICACAACg2Dp16pQCAwOVkpJS0KXI0dFRsbGxdxwSJWny5Mny9/eXYRg6e/asIiMj1bFjR61du7ZYz/Th9hEQAQAAUGwlJCQUinAoSSkpKUpISLirgBgaGqpGjRqZ3/v06SMvLy99/PHHD2xAvHz5skqWLFnQZRQbPIMIAAAAFFFubm5ycnKyer3HzJkz1bRpU5UrV05OTk5q2LChPvvssxz3/+ijj9S4cWM5OzurTJkyeuyxx7R58+ZbnnPp0qWys7PTqFGjzLbz58/rueeek4uLi9zc3BQWFqYffvhBFotFkZGRZr/w8HCVKlVKx44dU8eOHVW6dGn16tVL0p9BceTIkfL19ZWDg4MCAwM1c+ZMGYZh7n/ixIlsx8xy8/OCEydOlMVi0dGjRxUeHi43Nze5urqqd+/eunLlitW+165d00svvSQPDw+VLl1aXbp00W+//XbLcXhQMYMIAAAAFBFJSUlKSEiQYRiKj4/XvHnzdOnSJT377LNmn7lz56pLly7q1auXrl+/rk8++UTPPPOMvvjiC3Xq1MnsN2nSJE2cOFFNmzbV5MmTZW9vr3379mnbtm1q165djudfvHixBg4cqFdeeUVTpkyRJGVkZOjxxx/X119/rUGDBql69er6/PPPFRYWluMx0tLS1L59ezVv3lwzZ86Us7OzDMNQly5dtH37dvXp00f169fXpk2bNGrUKJ0+fVqzZ8++4zHr1q2b/P39FRERoe+//17vvvuuPD09NW3aNLNP37599dFHH6lnz55q2rSptm3bZjVWRQkBEQAAACgiQkJCrL47ODjo/fffV9u2bc22//73v3JycjK/DxkyRA8//LBmzZplhp6jR49q8uTJevLJJ/XZZ5/JxuZ/Nx7eOGN3o7ffflvDhw/X5MmT9dprr5ntq1evVnR0tObMmaNhw4ZJkgYNGmRV042uXbumZ555RhEREWbb559/rm3btmnKlCl69dVXJUmDBw/WM888o7lz52rIkCEKCAi4rTG6WYMGDfTee++Z38+fP6/33nvPDIg//PCDPvroI73wwguaP3++ee5evXrpwIEDd3TOwoxbTAEAAIAiYv78+YqKilJUVJQ++ugjBQcHq2/fvlq5cqXZ58Zw+McffygpKUktWrTQ999/b7avXr1aGRkZGj9+vFU4lHJ+4fr06dM1bNgwTZs2zSocStLGjRtVokQJ9evXz2yzsbHR4MGDc72OQYMGWX1fv369bG1t9eKLL1q1jxw5UoZhaMOGDbke668MHDjQ6nuLFi10/vx5JScnm+eWlO3cw4cPv+NzFmbMIAIAAABFROPGja0WqenRo4caNGigIUOGqHPnzrK3t9cXX3yhKVOmKCYmRteuXTP73hj8jh07JhsbG9WsWfMvz7lz506tW7dOY8aMsXruMMvJkydVvnx5OTs7W7VXqVIlx+PZ2dmpQoUK2Y7h4+Oj0qVLW7XXqFHD3H6nbl4UqEyZMpL+DM8uLi46efKkbGxsss1QBgYG3vE5CzNmEAEAAIAiysbGRsHBwTpz5oyOHDmiL7/8Ul26dJGjo6MWLFig9evXKyoqSj179sz11tG/UqtWLQUGBurDDz/U8ePH77pmBweHbLOWtyun2U1JSk9Pz3UfW1vbHNvvdDwedAREAAAAoAhLS0uTJF26dEn/93//J0dHR23atEn/+Mc/FBoamu25RUkKCAhQRkaGfvrpp788vru7u7Zs2aISJUqoTZs2+v333622V6xYUWfOnMm2MujRo0dv+xoqVqyo33//XRcvXrRq//nnn83t0v9m/xITE6363c0MY8WKFZWRkaFjx45ZtcfGxt7xMQszAiIAAABQRKWmpmrz5s2yt7dXjRo1ZGtrK4vFYjWjduLECa1evdpqv65du8rGxkaTJ09WRkaG1bacZtYqVKigLVu26OrVq2rbtq3Onz9vbmvfvr1SU1P173//22zLyMgwF3y5HR07dlR6erreeecdq/bZs2fLYrEoNDRUkuTi4iJ3d3ft2rXLqt+CBQtu+1w3yzr222+/bdU+Z86cOz5mYcYziAAAAEARsWHDBnNWLT4+XsuXL9eRI0c0duxYubi4qFOnTpo1a5Y6dOignj17Kj4+XvPnz1eVKlWsVuSsUqWKXn31Vb3xxhtq0aKFnnrqKTk4OOibb76Rj4+P1QqjN+6zefNmtWrVSu3bt9e2bdvk4uKirl27qnHjxho5cqSOHj2q6tWra82aNbpw4YKk3G8LvdHjjz+u4OBgvfrqqzpx4oTq1aunzZs36/PPP9fw4cOtng/s27evpk6dqr59+6pRo0batWuX/vvf/97xmNavX189evTQggULlJSUpKZNm2rr1q15mgF9kBAQAQAAgCJi/Pjx5p8dHR1VvXp1LVy4UAMGDJAktW7dWu+9956mTp2q4cOHy9/fX9OmTdOJEyeyvbJh8uTJ8vf317x58/Tqq6/K2dlZdevW1XPPPZfr+evUqaMNGzYoJCREjz/+uDZu3CgnJyetW7dOw4YN09KlS2VjY6Mnn3xSEyZMULNmzeTo6PiX12VjY6M1a9Zo/Pjx+s9//qMlS5aoUqVKmjFjhkaOHJltDM6dO6fPPvtMn376qUJDQ7VhwwZ5enrmZSitvP/++/Lw8NCyZcu0evVqtW7dWuvWrZOvr+8dH7OwshhF9OnL5ORkubq6ys7O7rb+qwQAAADuLcMwlJaWpqSkJLm4uNzXc6ekpOj48ePy9/e3CiSnTp1SYGCgUlJS7ms9OXF0dFRsbGy2VTWLqtWrV+vJJ5/U7t271axZs4Iup8jL7XfgZswgAgAAoNjy8/NTbGysEhISCroUubu7F9lwePXqVav3L6anp2vevHlycXHRww8/XICV4WYERAAAABRrfn5+RTaYFRZDhw7V1atXFRQUpGvXrmnlypX66quv9Oabb1oFRxQ8AiIAAACAe6p169Z666239MUXXyglJUVVqlTRvHnzNGTIkIIuDTchIAIAAAC4p3r27KmePXsWdBm4DbwHEQAAAAAgiYAIAAAAAMhEQAQAAAAASCIgAgAAAAAyERABAAAAAJIIiAAAAACATAREAAAAAIAkAiIAAACAHEycOFEWi8WqrVKlSgoPD//LfSMjI2WxWHTixAmzrVWrVmrVqlX+FnmHwsPDValSpQI59+2O4e06ceKELBaLIiMj8+V4BEQAAADgAZcVyG78eHp6Kjg4WBs2bCjo8u6brLCU0+fRRx8t6PIeCHYFXQAAAABQoE6dkhISCroKyd1d8vO7q0NMnjxZ/v7+MgxDZ8+eVWRkpDp27Ki1a9eqc+fOeTrWa6+9prFjx95VPTfavHlzvh3rr/To0UMdO3a0avPw8Lhv53+QERABAABQfJ06JQUGSikpBV2J5OgoxcbeVUgMDQ1Vo0aNzO99+vSRl5eXPv744zwHRDs7O9nZ5V9csLe3z7dj/ZWHH35Yzz777H07X1HCLaYAAAAovhISCkc4lP6sI59nMt3c3OTk5GQGvR07dshisWjHjh1W/XJ6ji2nZxBzcujQIbVu3VpOTk6qUKGCpkyZooyMjGz9bn4GMauWTz/9VP/85z9VoUIFOTo6qk2bNjp69Gi2/efPn6/KlSvLyclJjRs31pdffpmvzzVevnxZI0eOlK+vrxwcHBQYGKiZM2fKMAyrfmlpaXrjjTcUEBAgBwcHVapUSa+88oquXbtm1c8wDE2ZMkUVKlSQs7OzgoODdejQoRzPnZiYqOHDh5vnrlKliqZNm5ZtHBMTExUeHi5XV1e5ubkpLCxMiYmJ+XL9WZhBBAAAAIqIpKQkJSQkyDAMxcfHa968ebp06dI9m02Li4tTcHCw0tLSNHbsWJUsWVKLFy+Wk5PTbR9j6tSpsrGx0csvv6ykpCRNnz5dvXr10r59+8w+Cxcu1JAhQ9SiRQu99NJLOnHihLp27aoyZcqoQoUK2Y555coVJdwUtl1dXVWiRIkcazAMQ126dNH27dvVp08f1a9fX5s2bdKoUaN0+vRpzZ492+zbt29fLV26VH/72980cuRI7du3TxERETp8+LBWrVpl9hs/frymTJmijh07qmPHjvr+++/Vrl07Xb9+PVutLVu21OnTpzVgwAD5+fnpq6++0rhx43TmzBnNmTPHrPGJJ57Q7t27NXDgQNWoUUOrVq1SWFjYbY/17SAgAgAAAEVESEiI1XcHBwe9//77atu27T0537Rp03Tu3Dnt27dPjRs3liSFhYWpatWqt32MlJQUxcTEmLeglilTRsOGDdPBgwdVu3ZtXb9+Xa+//roeeeQRbdu2zZwNrVu3rsLDw3MMiBMmTNCECROs2rZv357rbOOaNWu0bds2TZkyRa+++qokafDgwXrmmWc0d+5cDRkyRAEBAfrhhx+0dOlS9e3bV//+978lSS+88II8PT01c+ZMbd++XcHBwTp37pymT5+uTp06ae3ateZM7Kuvvqo333zT6tyzZs3SsWPHtH//fnPcBgwYIB8fH82YMcOc1VyzZo127dql6dOna9SoUZKkQYMGKTg4+LbH+nZwiykAAABQRMyfP19RUVGKiorSRx99pODgYPXt21crV668J+dbv369Hn30UTMcSn8uBtOrV6/bPkbv3r2tnk9s0aKFJOmXX36RJH377bc6f/68+vXrZ/VMZK9evVSmTJkcj9m/f39zHLI+9erVu+V12Nra6sUXX7RqHzlypAzDMFeCXb9+vSRpxIgR2fpJ0rp16yRJW7Zs0fXr1zV06FCr23SHDx+e7dwrVqxQixYtVKZMGSUkJJifkJAQpaena9euXea57ezsNGjQIHNfW1tbDR06NNfruhPMIAIAAABFROPGja0WqenRo4caNGigIUOG5HmRmttx8uRJNWnSJFt7YGDgbR/D76ZFebJC3x9//GGeQ5KqVKli1c/Ozi7XdxlWrVo122zqrZw8eVI+Pj4qXbq0VXuNGjWsajh58qRsbGyy1eLt7S03Nzerfll13MjDwyNbqD1y5IgOHDiQ6yqr8fHx5jHLly+vUqVKWW3Py1jfDgIiAAAAUETZ2NgoODhYc+fO1ZEjR3JddCY9Pf0+V/Y/tra2ObbfvDhMYXI7i/fcroyMDLVt21ajR4/OcXu1atXy7Vy3g4AIAAAAFGFpaWmSpEuXLpmzVzevfJk145VXFStW1JEjR7K1x8bG3tHxcjuHJB09etTqebu0tDSdOHFCdevWzZdzbNmyRRcvXrSaRfz555+taqhYsaIyMjJ05MgRc3ZRks6ePavExESrftKfs4OVK1c2+507d86cGc0SEBCgS5cu/eWMZ8WKFbV161ZdunTJahYxP8da4hlEAAAAoMhKTU3V5s2bZW9vrxo1aqhixYqytbU1n2vLsmDBgjs6fseOHbV37159/fXXZtu5c+e0bNmyu6r7Ro0aNVK5cuX073//2wy7krRs2bJsYetOdezYUenp6XrnnXes2mfPni2LxaLQ0FCznyRzZdEss2bNkiR16tRJ0p+LBZUoUULz5s2zmgm9eT9J6tatm6Kjo7Vp06Zs2xITE81r7tixo9LS0rRw4UJze3p6uubNm5fHq701ZhABAACAImLDhg3mrFd8fLyWL1+uI0eOaOzYsXJxcZEkPfPMM5o3b54sFosCAgL0xRdfmM+55dXo0aP14YcfqkOHDho2bJj5mouKFSvqwIED+XJN9vb2mjhxooYOHarWrVurW7duOnHihCIjIxUQEJAvt3s+/vjjCg4O1quvvqoTJ06oXr162rx5sz7//HMNHz5cAQEBkqR69eopLCxMixcvVmJiolq2bKmvv/5aS5cuVdeuXc0ZTg8PD7388suKiIhQ586d1bFjR+3fv18bNmyQu7u71blHjRqlNWvWqHPnzgoPD1fDhg11+fJl/fjjj/rss8904sQJubu76/HHH1ezZs00duxYnThxQjVr1tTKlSuVlJR019d/IwIiAAAAUESMHz/e/LOjo6OqV6+uhQsXasCAAWb7vHnzlJqaqkWLFsnBwUHdunXTjBkzVLt27Tyfr3z58tq+fbuGDh2qqVOnqly5cho4cKB8fHzUp0+ffLkmSRoyZIgMw9Bbb72ll19+WfXq1dOaNWv04osvytHR8a6Pb2NjozVr1mj8+PH6z3/+oyVLlqhSpUrmayZu9O6776py5cqKjIzUqlWr5O3trXHjxmV7rcaUKVPk6OioRYsWafv27WrSpIk2b95szjJmcXZ21s6dO/Xmm29qxYoV+uCDD+Ti4qJq1app0qRJcnV1tapx+PDh+uijj2SxWNSlSxe99dZbatCgwV2PQRaLUZif/rwLycnJcnV1lZ2dXb4+RAoAAIA7YxiG0tLSlJSUZM5m3S8pKSk6fvy4/P39rQPFqVNSYKCUknJf68mRo6MUGyvdtKoncpaRkSEPDw899dRT5jsJkbtcfwduwgwiAAAAii8/vz9DWUJCQVciubsTDnORkpIiBwcHq4mfDz74QBcuXFCrVq0KrrAiiIAIAACA4s3Pj2BWyO3du1cvvfSSnnnmGZUrV07ff/+93nvvPdWuXVvPPPNMQZdXpBAQAQAAABRqlSpVkq+vr95++21duHBBZcuW1fPPP6+pU6fK3t6+oMsrUgiIAAAAAAq1SpUqac2aNQVdRrHAexABAAAAAJIIiAAAAACATAREAAAAAIAkAiIAAAAAIBMBEQAAAAAgiYAIAAAAAMhEQAQAAAAASCIgAgAAAAAyERABAAAAFDqRkZGyWCw6ceLEfT93eHi4KlWqlK/HrFSpksLDw/P1mPeCXUEXAAAAABSkq/Hxup6cXNBlyN7FRU6enne0b2RkpHr37m3V5uHhoVq1amn06NEKDQ012y0WiyRp5syZGjlyZI7H+eabb9SoUaM7quV2VKpUSSdPnsxx29WrV+Xo6HjPzo1bIyACAACg2LoaH6+dffsqIzW1oEuRTYkSavnuu3ccEiVp8uTJ8vf3l2EYOnv2rCIjI9WxY0etXbtWnTt3tuo7Y8YMDRo0SM7Ozndb+h2pX79+toAqSfb29gVQDbIQEAEAAFBsXU9OLhThUJIyUlN1PTn5rgJiaGio1cxfnz595OXlpY8//tgqINavX18xMTFatGiRRowYcVd136mHHnpIzz77bIGcG7njGUQAAACgiHJzc5OTk5Ps7KznhZo1a6bWrVtr+vTpunr16l8eZ9u2bWrRooVKliwpNzc3PfHEEzp8+LBVn4kTJ8pisejo0aMKDw+Xm5ubXF1d1bt3b125ciXfrmnBggWqVauWHBwc5OPjo8GDBysxMTFbvxUrVqhhw4ZycnKSu7u7nn32WZ0+fTpbv9WrV6t27dpydHRU7dq1tWrVqhzPm5GRoTlz5qhWrVpydHSUl5eXBgwYoD/++MOqn2EYmjJliipUqCBnZ2cFBwfr0KFD+XLt9wMBEQAAACgikpKSlJCQoHPnzunQoUMaNGiQLl26lONM3cSJE3X27FktXLjwlsfcsmWL2rdvr/j4eE2cOFEjRozQV199pWbNmuW4gEy3bt108eJFRUREqFu3boqMjNSkSZOy9UtNTVVCQoLV56+C5MSJEzV48GD5+Pjorbfe0tNPP61//etfateunVJvmAmOjIxUt27dZGtrq4iICPXr108rV65U8+bNrcLk5s2b9fTTT8tisSgiIkJdu3ZV79699e2332Y794ABAzRq1Cg1a9ZMc+fOVe/evbVs2TK1b9/e6tzjx4/X66+/rnr16mnGjBmqXLmy2rVrp8uXL9/y2goLbjEFAAAAioiQkBCr7w4ODnr//ffVtm3bbH1btGih4OBg81lEJyenHI85atQolS1bVtHR0SpbtqwkqWvXrmrQoIEmTJigpUuXWvVv0KCB3nvvPfP7+fPn9d5772natGlW/TZv3iwPDw+rtgkTJmjixIk51nHu3DlFRESoXbt22rBhg2xs/pzrql69uoYMGaKPPvpIvXv3VmpqqsaMGaPatWtr165d5oI3zZs3V+fOnTV79mwzsI4ZM0ZeXl7avXu3XF1dJUktW7ZUu3btVLFiRfPcu3fv1rvvvqtly5apZ8+eZntwcLA6dOigFStWqGfPnjp37pymT5+uTp06ae3ateaCQK+++qrefPPNHK+rsGEGEQAAACgi5s+fr6ioKEVFRemjjz5ScHCw+vbtq5UrV+bYf+LEiYqLi9OiRYty3H7mzBnFxMQoPDzcDIeSVLduXbVt21br16/Pts/AgQOtvrdo0ULnz59X8k0rxTZp0sSsNevz/PPP53ptW7Zs0fXr1zV8+HAzHEpSv3795OLionXr1kmSvv32W8XHx+uFF16wWg21U6dOql69utkv69rCwsLMcChJbdu2Vc2aNa3OvWLFCrm6uqpt27ZWM54NGzZUqVKltH37dqsahw4daoZDSRo+fHiu11XYMIMIAAAAFBGNGze2WqSmR48eatCggYYMGaLOnTtnWyH0scceU3BwsKZPn54t2EkyX0URGBiYbVuNGjW0adMmXb58WSVLljTb/fz8rPqVKVNGkvTHH3/IxcXFbHd3d88243krudVib2+vypUrm9tvVXP16tW1e/duq35Vq1bN1i8wMFDff/+9+f3IkSNKSkqSZy4LCMXHx9/ymB4eHuY4FHYERAAAAKCIsrGxUXBwsObOnasjR46oVq1a2fpMmDBBrVq10r/+9S+5ubnd9TltbW1zbDcM466PXVAyMjLk6empZcuW5bj95ltlH2QERAAAAKAIS0tLkyRdunQpx+0tW7ZUq1atNG3aNI0fP95qW9ZzeLGxsdn2+/nnn+Xu7m41e3gv3VhL5cqVzfbr16/r+PHj5mzkjf1at25tdYzY2Fhze9b/HjlyJNu5br7egIAAbdmyRc2aNcv1Wc2bj3ljjefOncu22mlhxTOIAAAAQBGVmpqqzZs3y97eXjVq1Mi1X9aziIsXL7ZqL1++vOrXr6+lS5darf558OBBbd68WR07drxXpWcTEhIie3t7vf3221azke+9956SkpLUqVMnSVKjRo3k6empRYsW6dq1a2a/DRs26PDhw2a/G68tKSnJ7BcVFaWffvrJ6tzdunVTenq63njjjWx1paWlmWMTEhKiEiVKaN68eVY1zpkz566v/35hBhEAAAAoIjZs2KCff/5Z0p/PxS1fvlxHjhzR2LFjrZ7/u1nLli3VsmVL7dy5M9u2GTNmKDQ0VEFBQerTp4+uXr2qefPmydXVNdcVR+8FDw8PjRs3TpMmTVKHDh3UpUsXxcbGasGCBXrkkUfMV3mUKFFC06ZNU+/evdWyZUv16NFDZ8+e1dy5c1WpUiW99NJL5jEjIiLUqVMnNW/eXP/4xz904cIFzZs3T7Vq1bKacW3ZsqUGDBigiIgIxcTEqF27dipRooSOHDmiFStWaO7cufrb3/4mDw8Pvfzyy4qIiFDnzp3VsWNH7d+/Xxs2bJC7u/t9G6u7ke8ziFkvyLzxU716dXN7SkqKBg8erHLlyqlUqVJ6+umndfbsWatjnDp1Sp06dZKzs7M8PT01atQoc2ocAAAAQM7Gjx+v5557Ts8995xeffVVpaena+HChbf1ioXcwl5ISIg2btyocuXKafz48Zo5c6YeffRR7dmzR/7+/vl8BX9d4zvvvKNTp07ppZde0qeffqr+/ftr8+bNKlGihNkvPDxc//nPf3T9+nWNGTNG//rXv/Tkk09q9+7dVs9ZZr2iIj09XePGjdPKlSu1ZMkSq4V+sixatEiLFy9WfHy8XnnlFY0bN07btm3Ts88+q2bNmpn9pkyZokmTJmn//v0aNWqUjh07ps2bN9+3W3HvlsXI56dFJ06cqM8++0xbtmwx2+zs7MzEPGjQIK1bt06RkZFydXXVkCFDZGNjoz179kiS0tPTVb9+fXl7e2vGjBk6c+aMnn/+efXr1y9P7w5JTk6Wq6ur7OzsrJaYBQAAQMEwDENpaWlKSkq65WzWvZCSkqLjx4/L39/f6tUHV+PjtbNvX2Xc8KLzgmJTooRavvuunHJZKRO4G7n9DtzsntxiamdnJ29v72ztSUlJeu+997R8+XLzgdElS5aoRo0a2rt3rx599FFt3rxZP/30k7Zs2SIvLy/Vr19fb7zxhsaMGaOJEydmW5oXAAAAuFNOnp5q+e67un7TO/oKgr2LC+EQBe6eBMQjR47Ix8dHjo6OCgoKUkREhPz8/PTdd98pNTXV6n0n1atXl5+fn6Kjo/Xoo48qOjpaderUkZeXl9mnffv2GjRokA4dOqQGDRrkeM5r165ZPYR684s4AQAAgJw4eXoSzIBM+f4MYpMmTRQZGamNGzdq4cKFOn78uFq0aKGLFy8qLi5O9vb22d6v4uXlpbi4OElSXFycVTjM2p61LTcRERFydXU1P76+vvl7YQAAAABQxOX7DGJoaKj557p166pJkyaqWLGiPv3001u+M+RujRs3TiNGjDC/JycnExIBAAAAIA/u+XsQ3dzcVK1aNR09elTe3t66fv261TtUJOns2bPmM4ve3t7ZVjXN+p7Tc41ZHBwc5OLiYvUBAAAAANy+ex4QL126pGPHjql8+fJq2LChSpQooa1bt5rbY2NjderUKQUFBUmSgoKC9OOPPyo+Pt7sExUVJRcXF9WsWfNelwsAAAAAxVa+32L68ssv6/HHH1fFihX1+++/a8KECbK1tVWPHj3k6uqqPn36aMSIESpbtqxcXFw0dOhQBQUF6dFHH5UktWvXTjVr1tRzzz2n6dOnKy4uTq+99poGDx4sBweH/C4XAAAAAJAp3wPib7/9ph49euj8+fPy8PBQ8+bNtXfvXnl4eEiSZs+eLRsbGz399NO6du2a2rdvrwULFpj729ra6osvvtCgQYMUFBSkkiVLKiwsTJMnT87vUgEAAAAAN7AYhmEUdBH3QnJyslxdXWVnZyeLxVLQ5QAAABR7hmEoLS1NSUlJ9329iNt9SThQVN3u78A9fwYRAAAAAPBgICACAAAAACQREAEAAADks8jISFksFp04cSJP++3YsUMWi0U7duy4J3XdysSJE/P90bRWrVqpVatW+XrMey3fF6kBAAAAHiQXL55SSkpCQZchR0d3lS7td0f7RkZGqnfv3uZ3W1tbeXl5qW3btvrnP/+phx56KL/KvGOtWrXSzp07c9x2+PBhVa9e/T5XhJwQEAEAAFBsXbx4Sh9/HKj09JSCLkW2to7q0SP2jkOiJE2ePFn+/v5KSUnR3r17FRkZqd27d+vgwYOFYnGeChUqKCIiIlu7j49PAVSDnBAQAQAAUGylpCQUinAoSenpKUpJSbirgBgaGqpGjRpJkvr27St3d3dNmzZNa9asUbdu3fKr1Dvm6uqqZ599tqDLwC3wDCIAAABQRLVo0UKSdOzYMbNt27ZtatGihUqWLCk3Nzc98cQTOnz4sNV+J0+e1AsvvKDAwEA5OTmpXLlyeuaZZ3J8pvDQoUNq3bq1nJycVKFCBU2ZMkUZGRn5eh0rVqxQw4YN5eTkJHd3dz377LM6ffp0tn63c22StHv3bj3yyCNydHRUQECA/vWvf+V67o8++sg8d9myZdW9e3f9+uuv2fotXrxYAQEBcnJyUuPGjfXll1/e3UUXEGYQAQAAgCIqK9CVKVNGkrRlyxaFhoaqcuXKmjhxoq5evap58+apWbNm+v7771WpUiVJ0jfffKOvvvpK3bt3V4UKFXTixAktXLhQrVq10k8//SRnZ2dJUlxcnIKDg5WWlqaxY8eqZMmSWrx4sZycnHKsJz09XQkJ1s97Ojo6qlSpUrleQ9bzlY888ogiIiJ09uxZzZ07V3v27NH+/fvl5uaWp2v78ccf1a5dO3l4eGjixIlKS0vThAkT5OXlle3c//znP/X666+rW7du6tu3r86dO6d58+bpscceszr3e++9pwEDBqhp06YaPny4fvnlF3Xp0kVly5aVr6/v7fyfqtAgIAIAAABFRFJSkhISEpSSkqJ9+/Zp0qRJcnBwUOfOnSVJo0aNUtmyZRUdHa2yZctKkrp27aoGDRpowoQJWrp0qSSpU6dO+tvf/mZ17Mcff1xBQUH6v//7Pz333HOSpGnTpuncuXPat2+fGjduLEkKCwtT1apVc6zv559/loeHh1VbWFiYIiMjc+yfmpqqMWPGqHbt2tq1a5f5HGXz5s3VuXNnzZ49W5MmTcrTtY0fP16GYejLL7+Un9+ft/M+/fTTqlOnjtW5T548qQkTJmjKlCl65ZVXzPannnpKDRo00IIFC/TKK68oNTVVr7zyiurXr6/t27fL3t5eklSzZk3179//gQuI3GIKAAAAFBEhISHy8PCQr6+v/va3v6lkyZJas2aNKlSooDNnzigmJkbh4eFmgJKkunXrqm3btlq/fr3ZduMMYGpqqs6fP68qVarIzc1N33//vblt/fr1evTRR81wKEkeHh7q1atXjvVVqlRJUVFRVp/Ro0fnej3ffvut4uPj9cILL1gtstOpUydVr15d69atk6Tbvrb09HRt2rRJXbt2NcOhJNWoUUPt27e3OvfKlSuVkZGhbt26KSEhwfx4e3uratWq2r59u1WNAwcONMOhJIWHh8vV1TXXayusmEEEAAAAioj58+erWrVqSkpK0vvvv69du3bJwcFB0p8zYpIUGBiYbb8aNWpo06ZNunz5skqWLKmrV68qIiJCS5Ys0enTp2UYhtk3KSnJ/PPJkyfVpEmTbMfL6RySVLJkSYWEhNz29dyq5urVq2v37t15uraLFy/q6tWrOc5wBgYGWoXkI0eOyDCMXGdDS5QoYXXum/uVKFFClStX/strLGwIiAAAAEAR0bhxY3MV065du6p58+bq2bOnYmNj83ScoUOHasmSJRo+fLiCgoLk6uoqi8Wi7t275/sCNIVVRkaGLBaLNmzYIFtb22zbb/Xc5IOMgAgAAAAUQba2toqIiFBwcLDeeecdhYWFSVKOYfHnn3+Wu7u7SpYsKUn67LPPFBYWprfeesvsk5KSosTERKv9KlasqCNHjmQ7Xl4DaW4qVqxoHq9169bZzpG1/cZ+N7vx2hwdHeXk5HRbNQcEBMgwDPn7+6tatWp/WeORI0esakxNTdXx48dVr16927nUQoNnEAEAAIAiqlWrVmrcuLHmzJmjMmXKqH79+lq6dKlV0Dt48KA2b96sjh07mm22trZWt5VK0rx585Senm7V1rFjR+3du1dff/212Xbu3DktW7YsX+pv1KiRPD09tWjRIl27ds1s37Bhgw4fPqxOnTpJksqXL39b12Zra6v27dtr9erVOnXqlNnv8OHD2rRpk9W5n3rqKdna2mrSpEnZxsIwDJ0/f96s0cPDQ4sWLdL169fNPpGRkdkC9YOAGUQAAACgCBs1apSeeeYZRUZGasaMGQoNDVVQUJD69OljvgrC1dVVEydONPfp3LmzPvzwQ7m6uqpmzZqKjo7Wli1bVK5cOatjjx49Wh9++KE6dOigYcOGma+5qFixog4cOHDXtZcoUULTpk1T79691bJlS/Xo0cN8zUWlSpX00ksvmX1v99omTZqkjRs3qkWLFnrhhReUlpamefPmqVatWlY1BwQEaMqUKRo3bpxOnDihrl27qnTp0jp+/LhWrVql/v376+WXX1aJEiU0ZcoUDRgwQK1bt9bf//53HT9+XEuWLOEZRAAAAACFy1NPPaWAgADNnDlTsbGx2rhxoyZMmKDx48erRIkSatmypaZNmyZ/f39zn7lz58rW1lbLli1TSkqKmjVrpi1btmRb6bN8+fLavn27hg4dqqlTp6pcuXIaOHCgfHx81KdPn3ypPzw8XM7Ozpo6darGjBmjkiVL6sknn9S0adPM9xBKf67gejvXVrduXW3atEkjRozQ+PHjVaFCBU2aNElnzpzJFmrHjh2ratWqWb1Ow9fXV+3atVOXLl3Mfv3791d6erpmzJihUaNGqU6dOlqzZo1ef/31fBmD+8li3DxfWkQkJyfL1dVVdnZ2slgsBV0OAABAsWcYhtLS0pSUlCQXF5f7eu6UlBQdP35c/v7+Vq9LuHjxlD7+OFDp6Sn3tZ6c2No6qkePWJUu7ffXnYE8yu134GbMIAIAAKDYKl3aTz16xColJaGgS5GjozvhEAWOgAgAAIBirXRpP4IZkIlVTAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAAqhEydOyGKxKDIy8r6fOzIyUhaLRSdOnMi3Y4aHh6tSpUr5drx7hYAIAAAAPOCyAk3Wx87OTg899JDCw8N1+vRpq76tWrWSxWLR448/nu04WaFs5syZ97Te8PBwq3pv/GzcuPGenhu3ZlfQBQAAAAAFKSkpSVevXi3oMuTk5CRXV9e7OsbkyZPl7++vlJQU7d27V5GRkdq9e7cOHjwoR0dHq75ffPGFvvvuOzVs2PCuznmnHBwc9O6772Zrr1evXgFUgywERAAAABRbSUlJWrx4sdLT0wu6FNna2qp///53FRJDQ0PVqFEjSVLfvn3l7u6uadOmac2aNerWrZvZz8/PTxcvXtSkSZO0Zs2au679TtjZ2enZZ58tkHMjd9xiCgAAgGLr6tWrhSIcSlJ6enq+z2S2aNFCknTs2DGr9tKlS+ull17S2rVr9f333//lcX755Rc988wzKlu2rJydnfXoo49q3bp1Vn127Nghi8WiTz/9VP/85z9VoUIFOTo6qk2bNjp69Gi+XdO2bdvUokULlSxZUm5ubnriiSd0+PDhbP3279+v0NBQubi4qFSpUmrTpo327t2brd+hQ4fUunVrOTk5qUKFCpoyZYoyMjJyPPeGDRvMc5cuXVqdOnXSoUOHsvVbvXq1ateuLUdHR9WuXVurVq26+wu/T5hBBAAAAIqorEVWypQpk23bsGHDNHv2bE2cOPGWs4hnz55V06ZNdeXKFb344osqV66cli5dqi5duuizzz7Tk08+adV/6tSpsrGx0csvv6ykpCRNnz5dvXr10r59+7IdOyEhwep7iRIlbjmDumXLFoWGhqpy5cqaOHGirl69qnnz5qlZs2b6/vvvzUVgDh06pBYtWsjFxUWjR49WiRIl9K9//UutWrXSzp071aRJE0lSXFycgoODlZaWprFjx6pkyZJavHixnJycsp37ww8/VFhYmNq3b69p06bpypUrWrhwoZo3b679+/eb5968ebOefvpp1axZUxERETp//rx69+6tChUq5HpdhQkBEQAAACgikpKSlJCQoJSUFO3bt0+TJk2Sg4ODOnfunK2vi4uLhg8frgkTJuj777/Xww8/nOMxp06dqrNnz+rLL79U8+bNJUn9+vVT3bp1NWLECD3xxBOysfnfjYkpKSmKiYmRvb29pD/D6bBhw3Tw4EHVrl3b7Hf58mV5eHhYnatly5basWNHrtc3atQolS1bVtHR0SpbtqwkqWvXrmrQoIEmTJigpUuXSpJee+01paamavfu3apcubIk6fnnn1dgYKBGjx6tnTt3SpKmTZumc+fOad++fWrcuLEkKSwsTFWrVrU676VLl/Tiiy+qb9++Wrx4sdkeFhamwMBAvfnmm2b7mDFj5OXlpd27d5tht2XLlmrXrp0qVqyY67UVFtxiCgAAABQRISEh8vDwkK+vr/72t7+pZMmSWrNmTa6zV8OGDVOZMmU0adKkXI+5fv16NW7c2AyHklSqVCn1799fJ06c0E8//WTVv3fv3mY4lP53m+svv/xi1c/R0VFRUVFWn7feeivXOs6cOaOYmBiFh4eb4VCS6tatq7Zt22r9+vWS/rxVd/PmzeratasZDiWpfPny6tmzp3bv3q3k5GTz2h599FEzHEqSh4eHevXqZXXuqKgoJSYmqkePHkpISDA/tra2atKkibZv325VY1hYmNVMaNu2bVWzZs1cr60wYQYRAAAAKCLmz5+vatWqKSkpSe+//7527dolBweHXPu7urqas4j79+/P8VbUkydPmrdk3qhGjRrm9htnBv38/Kz6ZR3zjz/+sGq3tbVVSEjIbV/byZMnJUmBgYE51rJp0yZdvnxZFy9e1JUrV3Ltl5GRoV9//VW1atXK9dpu3vfIkSOSpNatW+dYm4uLi1WNN89AZh3zdp73LGgERAAAAKCIaNy4sbmKadeuXdW8eXP17NlTsbGxKlWqVI77ZD2LOGnSJM2ZM+eua7C1tc2x3TCMuz52QclatObDDz+Ut7d3tu12dkUnVhWdKwEAAABgsrW1VUREhIKDg/XOO+9o7NixOfbLmkWcOHGiwsLCsm2vWLGiYmNjs7X//PPP5vb7Ies8udXi7u6ukiVLytHRUc7Ozrn2s7Gxka+vr3nMrNnBG928b0BAgCTJ09PzlrOeWTXezjELK55BBAAAAIqoVq1aqXHjxpozZ45SUlJy7Td8+HC5ublp8uTJ2bZ17NhRX3/9taKjo822y5cva/HixapUqdJ9e7aufPnyql+/vpYuXarExESz/eDBg9q8ebM6duwo6c9g3K5dO33++efmKq7Sn6uxLl++XM2bNzdvCe3YsaP27t2rr7/+2ux37tw5LVu2zOrc7du3l4uLi958802lpqZmq+3cuXPZakxKSjK3R0VFZXtWs7AiIAIAAABF2KhRo3T27FlFRkbm2sfV1VXDhg1TTExMtm1jx46Vl5eXQkNDNX78eM2ZM0fNmzfX8ePHNWvWLKsVTO+1GTNm6Pz58woKCtLMmTP1xhtvqHXr1nJ1ddXEiRPNflOmTJGdnZ2aN2+uN998U9OnT1fTpk117do1TZ8+3ew3evRolStXTh06dNCkSZM0c+ZMNWvWLNusqIuLixYuXKgvv/xSDz/8sP75z39q8eLFeu2119SgQQOrRX4iIiJ09uxZNW/eXLNnz9brr7+uZ555RrVq1brn45MfCIgAAABAEfbUU08pICBAM2fOVHp6eq79hg8fnuM7CL28vPTVV1+pbdu2mjdvnsaNGyd7e3utXbs22zsQ77WQkBBt3LhR5cqV0/jx4zVz5kw9+uij2rNnj/z9/c1+tWrV0pdffqnatWsrIiJCkyZNUsWKFbV9+3arRWnKly+v7du3q27dupo6darmzJmj559/XsOGDct27p49e2rr1q166KGHNGPGDA0bNkyffPKJ6tevr969e5v9OnTooBUrVig9PV3jxo3TypUrtWTJEvPZ0MLOYjzIT4veQnJyslxdXWVnZyeLxVLQ5QAAABR7hmEoLS1NSUlJ5i1+90tKSoqOHz8uf39/OTo6mu1JSUlavHjxLYPT/WJra6v+/fvf8kXxwJ3K7XfgZixSAwAAgGLL1dVV/fv319WrVwu6FDk5OREOUeAIiAAAACjWXF1dCWZAJp5BBAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkiS7gi4AAAAAKEin0tKUkJ5e0GXI3dZWfnZ5/+f5p59+qr///e9auXKlnnzySatt9erV04EDB7Rt2zYFBwdbbfPz81OFChX01Vdf3dZ5FixYIGdnZ4WHh+e5Rjw4CIgAAAAotk6lpSnw9GmlFHQhkhwlxT70UJ5DYvPmzSVJu3fvtgqIycnJOnjwoOzs7LRnzx6rgPjrr7/q119/Vffu3W/7PAsWLJC7uzsBsYjjFlMAAAAUWwnp6YUiHEpSinRHM5k+Pj7y9/fX7t27rdqjo6NlGIaeeeaZbNuyvmeFy4KSlpam69evF2gNsEZABAAAAB5wzZs31/79+3X16lWzbc+ePapVq5ZCQ0O1d+9eZWRkWG2zWCxq1qyZlixZotatW8vT01MODg6qWbOmFi5caHX8SpUq6dChQ9q5c6csFossFotatWplbk9MTNTw4cPl6+srBwcHValSRdOmTbM654kTJ2SxWDRz5kzNmTNHAQEBcnBw0E8//XTvBgZ5xi2mAAAAwAOuefPm+vDDD7Vv3z4zuO3Zs0dNmzZV06ZNlZSUpIMHD6pu3brmturVq6tcuXJauHChatWqpS5dusjOzk5r167VCy+8oIyMDA0ePFiSNGfOHA0dOlSlSpXSq6++Kkny8vKSJF25ckUtW7bU6dOnNWDAAPn5+emrr77SuHHjdObMGc2ZM8eq1iVLliglJUX9+/eXg4ODypYte38GCbeFgAgAAAA84G58DrFVq1ZKS0vTvn37FBYWpoCAAHl5eWn37t2qW7euLl68qB9//FH/+Mc/JEk7d+6Uk5OTeawhQ4aoQ4cOmjVrlhkQu3btqtdee03u7u569tlnrc49a9YsHTt2TPv371fVqlUlSQMGDJCPj49mzJihkSNHytfX1+z/22+/6ejRo/Lw8LinY4I7wy2mAAAAwAOuRo0aKleunPls4Q8//KDLly+radOmkqSmTZtqz549kv58NjE9Pd0MlTeGw6SkJCUkJKhly5b65ZdflJSU9JfnXrFihVq0aKEyZcooISHB/ISEhCg9PV27du2y6v/0008TDgsxZhABAACAB5zFYlHTpk21a9cuZWRkaM+ePfL09FSVKlUk/RkQ33nnHUkyg2JWQNyzZ48mTJig6OhoXblyxeq4SUlJcnV1veW5jxw5ogMHDuQa+uLj462++/v75/0Ccd8QEAEAAIAioHnz5lq7dq1+/PFH8/nDLE2bNtWoUaN0+vRp7d69Wz4+PqpcubKOHTumNm3aqHr16po1a5Z8fX1lb2+v9evXa/bs2VaLzOQmIyNDbdu21ejRo3PcXq1aNavvN85YovAhIAIAAABFwI3PIe7Zs0fDhw83tzVs2FAODg7asWOH9u3bp44dO0qS1q5dq2vXrmnNmjXy8/Mz+2/fvj3b8S0WS47nDQgI0KVLlxQSEpKPV4OCkudnEHft2qXHH39cPj4+slgsWr16tdV2wzA0fvx4lS9fXk5OTgoJCdGRI0es+ly4cEG9evWSi4uL3Nzc1KdPH126dMmqz4EDB9SiRQs5OjrK19dX06dPz/vVAQAAAMVEo0aN5OjoqGXLlun06dNWM4gODg56+OGHNX/+fF2+fNkMk7a2tpL+/Dd8lqSkJC1ZsiTb8UuWLKnExMRs7d26dVN0dLQ2bdqUbVtiYqLS0tLu9tJwH+U5IF6+fFn16tXT/Pnzc9w+ffp0vf3221q0aJH27dunkiVLqn379kpJ+d8rSHv16qVDhw4pKipKX3zxhXbt2qX+/fub25OTk9WuXTtVrFhR3333nWbMmKGJEydq8eLFd3CJAAAAQNFnb2+vRx55RNHR0XJwcFDDhg2ttjdt2lTR0dGS/jfb2K5dO9nb2+vxxx/X/PnzNW3aNDVs2FCenp7Zjt+wYUMdOHBAU6ZM0SeffKJt27ZJkkaNGqWHH35YnTt3Vr9+/bRo0SK99dZbCg8PV4UKFXIMlSi88nyLaWhoqEJDQ3PcZhiG5syZo9dee01PPPGEJOmDDz6Ql5eXVq9ere7du+vw4cPauHGjvvnmGzVq1EiSNG/ePHXs2FEzZ86Uj4+Pli1bpuvXr+v999+Xvb29atWqpZiYGM2aNcsqSAIAAAD4n+bNm+vLL780bym9UbNmzfTWW2+pdOnSqlevniQpMDBQn332mV577TW9/PLL8vb21qBBg+Th4WG+BiPL+PHjdfLkSU2fPl0XL15Uy5Yt1bp1azk7O2vnzp168803tWLFCn3wwQdycXFRtWrVNGnSpL9c5AaFi8W4cT45rztbLFq1apW6du0qSfrll18UEBCg/fv3q379+ma/li1bqn79+po7d67ef/99jRw5Un/88Ye5PS0tTY6OjlqxYoWefPJJPf/880pOTra6fXX79u1q3bq1Lly4oDJlymSr5dq1a7p27Zr5PTk5Wb6+vrKzs8v1fmkAAADcP4ZhKC0tTUlJSXJxcbmv505JSdHx48fl7+8vR0dHs/1UWpoCT59Wyi32vV8cJcU+9JD87FgmBPkvt9+Bm+XrT19cXJwkycvLy6rdy8vL3BYXF5dtytrOzk5ly5a16nPz8rdZx4yLi8sxIEZERGjSpEn5cyEAAAAoFvzs7BT70ENKSE8v6FLkbmtLOESBKzI/gePGjdOIESPM71kziAAAAMCt+NnZEcyATHlepOZWvL29JUlnz561aj979qy5zdvbO9vLMtPS0nThwgWrPjkd48Zz3MzBwUEuLi5WHwAAAADA7cvXgOjv7y9vb29t3brVbEtOTta+ffsUFBQkSQoKClJiYqK+++47s8+2bduUkZGhJk2amH127dql1NRUs09UVJQCAwNzvL0UAAAAAHD38hwQL126pJiYGMXExEiSjh8/rpiYGJ06dUoWi0XDhw/XlClTtGbNGv344496/vnn5ePjYy5kU6NGDXXo0EH9+vXT119/rT179mjIkCHq3r27fHx8JEk9e/aUvb29+vTpo0OHDuk///mP5s6da3ULKQAAAAAgf+X5Zutvv/1WwcHB5ves0BYWFqbIyEiNHj1aly9fVv/+/ZWYmKjmzZtr48aNVivlLFu2TEOGDFGbNm1kY2Ojp59+Wm+//ba53dXVVZs3b9bgwYPVsGFDubu7a/z48bziAgAAAADuobt6zUVhlpycLFdXV15zAQAAUEgUxtdcAMXF7f4O5OsziAAAAACABxcBEQAAAAAgiYAIAAAAAMhEQAQAAAAASCIgAgAAAAAy5fk1FwAAAEBRcupUmhISMgq6DLm728jPL2//PL/d1fq3b9+uVq1a3UFVKG4IiAAAACi2Tp1KU2Dg70pJKehKJEdHKTbWJ08h8cMPP7T6/sEHHygqKipbe40aNfKlRhR9BEQAAAAUWwkJGYUiHEpSSsqf9fj53f4+zz77rNX3vXv3KioqKlv7za5cuSJnZ+c7KRNFHM8gAgAAAEVYq1atVLt2bX333Xd67LHH5OzsrFdeeUWSdO3aNU2YMEFVqlSRg4ODfH19NXr0aF27di3bcT766CM1bNhQTk5OKlu2rLp3765ff/31fl8O7jFmEAEAAIAi7vz58woNDVX37t317LPPysvLSxkZGerSpYt2796t/v37q0aNGvrxxx81e/Zs/fe//9Xq1avN/f/5z3/q9ddfV7du3dS3b1+dO3dO8+bN02OPPab9+/fLzc2twK4N+YuACAAAABRxcXFxWrRokQYMGGC2ffTRR9qyZYt27typ5s2bm+21a9fWwIED9dVXX6lp06Y6efKkJkyYoClTppgzj5L01FNPqUGDBlqwYIFVOx5s3GIKAAAAFHEODg7q3bu3VduKFStUo0YNVa9eXQkJCeandevWkv5c+VSSVq5cqYyMDHXr1s2qn7e3t6pWrWr2Q9HADCIAAABQxD300EOyt7e3ajty5IgOHz4sDw+PHPeJj483+xmGoapVq+bYr0SJEvlbLAoUAREAAAAo4pycnLK1ZWRkqE6dOpo1a1aO+/j6+pr9LBaLNmzYIFtb22z9SpUqlb/FokAREAEAAIBiKCAgQD/88IPatGkji8Vyy36GYcjf31/VqlW7jxWiIPAMIgAAAFAMdevWTadPn9a///3vbNuuXr2qy5cvS/pzMRpbW1tNmjRJhmFY9TMMQ+fPn78v9eL+YAYRAAAAKIaee+45ffrppxo4cKC2b9+uZs2aKT09XT///LM+/fRTbdq0SY0aNVJAQICmTJmicePG6cSJE+ratatKly6t48ePa9WqVerfv79efvnlgr4c5BMCIgAAAFAM2djYaPXq1Zo9e7Y++OADrVq1Ss7OzqpcubKGDRtmdTvp2LFjVa1aNc2ePVuTJk2S9Ocziu3atVOXLl0K6hJwD1iMm+eJi4jk5GS5urrKzs7ulvdUAwAA4P4wDENpaWlKSkqSi4vLfT13SkqKjh8/Ln9/fzk6Oprtp06lKTDwd6Wk3NdycuToKMXG+sjPjzkc5L/cfgduxk8fAAAAii0/PzvFxvooISGjoEuRu7sN4RAFjp9AAAAAFGt+fnby8yvoKoDCgVVMAQAAAACSCIgAAAAAgEwERAAAAACAJAIiAAAAACATAREAAAAAIImACAAAAADIREAEAAAAAEgiIAIAAAAAMhEQAQAAAACSCIgAAAAA8qhSpUoKDw83v+/YsUMWi0U7duwosJqQPwiIAAAAwAOqS5cucnZ21sWLF3Pt06tXL9nb2+v8+fP3sTI8qOwKugAAAACgIF0/dV1pCWkFXYbs3O1k72efp3169eqltWvXatWqVXr++eezbb9y5Yo+//xzdejQQeXKlcuvUhUbGysbG+aaiiICIgAAAIqt66eu62DgQRkpRkGXIoujRbVja+cpJHbp0kWlS5fW8uXLcwyIn3/+uS5fvqxevXrlZ6lycHDI1+Oh8CD2AwAAoNhKS0grFOFQkowUI88zmU5OTnrqqae0detWxcfHZ9u+fPlylS5dWl26dFFiYqKGDx8uX19fOTg4qEqVKpo2bZoyMjKs9snIyNDcuXNVp04dOTo6ysPDQx06dNC3335r9rn5GcTc7Nu3Tx06dJCrq6ucnZ3VsmVL7dmzJ0/XiPuLgAgAAAA8wHr16qW0tDR9+umnVu0XLlzQpk2b9OSTT8owDLVs2VIfffSRnn/+eb399ttq1qyZxo0bpxEjRljt16dPHzNITps2TWPHjpWjo6P27t2bp7q2bdumxx57TMnJyZowYYLefPNNJSYmqnXr1vr666/v+rpxb3CLKQAAAPAAa926tcqXL6/ly5dryJAhZvuKFSuUmpqqXr16adasWTp27Jj279+vqlWrSpIGDBggHx8fzZgxQyNHjpSvr6+2b9+uyMhIvfjii5o7d655rJEjR8owbn+m1TAMDRw4UMHBwdqwYYMsFot5zlq1aum1117T5s2b82kEkJ+YQQQAAAAeYLa2turevbuio6N14sQJs3358uXy8vJSmzZttGLFCrVo0UJlypRRQkKC+QkJCVF6erp27dolSfq///s/WSwWTZgwIdt5skLe7YiJidGRI0fUs2dPnT9/3jzf5cuX1aZNG+3atSvbra0oHJhBBAAAAB5wvXr10uzZs7V8+XK98sor+u233/Tll1/qxRdflK2trY4cOaIDBw7Iw8Mjx/2znl88duyYfHx8VLZs2buq58iRI5KksLCwXPskJSWpTJkyd3Ue5D8CIgAAAPCAa9iwoapXr66PP/5Yr7zyij7++GMZhmGuXpqRkaG2bdtq9OjROe5frVq1fK0na3ZwxowZql+/fo59SpUqla/nRP4gIAIAAABFQK9evfT666/rwIEDWr58uapWrapHHnlEkhQQEKBLly4pJCTklscICAjQpk2bdOHChbuaRQwICJAkubi4/OU5UbjwDCIAAABQBGTNFo4fP14xMTFW7z7s1q2boqOjtWnTpmz7JSYmKi3tz9drPP300zIMQ5MmTcrWLy+L1DRs2FABAQGaOXOmLl26lG37uXPnbvtYuL+YQQQAAACKAH9/fzVt2lSff/65JFkFxFGjRmnNmjXq3LmzwsPD1bBhQ12+fFk//vijPvvsM504cULu7u4KDg7Wc889p7fffltHjhxRhw4dlJGRoS+//FLBwcFWq6Teio2Njd59912FhoaqVq1a6t27tx566CGdPn1a27dvl4uLi9auXXtPxgF3h4AIAAAAFBG9evXSV199pcaNG6tKlSpmu7Ozs3bu3Kk333xTK1as0AcffCAXFxdVq1ZNkyZNkqurq9l3yZIlqlu3rt577z2NGjVKrq6uatSokZo2bZqnWlq1aqXo6Gi98cYbeuedd3Tp0iV5e3urSZMmGjBgQL5dM/KXxcjLXPEDJDk5Wa6urrKzs8vTkrwAAAC4NwzDUFpampKSkuTi4nJfz52SkqLjx4/L399fjo6OZvv1U9d1MPCgjJSC/yexxdGi2rG1Ze9nX9CloAjK7XfgZswgAgAAoNiy97NX7djaSktIK+hSZOduRzhEgSMgAgAAoFiz97MnmAGZWMUUAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAKEaK6CvAgb90uz/7BEQAAAAUeSVKlJAkXblypYArAQrG5cuXZbFYzN+F3PAeRAAAABR5tra2cnNzU3x8vCTJ2dlZFoulgKsC7i3DMJSWlqbk5GQlJyfLzc1Ntra2t9yHgAgAAIBiwdvbW5LMkAgUF7a2tipfvrxcXV3/si8BEQAAAMWCxWJR+fLl5enpqdTU1IIuB7gv7OzsZGtre9sz5gREAAAAFCu2trZ/eZsdUFyxSA0AAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAECmPAfEXbt26fHHH5ePj48sFotWr15ttT08PFwWi8Xq06FDB6s+Fy5cUK9eveTi4iI3Nzf16dNHly5dsupz4MABtWjRQo6OjvL19dX06dPzfnUAAAAAgNuW54B4+fJl1atXT/Pnz8+1T4cOHXTmzBnz8/HHH1tt79Wrlw4dOqSoqCh98cUX2rVrl/r3729uT05OVrt27VSxYkV99913mjFjhiZOnKjFixfntVwAAAAAwG2yy+sOoaGhCg0NvWUfBwcHeXt757jt8OHD2rhxo7755hs1atRIkjRv3jx17NhRM2fOlI+Pj5YtW6br16/r/fffl729vWrVqqWYmBjNmjXLKkgCAAAAAPLPPXkGcceOHfL09FRgYKAGDRqk8+fPm9uio6Pl5uZmhkNJCgkJkY2Njfbt22f2eeyxx2Rvb2/2ad++vWJjY/XHH3/keM5r164pOTnZ6gMAAAAAuH35HhA7dOigDz74QFu3btW0adO0c+dOhYaGKj09XZIUFxcnT09Pq33s7OxUtmxZxcXFmX28vLys+mR9z+pzs4iICLm6upofX1/f/L40AAAAACjS8nyL6V/p3r27+ec6deqobt26CggI0I4dO9SmTZv8Pp1p3LhxGjFihPk9OTmZkAgAAAAAeXDPX3NRuXJlubu76+jRo5Ikb29vxcfHW/VJS0vThQsXzOcWvb29dfbsWas+Wd9ze7bRwcFBLi4uVh8AAAAAwO275wHxt99+0/nz51W+fHlJUlBQkBITE/Xdd9+ZfbZt26aMjAw1adLE7LNr1y6lpqaafaKiohQYGKgyZcrc65IBAAAAoFjKc0C8dOmSYmJiFBMTI0k6fvy4YmJidOrUKV26dEmjRo3S3r17deLECW3dulVPPPGEqlSpovbt20uSatSooQ4dOqhfv376+uuvtWfPHg0ZMkTdu3eXj4+PJKlnz56yt7dXnz59dOjQIf3nP//R3LlzrW4hBQAAAADkL4thGEZedtixY4eCg4OztYeFhWnhwoXq2rWr9u/fr8TERPn4+Khdu3Z64403rBaduXDhgoYMGaK1a9fKxsZGTz/9tN5++22VKlXK7HPgwAENHjxY33zzjdzd3TV06FCNGTPmtutMTk6Wq6ur7OzsZLFY8nKJAAAAuAcMw1BaWpqSkpJ4HAgopPIcEB8UBEQAAIDChYAIFH73/BlEAAAAAMCDgYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJCUx4AYERGhRx55RKVLl5anp6e6du2q2NhYqz4pKSkaPHiwypUrp1KlSunpp5/W2bNnrfqcOnVKnTp1krOzszw9PTVq1CilpaVZ9dmxY4cefvhhOTg4qEqVKoqMjLyzKwQAAAAA3JY8BcSdO3dq8ODB2rt3r6KiopSamqp27drp8uXLZp+XXnpJa9eu1YoVK7Rz5079/vvveuqpp8zt6enp6tSpk65fv66vvvpKS5cuVWRkpMaPH2/2OX78uDp16qTg4GDFxMRo+PDh6tu3rzZt2pQPlwwAAAAAyInFMAzjTnc+d+6cPD09tXPnTj322GNKSkqSh4eHli9frr/97W+SpJ9//lk1atRQdHS0Hn30UW3YsEGdO3fW77//Li8vL0nSokWLNGbMGJ07d0729vYaM2aM1q1bp4MHD5rn6t69uxITE7Vx48bbqi05OVmurq6ys7OTxWK500sEAABAPjEMQ2lpaUpKSpKLi0tBlwMgB3f1DGJSUpIkqWzZspKk7777TqmpqQoJCTH7VK9eXX5+foqOjpYkRUdHq06dOmY4lKT27dsrOTlZhw4dMvvceIysPlnHyMm1a9eUnJxs9QEAAAAA3L47DogZGRkaPny4mjVrptq1a0uS4uLiZG9vLzc3N6u+Xl5eiouLM/vcGA6ztmdtu1Wf5ORkXb16Ncd6IiIi5Orqan58fX3v9NIAAAAAoFi644A4ePBgHTx4UJ988kl+1nPHxo0bp6SkJPPz66+/FnRJAAAAAPBAsbuTnYYMGaIvvvhCu3btUoUKFcx2b29vXb9+XYmJiVaziGfPnpW3t7fZ5+uvv7Y6XtYqpzf2uXnl07Nnz8rFxUVOTk451uTg4CAHB4c7uRwAAAAAgPI4g2gYhoYMGaJVq1Zp27Zt8vf3t9resGFDlShRQlu3bjXbYmNjderUKQUFBUmSgoKC9OOPPyo+Pt7sExUVJRcXF9WsWdPsc+MxsvpkHQMAAAAAkP/ytIrpCy+8oOXLl+vzzz9XYGCg2e7q6mrO7A0aNEjr169XZGSkXFxcNHToUEnSV199JenP11zUr19fPj4+mj59uuLi4vTcc8+pb9++evPNNyX9+ZqL2rVra/DgwfrHP/6hbdu26cUXX9S6devUvn3726qVVUwBAAAKF1YxBQq/PAXE3ILWkiVLFB4eLklKSUnRyJEj9fHHH+vatWtq3769FixYYN4+KkknT57UoEGDtGPHDpUsWVJhYWGaOnWq7Oz+d8frjh079NJLL+mnn35ShQoV9Prrr5vnuB0ERAAAgMKFgAgUfnf1HsTCjIAIAABQuBAQgcLvrt6DCAAAAAAoOgiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJeQyIEREReuSRR1S6dGl5enqqa9euio2NterTqlUrWSwWq8/AgQOt+pw6dUqdOnWSs7OzPD09NWrUKKWlpVn12bFjhx5++GE5ODioSpUqioyMvLMrBAAAAADcljwFxJ07d2rw4MHau3evoqKilJqaqnbt2uny5ctW/fr166czZ86Yn+nTp5vb0tPT1alTJ12/fl1fffWVli5dqsjISI0fP97sc/z4cXXq1EnBwcGKiYnR8OHD1bdvX23atOkuLxcAAAAAkBuLYRjGne587tw5eXp6aufOnXrsscck/TmDWL9+fc2ZMyfHfTZs2KDOnTvr999/l5eXlyRp0aJFGjNmjM6dOyd7e3uNGTNG69at08GDB839unfvrsTERG3cuPG2aktOTparq6vs7OxksVju9BIBAACQTwzDUFpampKSkuTi4lLQ5QDIwV09g5iUlCRJKlu2rFX7smXL5O7urtq1a2vcuHG6cuWKuS06Olp16tQxw6EktW/fXsnJyTp06JDZJyQkxOqY7du3V3R0dK61XLt2TcnJyVYfAAAAAMDts7vTHTMyMjR8+HA1a9ZMtWvXNtt79uypihUrysfHRwcOHNCYMWMUGxurlStXSpLi4uKswqEk83tcXNwt+yQnJ+vq1atycnLKVk9ERIQmTZp0p5cDAAAAAMXeHQfEwYMH6+DBg9q9e7dVe//+/c0/16lTR+XLl1ebNm107NgxBQQE3Hmlf2HcuHEaMWKE+T05OVm+vr737HwAAAAAUNTc0S2mQ4YM0RdffKHt27erQoUKt+zbpEkTSdLRo0clSd7e3jp79qxVn6zv3t7et+zj4uKS4+yhJDk4OMjFxcXqAwAAAAC4fXkKiIZhaMiQIVq1apW2bdsmf3//v9wnJiZGklS+fHlJUlBQkH788UfFx8ebfaKiouTi4qKaNWuafbZu3Wp1nKioKAUFBeWlXAAAAABAHuRpFdMXXnhBy5cv1+eff67AwECz3dXVVU5OTjp27JiWL1+ujh07qly5cjpw4IBeeuklVahQQTt37pT052su6tevLx8fH02fPl1xcXF67rnn1LdvX7355puS/nzNRe3atTV48GD94x//0LZt2/Tiiy9q3bp1at++/W3VyiqmAAAAhQurmAKFX54CYm5Ba8mSJQoPD9evv/6qZ599VgcPHtTly5fl6+urJ598Uq+99prVXwInT57UoEGDtGPHDpUsWVJhYWGaOnWq7Oz+90jkjh079NJLL+mnn35ShQoV9Prrrys8PPy2L4yACAAAULgQEIHC767eg1iYERABAAAKFwIiUPjd1XsQAQAAAABFBwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADLZFXQB94phGFb/CwAAgILFv8+Awq/IBsTz589LktLT0wu4EgAAANzo4sWLcnV1LegyAOSgyAbEsmXLSpJOnTrFX0C3KTk5Wb6+vvr111/l4uJS0OU8EBizvGPM8o4xyzvGLO8Ys7xjzPLOMAxdvHhRPj4+BV0KgFwU2YBoY/Pn45Wurq78pZ1HLi4ujFkeMWZ5x5jlHWOWd4xZ3jFmeceY5Q3/4R4o3FikBgAAAAAgiYAIAAAAAMhUZAOig4ODJkyYIAcHh4Iu5YHBmOUdY5Z3jFneMWZ5x5jlHWOWd4wZgKLIYrDOMAAAAABARXgGEQAAAACQNwREAAAAAIAkAiIAAAAAIBMBEQAAAAAgqYgGxPnz56tSpUpydHRUkyZN9PXXXxd0SQVm4sSJslgsVp/q1aub21NSUjR48GCVK1dOpUqV0tNPP62zZ89aHePUqVPq1KmTnJ2d5enpqVGjRiktLe1+X8o9s2vXLj3++OPy8fGRxWLR6tWrrbYbhqHx48erfPnycnJyUkhIiI4cOWLV58KFC+rVq5dcXFzk5uamPn366NKlS1Z9Dhw4oBYtWsjR0VG+vr6aPn36vb60e+avxiw8PDzbz12HDh2s+hSnMYuIiNAjjzyi0qVLy9PTU127dlVsbKxVn/z6XdyxY4cefvhhOTg4qEqVKoqMjLzXl3dP3M6YtWrVKtvP2cCBA636FKcxW7hwoerWrWu+tD0oKEgbNmwwt/Mzlt1fjRk/YwCKJaOI+eSTTwx7e3vj/fffNw4dOmT069fPcHNzM86ePVvQpRWICRMmGLVq1TLOnDljfs6dO2duHzhwoOHr62ts3brV+Pbbb41HH33UaNq0qbk9LS3NqF27thESEmLs37/fWL9+veHu7m6MGzeuIC7nnli/fr3x6quvGitXrjQkGatWrbLaPnXqVMPV1dVYvXq18cMPPxhdunQx/P39jatXr5p9OnToYNSrV8/Yu3ev8eWXXxpVqlQxevToYW5PSkoyvLy8jF69ehkHDx40Pv74Y8PJycn417/+db8uM1/91ZiFhYUZHTp0sPq5u3DhglWf4jRm7du3N5YsWWIcPHjQiImJMTp27Gj4+fkZly5dMvvkx+/iL7/8Yjg7OxsjRowwfvrpJ2PevHmGra2tsXHjxvt6vfnhdsasZcuWRr9+/ax+zpKSksztxW3M1qxZY6xbt87473//a8TGxhqvvPKKUaJECePgwYOGYfAzlpO/GjN+xgAUR0UuIDZu3NgYPHiw+T09Pd3w8fExIiIiCrCqgjNhwgSjXr16OW5LTEw0SpQoYaxYscJsO3z4sCHJiI6ONgzjzyBgY2NjxMXFmX0WLlxouLi4GNeuXbuntReEm8NORkaG4e3tbcyYMcNsS0xMNBwcHIyPP/7YMAzD+OmnnwxJxjfffGP22bBhg2GxWIzTp08bhmEYCxYsMMqUKWM1ZmPGjDECAwPv8RXde7kFxCeeeCLXfYr7mMXHxxuSjJ07dxqGkX+/i6NHjzZq1aplda6///3vRvv27e/1Jd1zN4+ZYfz5j/dhw4bluk9xHzPDMIwyZcoY7777Lj9jeZA1ZobBzxiA4qlI3WJ6/fp1fffddwoJCTHbbGxsFBISoujo6AKsrGAdOXJEPj4+qly5snr16qVTp05Jkr777julpqZajVf16tXl5+dnjld0dLTq1KkjLy8vs0/79u2VnJysQ4cO3d8LKQDHjx9XXFyc1Ri5urqqSZMmVmPk5uamRo0amX1CQkJkY2Ojffv2mX0ee+wx2dvbm33at2+v2NhY/fHHH/fpau6vHTt2yNPTU4GBgRo0aJDOnz9vbivuY5aUlCRJKlu2rKT8+12Mjo62OkZWn6Lw99/NY5Zl2bJlcnd3V+3atTVu3DhduXLF3Facxyw9PV2ffPKJLl++rKCgIH7GbsPNY5aFnzEAxY1dQReQnxISEpSenm71F7UkeXl56eeffy6gqgpWkyZNFBkZqcDAQJ05c0aTJk1SixYtdPDgQcXFxcne3l5ubm5W+3h5eSkuLk6SFBcXl+N4Zm0r6rKuMacxuHGMPD09rbbb2dmpbNmyVn38/f2zHSNrW5kyZe5J/QWlQ4cOeuqpp+Tv769jx47plVdeUWhoqKKjo2Vra1usxywjI0PDhw9Xs2bNVLt2bUnKt9/F3PokJyfr6tWrcnJyuheXdM/lNGaS1LNnT1WsWFE+Pj46cOCAxowZo9jYWK1cuVJS8RyzH3/8UUFBQUpJSVGpUqW0atUq1axZUzExMfyM5SK3MZP4GQNQPBWpgIjsQkNDzT/XrVtXTZo0UcWKFfXpp5/y/5Rwz3Tv3t38c506dVS3bl0FBARox44datOmTQFWVvAGDx6sgwcPavfu3QVdygMjtzHr37+/+ec6deqofPnyatOmjY4dO6aAgID7XWahEBgYqJiYGCUlJemzzz5TWFiYdu7cWdBlFWq5jVnNmjX5GQNQLBWpW0zd3d1la2ubbVW2s2fPytvbu4CqKlzc3NxUrVo1HT16VN7e3rp+/boSExOt+tw4Xt7e3jmOZ9a2oi7rGm/1M+Xt7a34+Hir7Wlpabpw4QLjmKly5cpyd3fX0aNHJRXfMRsyZIi++OILbd++XRUqVDDb8+t3Mbc+Li4uD+x/EMptzHLSpEkTSbL6OStuY2Zvb68qVaqoYcOGioiIUL169TR37lx+xm4htzHLCT9jAIqDIhUQ7e3t1bBhQ23dutVsy8jI0NatW62eJyjOLl26pGPHjql8+fJq2LChSpQoYTVesbGxOnXqlDleQUFB+vHHH63+MR8VFSUXFxfzFpyizN/fX97e3lZjlJycrH379lmNUWJior777juzz7Zt25SRkWH+YyIoKEi7du1Samqq2ScqKkqBgYEP7K2SefHbb7/p/PnzKl++vKTiN2aGYWjIkCFatWqVtm3blu3W2fz6XQwKCrI6RlafB/Hvv78as5zExMRIktXPWXEas5xkZGTo2rVr/IzlQdaY5YSfMQDFQkGvkpPfPvnkE8PBwcGIjIw0fvrpJ6N///6Gm5ub1QpjxcnIkSONHTt2GMePHzf27NljhISEGO7u7kZ8fLxhGH8ue+7n52ds27bN+Pbbb42goCAjKCjI3D9rCe927doZMTExxsaNGw0PD48i9ZqLixcvGvv37zf2799vSDJmzZpl7N+/3zh58qRhGH++5sLNzc34/PPPjQMHDhhPPPFEjq+5aNCggbFv3z5j9+7dRtWqVa1e2ZCYmGh4eXkZzz33nHHw4EHjk08+MZydnR/IVzYYxq3H7OLFi8bLL79sREdHG8ePHze2bNliPPzww0bVqlWNlJQU8xjFacwGDRpkuLq6Gjt27LBaLv/KlStmn/z4XcxaTn/UqFHG4cOHjfnz5z+wy+n/1ZgdPXrUmDx5svHtt98ax48fNz7//HOjcuXKxmOPPWYeo7iN2dixY42dO3cax48fNw4cOGCMHTvWsFgsxubNmw3D4GcsJ7caM37GABRXRS4gGoZhzJs3z/Dz8zPs7e2Nxo0bG3v37i3okgrM3//+d6N8+fKGvb298dBDDxl///vfjaNHj5rbr169arzwwgtGmTJlDGdnZ+PJJ580zpw5Y3WMEydOGKGhoYaTk5Ph7u5ujBw50khNTb3fl3LPbN++3ZCU7RMWFmYYxp+vunj99dcNLy8vw8HBwWjTpo0RGxtrdYzz588bPXr0MEqVKmW4uLgYvXv3Ni5evGjV54cffjCaN29uODg4GA899JAxderU+3WJ+e5WY3blyhWjXbt2hoeHh1GiRAmjYsWKRr9+/bL9R5riNGY5jZUkY8mSJWaf/Ppd3L59u1G/fn3D3t7eqFy5stU5HiR/NWanTp0yHnvsMaNs2bKGg4ODUaVKFWPUqFFW76gzjOI1Zv/4xz+MihUrGvb29oaHh4fRpk0bMxwaBj9jObnVmPEzBqC4shiGYdy/+UoAAAAAQGFVpJ5BBAAAAADcOQIiAAAAAEASAREAAAAAkImACAAAAACQREAEAAAAAGQiIAIAAAAAJBEQAQAAAACZCIgAAAAAAEkERAAAAABAJgIiAAAAAEASAREAAAAAkImACAAAAACQJP0/8oKJmaIHfpsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = Image.open('/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/annotations/training/10166_lab.png')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(8)]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c5ece21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:29.044538Z",
     "iopub.status.busy": "2024-03-09T10:16:29.043498Z",
     "iopub.status.idle": "2024-03-09T10:16:29.050277Z",
     "shell.execute_reply": "2024-03-09T10:16:29.049243Z"
    },
    "papermill": {
     "duration": 0.091705,
     "end_time": "2024-03-09T10:16:29.053156",
     "exception": false,
     "start_time": "2024-03-09T10:16:28.961451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Background',\n",
       " 'BuildingFlooded',\n",
       " 'BNonFlooded',\n",
       " 'RoadFlooded',\n",
       " 'RNonFlooded',\n",
       " 'Water',\n",
       " 'Tree',\n",
       " 'Vecile',\n",
       " 'Pool',\n",
       " 'Grass']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "121c74fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:29.224483Z",
     "iopub.status.busy": "2024-03-09T10:16:29.223616Z",
     "iopub.status.idle": "2024-03-09T10:16:29.230429Z",
     "shell.execute_reply": "2024-03-09T10:16:29.229579Z"
    },
    "papermill": {
     "duration": 0.086573,
     "end_time": "2024-03-09T10:16:29.232301",
     "exception": false,
     "start_time": "2024-03-09T10:16:29.145728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0]),\n",
       " array([255,   0,   0]),\n",
       " array([181,  72,  72]),\n",
       " array([150, 150,   0]),\n",
       " array([135, 135, 135]),\n",
       " array([  0, 224, 224]),\n",
       " array([  0,   0, 225]),\n",
       " array([204,   0, 204]),\n",
       " array([237, 237,   0]),\n",
       " array([  0, 225,   0])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8e0c445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:29.388593Z",
     "iopub.status.busy": "2024-03-09T10:16:29.387713Z",
     "iopub.status.idle": "2024-03-09T10:16:42.577998Z",
     "shell.execute_reply": "2024-03-09T10:16:42.576857Z"
    },
    "papermill": {
     "duration": 13.270292,
     "end_time": "2024-03-09T10:16:42.580562",
     "exception": false,
     "start_time": "2024-03-09T10:16:29.310270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\r\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.13)\r\n",
      "Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ftfy\r\n",
      "Successfully installed ftfy-6.1.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8992fa2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:42.734652Z",
     "iopub.status.busy": "2024-03-09T10:16:42.734252Z",
     "iopub.status.idle": "2024-03-09T10:16:46.279168Z",
     "shell.execute_reply": "2024-03-09T10:16:46.278385Z"
    },
    "papermill": {
     "duration": 3.62537,
     "end_time": "2024-03-09T10:16:46.281478",
     "exception": false,
     "start_time": "2024-03-09T10:16:42.656108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmseg.registry import DATASETS\n",
    "from mmseg.datasets import BaseSegDataset\n",
    "\n",
    "## should be run only once\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ImageSegmentationDataset(BaseSegDataset):\n",
    "    METAINFO = dict(classes = classes, palette = palette)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(img_suffix='.jpg', seg_map_suffix=\"_lab.png\", **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ed5e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:46.438128Z",
     "iopub.status.busy": "2024-03-09T10:16:46.437081Z",
     "iopub.status.idle": "2024-03-09T10:16:46.444156Z",
     "shell.execute_reply": "2024-03-09T10:16:46.442917Z"
    },
    "papermill": {
     "duration": 0.088596,
     "end_time": "2024-03-09T10:16:46.446149",
     "exception": false,
     "start_time": "2024-03-09T10:16:46.357553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16ad383d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:46.601877Z",
     "iopub.status.busy": "2024-03-09T10:16:46.601009Z",
     "iopub.status.idle": "2024-03-09T10:16:48.538908Z",
     "shell.execute_reply": "2024-03-09T10:16:48.537493Z"
    },
    "papermill": {
     "duration": 2.018672,
     "end_time": "2024-03-09T10:16:48.541642",
     "exception": false,
     "start_time": "2024-03-09T10:16:46.522970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'checkpoint': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r checkpoint\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a67162",
   "metadata": {
    "papermill": {
     "duration": 0.076448,
     "end_time": "2024-03-09T10:16:48.694274",
     "exception": false,
     "start_time": "2024-03-09T10:16:48.617826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec007fa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:48.852143Z",
     "iopub.status.busy": "2024-03-09T10:16:48.851756Z",
     "iopub.status.idle": "2024-03-09T10:16:49.497766Z",
     "shell.execute_reply": "2024-03-09T10:16:49.496846Z"
    },
    "papermill": {
     "duration": 0.728414,
     "end_time": "2024-03-09T10:16:49.500548",
     "exception": false,
     "start_time": "2024-03-09T10:16:48.772134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/ade/ADEChallengeData2016'\n",
      "dataset_type = 'ADE20KDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=150,\n",
      "        type='SegformerHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from mmengine import Config\n",
    "cfg = Config.fromfile('/kaggle/working/mmsegmentation/configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-512x512.py')\n",
    "#cfg = Config.fromfile('/kaggle/working/mmsegmentation/configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-640x640.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7598625e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:49.659664Z",
     "iopub.status.busy": "2024-03-09T10:16:49.658801Z",
     "iopub.status.idle": "2024-03-09T10:16:49.665267Z",
     "shell.execute_reply": "2024-03-09T10:16:49.664420Z"
    },
    "papermill": {
     "duration": 0.087026,
     "end_time": "2024-03-09T10:16:49.667134",
     "exception": false,
     "start_time": "2024-03-09T10:16:49.580108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.decode_head.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d154d527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:49.822472Z",
     "iopub.status.busy": "2024-03-09T10:16:49.822088Z",
     "iopub.status.idle": "2024-03-09T10:16:49.826854Z",
     "shell.execute_reply": "2024-03-09T10:16:49.826017Z"
    },
    "papermill": {
     "duration": 0.085428,
     "end_time": "2024-03-09T10:16:49.829034",
     "exception": false,
     "start_time": "2024-03-09T10:16:49.743606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.model.pretrained None\n"
     ]
    }
   ],
   "source": [
    "#cfg.model.pretrained = True\n",
    "print(\"cfg.model.pretrained\", cfg.model.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fba96b2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:49.983803Z",
     "iopub.status.busy": "2024-03-09T10:16:49.983401Z",
     "iopub.status.idle": "2024-03-09T10:16:49.999465Z",
     "shell.execute_reply": "2024-03-09T10:16:49.998661Z"
    },
    "papermill": {
     "duration": 0.095867,
     "end_time": "2024-03-09T10:16:50.001396",
     "exception": false,
     "start_time": "2024-03-09T10:16:49.905529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 10\n",
    "#cfg.model.auxiliary_head.num_classes = 10\n",
    "\n",
    "\n",
    "#cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_640x640_160k_ade20k/segformer_mit-b5_640x640_160k_ade20k_20210801_121243-41d2845b.pth'\n",
    "#cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth'\n",
    "cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'\n",
    "\n",
    "cfg.val_evaluator = dict(type='IoUMetric',\n",
    "                         iou_metrics=['mIoU', 'mDice', 'mFscore'],\n",
    "#                          format_only=True,\n",
    "#                          output_dir='/kaggle/working/results'\n",
    "                        )\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# # Modify dataset type and path\n",
    "cfg.dataset_type = 'ImageSegmentationDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "\n",
    "cfg.train_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.val_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.test_dataloader.dataset.type=cfg.dataset_type\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(\n",
    "        type='RandomResize',\n",
    "        scale=(\n",
    "            512,\n",
    "            512,\n",
    "        ),\n",
    "        ratio_range=(\n",
    "            0.5,\n",
    "            2.0,\n",
    "        ),\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomCrop', crop_size=(\n",
    "        512,\n",
    "        512,\n",
    "    ), cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='PackSegInputs'),\n",
    "]\n",
    "\n",
    "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
    "\n",
    "cfg.test_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "cfg.train_dataloader.dataset.data_root =data_root \n",
    "cfg.val_dataloader.dataset.data_root =data_root \n",
    "cfg.test_dataloader.dataset.data_root=data_root\n",
    "\n",
    "cfg.train_dataloader.num_workers=1\n",
    "cfg.train_dataloader.batch_size = 2\n",
    "cfg.train_dataloader.persistent_workers=False\n",
    "\n",
    "\n",
    "cfg.val_dataloader.batch_size = 1\n",
    "cfg.val_dataloader.num_workers=1\n",
    "cfg.val_dataloader.persistent_workers=False\n",
    "\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.test_dataloader.num_workers=1\n",
    "cfg.test_dataloader.persistent_workers=False\n",
    "\n",
    "#cfg.work_dir = './checkpoint'\n",
    "cfg.work_dir = '/kaggle/working/checkpoint'\n",
    "\n",
    "cfg.train_cfg.max_iters = 40000\n",
    "cfg.train_cfg.val_interval = 50000\n",
    "cfg.default_hooks.logger.interval =100\n",
    "cfg.default_hooks.checkpoint.interval = 10000\n",
    "cfg.default_hooks.checkpoint.save_best='mIoU'\n",
    "\n",
    "# Set seed to facilitate reproducing the result\n",
    "cfg['randomness'] = dict(seed=0)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "#print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13132bf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:50.160961Z",
     "iopub.status.busy": "2024-03-09T10:16:50.160582Z",
     "iopub.status.idle": "2024-03-09T10:16:50.168994Z",
     "shell.execute_reply": "2024-03-09T10:16:50.168142Z"
    },
    "papermill": {
     "duration": 0.091198,
     "end_time": "2024-03-09T10:16:50.171265",
     "exception": false,
     "start_time": "2024-03-09T10:16:50.080067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'EncoderDecoder',\n",
       " 'data_preprocessor': {'type': 'SegDataPreProcessor',\n",
       "  'mean': [123.675, 116.28, 103.53],\n",
       "  'std': [58.395, 57.12, 57.375],\n",
       "  'bgr_to_rgb': True,\n",
       "  'pad_val': 0,\n",
       "  'seg_pad_val': 255,\n",
       "  'size': (512, 512)},\n",
       " 'pretrained': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth',\n",
       " 'backbone': {'type': 'MixVisionTransformer',\n",
       "  'in_channels': 3,\n",
       "  'embed_dims': 64,\n",
       "  'num_stages': 4,\n",
       "  'num_layers': [3, 6, 40, 3],\n",
       "  'num_heads': [1, 2, 5, 8],\n",
       "  'patch_sizes': [7, 3, 3, 3],\n",
       "  'sr_ratios': [8, 4, 2, 1],\n",
       "  'out_indices': (0, 1, 2, 3),\n",
       "  'mlp_ratio': 4,\n",
       "  'qkv_bias': True,\n",
       "  'drop_rate': 0.0,\n",
       "  'attn_drop_rate': 0.0,\n",
       "  'drop_path_rate': 0.1,\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}},\n",
       " 'decode_head': {'type': 'SegformerHead',\n",
       "  'in_channels': [64, 128, 320, 512],\n",
       "  'in_index': [0, 1, 2, 3],\n",
       "  'channels': 256,\n",
       "  'dropout_ratio': 0.1,\n",
       "  'num_classes': 10,\n",
       "  'norm_cfg': {'type': 'SyncBN', 'requires_grad': True},\n",
       "  'align_corners': False,\n",
       "  'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "   'use_sigmoid': False,\n",
       "   'loss_weight': 1.0}},\n",
       " 'train_cfg': {},\n",
       " 'test_cfg': {'mode': 'whole'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bb220f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:50.331028Z",
     "iopub.status.busy": "2024-03-09T10:16:50.330080Z",
     "iopub.status.idle": "2024-03-09T10:16:50.336794Z",
     "shell.execute_reply": "2024-03-09T10:16:50.335875Z"
    },
    "papermill": {
     "duration": 0.08892,
     "end_time": "2024-03-09T10:16:50.338693",
     "exception": false,
     "start_time": "2024-03-09T10:16:50.249773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adding Vit decoder\n",
    "\n",
    "cfg.model.decode_head=dict(\n",
    "    type='UPerHead',\n",
    "    in_channels=[64, 128, 320, 512],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=256,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=10,\n",
    "    norm_cfg=cfg.norm_cfg,\n",
    "    align_corners=False,\n",
    "    loss_decode=dict(\n",
    "        type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "    init_cfg=dict(\n",
    "        type='Pretrained',\n",
    "        checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth'\n",
    "    ))\n",
    "cfg.model.auxiliary_head=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef362b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:50.497040Z",
     "iopub.status.busy": "2024-03-09T10:16:50.496401Z",
     "iopub.status.idle": "2024-03-09T10:16:50.501128Z",
     "shell.execute_reply": "2024-03-09T10:16:50.500280Z"
    },
    "papermill": {
     "duration": 0.086135,
     "end_time": "2024-03-09T10:16:50.503481",
     "exception": false,
     "start_time": "2024-03-09T10:16:50.417346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    }
   ],
   "source": [
    "print(cfg.model.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e808014c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:50.658396Z",
     "iopub.status.busy": "2024-03-09T10:16:50.658037Z",
     "iopub.status.idle": "2024-03-09T10:16:51.968623Z",
     "shell.execute_reply": "2024-03-09T10:16:51.967498Z"
    },
    "papermill": {
     "duration": 1.390746,
     "end_time": "2024-03-09T10:16:51.971253",
     "exception": false,
     "start_time": "2024-03-09T10:16:50.580507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.dump('/kaggle/working/my_config_file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3835fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:52.138628Z",
     "iopub.status.busy": "2024-03-09T10:16:52.137942Z",
     "iopub.status.idle": "2024-03-09T10:16:52.147095Z",
     "shell.execute_reply": "2024-03-09T10:16:52.146262Z"
    },
    "papermill": {
     "duration": 0.093319,
     "end_time": "2024-03-09T10:16:52.148926",
     "exception": false,
     "start_time": "2024-03-09T10:16:52.055607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'EncoderDecoder',\n",
       " 'data_preprocessor': {'type': 'SegDataPreProcessor',\n",
       "  'mean': [123.675, 116.28, 103.53],\n",
       "  'std': [58.395, 57.12, 57.375],\n",
       "  'bgr_to_rgb': True,\n",
       "  'pad_val': 0,\n",
       "  'seg_pad_val': 255,\n",
       "  'size': (512, 512)},\n",
       " 'pretrained': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth',\n",
       " 'backbone': {'type': 'MixVisionTransformer',\n",
       "  'in_channels': 3,\n",
       "  'embed_dims': 64,\n",
       "  'num_stages': 4,\n",
       "  'num_layers': [3, 6, 40, 3],\n",
       "  'num_heads': [1, 2, 5, 8],\n",
       "  'patch_sizes': [7, 3, 3, 3],\n",
       "  'sr_ratios': [8, 4, 2, 1],\n",
       "  'out_indices': (0, 1, 2, 3),\n",
       "  'mlp_ratio': 4,\n",
       "  'qkv_bias': True,\n",
       "  'drop_rate': 0.0,\n",
       "  'attn_drop_rate': 0.0,\n",
       "  'drop_path_rate': 0.1,\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}},\n",
       " 'decode_head': {'type': 'UPerHead',\n",
       "  'in_channels': [64, 128, 320, 512],\n",
       "  'in_index': [0, 1, 2, 3],\n",
       "  'channels': 256,\n",
       "  'dropout_ratio': 0.1,\n",
       "  'num_classes': 10,\n",
       "  'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       "  'align_corners': False,\n",
       "  'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "   'use_sigmoid': False,\n",
       "   'loss_weight': 1.0},\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth'}},\n",
       " 'train_cfg': {},\n",
       " 'test_cfg': {'mode': 'whole'},\n",
       " 'auxiliary_head': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5955319c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:52.314515Z",
     "iopub.status.busy": "2024-03-09T10:16:52.314084Z",
     "iopub.status.idle": "2024-03-09T10:16:52.320651Z",
     "shell.execute_reply": "2024-03-09T10:16:52.319728Z"
    },
    "papermill": {
     "duration": 0.092315,
     "end_time": "2024-03-09T10:16:52.322743",
     "exception": false,
     "start_time": "2024-03-09T10:16:52.230428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Pretrained',\n",
       " 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model['backbone'].pop('init_cfg', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75d3b5bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:16:52.489541Z",
     "iopub.status.busy": "2024-03-09T10:16:52.489094Z",
     "iopub.status.idle": "2024-03-09T10:17:01.870397Z",
     "shell.execute_reply": "2024-03-09T10:17:01.869572Z"
    },
    "papermill": {
     "duration": 9.467583,
     "end_time": "2024-03-09T10:17:01.872716",
     "exception": false,
     "start_time": "2024-03-09T10:16:52.405133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 10:16:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0: Tesla P100-PCIE-16GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.0+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.0+cu102\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/09 10:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
      "dataset_type = 'ImageSegmentationDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=10000,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=None,\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth',\n",
      "            type='Pretrained'),\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=10,\n",
      "        type='UPerHead'),\n",
      "    pretrained=\n",
      "    'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=40000, type='IterBasedTrainLoop', val_interval=50000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root=\n",
      "        '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/kaggle/working/checkpoint'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/backbones/mit.py:365: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 10:17:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/09 10:17:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a1a5a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T10:17:02.032676Z",
     "iopub.status.busy": "2024-03-09T10:17:02.032291Z",
     "iopub.status.idle": "2024-03-09T19:00:21.030978Z",
     "shell.execute_reply": "2024-03-09T19:00:21.029906Z"
    },
    "papermill": {
     "duration": 31399.082941,
     "end_time": "2024-03-09T19:00:21.035295",
     "exception": false,
     "start_time": "2024-03-09T10:17:01.952354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/datasets/transforms/loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:lr=6e-05\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:weight_decay=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:decay_mult=0.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.0.1.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.1.1.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.2.1.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.psp_modules.3.1.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.bottleneck.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.0.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.1.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.lateral_convs.2.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.0.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.1.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_convs.2.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.conv.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.conv.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.conv.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.weight:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.weight:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.weight:lr_mult=10.0\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.bias:lr=0.0006000000000000001\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.bias:weight_decay=0.01\n",
      "03/09 10:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fpn_bottleneck.bn.bias:lr_mult=10.0\n",
      "03/09 10:17:07 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "03/09 10:17:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n",
      "03/09 10:17:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\" to /root/.cache/torch/hub/checkpoints/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 10:17:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.layers.0.0.projection.weight, backbone.layers.0.0.projection.bias, backbone.layers.0.0.norm.weight, backbone.layers.0.0.norm.bias, backbone.layers.0.1.0.norm1.weight, backbone.layers.0.1.0.norm1.bias, backbone.layers.0.1.0.attn.attn.in_proj_weight, backbone.layers.0.1.0.attn.attn.in_proj_bias, backbone.layers.0.1.0.attn.attn.out_proj.weight, backbone.layers.0.1.0.attn.attn.out_proj.bias, backbone.layers.0.1.0.attn.sr.weight, backbone.layers.0.1.0.attn.sr.bias, backbone.layers.0.1.0.attn.norm.weight, backbone.layers.0.1.0.attn.norm.bias, backbone.layers.0.1.0.norm2.weight, backbone.layers.0.1.0.norm2.bias, backbone.layers.0.1.0.ffn.layers.0.weight, backbone.layers.0.1.0.ffn.layers.0.bias, backbone.layers.0.1.0.ffn.layers.1.weight, backbone.layers.0.1.0.ffn.layers.1.bias, backbone.layers.0.1.0.ffn.layers.4.weight, backbone.layers.0.1.0.ffn.layers.4.bias, backbone.layers.0.1.1.norm1.weight, backbone.layers.0.1.1.norm1.bias, backbone.layers.0.1.1.attn.attn.in_proj_weight, backbone.layers.0.1.1.attn.attn.in_proj_bias, backbone.layers.0.1.1.attn.attn.out_proj.weight, backbone.layers.0.1.1.attn.attn.out_proj.bias, backbone.layers.0.1.1.attn.sr.weight, backbone.layers.0.1.1.attn.sr.bias, backbone.layers.0.1.1.attn.norm.weight, backbone.layers.0.1.1.attn.norm.bias, backbone.layers.0.1.1.norm2.weight, backbone.layers.0.1.1.norm2.bias, backbone.layers.0.1.1.ffn.layers.0.weight, backbone.layers.0.1.1.ffn.layers.0.bias, backbone.layers.0.1.1.ffn.layers.1.weight, backbone.layers.0.1.1.ffn.layers.1.bias, backbone.layers.0.1.1.ffn.layers.4.weight, backbone.layers.0.1.1.ffn.layers.4.bias, backbone.layers.0.1.2.norm1.weight, backbone.layers.0.1.2.norm1.bias, backbone.layers.0.1.2.attn.attn.in_proj_weight, backbone.layers.0.1.2.attn.attn.in_proj_bias, backbone.layers.0.1.2.attn.attn.out_proj.weight, backbone.layers.0.1.2.attn.attn.out_proj.bias, backbone.layers.0.1.2.attn.sr.weight, backbone.layers.0.1.2.attn.sr.bias, backbone.layers.0.1.2.attn.norm.weight, backbone.layers.0.1.2.attn.norm.bias, backbone.layers.0.1.2.norm2.weight, backbone.layers.0.1.2.norm2.bias, backbone.layers.0.1.2.ffn.layers.0.weight, backbone.layers.0.1.2.ffn.layers.0.bias, backbone.layers.0.1.2.ffn.layers.1.weight, backbone.layers.0.1.2.ffn.layers.1.bias, backbone.layers.0.1.2.ffn.layers.4.weight, backbone.layers.0.1.2.ffn.layers.4.bias, backbone.layers.0.2.weight, backbone.layers.0.2.bias, backbone.layers.1.0.projection.weight, backbone.layers.1.0.projection.bias, backbone.layers.1.0.norm.weight, backbone.layers.1.0.norm.bias, backbone.layers.1.1.0.norm1.weight, backbone.layers.1.1.0.norm1.bias, backbone.layers.1.1.0.attn.attn.in_proj_weight, backbone.layers.1.1.0.attn.attn.in_proj_bias, backbone.layers.1.1.0.attn.attn.out_proj.weight, backbone.layers.1.1.0.attn.attn.out_proj.bias, backbone.layers.1.1.0.attn.sr.weight, backbone.layers.1.1.0.attn.sr.bias, backbone.layers.1.1.0.attn.norm.weight, backbone.layers.1.1.0.attn.norm.bias, backbone.layers.1.1.0.norm2.weight, backbone.layers.1.1.0.norm2.bias, backbone.layers.1.1.0.ffn.layers.0.weight, backbone.layers.1.1.0.ffn.layers.0.bias, backbone.layers.1.1.0.ffn.layers.1.weight, backbone.layers.1.1.0.ffn.layers.1.bias, backbone.layers.1.1.0.ffn.layers.4.weight, backbone.layers.1.1.0.ffn.layers.4.bias, backbone.layers.1.1.1.norm1.weight, backbone.layers.1.1.1.norm1.bias, backbone.layers.1.1.1.attn.attn.in_proj_weight, backbone.layers.1.1.1.attn.attn.in_proj_bias, backbone.layers.1.1.1.attn.attn.out_proj.weight, backbone.layers.1.1.1.attn.attn.out_proj.bias, backbone.layers.1.1.1.attn.sr.weight, backbone.layers.1.1.1.attn.sr.bias, backbone.layers.1.1.1.attn.norm.weight, backbone.layers.1.1.1.attn.norm.bias, backbone.layers.1.1.1.norm2.weight, backbone.layers.1.1.1.norm2.bias, backbone.layers.1.1.1.ffn.layers.0.weight, backbone.layers.1.1.1.ffn.layers.0.bias, backbone.layers.1.1.1.ffn.layers.1.weight, backbone.layers.1.1.1.ffn.layers.1.bias, backbone.layers.1.1.1.ffn.layers.4.weight, backbone.layers.1.1.1.ffn.layers.4.bias, backbone.layers.1.1.2.norm1.weight, backbone.layers.1.1.2.norm1.bias, backbone.layers.1.1.2.attn.attn.in_proj_weight, backbone.layers.1.1.2.attn.attn.in_proj_bias, backbone.layers.1.1.2.attn.attn.out_proj.weight, backbone.layers.1.1.2.attn.attn.out_proj.bias, backbone.layers.1.1.2.attn.sr.weight, backbone.layers.1.1.2.attn.sr.bias, backbone.layers.1.1.2.attn.norm.weight, backbone.layers.1.1.2.attn.norm.bias, backbone.layers.1.1.2.norm2.weight, backbone.layers.1.1.2.norm2.bias, backbone.layers.1.1.2.ffn.layers.0.weight, backbone.layers.1.1.2.ffn.layers.0.bias, backbone.layers.1.1.2.ffn.layers.1.weight, backbone.layers.1.1.2.ffn.layers.1.bias, backbone.layers.1.1.2.ffn.layers.4.weight, backbone.layers.1.1.2.ffn.layers.4.bias, backbone.layers.1.1.3.norm1.weight, backbone.layers.1.1.3.norm1.bias, backbone.layers.1.1.3.attn.attn.in_proj_weight, backbone.layers.1.1.3.attn.attn.in_proj_bias, backbone.layers.1.1.3.attn.attn.out_proj.weight, backbone.layers.1.1.3.attn.attn.out_proj.bias, backbone.layers.1.1.3.attn.sr.weight, backbone.layers.1.1.3.attn.sr.bias, backbone.layers.1.1.3.attn.norm.weight, backbone.layers.1.1.3.attn.norm.bias, backbone.layers.1.1.3.norm2.weight, backbone.layers.1.1.3.norm2.bias, backbone.layers.1.1.3.ffn.layers.0.weight, backbone.layers.1.1.3.ffn.layers.0.bias, backbone.layers.1.1.3.ffn.layers.1.weight, backbone.layers.1.1.3.ffn.layers.1.bias, backbone.layers.1.1.3.ffn.layers.4.weight, backbone.layers.1.1.3.ffn.layers.4.bias, backbone.layers.1.1.4.norm1.weight, backbone.layers.1.1.4.norm1.bias, backbone.layers.1.1.4.attn.attn.in_proj_weight, backbone.layers.1.1.4.attn.attn.in_proj_bias, backbone.layers.1.1.4.attn.attn.out_proj.weight, backbone.layers.1.1.4.attn.attn.out_proj.bias, backbone.layers.1.1.4.attn.sr.weight, backbone.layers.1.1.4.attn.sr.bias, backbone.layers.1.1.4.attn.norm.weight, backbone.layers.1.1.4.attn.norm.bias, backbone.layers.1.1.4.norm2.weight, backbone.layers.1.1.4.norm2.bias, backbone.layers.1.1.4.ffn.layers.0.weight, backbone.layers.1.1.4.ffn.layers.0.bias, backbone.layers.1.1.4.ffn.layers.1.weight, backbone.layers.1.1.4.ffn.layers.1.bias, backbone.layers.1.1.4.ffn.layers.4.weight, backbone.layers.1.1.4.ffn.layers.4.bias, backbone.layers.1.1.5.norm1.weight, backbone.layers.1.1.5.norm1.bias, backbone.layers.1.1.5.attn.attn.in_proj_weight, backbone.layers.1.1.5.attn.attn.in_proj_bias, backbone.layers.1.1.5.attn.attn.out_proj.weight, backbone.layers.1.1.5.attn.attn.out_proj.bias, backbone.layers.1.1.5.attn.sr.weight, backbone.layers.1.1.5.attn.sr.bias, backbone.layers.1.1.5.attn.norm.weight, backbone.layers.1.1.5.attn.norm.bias, backbone.layers.1.1.5.norm2.weight, backbone.layers.1.1.5.norm2.bias, backbone.layers.1.1.5.ffn.layers.0.weight, backbone.layers.1.1.5.ffn.layers.0.bias, backbone.layers.1.1.5.ffn.layers.1.weight, backbone.layers.1.1.5.ffn.layers.1.bias, backbone.layers.1.1.5.ffn.layers.4.weight, backbone.layers.1.1.5.ffn.layers.4.bias, backbone.layers.1.2.weight, backbone.layers.1.2.bias, backbone.layers.2.0.projection.weight, backbone.layers.2.0.projection.bias, backbone.layers.2.0.norm.weight, backbone.layers.2.0.norm.bias, backbone.layers.2.1.0.norm1.weight, backbone.layers.2.1.0.norm1.bias, backbone.layers.2.1.0.attn.attn.in_proj_weight, backbone.layers.2.1.0.attn.attn.in_proj_bias, backbone.layers.2.1.0.attn.attn.out_proj.weight, backbone.layers.2.1.0.attn.attn.out_proj.bias, backbone.layers.2.1.0.attn.sr.weight, backbone.layers.2.1.0.attn.sr.bias, backbone.layers.2.1.0.attn.norm.weight, backbone.layers.2.1.0.attn.norm.bias, backbone.layers.2.1.0.norm2.weight, backbone.layers.2.1.0.norm2.bias, backbone.layers.2.1.0.ffn.layers.0.weight, backbone.layers.2.1.0.ffn.layers.0.bias, backbone.layers.2.1.0.ffn.layers.1.weight, backbone.layers.2.1.0.ffn.layers.1.bias, backbone.layers.2.1.0.ffn.layers.4.weight, backbone.layers.2.1.0.ffn.layers.4.bias, backbone.layers.2.1.1.norm1.weight, backbone.layers.2.1.1.norm1.bias, backbone.layers.2.1.1.attn.attn.in_proj_weight, backbone.layers.2.1.1.attn.attn.in_proj_bias, backbone.layers.2.1.1.attn.attn.out_proj.weight, backbone.layers.2.1.1.attn.attn.out_proj.bias, backbone.layers.2.1.1.attn.sr.weight, backbone.layers.2.1.1.attn.sr.bias, backbone.layers.2.1.1.attn.norm.weight, backbone.layers.2.1.1.attn.norm.bias, backbone.layers.2.1.1.norm2.weight, backbone.layers.2.1.1.norm2.bias, backbone.layers.2.1.1.ffn.layers.0.weight, backbone.layers.2.1.1.ffn.layers.0.bias, backbone.layers.2.1.1.ffn.layers.1.weight, backbone.layers.2.1.1.ffn.layers.1.bias, backbone.layers.2.1.1.ffn.layers.4.weight, backbone.layers.2.1.1.ffn.layers.4.bias, backbone.layers.2.1.2.norm1.weight, backbone.layers.2.1.2.norm1.bias, backbone.layers.2.1.2.attn.attn.in_proj_weight, backbone.layers.2.1.2.attn.attn.in_proj_bias, backbone.layers.2.1.2.attn.attn.out_proj.weight, backbone.layers.2.1.2.attn.attn.out_proj.bias, backbone.layers.2.1.2.attn.sr.weight, backbone.layers.2.1.2.attn.sr.bias, backbone.layers.2.1.2.attn.norm.weight, backbone.layers.2.1.2.attn.norm.bias, backbone.layers.2.1.2.norm2.weight, backbone.layers.2.1.2.norm2.bias, backbone.layers.2.1.2.ffn.layers.0.weight, backbone.layers.2.1.2.ffn.layers.0.bias, backbone.layers.2.1.2.ffn.layers.1.weight, backbone.layers.2.1.2.ffn.layers.1.bias, backbone.layers.2.1.2.ffn.layers.4.weight, backbone.layers.2.1.2.ffn.layers.4.bias, backbone.layers.2.1.3.norm1.weight, backbone.layers.2.1.3.norm1.bias, backbone.layers.2.1.3.attn.attn.in_proj_weight, backbone.layers.2.1.3.attn.attn.in_proj_bias, backbone.layers.2.1.3.attn.attn.out_proj.weight, backbone.layers.2.1.3.attn.attn.out_proj.bias, backbone.layers.2.1.3.attn.sr.weight, backbone.layers.2.1.3.attn.sr.bias, backbone.layers.2.1.3.attn.norm.weight, backbone.layers.2.1.3.attn.norm.bias, backbone.layers.2.1.3.norm2.weight, backbone.layers.2.1.3.norm2.bias, backbone.layers.2.1.3.ffn.layers.0.weight, backbone.layers.2.1.3.ffn.layers.0.bias, backbone.layers.2.1.3.ffn.layers.1.weight, backbone.layers.2.1.3.ffn.layers.1.bias, backbone.layers.2.1.3.ffn.layers.4.weight, backbone.layers.2.1.3.ffn.layers.4.bias, backbone.layers.2.1.4.norm1.weight, backbone.layers.2.1.4.norm1.bias, backbone.layers.2.1.4.attn.attn.in_proj_weight, backbone.layers.2.1.4.attn.attn.in_proj_bias, backbone.layers.2.1.4.attn.attn.out_proj.weight, backbone.layers.2.1.4.attn.attn.out_proj.bias, backbone.layers.2.1.4.attn.sr.weight, backbone.layers.2.1.4.attn.sr.bias, backbone.layers.2.1.4.attn.norm.weight, backbone.layers.2.1.4.attn.norm.bias, backbone.layers.2.1.4.norm2.weight, backbone.layers.2.1.4.norm2.bias, backbone.layers.2.1.4.ffn.layers.0.weight, backbone.layers.2.1.4.ffn.layers.0.bias, backbone.layers.2.1.4.ffn.layers.1.weight, backbone.layers.2.1.4.ffn.layers.1.bias, backbone.layers.2.1.4.ffn.layers.4.weight, backbone.layers.2.1.4.ffn.layers.4.bias, backbone.layers.2.1.5.norm1.weight, backbone.layers.2.1.5.norm1.bias, backbone.layers.2.1.5.attn.attn.in_proj_weight, backbone.layers.2.1.5.attn.attn.in_proj_bias, backbone.layers.2.1.5.attn.attn.out_proj.weight, backbone.layers.2.1.5.attn.attn.out_proj.bias, backbone.layers.2.1.5.attn.sr.weight, backbone.layers.2.1.5.attn.sr.bias, backbone.layers.2.1.5.attn.norm.weight, backbone.layers.2.1.5.attn.norm.bias, backbone.layers.2.1.5.norm2.weight, backbone.layers.2.1.5.norm2.bias, backbone.layers.2.1.5.ffn.layers.0.weight, backbone.layers.2.1.5.ffn.layers.0.bias, backbone.layers.2.1.5.ffn.layers.1.weight, backbone.layers.2.1.5.ffn.layers.1.bias, backbone.layers.2.1.5.ffn.layers.4.weight, backbone.layers.2.1.5.ffn.layers.4.bias, backbone.layers.2.1.6.norm1.weight, backbone.layers.2.1.6.norm1.bias, backbone.layers.2.1.6.attn.attn.in_proj_weight, backbone.layers.2.1.6.attn.attn.in_proj_bias, backbone.layers.2.1.6.attn.attn.out_proj.weight, backbone.layers.2.1.6.attn.attn.out_proj.bias, backbone.layers.2.1.6.attn.sr.weight, backbone.layers.2.1.6.attn.sr.bias, backbone.layers.2.1.6.attn.norm.weight, backbone.layers.2.1.6.attn.norm.bias, backbone.layers.2.1.6.norm2.weight, backbone.layers.2.1.6.norm2.bias, backbone.layers.2.1.6.ffn.layers.0.weight, backbone.layers.2.1.6.ffn.layers.0.bias, backbone.layers.2.1.6.ffn.layers.1.weight, backbone.layers.2.1.6.ffn.layers.1.bias, backbone.layers.2.1.6.ffn.layers.4.weight, backbone.layers.2.1.6.ffn.layers.4.bias, backbone.layers.2.1.7.norm1.weight, backbone.layers.2.1.7.norm1.bias, backbone.layers.2.1.7.attn.attn.in_proj_weight, backbone.layers.2.1.7.attn.attn.in_proj_bias, backbone.layers.2.1.7.attn.attn.out_proj.weight, backbone.layers.2.1.7.attn.attn.out_proj.bias, backbone.layers.2.1.7.attn.sr.weight, backbone.layers.2.1.7.attn.sr.bias, backbone.layers.2.1.7.attn.norm.weight, backbone.layers.2.1.7.attn.norm.bias, backbone.layers.2.1.7.norm2.weight, backbone.layers.2.1.7.norm2.bias, backbone.layers.2.1.7.ffn.layers.0.weight, backbone.layers.2.1.7.ffn.layers.0.bias, backbone.layers.2.1.7.ffn.layers.1.weight, backbone.layers.2.1.7.ffn.layers.1.bias, backbone.layers.2.1.7.ffn.layers.4.weight, backbone.layers.2.1.7.ffn.layers.4.bias, backbone.layers.2.1.8.norm1.weight, backbone.layers.2.1.8.norm1.bias, backbone.layers.2.1.8.attn.attn.in_proj_weight, backbone.layers.2.1.8.attn.attn.in_proj_bias, backbone.layers.2.1.8.attn.attn.out_proj.weight, backbone.layers.2.1.8.attn.attn.out_proj.bias, backbone.layers.2.1.8.attn.sr.weight, backbone.layers.2.1.8.attn.sr.bias, backbone.layers.2.1.8.attn.norm.weight, backbone.layers.2.1.8.attn.norm.bias, backbone.layers.2.1.8.norm2.weight, backbone.layers.2.1.8.norm2.bias, backbone.layers.2.1.8.ffn.layers.0.weight, backbone.layers.2.1.8.ffn.layers.0.bias, backbone.layers.2.1.8.ffn.layers.1.weight, backbone.layers.2.1.8.ffn.layers.1.bias, backbone.layers.2.1.8.ffn.layers.4.weight, backbone.layers.2.1.8.ffn.layers.4.bias, backbone.layers.2.1.9.norm1.weight, backbone.layers.2.1.9.norm1.bias, backbone.layers.2.1.9.attn.attn.in_proj_weight, backbone.layers.2.1.9.attn.attn.in_proj_bias, backbone.layers.2.1.9.attn.attn.out_proj.weight, backbone.layers.2.1.9.attn.attn.out_proj.bias, backbone.layers.2.1.9.attn.sr.weight, backbone.layers.2.1.9.attn.sr.bias, backbone.layers.2.1.9.attn.norm.weight, backbone.layers.2.1.9.attn.norm.bias, backbone.layers.2.1.9.norm2.weight, backbone.layers.2.1.9.norm2.bias, backbone.layers.2.1.9.ffn.layers.0.weight, backbone.layers.2.1.9.ffn.layers.0.bias, backbone.layers.2.1.9.ffn.layers.1.weight, backbone.layers.2.1.9.ffn.layers.1.bias, backbone.layers.2.1.9.ffn.layers.4.weight, backbone.layers.2.1.9.ffn.layers.4.bias, backbone.layers.2.1.10.norm1.weight, backbone.layers.2.1.10.norm1.bias, backbone.layers.2.1.10.attn.attn.in_proj_weight, backbone.layers.2.1.10.attn.attn.in_proj_bias, backbone.layers.2.1.10.attn.attn.out_proj.weight, backbone.layers.2.1.10.attn.attn.out_proj.bias, backbone.layers.2.1.10.attn.sr.weight, backbone.layers.2.1.10.attn.sr.bias, backbone.layers.2.1.10.attn.norm.weight, backbone.layers.2.1.10.attn.norm.bias, backbone.layers.2.1.10.norm2.weight, backbone.layers.2.1.10.norm2.bias, backbone.layers.2.1.10.ffn.layers.0.weight, backbone.layers.2.1.10.ffn.layers.0.bias, backbone.layers.2.1.10.ffn.layers.1.weight, backbone.layers.2.1.10.ffn.layers.1.bias, backbone.layers.2.1.10.ffn.layers.4.weight, backbone.layers.2.1.10.ffn.layers.4.bias, backbone.layers.2.1.11.norm1.weight, backbone.layers.2.1.11.norm1.bias, backbone.layers.2.1.11.attn.attn.in_proj_weight, backbone.layers.2.1.11.attn.attn.in_proj_bias, backbone.layers.2.1.11.attn.attn.out_proj.weight, backbone.layers.2.1.11.attn.attn.out_proj.bias, backbone.layers.2.1.11.attn.sr.weight, backbone.layers.2.1.11.attn.sr.bias, backbone.layers.2.1.11.attn.norm.weight, backbone.layers.2.1.11.attn.norm.bias, backbone.layers.2.1.11.norm2.weight, backbone.layers.2.1.11.norm2.bias, backbone.layers.2.1.11.ffn.layers.0.weight, backbone.layers.2.1.11.ffn.layers.0.bias, backbone.layers.2.1.11.ffn.layers.1.weight, backbone.layers.2.1.11.ffn.layers.1.bias, backbone.layers.2.1.11.ffn.layers.4.weight, backbone.layers.2.1.11.ffn.layers.4.bias, backbone.layers.2.1.12.norm1.weight, backbone.layers.2.1.12.norm1.bias, backbone.layers.2.1.12.attn.attn.in_proj_weight, backbone.layers.2.1.12.attn.attn.in_proj_bias, backbone.layers.2.1.12.attn.attn.out_proj.weight, backbone.layers.2.1.12.attn.attn.out_proj.bias, backbone.layers.2.1.12.attn.sr.weight, backbone.layers.2.1.12.attn.sr.bias, backbone.layers.2.1.12.attn.norm.weight, backbone.layers.2.1.12.attn.norm.bias, backbone.layers.2.1.12.norm2.weight, backbone.layers.2.1.12.norm2.bias, backbone.layers.2.1.12.ffn.layers.0.weight, backbone.layers.2.1.12.ffn.layers.0.bias, backbone.layers.2.1.12.ffn.layers.1.weight, backbone.layers.2.1.12.ffn.layers.1.bias, backbone.layers.2.1.12.ffn.layers.4.weight, backbone.layers.2.1.12.ffn.layers.4.bias, backbone.layers.2.1.13.norm1.weight, backbone.layers.2.1.13.norm1.bias, backbone.layers.2.1.13.attn.attn.in_proj_weight, backbone.layers.2.1.13.attn.attn.in_proj_bias, backbone.layers.2.1.13.attn.attn.out_proj.weight, backbone.layers.2.1.13.attn.attn.out_proj.bias, backbone.layers.2.1.13.attn.sr.weight, backbone.layers.2.1.13.attn.sr.bias, backbone.layers.2.1.13.attn.norm.weight, backbone.layers.2.1.13.attn.norm.bias, backbone.layers.2.1.13.norm2.weight, backbone.layers.2.1.13.norm2.bias, backbone.layers.2.1.13.ffn.layers.0.weight, backbone.layers.2.1.13.ffn.layers.0.bias, backbone.layers.2.1.13.ffn.layers.1.weight, backbone.layers.2.1.13.ffn.layers.1.bias, backbone.layers.2.1.13.ffn.layers.4.weight, backbone.layers.2.1.13.ffn.layers.4.bias, backbone.layers.2.1.14.norm1.weight, backbone.layers.2.1.14.norm1.bias, backbone.layers.2.1.14.attn.attn.in_proj_weight, backbone.layers.2.1.14.attn.attn.in_proj_bias, backbone.layers.2.1.14.attn.attn.out_proj.weight, backbone.layers.2.1.14.attn.attn.out_proj.bias, backbone.layers.2.1.14.attn.sr.weight, backbone.layers.2.1.14.attn.sr.bias, backbone.layers.2.1.14.attn.norm.weight, backbone.layers.2.1.14.attn.norm.bias, backbone.layers.2.1.14.norm2.weight, backbone.layers.2.1.14.norm2.bias, backbone.layers.2.1.14.ffn.layers.0.weight, backbone.layers.2.1.14.ffn.layers.0.bias, backbone.layers.2.1.14.ffn.layers.1.weight, backbone.layers.2.1.14.ffn.layers.1.bias, backbone.layers.2.1.14.ffn.layers.4.weight, backbone.layers.2.1.14.ffn.layers.4.bias, backbone.layers.2.1.15.norm1.weight, backbone.layers.2.1.15.norm1.bias, backbone.layers.2.1.15.attn.attn.in_proj_weight, backbone.layers.2.1.15.attn.attn.in_proj_bias, backbone.layers.2.1.15.attn.attn.out_proj.weight, backbone.layers.2.1.15.attn.attn.out_proj.bias, backbone.layers.2.1.15.attn.sr.weight, backbone.layers.2.1.15.attn.sr.bias, backbone.layers.2.1.15.attn.norm.weight, backbone.layers.2.1.15.attn.norm.bias, backbone.layers.2.1.15.norm2.weight, backbone.layers.2.1.15.norm2.bias, backbone.layers.2.1.15.ffn.layers.0.weight, backbone.layers.2.1.15.ffn.layers.0.bias, backbone.layers.2.1.15.ffn.layers.1.weight, backbone.layers.2.1.15.ffn.layers.1.bias, backbone.layers.2.1.15.ffn.layers.4.weight, backbone.layers.2.1.15.ffn.layers.4.bias, backbone.layers.2.1.16.norm1.weight, backbone.layers.2.1.16.norm1.bias, backbone.layers.2.1.16.attn.attn.in_proj_weight, backbone.layers.2.1.16.attn.attn.in_proj_bias, backbone.layers.2.1.16.attn.attn.out_proj.weight, backbone.layers.2.1.16.attn.attn.out_proj.bias, backbone.layers.2.1.16.attn.sr.weight, backbone.layers.2.1.16.attn.sr.bias, backbone.layers.2.1.16.attn.norm.weight, backbone.layers.2.1.16.attn.norm.bias, backbone.layers.2.1.16.norm2.weight, backbone.layers.2.1.16.norm2.bias, backbone.layers.2.1.16.ffn.layers.0.weight, backbone.layers.2.1.16.ffn.layers.0.bias, backbone.layers.2.1.16.ffn.layers.1.weight, backbone.layers.2.1.16.ffn.layers.1.bias, backbone.layers.2.1.16.ffn.layers.4.weight, backbone.layers.2.1.16.ffn.layers.4.bias, backbone.layers.2.1.17.norm1.weight, backbone.layers.2.1.17.norm1.bias, backbone.layers.2.1.17.attn.attn.in_proj_weight, backbone.layers.2.1.17.attn.attn.in_proj_bias, backbone.layers.2.1.17.attn.attn.out_proj.weight, backbone.layers.2.1.17.attn.attn.out_proj.bias, backbone.layers.2.1.17.attn.sr.weight, backbone.layers.2.1.17.attn.sr.bias, backbone.layers.2.1.17.attn.norm.weight, backbone.layers.2.1.17.attn.norm.bias, backbone.layers.2.1.17.norm2.weight, backbone.layers.2.1.17.norm2.bias, backbone.layers.2.1.17.ffn.layers.0.weight, backbone.layers.2.1.17.ffn.layers.0.bias, backbone.layers.2.1.17.ffn.layers.1.weight, backbone.layers.2.1.17.ffn.layers.1.bias, backbone.layers.2.1.17.ffn.layers.4.weight, backbone.layers.2.1.17.ffn.layers.4.bias, backbone.layers.2.1.18.norm1.weight, backbone.layers.2.1.18.norm1.bias, backbone.layers.2.1.18.attn.attn.in_proj_weight, backbone.layers.2.1.18.attn.attn.in_proj_bias, backbone.layers.2.1.18.attn.attn.out_proj.weight, backbone.layers.2.1.18.attn.attn.out_proj.bias, backbone.layers.2.1.18.attn.sr.weight, backbone.layers.2.1.18.attn.sr.bias, backbone.layers.2.1.18.attn.norm.weight, backbone.layers.2.1.18.attn.norm.bias, backbone.layers.2.1.18.norm2.weight, backbone.layers.2.1.18.norm2.bias, backbone.layers.2.1.18.ffn.layers.0.weight, backbone.layers.2.1.18.ffn.layers.0.bias, backbone.layers.2.1.18.ffn.layers.1.weight, backbone.layers.2.1.18.ffn.layers.1.bias, backbone.layers.2.1.18.ffn.layers.4.weight, backbone.layers.2.1.18.ffn.layers.4.bias, backbone.layers.2.1.19.norm1.weight, backbone.layers.2.1.19.norm1.bias, backbone.layers.2.1.19.attn.attn.in_proj_weight, backbone.layers.2.1.19.attn.attn.in_proj_bias, backbone.layers.2.1.19.attn.attn.out_proj.weight, backbone.layers.2.1.19.attn.attn.out_proj.bias, backbone.layers.2.1.19.attn.sr.weight, backbone.layers.2.1.19.attn.sr.bias, backbone.layers.2.1.19.attn.norm.weight, backbone.layers.2.1.19.attn.norm.bias, backbone.layers.2.1.19.norm2.weight, backbone.layers.2.1.19.norm2.bias, backbone.layers.2.1.19.ffn.layers.0.weight, backbone.layers.2.1.19.ffn.layers.0.bias, backbone.layers.2.1.19.ffn.layers.1.weight, backbone.layers.2.1.19.ffn.layers.1.bias, backbone.layers.2.1.19.ffn.layers.4.weight, backbone.layers.2.1.19.ffn.layers.4.bias, backbone.layers.2.1.20.norm1.weight, backbone.layers.2.1.20.norm1.bias, backbone.layers.2.1.20.attn.attn.in_proj_weight, backbone.layers.2.1.20.attn.attn.in_proj_bias, backbone.layers.2.1.20.attn.attn.out_proj.weight, backbone.layers.2.1.20.attn.attn.out_proj.bias, backbone.layers.2.1.20.attn.sr.weight, backbone.layers.2.1.20.attn.sr.bias, backbone.layers.2.1.20.attn.norm.weight, backbone.layers.2.1.20.attn.norm.bias, backbone.layers.2.1.20.norm2.weight, backbone.layers.2.1.20.norm2.bias, backbone.layers.2.1.20.ffn.layers.0.weight, backbone.layers.2.1.20.ffn.layers.0.bias, backbone.layers.2.1.20.ffn.layers.1.weight, backbone.layers.2.1.20.ffn.layers.1.bias, backbone.layers.2.1.20.ffn.layers.4.weight, backbone.layers.2.1.20.ffn.layers.4.bias, backbone.layers.2.1.21.norm1.weight, backbone.layers.2.1.21.norm1.bias, backbone.layers.2.1.21.attn.attn.in_proj_weight, backbone.layers.2.1.21.attn.attn.in_proj_bias, backbone.layers.2.1.21.attn.attn.out_proj.weight, backbone.layers.2.1.21.attn.attn.out_proj.bias, backbone.layers.2.1.21.attn.sr.weight, backbone.layers.2.1.21.attn.sr.bias, backbone.layers.2.1.21.attn.norm.weight, backbone.layers.2.1.21.attn.norm.bias, backbone.layers.2.1.21.norm2.weight, backbone.layers.2.1.21.norm2.bias, backbone.layers.2.1.21.ffn.layers.0.weight, backbone.layers.2.1.21.ffn.layers.0.bias, backbone.layers.2.1.21.ffn.layers.1.weight, backbone.layers.2.1.21.ffn.layers.1.bias, backbone.layers.2.1.21.ffn.layers.4.weight, backbone.layers.2.1.21.ffn.layers.4.bias, backbone.layers.2.1.22.norm1.weight, backbone.layers.2.1.22.norm1.bias, backbone.layers.2.1.22.attn.attn.in_proj_weight, backbone.layers.2.1.22.attn.attn.in_proj_bias, backbone.layers.2.1.22.attn.attn.out_proj.weight, backbone.layers.2.1.22.attn.attn.out_proj.bias, backbone.layers.2.1.22.attn.sr.weight, backbone.layers.2.1.22.attn.sr.bias, backbone.layers.2.1.22.attn.norm.weight, backbone.layers.2.1.22.attn.norm.bias, backbone.layers.2.1.22.norm2.weight, backbone.layers.2.1.22.norm2.bias, backbone.layers.2.1.22.ffn.layers.0.weight, backbone.layers.2.1.22.ffn.layers.0.bias, backbone.layers.2.1.22.ffn.layers.1.weight, backbone.layers.2.1.22.ffn.layers.1.bias, backbone.layers.2.1.22.ffn.layers.4.weight, backbone.layers.2.1.22.ffn.layers.4.bias, backbone.layers.2.1.23.norm1.weight, backbone.layers.2.1.23.norm1.bias, backbone.layers.2.1.23.attn.attn.in_proj_weight, backbone.layers.2.1.23.attn.attn.in_proj_bias, backbone.layers.2.1.23.attn.attn.out_proj.weight, backbone.layers.2.1.23.attn.attn.out_proj.bias, backbone.layers.2.1.23.attn.sr.weight, backbone.layers.2.1.23.attn.sr.bias, backbone.layers.2.1.23.attn.norm.weight, backbone.layers.2.1.23.attn.norm.bias, backbone.layers.2.1.23.norm2.weight, backbone.layers.2.1.23.norm2.bias, backbone.layers.2.1.23.ffn.layers.0.weight, backbone.layers.2.1.23.ffn.layers.0.bias, backbone.layers.2.1.23.ffn.layers.1.weight, backbone.layers.2.1.23.ffn.layers.1.bias, backbone.layers.2.1.23.ffn.layers.4.weight, backbone.layers.2.1.23.ffn.layers.4.bias, backbone.layers.2.1.24.norm1.weight, backbone.layers.2.1.24.norm1.bias, backbone.layers.2.1.24.attn.attn.in_proj_weight, backbone.layers.2.1.24.attn.attn.in_proj_bias, backbone.layers.2.1.24.attn.attn.out_proj.weight, backbone.layers.2.1.24.attn.attn.out_proj.bias, backbone.layers.2.1.24.attn.sr.weight, backbone.layers.2.1.24.attn.sr.bias, backbone.layers.2.1.24.attn.norm.weight, backbone.layers.2.1.24.attn.norm.bias, backbone.layers.2.1.24.norm2.weight, backbone.layers.2.1.24.norm2.bias, backbone.layers.2.1.24.ffn.layers.0.weight, backbone.layers.2.1.24.ffn.layers.0.bias, backbone.layers.2.1.24.ffn.layers.1.weight, backbone.layers.2.1.24.ffn.layers.1.bias, backbone.layers.2.1.24.ffn.layers.4.weight, backbone.layers.2.1.24.ffn.layers.4.bias, backbone.layers.2.1.25.norm1.weight, backbone.layers.2.1.25.norm1.bias, backbone.layers.2.1.25.attn.attn.in_proj_weight, backbone.layers.2.1.25.attn.attn.in_proj_bias, backbone.layers.2.1.25.attn.attn.out_proj.weight, backbone.layers.2.1.25.attn.attn.out_proj.bias, backbone.layers.2.1.25.attn.sr.weight, backbone.layers.2.1.25.attn.sr.bias, backbone.layers.2.1.25.attn.norm.weight, backbone.layers.2.1.25.attn.norm.bias, backbone.layers.2.1.25.norm2.weight, backbone.layers.2.1.25.norm2.bias, backbone.layers.2.1.25.ffn.layers.0.weight, backbone.layers.2.1.25.ffn.layers.0.bias, backbone.layers.2.1.25.ffn.layers.1.weight, backbone.layers.2.1.25.ffn.layers.1.bias, backbone.layers.2.1.25.ffn.layers.4.weight, backbone.layers.2.1.25.ffn.layers.4.bias, backbone.layers.2.1.26.norm1.weight, backbone.layers.2.1.26.norm1.bias, backbone.layers.2.1.26.attn.attn.in_proj_weight, backbone.layers.2.1.26.attn.attn.in_proj_bias, backbone.layers.2.1.26.attn.attn.out_proj.weight, backbone.layers.2.1.26.attn.attn.out_proj.bias, backbone.layers.2.1.26.attn.sr.weight, backbone.layers.2.1.26.attn.sr.bias, backbone.layers.2.1.26.attn.norm.weight, backbone.layers.2.1.26.attn.norm.bias, backbone.layers.2.1.26.norm2.weight, backbone.layers.2.1.26.norm2.bias, backbone.layers.2.1.26.ffn.layers.0.weight, backbone.layers.2.1.26.ffn.layers.0.bias, backbone.layers.2.1.26.ffn.layers.1.weight, backbone.layers.2.1.26.ffn.layers.1.bias, backbone.layers.2.1.26.ffn.layers.4.weight, backbone.layers.2.1.26.ffn.layers.4.bias, backbone.layers.2.1.27.norm1.weight, backbone.layers.2.1.27.norm1.bias, backbone.layers.2.1.27.attn.attn.in_proj_weight, backbone.layers.2.1.27.attn.attn.in_proj_bias, backbone.layers.2.1.27.attn.attn.out_proj.weight, backbone.layers.2.1.27.attn.attn.out_proj.bias, backbone.layers.2.1.27.attn.sr.weight, backbone.layers.2.1.27.attn.sr.bias, backbone.layers.2.1.27.attn.norm.weight, backbone.layers.2.1.27.attn.norm.bias, backbone.layers.2.1.27.norm2.weight, backbone.layers.2.1.27.norm2.bias, backbone.layers.2.1.27.ffn.layers.0.weight, backbone.layers.2.1.27.ffn.layers.0.bias, backbone.layers.2.1.27.ffn.layers.1.weight, backbone.layers.2.1.27.ffn.layers.1.bias, backbone.layers.2.1.27.ffn.layers.4.weight, backbone.layers.2.1.27.ffn.layers.4.bias, backbone.layers.2.1.28.norm1.weight, backbone.layers.2.1.28.norm1.bias, backbone.layers.2.1.28.attn.attn.in_proj_weight, backbone.layers.2.1.28.attn.attn.in_proj_bias, backbone.layers.2.1.28.attn.attn.out_proj.weight, backbone.layers.2.1.28.attn.attn.out_proj.bias, backbone.layers.2.1.28.attn.sr.weight, backbone.layers.2.1.28.attn.sr.bias, backbone.layers.2.1.28.attn.norm.weight, backbone.layers.2.1.28.attn.norm.bias, backbone.layers.2.1.28.norm2.weight, backbone.layers.2.1.28.norm2.bias, backbone.layers.2.1.28.ffn.layers.0.weight, backbone.layers.2.1.28.ffn.layers.0.bias, backbone.layers.2.1.28.ffn.layers.1.weight, backbone.layers.2.1.28.ffn.layers.1.bias, backbone.layers.2.1.28.ffn.layers.4.weight, backbone.layers.2.1.28.ffn.layers.4.bias, backbone.layers.2.1.29.norm1.weight, backbone.layers.2.1.29.norm1.bias, backbone.layers.2.1.29.attn.attn.in_proj_weight, backbone.layers.2.1.29.attn.attn.in_proj_bias, backbone.layers.2.1.29.attn.attn.out_proj.weight, backbone.layers.2.1.29.attn.attn.out_proj.bias, backbone.layers.2.1.29.attn.sr.weight, backbone.layers.2.1.29.attn.sr.bias, backbone.layers.2.1.29.attn.norm.weight, backbone.layers.2.1.29.attn.norm.bias, backbone.layers.2.1.29.norm2.weight, backbone.layers.2.1.29.norm2.bias, backbone.layers.2.1.29.ffn.layers.0.weight, backbone.layers.2.1.29.ffn.layers.0.bias, backbone.layers.2.1.29.ffn.layers.1.weight, backbone.layers.2.1.29.ffn.layers.1.bias, backbone.layers.2.1.29.ffn.layers.4.weight, backbone.layers.2.1.29.ffn.layers.4.bias, backbone.layers.2.1.30.norm1.weight, backbone.layers.2.1.30.norm1.bias, backbone.layers.2.1.30.attn.attn.in_proj_weight, backbone.layers.2.1.30.attn.attn.in_proj_bias, backbone.layers.2.1.30.attn.attn.out_proj.weight, backbone.layers.2.1.30.attn.attn.out_proj.bias, backbone.layers.2.1.30.attn.sr.weight, backbone.layers.2.1.30.attn.sr.bias, backbone.layers.2.1.30.attn.norm.weight, backbone.layers.2.1.30.attn.norm.bias, backbone.layers.2.1.30.norm2.weight, backbone.layers.2.1.30.norm2.bias, backbone.layers.2.1.30.ffn.layers.0.weight, backbone.layers.2.1.30.ffn.layers.0.bias, backbone.layers.2.1.30.ffn.layers.1.weight, backbone.layers.2.1.30.ffn.layers.1.bias, backbone.layers.2.1.30.ffn.layers.4.weight, backbone.layers.2.1.30.ffn.layers.4.bias, backbone.layers.2.1.31.norm1.weight, backbone.layers.2.1.31.norm1.bias, backbone.layers.2.1.31.attn.attn.in_proj_weight, backbone.layers.2.1.31.attn.attn.in_proj_bias, backbone.layers.2.1.31.attn.attn.out_proj.weight, backbone.layers.2.1.31.attn.attn.out_proj.bias, backbone.layers.2.1.31.attn.sr.weight, backbone.layers.2.1.31.attn.sr.bias, backbone.layers.2.1.31.attn.norm.weight, backbone.layers.2.1.31.attn.norm.bias, backbone.layers.2.1.31.norm2.weight, backbone.layers.2.1.31.norm2.bias, backbone.layers.2.1.31.ffn.layers.0.weight, backbone.layers.2.1.31.ffn.layers.0.bias, backbone.layers.2.1.31.ffn.layers.1.weight, backbone.layers.2.1.31.ffn.layers.1.bias, backbone.layers.2.1.31.ffn.layers.4.weight, backbone.layers.2.1.31.ffn.layers.4.bias, backbone.layers.2.1.32.norm1.weight, backbone.layers.2.1.32.norm1.bias, backbone.layers.2.1.32.attn.attn.in_proj_weight, backbone.layers.2.1.32.attn.attn.in_proj_bias, backbone.layers.2.1.32.attn.attn.out_proj.weight, backbone.layers.2.1.32.attn.attn.out_proj.bias, backbone.layers.2.1.32.attn.sr.weight, backbone.layers.2.1.32.attn.sr.bias, backbone.layers.2.1.32.attn.norm.weight, backbone.layers.2.1.32.attn.norm.bias, backbone.layers.2.1.32.norm2.weight, backbone.layers.2.1.32.norm2.bias, backbone.layers.2.1.32.ffn.layers.0.weight, backbone.layers.2.1.32.ffn.layers.0.bias, backbone.layers.2.1.32.ffn.layers.1.weight, backbone.layers.2.1.32.ffn.layers.1.bias, backbone.layers.2.1.32.ffn.layers.4.weight, backbone.layers.2.1.32.ffn.layers.4.bias, backbone.layers.2.1.33.norm1.weight, backbone.layers.2.1.33.norm1.bias, backbone.layers.2.1.33.attn.attn.in_proj_weight, backbone.layers.2.1.33.attn.attn.in_proj_bias, backbone.layers.2.1.33.attn.attn.out_proj.weight, backbone.layers.2.1.33.attn.attn.out_proj.bias, backbone.layers.2.1.33.attn.sr.weight, backbone.layers.2.1.33.attn.sr.bias, backbone.layers.2.1.33.attn.norm.weight, backbone.layers.2.1.33.attn.norm.bias, backbone.layers.2.1.33.norm2.weight, backbone.layers.2.1.33.norm2.bias, backbone.layers.2.1.33.ffn.layers.0.weight, backbone.layers.2.1.33.ffn.layers.0.bias, backbone.layers.2.1.33.ffn.layers.1.weight, backbone.layers.2.1.33.ffn.layers.1.bias, backbone.layers.2.1.33.ffn.layers.4.weight, backbone.layers.2.1.33.ffn.layers.4.bias, backbone.layers.2.1.34.norm1.weight, backbone.layers.2.1.34.norm1.bias, backbone.layers.2.1.34.attn.attn.in_proj_weight, backbone.layers.2.1.34.attn.attn.in_proj_bias, backbone.layers.2.1.34.attn.attn.out_proj.weight, backbone.layers.2.1.34.attn.attn.out_proj.bias, backbone.layers.2.1.34.attn.sr.weight, backbone.layers.2.1.34.attn.sr.bias, backbone.layers.2.1.34.attn.norm.weight, backbone.layers.2.1.34.attn.norm.bias, backbone.layers.2.1.34.norm2.weight, backbone.layers.2.1.34.norm2.bias, backbone.layers.2.1.34.ffn.layers.0.weight, backbone.layers.2.1.34.ffn.layers.0.bias, backbone.layers.2.1.34.ffn.layers.1.weight, backbone.layers.2.1.34.ffn.layers.1.bias, backbone.layers.2.1.34.ffn.layers.4.weight, backbone.layers.2.1.34.ffn.layers.4.bias, backbone.layers.2.1.35.norm1.weight, backbone.layers.2.1.35.norm1.bias, backbone.layers.2.1.35.attn.attn.in_proj_weight, backbone.layers.2.1.35.attn.attn.in_proj_bias, backbone.layers.2.1.35.attn.attn.out_proj.weight, backbone.layers.2.1.35.attn.attn.out_proj.bias, backbone.layers.2.1.35.attn.sr.weight, backbone.layers.2.1.35.attn.sr.bias, backbone.layers.2.1.35.attn.norm.weight, backbone.layers.2.1.35.attn.norm.bias, backbone.layers.2.1.35.norm2.weight, backbone.layers.2.1.35.norm2.bias, backbone.layers.2.1.35.ffn.layers.0.weight, backbone.layers.2.1.35.ffn.layers.0.bias, backbone.layers.2.1.35.ffn.layers.1.weight, backbone.layers.2.1.35.ffn.layers.1.bias, backbone.layers.2.1.35.ffn.layers.4.weight, backbone.layers.2.1.35.ffn.layers.4.bias, backbone.layers.2.1.36.norm1.weight, backbone.layers.2.1.36.norm1.bias, backbone.layers.2.1.36.attn.attn.in_proj_weight, backbone.layers.2.1.36.attn.attn.in_proj_bias, backbone.layers.2.1.36.attn.attn.out_proj.weight, backbone.layers.2.1.36.attn.attn.out_proj.bias, backbone.layers.2.1.36.attn.sr.weight, backbone.layers.2.1.36.attn.sr.bias, backbone.layers.2.1.36.attn.norm.weight, backbone.layers.2.1.36.attn.norm.bias, backbone.layers.2.1.36.norm2.weight, backbone.layers.2.1.36.norm2.bias, backbone.layers.2.1.36.ffn.layers.0.weight, backbone.layers.2.1.36.ffn.layers.0.bias, backbone.layers.2.1.36.ffn.layers.1.weight, backbone.layers.2.1.36.ffn.layers.1.bias, backbone.layers.2.1.36.ffn.layers.4.weight, backbone.layers.2.1.36.ffn.layers.4.bias, backbone.layers.2.1.37.norm1.weight, backbone.layers.2.1.37.norm1.bias, backbone.layers.2.1.37.attn.attn.in_proj_weight, backbone.layers.2.1.37.attn.attn.in_proj_bias, backbone.layers.2.1.37.attn.attn.out_proj.weight, backbone.layers.2.1.37.attn.attn.out_proj.bias, backbone.layers.2.1.37.attn.sr.weight, backbone.layers.2.1.37.attn.sr.bias, backbone.layers.2.1.37.attn.norm.weight, backbone.layers.2.1.37.attn.norm.bias, backbone.layers.2.1.37.norm2.weight, backbone.layers.2.1.37.norm2.bias, backbone.layers.2.1.37.ffn.layers.0.weight, backbone.layers.2.1.37.ffn.layers.0.bias, backbone.layers.2.1.37.ffn.layers.1.weight, backbone.layers.2.1.37.ffn.layers.1.bias, backbone.layers.2.1.37.ffn.layers.4.weight, backbone.layers.2.1.37.ffn.layers.4.bias, backbone.layers.2.1.38.norm1.weight, backbone.layers.2.1.38.norm1.bias, backbone.layers.2.1.38.attn.attn.in_proj_weight, backbone.layers.2.1.38.attn.attn.in_proj_bias, backbone.layers.2.1.38.attn.attn.out_proj.weight, backbone.layers.2.1.38.attn.attn.out_proj.bias, backbone.layers.2.1.38.attn.sr.weight, backbone.layers.2.1.38.attn.sr.bias, backbone.layers.2.1.38.attn.norm.weight, backbone.layers.2.1.38.attn.norm.bias, backbone.layers.2.1.38.norm2.weight, backbone.layers.2.1.38.norm2.bias, backbone.layers.2.1.38.ffn.layers.0.weight, backbone.layers.2.1.38.ffn.layers.0.bias, backbone.layers.2.1.38.ffn.layers.1.weight, backbone.layers.2.1.38.ffn.layers.1.bias, backbone.layers.2.1.38.ffn.layers.4.weight, backbone.layers.2.1.38.ffn.layers.4.bias, backbone.layers.2.1.39.norm1.weight, backbone.layers.2.1.39.norm1.bias, backbone.layers.2.1.39.attn.attn.in_proj_weight, backbone.layers.2.1.39.attn.attn.in_proj_bias, backbone.layers.2.1.39.attn.attn.out_proj.weight, backbone.layers.2.1.39.attn.attn.out_proj.bias, backbone.layers.2.1.39.attn.sr.weight, backbone.layers.2.1.39.attn.sr.bias, backbone.layers.2.1.39.attn.norm.weight, backbone.layers.2.1.39.attn.norm.bias, backbone.layers.2.1.39.norm2.weight, backbone.layers.2.1.39.norm2.bias, backbone.layers.2.1.39.ffn.layers.0.weight, backbone.layers.2.1.39.ffn.layers.0.bias, backbone.layers.2.1.39.ffn.layers.1.weight, backbone.layers.2.1.39.ffn.layers.1.bias, backbone.layers.2.1.39.ffn.layers.4.weight, backbone.layers.2.1.39.ffn.layers.4.bias, backbone.layers.2.2.weight, backbone.layers.2.2.bias, backbone.layers.3.0.projection.weight, backbone.layers.3.0.projection.bias, backbone.layers.3.0.norm.weight, backbone.layers.3.0.norm.bias, backbone.layers.3.1.0.norm1.weight, backbone.layers.3.1.0.norm1.bias, backbone.layers.3.1.0.attn.attn.in_proj_weight, backbone.layers.3.1.0.attn.attn.in_proj_bias, backbone.layers.3.1.0.attn.attn.out_proj.weight, backbone.layers.3.1.0.attn.attn.out_proj.bias, backbone.layers.3.1.0.norm2.weight, backbone.layers.3.1.0.norm2.bias, backbone.layers.3.1.0.ffn.layers.0.weight, backbone.layers.3.1.0.ffn.layers.0.bias, backbone.layers.3.1.0.ffn.layers.1.weight, backbone.layers.3.1.0.ffn.layers.1.bias, backbone.layers.3.1.0.ffn.layers.4.weight, backbone.layers.3.1.0.ffn.layers.4.bias, backbone.layers.3.1.1.norm1.weight, backbone.layers.3.1.1.norm1.bias, backbone.layers.3.1.1.attn.attn.in_proj_weight, backbone.layers.3.1.1.attn.attn.in_proj_bias, backbone.layers.3.1.1.attn.attn.out_proj.weight, backbone.layers.3.1.1.attn.attn.out_proj.bias, backbone.layers.3.1.1.norm2.weight, backbone.layers.3.1.1.norm2.bias, backbone.layers.3.1.1.ffn.layers.0.weight, backbone.layers.3.1.1.ffn.layers.0.bias, backbone.layers.3.1.1.ffn.layers.1.weight, backbone.layers.3.1.1.ffn.layers.1.bias, backbone.layers.3.1.1.ffn.layers.4.weight, backbone.layers.3.1.1.ffn.layers.4.bias, backbone.layers.3.1.2.norm1.weight, backbone.layers.3.1.2.norm1.bias, backbone.layers.3.1.2.attn.attn.in_proj_weight, backbone.layers.3.1.2.attn.attn.in_proj_bias, backbone.layers.3.1.2.attn.attn.out_proj.weight, backbone.layers.3.1.2.attn.attn.out_proj.bias, backbone.layers.3.1.2.norm2.weight, backbone.layers.3.1.2.norm2.bias, backbone.layers.3.1.2.ffn.layers.0.weight, backbone.layers.3.1.2.ffn.layers.0.bias, backbone.layers.3.1.2.ffn.layers.1.weight, backbone.layers.3.1.2.ffn.layers.1.bias, backbone.layers.3.1.2.ffn.layers.4.weight, backbone.layers.3.1.2.ffn.layers.4.bias, backbone.layers.3.2.weight, backbone.layers.3.2.bias, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.convs.0.conv.weight, decode_head.convs.0.bn.weight, decode_head.convs.0.bn.bias, decode_head.convs.0.bn.running_mean, decode_head.convs.0.bn.running_var, decode_head.convs.0.bn.num_batches_tracked, decode_head.convs.1.conv.weight, decode_head.convs.1.bn.weight, decode_head.convs.1.bn.bias, decode_head.convs.1.bn.running_mean, decode_head.convs.1.bn.running_var, decode_head.convs.1.bn.num_batches_tracked, decode_head.convs.2.conv.weight, decode_head.convs.2.bn.weight, decode_head.convs.2.bn.bias, decode_head.convs.2.bn.running_mean, decode_head.convs.2.bn.running_var, decode_head.convs.2.bn.num_batches_tracked, decode_head.convs.3.conv.weight, decode_head.convs.3.bn.weight, decode_head.convs.3.bn.bias, decode_head.convs.3.bn.running_mean, decode_head.convs.3.bn.running_var, decode_head.convs.3.bn.num_batches_tracked, decode_head.fusion_conv.conv.weight, decode_head.fusion_conv.bn.weight, decode_head.fusion_conv.bn.bias, decode_head.fusion_conv.bn.running_mean, decode_head.fusion_conv.bn.running_var, decode_head.fusion_conv.bn.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: layers.0.0.projection.weight, layers.0.0.projection.bias, layers.0.0.norm.weight, layers.0.0.norm.bias, layers.0.1.0.norm1.weight, layers.0.1.0.norm1.bias, layers.0.1.0.attn.attn.in_proj_weight, layers.0.1.0.attn.attn.in_proj_bias, layers.0.1.0.attn.attn.out_proj.weight, layers.0.1.0.attn.attn.out_proj.bias, layers.0.1.0.attn.sr.weight, layers.0.1.0.attn.sr.bias, layers.0.1.0.attn.norm.weight, layers.0.1.0.attn.norm.bias, layers.0.1.0.norm2.weight, layers.0.1.0.norm2.bias, layers.0.1.0.ffn.layers.0.weight, layers.0.1.0.ffn.layers.0.bias, layers.0.1.0.ffn.layers.1.weight, layers.0.1.0.ffn.layers.1.bias, layers.0.1.0.ffn.layers.4.weight, layers.0.1.0.ffn.layers.4.bias, layers.0.1.1.norm1.weight, layers.0.1.1.norm1.bias, layers.0.1.1.attn.attn.in_proj_weight, layers.0.1.1.attn.attn.in_proj_bias, layers.0.1.1.attn.attn.out_proj.weight, layers.0.1.1.attn.attn.out_proj.bias, layers.0.1.1.attn.sr.weight, layers.0.1.1.attn.sr.bias, layers.0.1.1.attn.norm.weight, layers.0.1.1.attn.norm.bias, layers.0.1.1.norm2.weight, layers.0.1.1.norm2.bias, layers.0.1.1.ffn.layers.0.weight, layers.0.1.1.ffn.layers.0.bias, layers.0.1.1.ffn.layers.1.weight, layers.0.1.1.ffn.layers.1.bias, layers.0.1.1.ffn.layers.4.weight, layers.0.1.1.ffn.layers.4.bias, layers.0.1.2.norm1.weight, layers.0.1.2.norm1.bias, layers.0.1.2.attn.attn.in_proj_weight, layers.0.1.2.attn.attn.in_proj_bias, layers.0.1.2.attn.attn.out_proj.weight, layers.0.1.2.attn.attn.out_proj.bias, layers.0.1.2.attn.sr.weight, layers.0.1.2.attn.sr.bias, layers.0.1.2.attn.norm.weight, layers.0.1.2.attn.norm.bias, layers.0.1.2.norm2.weight, layers.0.1.2.norm2.bias, layers.0.1.2.ffn.layers.0.weight, layers.0.1.2.ffn.layers.0.bias, layers.0.1.2.ffn.layers.1.weight, layers.0.1.2.ffn.layers.1.bias, layers.0.1.2.ffn.layers.4.weight, layers.0.1.2.ffn.layers.4.bias, layers.0.2.weight, layers.0.2.bias, layers.1.0.projection.weight, layers.1.0.projection.bias, layers.1.0.norm.weight, layers.1.0.norm.bias, layers.1.1.0.norm1.weight, layers.1.1.0.norm1.bias, layers.1.1.0.attn.attn.in_proj_weight, layers.1.1.0.attn.attn.in_proj_bias, layers.1.1.0.attn.attn.out_proj.weight, layers.1.1.0.attn.attn.out_proj.bias, layers.1.1.0.attn.sr.weight, layers.1.1.0.attn.sr.bias, layers.1.1.0.attn.norm.weight, layers.1.1.0.attn.norm.bias, layers.1.1.0.norm2.weight, layers.1.1.0.norm2.bias, layers.1.1.0.ffn.layers.0.weight, layers.1.1.0.ffn.layers.0.bias, layers.1.1.0.ffn.layers.1.weight, layers.1.1.0.ffn.layers.1.bias, layers.1.1.0.ffn.layers.4.weight, layers.1.1.0.ffn.layers.4.bias, layers.1.1.1.norm1.weight, layers.1.1.1.norm1.bias, layers.1.1.1.attn.attn.in_proj_weight, layers.1.1.1.attn.attn.in_proj_bias, layers.1.1.1.attn.attn.out_proj.weight, layers.1.1.1.attn.attn.out_proj.bias, layers.1.1.1.attn.sr.weight, layers.1.1.1.attn.sr.bias, layers.1.1.1.attn.norm.weight, layers.1.1.1.attn.norm.bias, layers.1.1.1.norm2.weight, layers.1.1.1.norm2.bias, layers.1.1.1.ffn.layers.0.weight, layers.1.1.1.ffn.layers.0.bias, layers.1.1.1.ffn.layers.1.weight, layers.1.1.1.ffn.layers.1.bias, layers.1.1.1.ffn.layers.4.weight, layers.1.1.1.ffn.layers.4.bias, layers.1.1.2.norm1.weight, layers.1.1.2.norm1.bias, layers.1.1.2.attn.attn.in_proj_weight, layers.1.1.2.attn.attn.in_proj_bias, layers.1.1.2.attn.attn.out_proj.weight, layers.1.1.2.attn.attn.out_proj.bias, layers.1.1.2.attn.sr.weight, layers.1.1.2.attn.sr.bias, layers.1.1.2.attn.norm.weight, layers.1.1.2.attn.norm.bias, layers.1.1.2.norm2.weight, layers.1.1.2.norm2.bias, layers.1.1.2.ffn.layers.0.weight, layers.1.1.2.ffn.layers.0.bias, layers.1.1.2.ffn.layers.1.weight, layers.1.1.2.ffn.layers.1.bias, layers.1.1.2.ffn.layers.4.weight, layers.1.1.2.ffn.layers.4.bias, layers.1.1.3.norm1.weight, layers.1.1.3.norm1.bias, layers.1.1.3.attn.attn.in_proj_weight, layers.1.1.3.attn.attn.in_proj_bias, layers.1.1.3.attn.attn.out_proj.weight, layers.1.1.3.attn.attn.out_proj.bias, layers.1.1.3.attn.sr.weight, layers.1.1.3.attn.sr.bias, layers.1.1.3.attn.norm.weight, layers.1.1.3.attn.norm.bias, layers.1.1.3.norm2.weight, layers.1.1.3.norm2.bias, layers.1.1.3.ffn.layers.0.weight, layers.1.1.3.ffn.layers.0.bias, layers.1.1.3.ffn.layers.1.weight, layers.1.1.3.ffn.layers.1.bias, layers.1.1.3.ffn.layers.4.weight, layers.1.1.3.ffn.layers.4.bias, layers.1.1.4.norm1.weight, layers.1.1.4.norm1.bias, layers.1.1.4.attn.attn.in_proj_weight, layers.1.1.4.attn.attn.in_proj_bias, layers.1.1.4.attn.attn.out_proj.weight, layers.1.1.4.attn.attn.out_proj.bias, layers.1.1.4.attn.sr.weight, layers.1.1.4.attn.sr.bias, layers.1.1.4.attn.norm.weight, layers.1.1.4.attn.norm.bias, layers.1.1.4.norm2.weight, layers.1.1.4.norm2.bias, layers.1.1.4.ffn.layers.0.weight, layers.1.1.4.ffn.layers.0.bias, layers.1.1.4.ffn.layers.1.weight, layers.1.1.4.ffn.layers.1.bias, layers.1.1.4.ffn.layers.4.weight, layers.1.1.4.ffn.layers.4.bias, layers.1.1.5.norm1.weight, layers.1.1.5.norm1.bias, layers.1.1.5.attn.attn.in_proj_weight, layers.1.1.5.attn.attn.in_proj_bias, layers.1.1.5.attn.attn.out_proj.weight, layers.1.1.5.attn.attn.out_proj.bias, layers.1.1.5.attn.sr.weight, layers.1.1.5.attn.sr.bias, layers.1.1.5.attn.norm.weight, layers.1.1.5.attn.norm.bias, layers.1.1.5.norm2.weight, layers.1.1.5.norm2.bias, layers.1.1.5.ffn.layers.0.weight, layers.1.1.5.ffn.layers.0.bias, layers.1.1.5.ffn.layers.1.weight, layers.1.1.5.ffn.layers.1.bias, layers.1.1.5.ffn.layers.4.weight, layers.1.1.5.ffn.layers.4.bias, layers.1.2.weight, layers.1.2.bias, layers.2.0.projection.weight, layers.2.0.projection.bias, layers.2.0.norm.weight, layers.2.0.norm.bias, layers.2.1.0.norm1.weight, layers.2.1.0.norm1.bias, layers.2.1.0.attn.attn.in_proj_weight, layers.2.1.0.attn.attn.in_proj_bias, layers.2.1.0.attn.attn.out_proj.weight, layers.2.1.0.attn.attn.out_proj.bias, layers.2.1.0.attn.sr.weight, layers.2.1.0.attn.sr.bias, layers.2.1.0.attn.norm.weight, layers.2.1.0.attn.norm.bias, layers.2.1.0.norm2.weight, layers.2.1.0.norm2.bias, layers.2.1.0.ffn.layers.0.weight, layers.2.1.0.ffn.layers.0.bias, layers.2.1.0.ffn.layers.1.weight, layers.2.1.0.ffn.layers.1.bias, layers.2.1.0.ffn.layers.4.weight, layers.2.1.0.ffn.layers.4.bias, layers.2.1.1.norm1.weight, layers.2.1.1.norm1.bias, layers.2.1.1.attn.attn.in_proj_weight, layers.2.1.1.attn.attn.in_proj_bias, layers.2.1.1.attn.attn.out_proj.weight, layers.2.1.1.attn.attn.out_proj.bias, layers.2.1.1.attn.sr.weight, layers.2.1.1.attn.sr.bias, layers.2.1.1.attn.norm.weight, layers.2.1.1.attn.norm.bias, layers.2.1.1.norm2.weight, layers.2.1.1.norm2.bias, layers.2.1.1.ffn.layers.0.weight, layers.2.1.1.ffn.layers.0.bias, layers.2.1.1.ffn.layers.1.weight, layers.2.1.1.ffn.layers.1.bias, layers.2.1.1.ffn.layers.4.weight, layers.2.1.1.ffn.layers.4.bias, layers.2.1.2.norm1.weight, layers.2.1.2.norm1.bias, layers.2.1.2.attn.attn.in_proj_weight, layers.2.1.2.attn.attn.in_proj_bias, layers.2.1.2.attn.attn.out_proj.weight, layers.2.1.2.attn.attn.out_proj.bias, layers.2.1.2.attn.sr.weight, layers.2.1.2.attn.sr.bias, layers.2.1.2.attn.norm.weight, layers.2.1.2.attn.norm.bias, layers.2.1.2.norm2.weight, layers.2.1.2.norm2.bias, layers.2.1.2.ffn.layers.0.weight, layers.2.1.2.ffn.layers.0.bias, layers.2.1.2.ffn.layers.1.weight, layers.2.1.2.ffn.layers.1.bias, layers.2.1.2.ffn.layers.4.weight, layers.2.1.2.ffn.layers.4.bias, layers.2.1.3.norm1.weight, layers.2.1.3.norm1.bias, layers.2.1.3.attn.attn.in_proj_weight, layers.2.1.3.attn.attn.in_proj_bias, layers.2.1.3.attn.attn.out_proj.weight, layers.2.1.3.attn.attn.out_proj.bias, layers.2.1.3.attn.sr.weight, layers.2.1.3.attn.sr.bias, layers.2.1.3.attn.norm.weight, layers.2.1.3.attn.norm.bias, layers.2.1.3.norm2.weight, layers.2.1.3.norm2.bias, layers.2.1.3.ffn.layers.0.weight, layers.2.1.3.ffn.layers.0.bias, layers.2.1.3.ffn.layers.1.weight, layers.2.1.3.ffn.layers.1.bias, layers.2.1.3.ffn.layers.4.weight, layers.2.1.3.ffn.layers.4.bias, layers.2.1.4.norm1.weight, layers.2.1.4.norm1.bias, layers.2.1.4.attn.attn.in_proj_weight, layers.2.1.4.attn.attn.in_proj_bias, layers.2.1.4.attn.attn.out_proj.weight, layers.2.1.4.attn.attn.out_proj.bias, layers.2.1.4.attn.sr.weight, layers.2.1.4.attn.sr.bias, layers.2.1.4.attn.norm.weight, layers.2.1.4.attn.norm.bias, layers.2.1.4.norm2.weight, layers.2.1.4.norm2.bias, layers.2.1.4.ffn.layers.0.weight, layers.2.1.4.ffn.layers.0.bias, layers.2.1.4.ffn.layers.1.weight, layers.2.1.4.ffn.layers.1.bias, layers.2.1.4.ffn.layers.4.weight, layers.2.1.4.ffn.layers.4.bias, layers.2.1.5.norm1.weight, layers.2.1.5.norm1.bias, layers.2.1.5.attn.attn.in_proj_weight, layers.2.1.5.attn.attn.in_proj_bias, layers.2.1.5.attn.attn.out_proj.weight, layers.2.1.5.attn.attn.out_proj.bias, layers.2.1.5.attn.sr.weight, layers.2.1.5.attn.sr.bias, layers.2.1.5.attn.norm.weight, layers.2.1.5.attn.norm.bias, layers.2.1.5.norm2.weight, layers.2.1.5.norm2.bias, layers.2.1.5.ffn.layers.0.weight, layers.2.1.5.ffn.layers.0.bias, layers.2.1.5.ffn.layers.1.weight, layers.2.1.5.ffn.layers.1.bias, layers.2.1.5.ffn.layers.4.weight, layers.2.1.5.ffn.layers.4.bias, layers.2.1.6.norm1.weight, layers.2.1.6.norm1.bias, layers.2.1.6.attn.attn.in_proj_weight, layers.2.1.6.attn.attn.in_proj_bias, layers.2.1.6.attn.attn.out_proj.weight, layers.2.1.6.attn.attn.out_proj.bias, layers.2.1.6.attn.sr.weight, layers.2.1.6.attn.sr.bias, layers.2.1.6.attn.norm.weight, layers.2.1.6.attn.norm.bias, layers.2.1.6.norm2.weight, layers.2.1.6.norm2.bias, layers.2.1.6.ffn.layers.0.weight, layers.2.1.6.ffn.layers.0.bias, layers.2.1.6.ffn.layers.1.weight, layers.2.1.6.ffn.layers.1.bias, layers.2.1.6.ffn.layers.4.weight, layers.2.1.6.ffn.layers.4.bias, layers.2.1.7.norm1.weight, layers.2.1.7.norm1.bias, layers.2.1.7.attn.attn.in_proj_weight, layers.2.1.7.attn.attn.in_proj_bias, layers.2.1.7.attn.attn.out_proj.weight, layers.2.1.7.attn.attn.out_proj.bias, layers.2.1.7.attn.sr.weight, layers.2.1.7.attn.sr.bias, layers.2.1.7.attn.norm.weight, layers.2.1.7.attn.norm.bias, layers.2.1.7.norm2.weight, layers.2.1.7.norm2.bias, layers.2.1.7.ffn.layers.0.weight, layers.2.1.7.ffn.layers.0.bias, layers.2.1.7.ffn.layers.1.weight, layers.2.1.7.ffn.layers.1.bias, layers.2.1.7.ffn.layers.4.weight, layers.2.1.7.ffn.layers.4.bias, layers.2.1.8.norm1.weight, layers.2.1.8.norm1.bias, layers.2.1.8.attn.attn.in_proj_weight, layers.2.1.8.attn.attn.in_proj_bias, layers.2.1.8.attn.attn.out_proj.weight, layers.2.1.8.attn.attn.out_proj.bias, layers.2.1.8.attn.sr.weight, layers.2.1.8.attn.sr.bias, layers.2.1.8.attn.norm.weight, layers.2.1.8.attn.norm.bias, layers.2.1.8.norm2.weight, layers.2.1.8.norm2.bias, layers.2.1.8.ffn.layers.0.weight, layers.2.1.8.ffn.layers.0.bias, layers.2.1.8.ffn.layers.1.weight, layers.2.1.8.ffn.layers.1.bias, layers.2.1.8.ffn.layers.4.weight, layers.2.1.8.ffn.layers.4.bias, layers.2.1.9.norm1.weight, layers.2.1.9.norm1.bias, layers.2.1.9.attn.attn.in_proj_weight, layers.2.1.9.attn.attn.in_proj_bias, layers.2.1.9.attn.attn.out_proj.weight, layers.2.1.9.attn.attn.out_proj.bias, layers.2.1.9.attn.sr.weight, layers.2.1.9.attn.sr.bias, layers.2.1.9.attn.norm.weight, layers.2.1.9.attn.norm.bias, layers.2.1.9.norm2.weight, layers.2.1.9.norm2.bias, layers.2.1.9.ffn.layers.0.weight, layers.2.1.9.ffn.layers.0.bias, layers.2.1.9.ffn.layers.1.weight, layers.2.1.9.ffn.layers.1.bias, layers.2.1.9.ffn.layers.4.weight, layers.2.1.9.ffn.layers.4.bias, layers.2.1.10.norm1.weight, layers.2.1.10.norm1.bias, layers.2.1.10.attn.attn.in_proj_weight, layers.2.1.10.attn.attn.in_proj_bias, layers.2.1.10.attn.attn.out_proj.weight, layers.2.1.10.attn.attn.out_proj.bias, layers.2.1.10.attn.sr.weight, layers.2.1.10.attn.sr.bias, layers.2.1.10.attn.norm.weight, layers.2.1.10.attn.norm.bias, layers.2.1.10.norm2.weight, layers.2.1.10.norm2.bias, layers.2.1.10.ffn.layers.0.weight, layers.2.1.10.ffn.layers.0.bias, layers.2.1.10.ffn.layers.1.weight, layers.2.1.10.ffn.layers.1.bias, layers.2.1.10.ffn.layers.4.weight, layers.2.1.10.ffn.layers.4.bias, layers.2.1.11.norm1.weight, layers.2.1.11.norm1.bias, layers.2.1.11.attn.attn.in_proj_weight, layers.2.1.11.attn.attn.in_proj_bias, layers.2.1.11.attn.attn.out_proj.weight, layers.2.1.11.attn.attn.out_proj.bias, layers.2.1.11.attn.sr.weight, layers.2.1.11.attn.sr.bias, layers.2.1.11.attn.norm.weight, layers.2.1.11.attn.norm.bias, layers.2.1.11.norm2.weight, layers.2.1.11.norm2.bias, layers.2.1.11.ffn.layers.0.weight, layers.2.1.11.ffn.layers.0.bias, layers.2.1.11.ffn.layers.1.weight, layers.2.1.11.ffn.layers.1.bias, layers.2.1.11.ffn.layers.4.weight, layers.2.1.11.ffn.layers.4.bias, layers.2.1.12.norm1.weight, layers.2.1.12.norm1.bias, layers.2.1.12.attn.attn.in_proj_weight, layers.2.1.12.attn.attn.in_proj_bias, layers.2.1.12.attn.attn.out_proj.weight, layers.2.1.12.attn.attn.out_proj.bias, layers.2.1.12.attn.sr.weight, layers.2.1.12.attn.sr.bias, layers.2.1.12.attn.norm.weight, layers.2.1.12.attn.norm.bias, layers.2.1.12.norm2.weight, layers.2.1.12.norm2.bias, layers.2.1.12.ffn.layers.0.weight, layers.2.1.12.ffn.layers.0.bias, layers.2.1.12.ffn.layers.1.weight, layers.2.1.12.ffn.layers.1.bias, layers.2.1.12.ffn.layers.4.weight, layers.2.1.12.ffn.layers.4.bias, layers.2.1.13.norm1.weight, layers.2.1.13.norm1.bias, layers.2.1.13.attn.attn.in_proj_weight, layers.2.1.13.attn.attn.in_proj_bias, layers.2.1.13.attn.attn.out_proj.weight, layers.2.1.13.attn.attn.out_proj.bias, layers.2.1.13.attn.sr.weight, layers.2.1.13.attn.sr.bias, layers.2.1.13.attn.norm.weight, layers.2.1.13.attn.norm.bias, layers.2.1.13.norm2.weight, layers.2.1.13.norm2.bias, layers.2.1.13.ffn.layers.0.weight, layers.2.1.13.ffn.layers.0.bias, layers.2.1.13.ffn.layers.1.weight, layers.2.1.13.ffn.layers.1.bias, layers.2.1.13.ffn.layers.4.weight, layers.2.1.13.ffn.layers.4.bias, layers.2.1.14.norm1.weight, layers.2.1.14.norm1.bias, layers.2.1.14.attn.attn.in_proj_weight, layers.2.1.14.attn.attn.in_proj_bias, layers.2.1.14.attn.attn.out_proj.weight, layers.2.1.14.attn.attn.out_proj.bias, layers.2.1.14.attn.sr.weight, layers.2.1.14.attn.sr.bias, layers.2.1.14.attn.norm.weight, layers.2.1.14.attn.norm.bias, layers.2.1.14.norm2.weight, layers.2.1.14.norm2.bias, layers.2.1.14.ffn.layers.0.weight, layers.2.1.14.ffn.layers.0.bias, layers.2.1.14.ffn.layers.1.weight, layers.2.1.14.ffn.layers.1.bias, layers.2.1.14.ffn.layers.4.weight, layers.2.1.14.ffn.layers.4.bias, layers.2.1.15.norm1.weight, layers.2.1.15.norm1.bias, layers.2.1.15.attn.attn.in_proj_weight, layers.2.1.15.attn.attn.in_proj_bias, layers.2.1.15.attn.attn.out_proj.weight, layers.2.1.15.attn.attn.out_proj.bias, layers.2.1.15.attn.sr.weight, layers.2.1.15.attn.sr.bias, layers.2.1.15.attn.norm.weight, layers.2.1.15.attn.norm.bias, layers.2.1.15.norm2.weight, layers.2.1.15.norm2.bias, layers.2.1.15.ffn.layers.0.weight, layers.2.1.15.ffn.layers.0.bias, layers.2.1.15.ffn.layers.1.weight, layers.2.1.15.ffn.layers.1.bias, layers.2.1.15.ffn.layers.4.weight, layers.2.1.15.ffn.layers.4.bias, layers.2.1.16.norm1.weight, layers.2.1.16.norm1.bias, layers.2.1.16.attn.attn.in_proj_weight, layers.2.1.16.attn.attn.in_proj_bias, layers.2.1.16.attn.attn.out_proj.weight, layers.2.1.16.attn.attn.out_proj.bias, layers.2.1.16.attn.sr.weight, layers.2.1.16.attn.sr.bias, layers.2.1.16.attn.norm.weight, layers.2.1.16.attn.norm.bias, layers.2.1.16.norm2.weight, layers.2.1.16.norm2.bias, layers.2.1.16.ffn.layers.0.weight, layers.2.1.16.ffn.layers.0.bias, layers.2.1.16.ffn.layers.1.weight, layers.2.1.16.ffn.layers.1.bias, layers.2.1.16.ffn.layers.4.weight, layers.2.1.16.ffn.layers.4.bias, layers.2.1.17.norm1.weight, layers.2.1.17.norm1.bias, layers.2.1.17.attn.attn.in_proj_weight, layers.2.1.17.attn.attn.in_proj_bias, layers.2.1.17.attn.attn.out_proj.weight, layers.2.1.17.attn.attn.out_proj.bias, layers.2.1.17.attn.sr.weight, layers.2.1.17.attn.sr.bias, layers.2.1.17.attn.norm.weight, layers.2.1.17.attn.norm.bias, layers.2.1.17.norm2.weight, layers.2.1.17.norm2.bias, layers.2.1.17.ffn.layers.0.weight, layers.2.1.17.ffn.layers.0.bias, layers.2.1.17.ffn.layers.1.weight, layers.2.1.17.ffn.layers.1.bias, layers.2.1.17.ffn.layers.4.weight, layers.2.1.17.ffn.layers.4.bias, layers.2.1.18.norm1.weight, layers.2.1.18.norm1.bias, layers.2.1.18.attn.attn.in_proj_weight, layers.2.1.18.attn.attn.in_proj_bias, layers.2.1.18.attn.attn.out_proj.weight, layers.2.1.18.attn.attn.out_proj.bias, layers.2.1.18.attn.sr.weight, layers.2.1.18.attn.sr.bias, layers.2.1.18.attn.norm.weight, layers.2.1.18.attn.norm.bias, layers.2.1.18.norm2.weight, layers.2.1.18.norm2.bias, layers.2.1.18.ffn.layers.0.weight, layers.2.1.18.ffn.layers.0.bias, layers.2.1.18.ffn.layers.1.weight, layers.2.1.18.ffn.layers.1.bias, layers.2.1.18.ffn.layers.4.weight, layers.2.1.18.ffn.layers.4.bias, layers.2.1.19.norm1.weight, layers.2.1.19.norm1.bias, layers.2.1.19.attn.attn.in_proj_weight, layers.2.1.19.attn.attn.in_proj_bias, layers.2.1.19.attn.attn.out_proj.weight, layers.2.1.19.attn.attn.out_proj.bias, layers.2.1.19.attn.sr.weight, layers.2.1.19.attn.sr.bias, layers.2.1.19.attn.norm.weight, layers.2.1.19.attn.norm.bias, layers.2.1.19.norm2.weight, layers.2.1.19.norm2.bias, layers.2.1.19.ffn.layers.0.weight, layers.2.1.19.ffn.layers.0.bias, layers.2.1.19.ffn.layers.1.weight, layers.2.1.19.ffn.layers.1.bias, layers.2.1.19.ffn.layers.4.weight, layers.2.1.19.ffn.layers.4.bias, layers.2.1.20.norm1.weight, layers.2.1.20.norm1.bias, layers.2.1.20.attn.attn.in_proj_weight, layers.2.1.20.attn.attn.in_proj_bias, layers.2.1.20.attn.attn.out_proj.weight, layers.2.1.20.attn.attn.out_proj.bias, layers.2.1.20.attn.sr.weight, layers.2.1.20.attn.sr.bias, layers.2.1.20.attn.norm.weight, layers.2.1.20.attn.norm.bias, layers.2.1.20.norm2.weight, layers.2.1.20.norm2.bias, layers.2.1.20.ffn.layers.0.weight, layers.2.1.20.ffn.layers.0.bias, layers.2.1.20.ffn.layers.1.weight, layers.2.1.20.ffn.layers.1.bias, layers.2.1.20.ffn.layers.4.weight, layers.2.1.20.ffn.layers.4.bias, layers.2.1.21.norm1.weight, layers.2.1.21.norm1.bias, layers.2.1.21.attn.attn.in_proj_weight, layers.2.1.21.attn.attn.in_proj_bias, layers.2.1.21.attn.attn.out_proj.weight, layers.2.1.21.attn.attn.out_proj.bias, layers.2.1.21.attn.sr.weight, layers.2.1.21.attn.sr.bias, layers.2.1.21.attn.norm.weight, layers.2.1.21.attn.norm.bias, layers.2.1.21.norm2.weight, layers.2.1.21.norm2.bias, layers.2.1.21.ffn.layers.0.weight, layers.2.1.21.ffn.layers.0.bias, layers.2.1.21.ffn.layers.1.weight, layers.2.1.21.ffn.layers.1.bias, layers.2.1.21.ffn.layers.4.weight, layers.2.1.21.ffn.layers.4.bias, layers.2.1.22.norm1.weight, layers.2.1.22.norm1.bias, layers.2.1.22.attn.attn.in_proj_weight, layers.2.1.22.attn.attn.in_proj_bias, layers.2.1.22.attn.attn.out_proj.weight, layers.2.1.22.attn.attn.out_proj.bias, layers.2.1.22.attn.sr.weight, layers.2.1.22.attn.sr.bias, layers.2.1.22.attn.norm.weight, layers.2.1.22.attn.norm.bias, layers.2.1.22.norm2.weight, layers.2.1.22.norm2.bias, layers.2.1.22.ffn.layers.0.weight, layers.2.1.22.ffn.layers.0.bias, layers.2.1.22.ffn.layers.1.weight, layers.2.1.22.ffn.layers.1.bias, layers.2.1.22.ffn.layers.4.weight, layers.2.1.22.ffn.layers.4.bias, layers.2.1.23.norm1.weight, layers.2.1.23.norm1.bias, layers.2.1.23.attn.attn.in_proj_weight, layers.2.1.23.attn.attn.in_proj_bias, layers.2.1.23.attn.attn.out_proj.weight, layers.2.1.23.attn.attn.out_proj.bias, layers.2.1.23.attn.sr.weight, layers.2.1.23.attn.sr.bias, layers.2.1.23.attn.norm.weight, layers.2.1.23.attn.norm.bias, layers.2.1.23.norm2.weight, layers.2.1.23.norm2.bias, layers.2.1.23.ffn.layers.0.weight, layers.2.1.23.ffn.layers.0.bias, layers.2.1.23.ffn.layers.1.weight, layers.2.1.23.ffn.layers.1.bias, layers.2.1.23.ffn.layers.4.weight, layers.2.1.23.ffn.layers.4.bias, layers.2.1.24.norm1.weight, layers.2.1.24.norm1.bias, layers.2.1.24.attn.attn.in_proj_weight, layers.2.1.24.attn.attn.in_proj_bias, layers.2.1.24.attn.attn.out_proj.weight, layers.2.1.24.attn.attn.out_proj.bias, layers.2.1.24.attn.sr.weight, layers.2.1.24.attn.sr.bias, layers.2.1.24.attn.norm.weight, layers.2.1.24.attn.norm.bias, layers.2.1.24.norm2.weight, layers.2.1.24.norm2.bias, layers.2.1.24.ffn.layers.0.weight, layers.2.1.24.ffn.layers.0.bias, layers.2.1.24.ffn.layers.1.weight, layers.2.1.24.ffn.layers.1.bias, layers.2.1.24.ffn.layers.4.weight, layers.2.1.24.ffn.layers.4.bias, layers.2.1.25.norm1.weight, layers.2.1.25.norm1.bias, layers.2.1.25.attn.attn.in_proj_weight, layers.2.1.25.attn.attn.in_proj_bias, layers.2.1.25.attn.attn.out_proj.weight, layers.2.1.25.attn.attn.out_proj.bias, layers.2.1.25.attn.sr.weight, layers.2.1.25.attn.sr.bias, layers.2.1.25.attn.norm.weight, layers.2.1.25.attn.norm.bias, layers.2.1.25.norm2.weight, layers.2.1.25.norm2.bias, layers.2.1.25.ffn.layers.0.weight, layers.2.1.25.ffn.layers.0.bias, layers.2.1.25.ffn.layers.1.weight, layers.2.1.25.ffn.layers.1.bias, layers.2.1.25.ffn.layers.4.weight, layers.2.1.25.ffn.layers.4.bias, layers.2.1.26.norm1.weight, layers.2.1.26.norm1.bias, layers.2.1.26.attn.attn.in_proj_weight, layers.2.1.26.attn.attn.in_proj_bias, layers.2.1.26.attn.attn.out_proj.weight, layers.2.1.26.attn.attn.out_proj.bias, layers.2.1.26.attn.sr.weight, layers.2.1.26.attn.sr.bias, layers.2.1.26.attn.norm.weight, layers.2.1.26.attn.norm.bias, layers.2.1.26.norm2.weight, layers.2.1.26.norm2.bias, layers.2.1.26.ffn.layers.0.weight, layers.2.1.26.ffn.layers.0.bias, layers.2.1.26.ffn.layers.1.weight, layers.2.1.26.ffn.layers.1.bias, layers.2.1.26.ffn.layers.4.weight, layers.2.1.26.ffn.layers.4.bias, layers.2.1.27.norm1.weight, layers.2.1.27.norm1.bias, layers.2.1.27.attn.attn.in_proj_weight, layers.2.1.27.attn.attn.in_proj_bias, layers.2.1.27.attn.attn.out_proj.weight, layers.2.1.27.attn.attn.out_proj.bias, layers.2.1.27.attn.sr.weight, layers.2.1.27.attn.sr.bias, layers.2.1.27.attn.norm.weight, layers.2.1.27.attn.norm.bias, layers.2.1.27.norm2.weight, layers.2.1.27.norm2.bias, layers.2.1.27.ffn.layers.0.weight, layers.2.1.27.ffn.layers.0.bias, layers.2.1.27.ffn.layers.1.weight, layers.2.1.27.ffn.layers.1.bias, layers.2.1.27.ffn.layers.4.weight, layers.2.1.27.ffn.layers.4.bias, layers.2.1.28.norm1.weight, layers.2.1.28.norm1.bias, layers.2.1.28.attn.attn.in_proj_weight, layers.2.1.28.attn.attn.in_proj_bias, layers.2.1.28.attn.attn.out_proj.weight, layers.2.1.28.attn.attn.out_proj.bias, layers.2.1.28.attn.sr.weight, layers.2.1.28.attn.sr.bias, layers.2.1.28.attn.norm.weight, layers.2.1.28.attn.norm.bias, layers.2.1.28.norm2.weight, layers.2.1.28.norm2.bias, layers.2.1.28.ffn.layers.0.weight, layers.2.1.28.ffn.layers.0.bias, layers.2.1.28.ffn.layers.1.weight, layers.2.1.28.ffn.layers.1.bias, layers.2.1.28.ffn.layers.4.weight, layers.2.1.28.ffn.layers.4.bias, layers.2.1.29.norm1.weight, layers.2.1.29.norm1.bias, layers.2.1.29.attn.attn.in_proj_weight, layers.2.1.29.attn.attn.in_proj_bias, layers.2.1.29.attn.attn.out_proj.weight, layers.2.1.29.attn.attn.out_proj.bias, layers.2.1.29.attn.sr.weight, layers.2.1.29.attn.sr.bias, layers.2.1.29.attn.norm.weight, layers.2.1.29.attn.norm.bias, layers.2.1.29.norm2.weight, layers.2.1.29.norm2.bias, layers.2.1.29.ffn.layers.0.weight, layers.2.1.29.ffn.layers.0.bias, layers.2.1.29.ffn.layers.1.weight, layers.2.1.29.ffn.layers.1.bias, layers.2.1.29.ffn.layers.4.weight, layers.2.1.29.ffn.layers.4.bias, layers.2.1.30.norm1.weight, layers.2.1.30.norm1.bias, layers.2.1.30.attn.attn.in_proj_weight, layers.2.1.30.attn.attn.in_proj_bias, layers.2.1.30.attn.attn.out_proj.weight, layers.2.1.30.attn.attn.out_proj.bias, layers.2.1.30.attn.sr.weight, layers.2.1.30.attn.sr.bias, layers.2.1.30.attn.norm.weight, layers.2.1.30.attn.norm.bias, layers.2.1.30.norm2.weight, layers.2.1.30.norm2.bias, layers.2.1.30.ffn.layers.0.weight, layers.2.1.30.ffn.layers.0.bias, layers.2.1.30.ffn.layers.1.weight, layers.2.1.30.ffn.layers.1.bias, layers.2.1.30.ffn.layers.4.weight, layers.2.1.30.ffn.layers.4.bias, layers.2.1.31.norm1.weight, layers.2.1.31.norm1.bias, layers.2.1.31.attn.attn.in_proj_weight, layers.2.1.31.attn.attn.in_proj_bias, layers.2.1.31.attn.attn.out_proj.weight, layers.2.1.31.attn.attn.out_proj.bias, layers.2.1.31.attn.sr.weight, layers.2.1.31.attn.sr.bias, layers.2.1.31.attn.norm.weight, layers.2.1.31.attn.norm.bias, layers.2.1.31.norm2.weight, layers.2.1.31.norm2.bias, layers.2.1.31.ffn.layers.0.weight, layers.2.1.31.ffn.layers.0.bias, layers.2.1.31.ffn.layers.1.weight, layers.2.1.31.ffn.layers.1.bias, layers.2.1.31.ffn.layers.4.weight, layers.2.1.31.ffn.layers.4.bias, layers.2.1.32.norm1.weight, layers.2.1.32.norm1.bias, layers.2.1.32.attn.attn.in_proj_weight, layers.2.1.32.attn.attn.in_proj_bias, layers.2.1.32.attn.attn.out_proj.weight, layers.2.1.32.attn.attn.out_proj.bias, layers.2.1.32.attn.sr.weight, layers.2.1.32.attn.sr.bias, layers.2.1.32.attn.norm.weight, layers.2.1.32.attn.norm.bias, layers.2.1.32.norm2.weight, layers.2.1.32.norm2.bias, layers.2.1.32.ffn.layers.0.weight, layers.2.1.32.ffn.layers.0.bias, layers.2.1.32.ffn.layers.1.weight, layers.2.1.32.ffn.layers.1.bias, layers.2.1.32.ffn.layers.4.weight, layers.2.1.32.ffn.layers.4.bias, layers.2.1.33.norm1.weight, layers.2.1.33.norm1.bias, layers.2.1.33.attn.attn.in_proj_weight, layers.2.1.33.attn.attn.in_proj_bias, layers.2.1.33.attn.attn.out_proj.weight, layers.2.1.33.attn.attn.out_proj.bias, layers.2.1.33.attn.sr.weight, layers.2.1.33.attn.sr.bias, layers.2.1.33.attn.norm.weight, layers.2.1.33.attn.norm.bias, layers.2.1.33.norm2.weight, layers.2.1.33.norm2.bias, layers.2.1.33.ffn.layers.0.weight, layers.2.1.33.ffn.layers.0.bias, layers.2.1.33.ffn.layers.1.weight, layers.2.1.33.ffn.layers.1.bias, layers.2.1.33.ffn.layers.4.weight, layers.2.1.33.ffn.layers.4.bias, layers.2.1.34.norm1.weight, layers.2.1.34.norm1.bias, layers.2.1.34.attn.attn.in_proj_weight, layers.2.1.34.attn.attn.in_proj_bias, layers.2.1.34.attn.attn.out_proj.weight, layers.2.1.34.attn.attn.out_proj.bias, layers.2.1.34.attn.sr.weight, layers.2.1.34.attn.sr.bias, layers.2.1.34.attn.norm.weight, layers.2.1.34.attn.norm.bias, layers.2.1.34.norm2.weight, layers.2.1.34.norm2.bias, layers.2.1.34.ffn.layers.0.weight, layers.2.1.34.ffn.layers.0.bias, layers.2.1.34.ffn.layers.1.weight, layers.2.1.34.ffn.layers.1.bias, layers.2.1.34.ffn.layers.4.weight, layers.2.1.34.ffn.layers.4.bias, layers.2.1.35.norm1.weight, layers.2.1.35.norm1.bias, layers.2.1.35.attn.attn.in_proj_weight, layers.2.1.35.attn.attn.in_proj_bias, layers.2.1.35.attn.attn.out_proj.weight, layers.2.1.35.attn.attn.out_proj.bias, layers.2.1.35.attn.sr.weight, layers.2.1.35.attn.sr.bias, layers.2.1.35.attn.norm.weight, layers.2.1.35.attn.norm.bias, layers.2.1.35.norm2.weight, layers.2.1.35.norm2.bias, layers.2.1.35.ffn.layers.0.weight, layers.2.1.35.ffn.layers.0.bias, layers.2.1.35.ffn.layers.1.weight, layers.2.1.35.ffn.layers.1.bias, layers.2.1.35.ffn.layers.4.weight, layers.2.1.35.ffn.layers.4.bias, layers.2.1.36.norm1.weight, layers.2.1.36.norm1.bias, layers.2.1.36.attn.attn.in_proj_weight, layers.2.1.36.attn.attn.in_proj_bias, layers.2.1.36.attn.attn.out_proj.weight, layers.2.1.36.attn.attn.out_proj.bias, layers.2.1.36.attn.sr.weight, layers.2.1.36.attn.sr.bias, layers.2.1.36.attn.norm.weight, layers.2.1.36.attn.norm.bias, layers.2.1.36.norm2.weight, layers.2.1.36.norm2.bias, layers.2.1.36.ffn.layers.0.weight, layers.2.1.36.ffn.layers.0.bias, layers.2.1.36.ffn.layers.1.weight, layers.2.1.36.ffn.layers.1.bias, layers.2.1.36.ffn.layers.4.weight, layers.2.1.36.ffn.layers.4.bias, layers.2.1.37.norm1.weight, layers.2.1.37.norm1.bias, layers.2.1.37.attn.attn.in_proj_weight, layers.2.1.37.attn.attn.in_proj_bias, layers.2.1.37.attn.attn.out_proj.weight, layers.2.1.37.attn.attn.out_proj.bias, layers.2.1.37.attn.sr.weight, layers.2.1.37.attn.sr.bias, layers.2.1.37.attn.norm.weight, layers.2.1.37.attn.norm.bias, layers.2.1.37.norm2.weight, layers.2.1.37.norm2.bias, layers.2.1.37.ffn.layers.0.weight, layers.2.1.37.ffn.layers.0.bias, layers.2.1.37.ffn.layers.1.weight, layers.2.1.37.ffn.layers.1.bias, layers.2.1.37.ffn.layers.4.weight, layers.2.1.37.ffn.layers.4.bias, layers.2.1.38.norm1.weight, layers.2.1.38.norm1.bias, layers.2.1.38.attn.attn.in_proj_weight, layers.2.1.38.attn.attn.in_proj_bias, layers.2.1.38.attn.attn.out_proj.weight, layers.2.1.38.attn.attn.out_proj.bias, layers.2.1.38.attn.sr.weight, layers.2.1.38.attn.sr.bias, layers.2.1.38.attn.norm.weight, layers.2.1.38.attn.norm.bias, layers.2.1.38.norm2.weight, layers.2.1.38.norm2.bias, layers.2.1.38.ffn.layers.0.weight, layers.2.1.38.ffn.layers.0.bias, layers.2.1.38.ffn.layers.1.weight, layers.2.1.38.ffn.layers.1.bias, layers.2.1.38.ffn.layers.4.weight, layers.2.1.38.ffn.layers.4.bias, layers.2.1.39.norm1.weight, layers.2.1.39.norm1.bias, layers.2.1.39.attn.attn.in_proj_weight, layers.2.1.39.attn.attn.in_proj_bias, layers.2.1.39.attn.attn.out_proj.weight, layers.2.1.39.attn.attn.out_proj.bias, layers.2.1.39.attn.sr.weight, layers.2.1.39.attn.sr.bias, layers.2.1.39.attn.norm.weight, layers.2.1.39.attn.norm.bias, layers.2.1.39.norm2.weight, layers.2.1.39.norm2.bias, layers.2.1.39.ffn.layers.0.weight, layers.2.1.39.ffn.layers.0.bias, layers.2.1.39.ffn.layers.1.weight, layers.2.1.39.ffn.layers.1.bias, layers.2.1.39.ffn.layers.4.weight, layers.2.1.39.ffn.layers.4.bias, layers.2.2.weight, layers.2.2.bias, layers.3.0.projection.weight, layers.3.0.projection.bias, layers.3.0.norm.weight, layers.3.0.norm.bias, layers.3.1.0.norm1.weight, layers.3.1.0.norm1.bias, layers.3.1.0.attn.attn.in_proj_weight, layers.3.1.0.attn.attn.in_proj_bias, layers.3.1.0.attn.attn.out_proj.weight, layers.3.1.0.attn.attn.out_proj.bias, layers.3.1.0.norm2.weight, layers.3.1.0.norm2.bias, layers.3.1.0.ffn.layers.0.weight, layers.3.1.0.ffn.layers.0.bias, layers.3.1.0.ffn.layers.1.weight, layers.3.1.0.ffn.layers.1.bias, layers.3.1.0.ffn.layers.4.weight, layers.3.1.0.ffn.layers.4.bias, layers.3.1.1.norm1.weight, layers.3.1.1.norm1.bias, layers.3.1.1.attn.attn.in_proj_weight, layers.3.1.1.attn.attn.in_proj_bias, layers.3.1.1.attn.attn.out_proj.weight, layers.3.1.1.attn.attn.out_proj.bias, layers.3.1.1.norm2.weight, layers.3.1.1.norm2.bias, layers.3.1.1.ffn.layers.0.weight, layers.3.1.1.ffn.layers.0.bias, layers.3.1.1.ffn.layers.1.weight, layers.3.1.1.ffn.layers.1.bias, layers.3.1.1.ffn.layers.4.weight, layers.3.1.1.ffn.layers.4.bias, layers.3.1.2.norm1.weight, layers.3.1.2.norm1.bias, layers.3.1.2.attn.attn.in_proj_weight, layers.3.1.2.attn.attn.in_proj_bias, layers.3.1.2.attn.attn.out_proj.weight, layers.3.1.2.attn.attn.out_proj.bias, layers.3.1.2.norm2.weight, layers.3.1.2.norm2.bias, layers.3.1.2.ffn.layers.0.weight, layers.3.1.2.ffn.layers.0.bias, layers.3.1.2.ffn.layers.1.weight, layers.3.1.2.ffn.layers.1.bias, layers.3.1.2.ffn.layers.4.weight, layers.3.1.2.ffn.layers.4.bias, layers.3.2.weight, layers.3.2.bias\n",
      "\n",
      "03/09 10:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth\n",
      "03/09 10:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth\" to /root/.cache/torch/hub/checkpoints/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 10:17:52 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token, backbone.pos_embed, backbone.patch_embed.projection.weight, backbone.patch_embed.projection.bias, backbone.layers.0.ln1.weight, backbone.layers.0.ln1.bias, backbone.layers.0.attn.attn.in_proj_weight, backbone.layers.0.attn.attn.in_proj_bias, backbone.layers.0.attn.attn.out_proj.weight, backbone.layers.0.attn.attn.out_proj.bias, backbone.layers.0.ln2.weight, backbone.layers.0.ln2.bias, backbone.layers.0.ffn.layers.0.0.weight, backbone.layers.0.ffn.layers.0.0.bias, backbone.layers.0.ffn.layers.1.weight, backbone.layers.0.ffn.layers.1.bias, backbone.layers.1.ln1.weight, backbone.layers.1.ln1.bias, backbone.layers.1.attn.attn.in_proj_weight, backbone.layers.1.attn.attn.in_proj_bias, backbone.layers.1.attn.attn.out_proj.weight, backbone.layers.1.attn.attn.out_proj.bias, backbone.layers.1.ln2.weight, backbone.layers.1.ln2.bias, backbone.layers.1.ffn.layers.0.0.weight, backbone.layers.1.ffn.layers.0.0.bias, backbone.layers.1.ffn.layers.1.weight, backbone.layers.1.ffn.layers.1.bias, backbone.layers.2.ln1.weight, backbone.layers.2.ln1.bias, backbone.layers.2.attn.attn.in_proj_weight, backbone.layers.2.attn.attn.in_proj_bias, backbone.layers.2.attn.attn.out_proj.weight, backbone.layers.2.attn.attn.out_proj.bias, backbone.layers.2.ln2.weight, backbone.layers.2.ln2.bias, backbone.layers.2.ffn.layers.0.0.weight, backbone.layers.2.ffn.layers.0.0.bias, backbone.layers.2.ffn.layers.1.weight, backbone.layers.2.ffn.layers.1.bias, backbone.layers.3.ln1.weight, backbone.layers.3.ln1.bias, backbone.layers.3.attn.attn.in_proj_weight, backbone.layers.3.attn.attn.in_proj_bias, backbone.layers.3.attn.attn.out_proj.weight, backbone.layers.3.attn.attn.out_proj.bias, backbone.layers.3.ln2.weight, backbone.layers.3.ln2.bias, backbone.layers.3.ffn.layers.0.0.weight, backbone.layers.3.ffn.layers.0.0.bias, backbone.layers.3.ffn.layers.1.weight, backbone.layers.3.ffn.layers.1.bias, backbone.layers.4.ln1.weight, backbone.layers.4.ln1.bias, backbone.layers.4.attn.attn.in_proj_weight, backbone.layers.4.attn.attn.in_proj_bias, backbone.layers.4.attn.attn.out_proj.weight, backbone.layers.4.attn.attn.out_proj.bias, backbone.layers.4.ln2.weight, backbone.layers.4.ln2.bias, backbone.layers.4.ffn.layers.0.0.weight, backbone.layers.4.ffn.layers.0.0.bias, backbone.layers.4.ffn.layers.1.weight, backbone.layers.4.ffn.layers.1.bias, backbone.layers.5.ln1.weight, backbone.layers.5.ln1.bias, backbone.layers.5.attn.attn.in_proj_weight, backbone.layers.5.attn.attn.in_proj_bias, backbone.layers.5.attn.attn.out_proj.weight, backbone.layers.5.attn.attn.out_proj.bias, backbone.layers.5.ln2.weight, backbone.layers.5.ln2.bias, backbone.layers.5.ffn.layers.0.0.weight, backbone.layers.5.ffn.layers.0.0.bias, backbone.layers.5.ffn.layers.1.weight, backbone.layers.5.ffn.layers.1.bias, backbone.layers.6.ln1.weight, backbone.layers.6.ln1.bias, backbone.layers.6.attn.attn.in_proj_weight, backbone.layers.6.attn.attn.in_proj_bias, backbone.layers.6.attn.attn.out_proj.weight, backbone.layers.6.attn.attn.out_proj.bias, backbone.layers.6.ln2.weight, backbone.layers.6.ln2.bias, backbone.layers.6.ffn.layers.0.0.weight, backbone.layers.6.ffn.layers.0.0.bias, backbone.layers.6.ffn.layers.1.weight, backbone.layers.6.ffn.layers.1.bias, backbone.layers.7.ln1.weight, backbone.layers.7.ln1.bias, backbone.layers.7.attn.attn.in_proj_weight, backbone.layers.7.attn.attn.in_proj_bias, backbone.layers.7.attn.attn.out_proj.weight, backbone.layers.7.attn.attn.out_proj.bias, backbone.layers.7.ln2.weight, backbone.layers.7.ln2.bias, backbone.layers.7.ffn.layers.0.0.weight, backbone.layers.7.ffn.layers.0.0.bias, backbone.layers.7.ffn.layers.1.weight, backbone.layers.7.ffn.layers.1.bias, backbone.layers.8.ln1.weight, backbone.layers.8.ln1.bias, backbone.layers.8.attn.attn.in_proj_weight, backbone.layers.8.attn.attn.in_proj_bias, backbone.layers.8.attn.attn.out_proj.weight, backbone.layers.8.attn.attn.out_proj.bias, backbone.layers.8.ln2.weight, backbone.layers.8.ln2.bias, backbone.layers.8.ffn.layers.0.0.weight, backbone.layers.8.ffn.layers.0.0.bias, backbone.layers.8.ffn.layers.1.weight, backbone.layers.8.ffn.layers.1.bias, backbone.layers.9.ln1.weight, backbone.layers.9.ln1.bias, backbone.layers.9.attn.attn.in_proj_weight, backbone.layers.9.attn.attn.in_proj_bias, backbone.layers.9.attn.attn.out_proj.weight, backbone.layers.9.attn.attn.out_proj.bias, backbone.layers.9.ln2.weight, backbone.layers.9.ln2.bias, backbone.layers.9.ffn.layers.0.0.weight, backbone.layers.9.ffn.layers.0.0.bias, backbone.layers.9.ffn.layers.1.weight, backbone.layers.9.ffn.layers.1.bias, backbone.layers.10.ln1.weight, backbone.layers.10.ln1.bias, backbone.layers.10.attn.attn.in_proj_weight, backbone.layers.10.attn.attn.in_proj_bias, backbone.layers.10.attn.attn.out_proj.weight, backbone.layers.10.attn.attn.out_proj.bias, backbone.layers.10.ln2.weight, backbone.layers.10.ln2.bias, backbone.layers.10.ffn.layers.0.0.weight, backbone.layers.10.ffn.layers.0.0.bias, backbone.layers.10.ffn.layers.1.weight, backbone.layers.10.ffn.layers.1.bias, backbone.layers.11.ln1.weight, backbone.layers.11.ln1.bias, backbone.layers.11.attn.attn.in_proj_weight, backbone.layers.11.attn.attn.in_proj_bias, backbone.layers.11.attn.attn.out_proj.weight, backbone.layers.11.attn.attn.out_proj.bias, backbone.layers.11.ln2.weight, backbone.layers.11.ln2.bias, backbone.layers.11.ffn.layers.0.0.weight, backbone.layers.11.ffn.layers.0.0.bias, backbone.layers.11.ffn.layers.1.weight, backbone.layers.11.ffn.layers.1.bias, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.psp_modules.0.1.conv.weight, decode_head.psp_modules.0.1.bn.weight, decode_head.psp_modules.0.1.bn.bias, decode_head.psp_modules.0.1.bn.running_mean, decode_head.psp_modules.0.1.bn.running_var, decode_head.psp_modules.0.1.bn.num_batches_tracked, decode_head.psp_modules.1.1.conv.weight, decode_head.psp_modules.1.1.bn.weight, decode_head.psp_modules.1.1.bn.bias, decode_head.psp_modules.1.1.bn.running_mean, decode_head.psp_modules.1.1.bn.running_var, decode_head.psp_modules.1.1.bn.num_batches_tracked, decode_head.psp_modules.2.1.conv.weight, decode_head.psp_modules.2.1.bn.weight, decode_head.psp_modules.2.1.bn.bias, decode_head.psp_modules.2.1.bn.running_mean, decode_head.psp_modules.2.1.bn.running_var, decode_head.psp_modules.2.1.bn.num_batches_tracked, decode_head.psp_modules.3.1.conv.weight, decode_head.psp_modules.3.1.bn.weight, decode_head.psp_modules.3.1.bn.bias, decode_head.psp_modules.3.1.bn.running_mean, decode_head.psp_modules.3.1.bn.running_var, decode_head.psp_modules.3.1.bn.num_batches_tracked, decode_head.bottleneck.conv.weight, decode_head.bottleneck.bn.weight, decode_head.bottleneck.bn.bias, decode_head.bottleneck.bn.running_mean, decode_head.bottleneck.bn.running_var, decode_head.bottleneck.bn.num_batches_tracked, decode_head.lateral_convs.0.conv.weight, decode_head.lateral_convs.0.bn.weight, decode_head.lateral_convs.0.bn.bias, decode_head.lateral_convs.0.bn.running_mean, decode_head.lateral_convs.0.bn.running_var, decode_head.lateral_convs.0.bn.num_batches_tracked, decode_head.lateral_convs.1.conv.weight, decode_head.lateral_convs.1.bn.weight, decode_head.lateral_convs.1.bn.bias, decode_head.lateral_convs.1.bn.running_mean, decode_head.lateral_convs.1.bn.running_var, decode_head.lateral_convs.1.bn.num_batches_tracked, decode_head.lateral_convs.2.conv.weight, decode_head.lateral_convs.2.bn.weight, decode_head.lateral_convs.2.bn.bias, decode_head.lateral_convs.2.bn.running_mean, decode_head.lateral_convs.2.bn.running_var, decode_head.lateral_convs.2.bn.num_batches_tracked, decode_head.fpn_convs.0.conv.weight, decode_head.fpn_convs.0.bn.weight, decode_head.fpn_convs.0.bn.bias, decode_head.fpn_convs.0.bn.running_mean, decode_head.fpn_convs.0.bn.running_var, decode_head.fpn_convs.0.bn.num_batches_tracked, decode_head.fpn_convs.1.conv.weight, decode_head.fpn_convs.1.bn.weight, decode_head.fpn_convs.1.bn.bias, decode_head.fpn_convs.1.bn.running_mean, decode_head.fpn_convs.1.bn.running_var, decode_head.fpn_convs.1.bn.num_batches_tracked, decode_head.fpn_convs.2.conv.weight, decode_head.fpn_convs.2.bn.weight, decode_head.fpn_convs.2.bn.bias, decode_head.fpn_convs.2.bn.running_mean, decode_head.fpn_convs.2.bn.running_var, decode_head.fpn_convs.2.bn.num_batches_tracked, decode_head.fpn_bottleneck.conv.weight, decode_head.fpn_bottleneck.bn.weight, decode_head.fpn_bottleneck.bn.bias, decode_head.fpn_bottleneck.bn.running_mean, decode_head.fpn_bottleneck.bn.running_var, decode_head.fpn_bottleneck.bn.num_batches_tracked, auxiliary_head.conv_seg.weight, auxiliary_head.conv_seg.bias, auxiliary_head.convs.0.conv.weight, auxiliary_head.convs.0.bn.weight, auxiliary_head.convs.0.bn.bias, auxiliary_head.convs.0.bn.running_mean, auxiliary_head.convs.0.bn.running_var, auxiliary_head.convs.0.bn.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: conv_seg.weight, conv_seg.bias, psp_modules.0.1.conv.weight, psp_modules.0.1.bn.weight, psp_modules.0.1.bn.bias, psp_modules.0.1.bn.running_mean, psp_modules.0.1.bn.running_var, psp_modules.1.1.conv.weight, psp_modules.1.1.bn.weight, psp_modules.1.1.bn.bias, psp_modules.1.1.bn.running_mean, psp_modules.1.1.bn.running_var, psp_modules.2.1.conv.weight, psp_modules.2.1.bn.weight, psp_modules.2.1.bn.bias, psp_modules.2.1.bn.running_mean, psp_modules.2.1.bn.running_var, psp_modules.3.1.conv.weight, psp_modules.3.1.bn.weight, psp_modules.3.1.bn.bias, psp_modules.3.1.bn.running_mean, psp_modules.3.1.bn.running_var, bottleneck.conv.weight, bottleneck.bn.weight, bottleneck.bn.bias, bottleneck.bn.running_mean, bottleneck.bn.running_var, lateral_convs.0.conv.weight, lateral_convs.0.bn.weight, lateral_convs.0.bn.bias, lateral_convs.0.bn.running_mean, lateral_convs.0.bn.running_var, lateral_convs.1.conv.weight, lateral_convs.1.bn.weight, lateral_convs.1.bn.bias, lateral_convs.1.bn.running_mean, lateral_convs.1.bn.running_var, lateral_convs.2.conv.weight, lateral_convs.2.bn.weight, lateral_convs.2.bn.bias, lateral_convs.2.bn.running_mean, lateral_convs.2.bn.running_var, fpn_convs.0.conv.weight, fpn_convs.0.bn.weight, fpn_convs.0.bn.bias, fpn_convs.0.bn.running_mean, fpn_convs.0.bn.running_var, fpn_convs.1.conv.weight, fpn_convs.1.bn.weight, fpn_convs.1.bn.bias, fpn_convs.1.bn.running_mean, fpn_convs.1.bn.running_var, fpn_convs.2.conv.weight, fpn_convs.2.bn.weight, fpn_convs.2.bn.bias, fpn_convs.2.bn.running_mean, fpn_convs.2.bn.running_var, fpn_bottleneck.conv.weight, fpn_bottleneck.bn.weight, fpn_bottleneck.bn.bias, fpn_bottleneck.bn.running_mean, fpn_bottleneck.bn.running_var\n",
      "\n",
      "03/09 10:17:52 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/09 10:17:52 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/09 10:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /kaggle/working/checkpoint.\n",
      "03/09 10:19:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  100/40000]  base_lr: 3.9627e-06 lr: 3.9627e-06  eta: 9:12:27  time: 0.8296  data_time: 0.0672  memory: 5632  loss: 1.3292  decode.loss_ce: 1.3292  decode.acc_seg: 25.5431\n",
      "03/09 10:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  200/40000]  base_lr: 7.9654e-06 lr: 7.9654e-06  eta: 9:10:58  time: 0.8322  data_time: 0.0705  memory: 5632  loss: 1.2209  decode.loss_ce: 1.2209  decode.acc_seg: 47.7847\n",
      "03/09 10:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  300/40000]  base_lr: 1.1968e-05 lr: 1.1968e-05  eta: 9:09:38  time: 0.8623  data_time: 0.1020  memory: 5632  loss: 1.1457  decode.loss_ce: 1.1457  decode.acc_seg: 21.2434\n",
      "03/09 10:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  400/40000]  base_lr: 1.5971e-05 lr: 1.5971e-05  eta: 9:06:23  time: 0.8253  data_time: 0.0638  memory: 5634  loss: 1.0437  decode.loss_ce: 1.0437  decode.acc_seg: 93.7078\n",
      "03/09 10:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  500/40000]  base_lr: 1.9973e-05 lr: 1.9973e-05  eta: 9:04:16  time: 0.8577  data_time: 0.0978  memory: 5634  loss: 1.1003  decode.loss_ce: 1.1003  decode.acc_seg: 51.6027\n",
      "03/09 10:26:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  600/40000]  base_lr: 2.3976e-05 lr: 2.3976e-05  eta: 9:02:37  time: 0.8092  data_time: 0.0483  memory: 5634  loss: 0.9546  decode.loss_ce: 0.9546  decode.acc_seg: 53.7241\n",
      "03/09 10:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  700/40000]  base_lr: 2.7979e-05 lr: 2.7979e-05  eta: 9:00:36  time: 0.8096  data_time: 0.0506  memory: 5634  loss: 0.9681  decode.loss_ce: 0.9681  decode.acc_seg: 41.4927\n",
      "03/09 10:27:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 10:28:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  800/40000]  base_lr: 3.1981e-05 lr: 3.1981e-05  eta: 8:56:12  time: 0.7801  data_time: 0.0221  memory: 5634  loss: 0.7567  decode.loss_ce: 0.7567  decode.acc_seg: 74.9872\n",
      "03/09 10:30:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  900/40000]  base_lr: 3.5984e-05 lr: 3.5984e-05  eta: 8:51:56  time: 0.7784  data_time: 0.0219  memory: 5633  loss: 0.7694  decode.loss_ce: 0.7694  decode.acc_seg: 23.5113\n",
      "03/09 10:31:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 10:31:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1000/40000]  base_lr: 3.9987e-05 lr: 3.9987e-05  eta: 8:48:09  time: 0.7786  data_time: 0.0215  memory: 5634  loss: 0.8416  decode.loss_ce: 0.8416  decode.acc_seg: 74.9908\n",
      "03/09 10:32:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1100/40000]  base_lr: 4.3989e-05 lr: 4.3989e-05  eta: 8:44:49  time: 0.7785  data_time: 0.0209  memory: 5632  loss: 0.7938  decode.loss_ce: 0.7938  decode.acc_seg: 68.5985\n",
      "03/09 10:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1200/40000]  base_lr: 4.7992e-05 lr: 4.7992e-05  eta: 8:41:54  time: 0.7787  data_time: 0.0214  memory: 5634  loss: 0.8374  decode.loss_ce: 0.8374  decode.acc_seg: 45.6831\n",
      "03/09 10:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1300/40000]  base_lr: 5.1995e-05 lr: 5.1995e-05  eta: 8:39:11  time: 0.7802  data_time: 0.0224  memory: 5634  loss: 0.8890  decode.loss_ce: 0.8890  decode.acc_seg: 57.2248\n",
      "03/09 10:36:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1400/40000]  base_lr: 5.5997e-05 lr: 5.5997e-05  eta: 8:36:38  time: 0.7779  data_time: 0.0216  memory: 5632  loss: 0.9730  decode.loss_ce: 0.9730  decode.acc_seg: 77.0855\n",
      "03/09 10:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1500/40000]  base_lr: 6.0000e-05 lr: 6.0000e-05  eta: 8:34:19  time: 0.7868  data_time: 0.0225  memory: 5634  loss: 0.7300  decode.loss_ce: 0.7300  decode.acc_seg: 60.6765\n",
      "03/09 10:39:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1600/40000]  base_lr: 5.9963e-05 lr: 5.9963e-05  eta: 8:32:09  time: 0.7793  data_time: 0.0220  memory: 5634  loss: 1.2291  decode.loss_ce: 1.2291  decode.acc_seg: 13.8772\n",
      "03/09 10:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1700/40000]  base_lr: 5.9925e-05 lr: 5.9925e-05  eta: 8:30:08  time: 0.7889  data_time: 0.0230  memory: 5634  loss: 0.9818  decode.loss_ce: 0.9818  decode.acc_seg: 72.8710\n",
      "03/09 10:41:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1800/40000]  base_lr: 5.9887e-05 lr: 5.9887e-05  eta: 8:28:13  time: 0.8006  data_time: 0.0226  memory: 5632  loss: 0.6676  decode.loss_ce: 0.6676  decode.acc_seg: 78.4766\n",
      "03/09 10:43:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1900/40000]  base_lr: 5.9849e-05 lr: 5.9849e-05  eta: 8:26:17  time: 0.7806  data_time: 0.0230  memory: 5632  loss: 0.6660  decode.loss_ce: 0.6660  decode.acc_seg: 58.5721\n",
      "03/09 10:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 10:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2000/40000]  base_lr: 5.9811e-05 lr: 5.9811e-05  eta: 8:24:26  time: 0.7787  data_time: 0.0226  memory: 5634  loss: 0.8358  decode.loss_ce: 0.8358  decode.acc_seg: 40.7555\n",
      "03/09 10:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2100/40000]  base_lr: 5.9773e-05 lr: 5.9773e-05  eta: 8:22:36  time: 0.7808  data_time: 0.0217  memory: 5632  loss: 0.8787  decode.loss_ce: 0.8787  decode.acc_seg: 88.7033\n",
      "03/09 10:47:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2200/40000]  base_lr: 5.9735e-05 lr: 5.9735e-05  eta: 8:20:52  time: 0.7827  data_time: 0.0228  memory: 5632  loss: 0.8660  decode.loss_ce: 0.8660  decode.acc_seg: 66.5555\n",
      "03/09 10:48:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2300/40000]  base_lr: 5.9698e-05 lr: 5.9698e-05  eta: 8:19:09  time: 0.7782  data_time: 0.0220  memory: 5632  loss: 0.6405  decode.loss_ce: 0.6405  decode.acc_seg: 46.0309\n",
      "03/09 10:49:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2400/40000]  base_lr: 5.9660e-05 lr: 5.9660e-05  eta: 8:17:28  time: 0.7818  data_time: 0.0218  memory: 5632  loss: 0.7720  decode.loss_ce: 0.7720  decode.acc_seg: 49.4848\n",
      "03/09 10:50:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2500/40000]  base_lr: 5.9622e-05 lr: 5.9622e-05  eta: 8:15:49  time: 0.7795  data_time: 0.0220  memory: 5633  loss: 0.5890  decode.loss_ce: 0.5890  decode.acc_seg: 80.3012\n",
      "03/09 10:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2600/40000]  base_lr: 5.9584e-05 lr: 5.9584e-05  eta: 8:14:12  time: 0.7797  data_time: 0.0215  memory: 5634  loss: 0.8899  decode.loss_ce: 0.8899  decode.acc_seg: 51.1609\n",
      "03/09 10:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2700/40000]  base_lr: 5.9546e-05 lr: 5.9546e-05  eta: 8:12:36  time: 0.7806  data_time: 0.0221  memory: 5632  loss: 0.6435  decode.loss_ce: 0.6435  decode.acc_seg: 65.6246\n",
      "03/09 10:54:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2800/40000]  base_lr: 5.9508e-05 lr: 5.9508e-05  eta: 8:11:01  time: 0.7783  data_time: 0.0217  memory: 5633  loss: 0.6449  decode.loss_ce: 0.6449  decode.acc_seg: 87.3590\n",
      "03/09 10:56:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2900/40000]  base_lr: 5.9470e-05 lr: 5.9470e-05  eta: 8:09:27  time: 0.7827  data_time: 0.0225  memory: 5634  loss: 0.5835  decode.loss_ce: 0.5835  decode.acc_seg: 58.4722\n",
      "03/09 10:57:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 10:57:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3000/40000]  base_lr: 5.9433e-05 lr: 5.9433e-05  eta: 8:07:53  time: 0.7771  data_time: 0.0213  memory: 5634  loss: 0.6408  decode.loss_ce: 0.6408  decode.acc_seg: 76.6691\n",
      "03/09 10:58:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3100/40000]  base_lr: 5.9395e-05 lr: 5.9395e-05  eta: 8:06:24  time: 0.7866  data_time: 0.0223  memory: 5634  loss: 0.7963  decode.loss_ce: 0.7963  decode.acc_seg: 42.9656\n",
      "03/09 11:00:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3200/40000]  base_lr: 5.9357e-05 lr: 5.9357e-05  eta: 8:04:56  time: 0.7813  data_time: 0.0215  memory: 5632  loss: 0.8364  decode.loss_ce: 0.8364  decode.acc_seg: 45.0281\n",
      "03/09 11:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3300/40000]  base_lr: 5.9319e-05 lr: 5.9319e-05  eta: 8:03:26  time: 0.7806  data_time: 0.0222  memory: 5634  loss: 0.6866  decode.loss_ce: 0.6866  decode.acc_seg: 88.9358\n",
      "03/09 11:02:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3400/40000]  base_lr: 5.9281e-05 lr: 5.9281e-05  eta: 8:01:56  time: 0.7782  data_time: 0.0210  memory: 5632  loss: 0.7001  decode.loss_ce: 0.7001  decode.acc_seg: 74.2088\n",
      "03/09 11:03:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3500/40000]  base_lr: 5.9243e-05 lr: 5.9243e-05  eta: 8:00:26  time: 0.7790  data_time: 0.0219  memory: 5632  loss: 0.8104  decode.loss_ce: 0.8104  decode.acc_seg: 86.7723\n",
      "03/09 11:05:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3600/40000]  base_lr: 5.9205e-05 lr: 5.9205e-05  eta: 7:59:00  time: 0.7826  data_time: 0.0219  memory: 5633  loss: 0.6452  decode.loss_ce: 0.6452  decode.acc_seg: 65.6875\n",
      "03/09 11:06:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3700/40000]  base_lr: 5.9168e-05 lr: 5.9168e-05  eta: 7:57:31  time: 0.7824  data_time: 0.0218  memory: 5634  loss: 0.6598  decode.loss_ce: 0.6598  decode.acc_seg: 64.5718\n",
      "03/09 11:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3800/40000]  base_lr: 5.9130e-05 lr: 5.9130e-05  eta: 7:56:04  time: 0.7863  data_time: 0.0223  memory: 5634  loss: 1.0372  decode.loss_ce: 1.0372  decode.acc_seg: 66.0803\n",
      "03/09 11:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3900/40000]  base_lr: 5.9092e-05 lr: 5.9092e-05  eta: 7:54:36  time: 0.7779  data_time: 0.0217  memory: 5632  loss: 0.5619  decode.loss_ce: 0.5619  decode.acc_seg: 63.3096\n",
      "03/09 11:10:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 11:10:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4000/40000]  base_lr: 5.9054e-05 lr: 5.9054e-05  eta: 7:53:09  time: 0.7785  data_time: 0.0212  memory: 5634  loss: 0.6464  decode.loss_ce: 0.6464  decode.acc_seg: 76.0948\n",
      "03/09 11:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4100/40000]  base_lr: 5.9016e-05 lr: 5.9016e-05  eta: 7:51:42  time: 0.7810  data_time: 0.0223  memory: 5632  loss: 0.7330  decode.loss_ce: 0.7330  decode.acc_seg: 78.8390\n",
      "03/09 11:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4200/40000]  base_lr: 5.8978e-05 lr: 5.8978e-05  eta: 7:50:17  time: 0.7776  data_time: 0.0215  memory: 5632  loss: 0.6465  decode.loss_ce: 0.6465  decode.acc_seg: 74.9875\n",
      "03/09 11:14:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4300/40000]  base_lr: 5.8940e-05 lr: 5.8940e-05  eta: 7:48:52  time: 0.7800  data_time: 0.0220  memory: 5632  loss: 0.6191  decode.loss_ce: 0.6191  decode.acc_seg: 75.1520\n",
      "03/09 11:15:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4400/40000]  base_lr: 5.8903e-05 lr: 5.8903e-05  eta: 7:47:27  time: 0.7847  data_time: 0.0222  memory: 5634  loss: 0.5362  decode.loss_ce: 0.5362  decode.acc_seg: 58.4372\n",
      "03/09 11:16:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4500/40000]  base_lr: 5.8865e-05 lr: 5.8865e-05  eta: 7:46:02  time: 0.7794  data_time: 0.0220  memory: 5634  loss: 0.9669  decode.loss_ce: 0.9669  decode.acc_seg: 31.9046\n",
      "03/09 11:18:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4600/40000]  base_lr: 5.8827e-05 lr: 5.8827e-05  eta: 7:44:38  time: 0.7825  data_time: 0.0222  memory: 5634  loss: 0.9006  decode.loss_ce: 0.9006  decode.acc_seg: 65.6822\n",
      "03/09 11:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4700/40000]  base_lr: 5.8789e-05 lr: 5.8789e-05  eta: 7:43:13  time: 0.7797  data_time: 0.0214  memory: 5634  loss: 0.7407  decode.loss_ce: 0.7407  decode.acc_seg: 72.5194\n",
      "03/09 11:20:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4800/40000]  base_lr: 5.8751e-05 lr: 5.8751e-05  eta: 7:41:49  time: 0.7775  data_time: 0.0208  memory: 5634  loss: 0.6951  decode.loss_ce: 0.6951  decode.acc_seg: 92.5245\n",
      "03/09 11:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4900/40000]  base_lr: 5.8713e-05 lr: 5.8713e-05  eta: 7:40:25  time: 0.7770  data_time: 0.0218  memory: 5634  loss: 0.6054  decode.loss_ce: 0.6054  decode.acc_seg: 81.1190\n",
      "03/09 11:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 11:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5000/40000]  base_lr: 5.8675e-05 lr: 5.8675e-05  eta: 7:39:01  time: 0.7769  data_time: 0.0212  memory: 5632  loss: 0.6063  decode.loss_ce: 0.6063  decode.acc_seg: 72.6082\n",
      "03/09 11:24:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5100/40000]  base_lr: 5.8638e-05 lr: 5.8638e-05  eta: 7:37:37  time: 0.7802  data_time: 0.0217  memory: 5633  loss: 0.6412  decode.loss_ce: 0.6412  decode.acc_seg: 69.6726\n",
      "03/09 11:26:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5200/40000]  base_lr: 5.8600e-05 lr: 5.8600e-05  eta: 7:36:14  time: 0.7785  data_time: 0.0215  memory: 5634  loss: 0.7471  decode.loss_ce: 0.7471  decode.acc_seg: 60.2410\n",
      "03/09 11:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5300/40000]  base_lr: 5.8562e-05 lr: 5.8562e-05  eta: 7:34:52  time: 0.7808  data_time: 0.0223  memory: 5634  loss: 0.5674  decode.loss_ce: 0.5674  decode.acc_seg: 79.3246\n",
      "03/09 11:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5400/40000]  base_lr: 5.8524e-05 lr: 5.8524e-05  eta: 7:33:31  time: 0.7823  data_time: 0.0218  memory: 5632  loss: 0.4559  decode.loss_ce: 0.4559  decode.acc_seg: 85.3122\n",
      "03/09 11:29:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5500/40000]  base_lr: 5.8486e-05 lr: 5.8486e-05  eta: 7:32:09  time: 0.7833  data_time: 0.0219  memory: 5632  loss: 0.6731  decode.loss_ce: 0.6731  decode.acc_seg: 46.7962\n",
      "03/09 11:31:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5600/40000]  base_lr: 5.8448e-05 lr: 5.8448e-05  eta: 7:30:50  time: 0.7796  data_time: 0.0215  memory: 5633  loss: 0.4052  decode.loss_ce: 0.4052  decode.acc_seg: 86.4232\n",
      "03/09 11:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5700/40000]  base_lr: 5.8410e-05 lr: 5.8410e-05  eta: 7:29:29  time: 0.7855  data_time: 0.0214  memory: 5634  loss: 0.6145  decode.loss_ce: 0.6145  decode.acc_seg: 92.5102\n",
      "03/09 11:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5800/40000]  base_lr: 5.8373e-05 lr: 5.8373e-05  eta: 7:28:08  time: 0.7803  data_time: 0.0215  memory: 5634  loss: 0.6012  decode.loss_ce: 0.6012  decode.acc_seg: 62.8458\n",
      "03/09 11:35:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5900/40000]  base_lr: 5.8335e-05 lr: 5.8335e-05  eta: 7:26:45  time: 0.7768  data_time: 0.0214  memory: 5634  loss: 0.5016  decode.loss_ce: 0.5016  decode.acc_seg: 88.4509\n",
      "03/09 11:36:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 11:36:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6000/40000]  base_lr: 5.8297e-05 lr: 5.8297e-05  eta: 7:25:24  time: 0.7836  data_time: 0.0220  memory: 5632  loss: 1.0364  decode.loss_ce: 1.0364  decode.acc_seg: 82.2543\n",
      "03/09 11:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6100/40000]  base_lr: 5.8259e-05 lr: 5.8259e-05  eta: 7:24:04  time: 0.7832  data_time: 0.0220  memory: 5634  loss: 0.6554  decode.loss_ce: 0.6554  decode.acc_seg: 75.1122\n",
      "03/09 11:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6200/40000]  base_lr: 5.8221e-05 lr: 5.8221e-05  eta: 7:22:45  time: 0.7852  data_time: 0.0222  memory: 5632  loss: 0.5516  decode.loss_ce: 0.5516  decode.acc_seg: 53.6494\n",
      "03/09 11:40:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6300/40000]  base_lr: 5.8183e-05 lr: 5.8183e-05  eta: 7:21:24  time: 0.7781  data_time: 0.0220  memory: 5634  loss: 0.4822  decode.loss_ce: 0.4822  decode.acc_seg: 87.4503\n",
      "03/09 11:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6400/40000]  base_lr: 5.8145e-05 lr: 5.8145e-05  eta: 7:20:03  time: 0.7844  data_time: 0.0227  memory: 5632  loss: 0.4172  decode.loss_ce: 0.4172  decode.acc_seg: 55.9496\n",
      "03/09 11:43:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6500/40000]  base_lr: 5.8108e-05 lr: 5.8108e-05  eta: 7:18:42  time: 0.7805  data_time: 0.0217  memory: 5634  loss: 0.7069  decode.loss_ce: 0.7069  decode.acc_seg: 80.6940\n",
      "03/09 11:44:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6600/40000]  base_lr: 5.8070e-05 lr: 5.8070e-05  eta: 7:17:21  time: 0.7820  data_time: 0.0224  memory: 5634  loss: 0.7087  decode.loss_ce: 0.7087  decode.acc_seg: 90.8641\n",
      "03/09 11:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6700/40000]  base_lr: 5.8032e-05 lr: 5.8032e-05  eta: 7:16:01  time: 0.7792  data_time: 0.0214  memory: 5632  loss: 0.5154  decode.loss_ce: 0.5154  decode.acc_seg: 94.0077\n",
      "03/09 11:46:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6800/40000]  base_lr: 5.7994e-05 lr: 5.7994e-05  eta: 7:14:40  time: 0.7806  data_time: 0.0216  memory: 5632  loss: 0.6711  decode.loss_ce: 0.6711  decode.acc_seg: 60.6775\n",
      "03/09 11:48:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6900/40000]  base_lr: 5.7956e-05 lr: 5.7956e-05  eta: 7:13:19  time: 0.7802  data_time: 0.0214  memory: 5632  loss: 0.5635  decode.loss_ce: 0.5635  decode.acc_seg: 70.8018\n",
      "03/09 11:49:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 11:49:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7000/40000]  base_lr: 5.7918e-05 lr: 5.7918e-05  eta: 7:11:59  time: 0.7810  data_time: 0.0218  memory: 5632  loss: 0.5456  decode.loss_ce: 0.5456  decode.acc_seg: 80.5667\n",
      "03/09 11:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7100/40000]  base_lr: 5.7880e-05 lr: 5.7880e-05  eta: 7:10:38  time: 0.7799  data_time: 0.0211  memory: 5634  loss: 0.6693  decode.loss_ce: 0.6693  decode.acc_seg: 80.8820\n",
      "03/09 11:52:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7200/40000]  base_lr: 5.7843e-05 lr: 5.7843e-05  eta: 7:09:18  time: 0.7823  data_time: 0.0221  memory: 5634  loss: 0.7259  decode.loss_ce: 0.7259  decode.acc_seg: 68.0206\n",
      "03/09 11:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7300/40000]  base_lr: 5.7805e-05 lr: 5.7805e-05  eta: 7:08:00  time: 0.7793  data_time: 0.0216  memory: 5632  loss: 0.4515  decode.loss_ce: 0.4515  decode.acc_seg: 74.9779\n",
      "03/09 11:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7400/40000]  base_lr: 5.7767e-05 lr: 5.7767e-05  eta: 7:06:40  time: 0.7797  data_time: 0.0219  memory: 5632  loss: 0.4254  decode.loss_ce: 0.4254  decode.acc_seg: 80.0321\n",
      "03/09 11:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7500/40000]  base_lr: 5.7729e-05 lr: 5.7729e-05  eta: 7:05:21  time: 0.7904  data_time: 0.0233  memory: 5632  loss: 0.7063  decode.loss_ce: 0.7063  decode.acc_seg: 62.0998\n",
      "03/09 11:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7600/40000]  base_lr: 5.7691e-05 lr: 5.7691e-05  eta: 7:04:02  time: 0.7806  data_time: 0.0224  memory: 5634  loss: 0.4337  decode.loss_ce: 0.4337  decode.acc_seg: 91.8957\n",
      "03/09 11:58:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7700/40000]  base_lr: 5.7653e-05 lr: 5.7653e-05  eta: 7:02:42  time: 0.7841  data_time: 0.0228  memory: 5632  loss: 0.7526  decode.loss_ce: 0.7526  decode.acc_seg: 83.3414\n",
      "03/09 11:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7800/40000]  base_lr: 5.7616e-05 lr: 5.7616e-05  eta: 7:01:23  time: 0.7782  data_time: 0.0216  memory: 5634  loss: 0.4348  decode.loss_ce: 0.4348  decode.acc_seg: 82.4124\n",
      "03/09 12:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7900/40000]  base_lr: 5.7578e-05 lr: 5.7578e-05  eta: 7:00:03  time: 0.7812  data_time: 0.0217  memory: 5634  loss: 0.3147  decode.loss_ce: 0.3147  decode.acc_seg: 95.5239\n",
      "03/09 12:02:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 12:02:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8000/40000]  base_lr: 5.7540e-05 lr: 5.7540e-05  eta: 6:58:43  time: 0.7787  data_time: 0.0221  memory: 5634  loss: 0.4775  decode.loss_ce: 0.4775  decode.acc_seg: 80.8203\n",
      "03/09 12:03:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8100/40000]  base_lr: 5.7502e-05 lr: 5.7502e-05  eta: 6:57:23  time: 0.7821  data_time: 0.0221  memory: 5634  loss: 0.4648  decode.loss_ce: 0.4648  decode.acc_seg: 68.6368\n",
      "03/09 12:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8200/40000]  base_lr: 5.7464e-05 lr: 5.7464e-05  eta: 6:56:03  time: 0.7782  data_time: 0.0216  memory: 5633  loss: 0.6743  decode.loss_ce: 0.6743  decode.acc_seg: 48.1415\n",
      "03/09 12:06:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8300/40000]  base_lr: 5.7426e-05 lr: 5.7426e-05  eta: 6:54:42  time: 0.7803  data_time: 0.0224  memory: 5634  loss: 0.7767  decode.loss_ce: 0.7767  decode.acc_seg: 59.4112\n",
      "03/09 12:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8400/40000]  base_lr: 5.7388e-05 lr: 5.7388e-05  eta: 6:53:23  time: 0.7792  data_time: 0.0219  memory: 5634  loss: 0.5424  decode.loss_ce: 0.5424  decode.acc_seg: 69.8818\n",
      "03/09 12:09:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8500/40000]  base_lr: 5.7351e-05 lr: 5.7351e-05  eta: 6:52:03  time: 0.7778  data_time: 0.0221  memory: 5634  loss: 0.3295  decode.loss_ce: 0.3295  decode.acc_seg: 84.6591\n",
      "03/09 12:10:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8600/40000]  base_lr: 5.7313e-05 lr: 5.7313e-05  eta: 6:50:42  time: 0.7851  data_time: 0.0223  memory: 5634  loss: 0.5398  decode.loss_ce: 0.5398  decode.acc_seg: 72.7219\n",
      "03/09 12:11:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8700/40000]  base_lr: 5.7275e-05 lr: 5.7275e-05  eta: 6:49:22  time: 0.7780  data_time: 0.0216  memory: 5633  loss: 0.7229  decode.loss_ce: 0.7229  decode.acc_seg: 57.0433\n",
      "03/09 12:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8800/40000]  base_lr: 5.7237e-05 lr: 5.7237e-05  eta: 6:48:03  time: 0.7817  data_time: 0.0227  memory: 5634  loss: 0.4046  decode.loss_ce: 0.4046  decode.acc_seg: 79.3055\n",
      "03/09 12:14:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8900/40000]  base_lr: 5.7199e-05 lr: 5.7199e-05  eta: 6:46:43  time: 0.7789  data_time: 0.0223  memory: 5634  loss: 0.3261  decode.loss_ce: 0.3261  decode.acc_seg: 89.0657\n",
      "03/09 12:15:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 12:15:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9000/40000]  base_lr: 5.7161e-05 lr: 5.7161e-05  eta: 6:45:24  time: 0.7810  data_time: 0.0223  memory: 5632  loss: 0.4401  decode.loss_ce: 0.4401  decode.acc_seg: 66.3554\n",
      "03/09 12:16:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9100/40000]  base_lr: 5.7123e-05 lr: 5.7123e-05  eta: 6:44:06  time: 0.7850  data_time: 0.0230  memory: 5634  loss: 0.6038  decode.loss_ce: 0.6038  decode.acc_seg: 75.5156\n",
      "03/09 12:18:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9200/40000]  base_lr: 5.7086e-05 lr: 5.7086e-05  eta: 6:42:48  time: 0.7784  data_time: 0.0213  memory: 5633  loss: 0.5843  decode.loss_ce: 0.5843  decode.acc_seg: 38.5907\n",
      "03/09 12:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9300/40000]  base_lr: 5.7048e-05 lr: 5.7048e-05  eta: 6:41:28  time: 0.7803  data_time: 0.0221  memory: 5634  loss: 0.6285  decode.loss_ce: 0.6285  decode.acc_seg: 93.3142\n",
      "03/09 12:20:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9400/40000]  base_lr: 5.7010e-05 lr: 5.7010e-05  eta: 6:40:08  time: 0.7785  data_time: 0.0217  memory: 5634  loss: 0.4313  decode.loss_ce: 0.4313  decode.acc_seg: 77.0953\n",
      "03/09 12:22:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9500/40000]  base_lr: 5.6972e-05 lr: 5.6972e-05  eta: 6:38:49  time: 0.7817  data_time: 0.0216  memory: 5632  loss: 0.4734  decode.loss_ce: 0.4734  decode.acc_seg: 77.7901\n",
      "03/09 12:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9600/40000]  base_lr: 5.6934e-05 lr: 5.6934e-05  eta: 6:37:28  time: 0.7798  data_time: 0.0222  memory: 5632  loss: 0.5013  decode.loss_ce: 0.5013  decode.acc_seg: 82.6397\n",
      "03/09 12:24:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9700/40000]  base_lr: 5.6896e-05 lr: 5.6896e-05  eta: 6:36:09  time: 0.7811  data_time: 0.0225  memory: 5632  loss: 0.4382  decode.loss_ce: 0.4382  decode.acc_seg: 87.3153\n",
      "03/09 12:26:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9800/40000]  base_lr: 5.6858e-05 lr: 5.6858e-05  eta: 6:34:49  time: 0.7788  data_time: 0.0215  memory: 5632  loss: 0.3874  decode.loss_ce: 0.3874  decode.acc_seg: 77.9545\n",
      "03/09 12:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9900/40000]  base_lr: 5.6821e-05 lr: 5.6821e-05  eta: 6:33:30  time: 0.7834  data_time: 0.0226  memory: 5633  loss: 0.6213  decode.loss_ce: 0.6213  decode.acc_seg: 78.3590\n",
      "03/09 12:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 12:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10000/40000]  base_lr: 5.6783e-05 lr: 5.6783e-05  eta: 6:32:10  time: 0.7789  data_time: 0.0226  memory: 5632  loss: 0.4911  decode.loss_ce: 0.4911  decode.acc_seg: 86.9263\n",
      "03/09 12:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10000 iterations\n",
      "03/09 12:29:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10100/40000]  base_lr: 5.6745e-05 lr: 5.6745e-05  eta: 6:31:05  time: 0.7832  data_time: 0.0234  memory: 5634  loss: 0.7063  decode.loss_ce: 0.7063  decode.acc_seg: 95.2656\n",
      "03/09 12:31:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10200/40000]  base_lr: 5.6707e-05 lr: 5.6707e-05  eta: 6:29:46  time: 0.7838  data_time: 0.0229  memory: 5634  loss: 0.3439  decode.loss_ce: 0.3439  decode.acc_seg: 97.3849\n",
      "03/09 12:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10300/40000]  base_lr: 5.6669e-05 lr: 5.6669e-05  eta: 6:28:26  time: 0.7809  data_time: 0.0224  memory: 5634  loss: 0.4534  decode.loss_ce: 0.4534  decode.acc_seg: 79.5528\n",
      "03/09 12:33:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10400/40000]  base_lr: 5.6631e-05 lr: 5.6631e-05  eta: 6:27:07  time: 0.7819  data_time: 0.0227  memory: 5634  loss: 0.5626  decode.loss_ce: 0.5626  decode.acc_seg: 74.2727\n",
      "03/09 12:35:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10500/40000]  base_lr: 5.6593e-05 lr: 5.6593e-05  eta: 6:25:48  time: 0.7793  data_time: 0.0220  memory: 5634  loss: 0.2846  decode.loss_ce: 0.2846  decode.acc_seg: 80.1997\n",
      "03/09 12:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10600/40000]  base_lr: 5.6556e-05 lr: 5.6556e-05  eta: 6:24:30  time: 0.7805  data_time: 0.0221  memory: 5634  loss: 0.6165  decode.loss_ce: 0.6165  decode.acc_seg: 74.4174\n",
      "03/09 12:37:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10700/40000]  base_lr: 5.6518e-05 lr: 5.6518e-05  eta: 6:23:11  time: 0.7840  data_time: 0.0234  memory: 5634  loss: 0.6080  decode.loss_ce: 0.6080  decode.acc_seg: 54.3741\n",
      "03/09 12:39:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10800/40000]  base_lr: 5.6480e-05 lr: 5.6480e-05  eta: 6:21:52  time: 0.7816  data_time: 0.0227  memory: 5632  loss: 0.5428  decode.loss_ce: 0.5428  decode.acc_seg: 87.1596\n",
      "03/09 12:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10900/40000]  base_lr: 5.6442e-05 lr: 5.6442e-05  eta: 6:20:33  time: 0.7807  data_time: 0.0223  memory: 5632  loss: 0.5758  decode.loss_ce: 0.5758  decode.acc_seg: 84.3426\n",
      "03/09 12:41:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 12:41:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11000/40000]  base_lr: 5.6404e-05 lr: 5.6404e-05  eta: 6:19:14  time: 0.7824  data_time: 0.0225  memory: 5632  loss: 0.4564  decode.loss_ce: 0.4564  decode.acc_seg: 75.0556\n",
      "03/09 12:43:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11100/40000]  base_lr: 5.6366e-05 lr: 5.6366e-05  eta: 6:17:54  time: 0.7798  data_time: 0.0221  memory: 5632  loss: 0.4587  decode.loss_ce: 0.4587  decode.acc_seg: 80.3877\n",
      "03/09 12:44:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11200/40000]  base_lr: 5.6328e-05 lr: 5.6328e-05  eta: 6:16:35  time: 0.7907  data_time: 0.0229  memory: 5634  loss: 0.4828  decode.loss_ce: 0.4828  decode.acc_seg: 88.7982\n",
      "03/09 12:45:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11300/40000]  base_lr: 5.6291e-05 lr: 5.6291e-05  eta: 6:15:15  time: 0.7778  data_time: 0.0216  memory: 5634  loss: 0.3834  decode.loss_ce: 0.3834  decode.acc_seg: 86.0913\n",
      "03/09 12:46:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11400/40000]  base_lr: 5.6253e-05 lr: 5.6253e-05  eta: 6:13:56  time: 0.7794  data_time: 0.0221  memory: 5632  loss: 0.4896  decode.loss_ce: 0.4896  decode.acc_seg: 91.7229\n",
      "03/09 12:48:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11500/40000]  base_lr: 5.6215e-05 lr: 5.6215e-05  eta: 6:12:37  time: 0.7813  data_time: 0.0219  memory: 5634  loss: 0.5506  decode.loss_ce: 0.5506  decode.acc_seg: 81.4525\n",
      "03/09 12:49:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11600/40000]  base_lr: 5.6177e-05 lr: 5.6177e-05  eta: 6:11:17  time: 0.7788  data_time: 0.0222  memory: 5632  loss: 0.5484  decode.loss_ce: 0.5484  decode.acc_seg: 70.7392\n",
      "03/09 12:50:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11700/40000]  base_lr: 5.6139e-05 lr: 5.6139e-05  eta: 6:09:58  time: 0.7803  data_time: 0.0227  memory: 5632  loss: 0.3237  decode.loss_ce: 0.3237  decode.acc_seg: 90.0331\n",
      "03/09 12:52:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11800/40000]  base_lr: 5.6101e-05 lr: 5.6101e-05  eta: 6:08:39  time: 0.7801  data_time: 0.0226  memory: 5634  loss: 0.3271  decode.loss_ce: 0.3271  decode.acc_seg: 74.1999\n",
      "03/09 12:53:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11900/40000]  base_lr: 5.6063e-05 lr: 5.6063e-05  eta: 6:07:20  time: 0.7853  data_time: 0.0231  memory: 5633  loss: 0.4800  decode.loss_ce: 0.4800  decode.acc_seg: 62.7377\n",
      "03/09 12:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 12:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12000/40000]  base_lr: 5.6026e-05 lr: 5.6026e-05  eta: 6:06:00  time: 0.7822  data_time: 0.0229  memory: 5632  loss: 0.3720  decode.loss_ce: 0.3720  decode.acc_seg: 63.3611\n",
      "03/09 12:56:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12100/40000]  base_lr: 5.5988e-05 lr: 5.5988e-05  eta: 6:04:41  time: 0.7845  data_time: 0.0233  memory: 5632  loss: 0.6105  decode.loss_ce: 0.6105  decode.acc_seg: 88.0018\n",
      "03/09 12:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12200/40000]  base_lr: 5.5950e-05 lr: 5.5950e-05  eta: 6:03:22  time: 0.7800  data_time: 0.0219  memory: 5634  loss: 0.4186  decode.loss_ce: 0.4186  decode.acc_seg: 70.0733\n",
      "03/09 12:58:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12300/40000]  base_lr: 5.5912e-05 lr: 5.5912e-05  eta: 6:02:03  time: 0.7821  data_time: 0.0219  memory: 5633  loss: 0.5541  decode.loss_ce: 0.5541  decode.acc_seg: 93.7758\n",
      "03/09 12:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12400/40000]  base_lr: 5.5874e-05 lr: 5.5874e-05  eta: 6:00:44  time: 0.7793  data_time: 0.0223  memory: 5633  loss: 0.5736  decode.loss_ce: 0.5736  decode.acc_seg: 79.8295\n",
      "03/09 13:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12500/40000]  base_lr: 5.5836e-05 lr: 5.5836e-05  eta: 5:59:25  time: 0.7799  data_time: 0.0230  memory: 5634  loss: 0.4769  decode.loss_ce: 0.4769  decode.acc_seg: 94.2648\n",
      "03/09 13:02:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12600/40000]  base_lr: 5.5798e-05 lr: 5.5798e-05  eta: 5:58:06  time: 0.7795  data_time: 0.0221  memory: 5632  loss: 0.5619  decode.loss_ce: 0.5619  decode.acc_seg: 90.1588\n",
      "03/09 13:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12700/40000]  base_lr: 5.5761e-05 lr: 5.5761e-05  eta: 5:56:47  time: 0.7794  data_time: 0.0219  memory: 5632  loss: 0.2900  decode.loss_ce: 0.2900  decode.acc_seg: 92.1268\n",
      "03/09 13:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12800/40000]  base_lr: 5.5723e-05 lr: 5.5723e-05  eta: 5:55:28  time: 0.7783  data_time: 0.0218  memory: 5632  loss: 0.3272  decode.loss_ce: 0.3272  decode.acc_seg: 86.0161\n",
      "03/09 13:06:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12900/40000]  base_lr: 5.5685e-05 lr: 5.5685e-05  eta: 5:54:08  time: 0.7788  data_time: 0.0220  memory: 5634  loss: 0.3834  decode.loss_ce: 0.3834  decode.acc_seg: 73.0406\n",
      "03/09 13:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 13:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13000/40000]  base_lr: 5.5647e-05 lr: 5.5647e-05  eta: 5:52:49  time: 0.7845  data_time: 0.0225  memory: 5634  loss: 0.3749  decode.loss_ce: 0.3749  decode.acc_seg: 98.5319\n",
      "03/09 13:09:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13100/40000]  base_lr: 5.5609e-05 lr: 5.5609e-05  eta: 5:51:30  time: 0.7792  data_time: 0.0225  memory: 5634  loss: 0.3190  decode.loss_ce: 0.3190  decode.acc_seg: 93.5714\n",
      "03/09 13:10:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13200/40000]  base_lr: 5.5571e-05 lr: 5.5571e-05  eta: 5:50:11  time: 0.7822  data_time: 0.0221  memory: 5634  loss: 0.3466  decode.loss_ce: 0.3466  decode.acc_seg: 82.1408\n",
      "03/09 13:11:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13300/40000]  base_lr: 5.5533e-05 lr: 5.5533e-05  eta: 5:48:53  time: 0.7809  data_time: 0.0231  memory: 5632  loss: 0.2909  decode.loss_ce: 0.2909  decode.acc_seg: 85.2631\n",
      "03/09 13:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13400/40000]  base_lr: 5.5496e-05 lr: 5.5496e-05  eta: 5:47:34  time: 0.7795  data_time: 0.0219  memory: 5632  loss: 0.5209  decode.loss_ce: 0.5209  decode.acc_seg: 84.5915\n",
      "03/09 13:14:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13500/40000]  base_lr: 5.5458e-05 lr: 5.5458e-05  eta: 5:46:15  time: 0.7789  data_time: 0.0220  memory: 5634  loss: 0.5816  decode.loss_ce: 0.5816  decode.acc_seg: 27.9822\n",
      "03/09 13:15:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13600/40000]  base_lr: 5.5420e-05 lr: 5.5420e-05  eta: 5:44:56  time: 0.7837  data_time: 0.0222  memory: 5633  loss: 0.5864  decode.loss_ce: 0.5864  decode.acc_seg: 96.7630\n",
      "03/09 13:16:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13700/40000]  base_lr: 5.5382e-05 lr: 5.5382e-05  eta: 5:43:37  time: 0.7787  data_time: 0.0223  memory: 5632  loss: 0.4744  decode.loss_ce: 0.4744  decode.acc_seg: 39.2884\n",
      "03/09 13:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13800/40000]  base_lr: 5.5344e-05 lr: 5.5344e-05  eta: 5:42:18  time: 0.7780  data_time: 0.0220  memory: 5632  loss: 0.2972  decode.loss_ce: 0.2972  decode.acc_seg: 86.1700\n",
      "03/09 13:19:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13900/40000]  base_lr: 5.5306e-05 lr: 5.5306e-05  eta: 5:40:59  time: 0.7866  data_time: 0.0229  memory: 5632  loss: 0.5449  decode.loss_ce: 0.5449  decode.acc_seg: 86.5657\n",
      "03/09 13:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 13:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14000/40000]  base_lr: 5.5268e-05 lr: 5.5268e-05  eta: 5:39:40  time: 0.7779  data_time: 0.0217  memory: 5634  loss: 0.6555  decode.loss_ce: 0.6555  decode.acc_seg: 62.6781\n",
      "03/09 13:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14100/40000]  base_lr: 5.5231e-05 lr: 5.5231e-05  eta: 5:38:21  time: 0.7815  data_time: 0.0226  memory: 5634  loss: 0.5599  decode.loss_ce: 0.5599  decode.acc_seg: 81.1924\n",
      "03/09 13:23:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14200/40000]  base_lr: 5.5193e-05 lr: 5.5193e-05  eta: 5:37:02  time: 0.7786  data_time: 0.0225  memory: 5632  loss: 0.4524  decode.loss_ce: 0.4524  decode.acc_seg: 89.6780\n",
      "03/09 13:24:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14300/40000]  base_lr: 5.5155e-05 lr: 5.5155e-05  eta: 5:35:43  time: 0.7823  data_time: 0.0230  memory: 5634  loss: 0.5199  decode.loss_ce: 0.5199  decode.acc_seg: 81.5018\n",
      "03/09 13:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14400/40000]  base_lr: 5.5117e-05 lr: 5.5117e-05  eta: 5:34:24  time: 0.7799  data_time: 0.0221  memory: 5632  loss: 0.3065  decode.loss_ce: 0.3065  decode.acc_seg: 77.6875\n",
      "03/09 13:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14500/40000]  base_lr: 5.5079e-05 lr: 5.5079e-05  eta: 5:33:05  time: 0.7803  data_time: 0.0222  memory: 5632  loss: 0.4622  decode.loss_ce: 0.4622  decode.acc_seg: 76.7986\n",
      "03/09 13:28:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14600/40000]  base_lr: 5.5041e-05 lr: 5.5041e-05  eta: 5:31:47  time: 0.7781  data_time: 0.0217  memory: 5634  loss: 0.4586  decode.loss_ce: 0.4586  decode.acc_seg: 87.3425\n",
      "03/09 13:29:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14700/40000]  base_lr: 5.5004e-05 lr: 5.5004e-05  eta: 5:30:27  time: 0.7775  data_time: 0.0214  memory: 5632  loss: 0.3133  decode.loss_ce: 0.3133  decode.acc_seg: 69.6787\n",
      "03/09 13:31:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14800/40000]  base_lr: 5.4966e-05 lr: 5.4966e-05  eta: 5:29:09  time: 0.7800  data_time: 0.0230  memory: 5633  loss: 0.4360  decode.loss_ce: 0.4360  decode.acc_seg: 88.6309\n",
      "03/09 13:32:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14900/40000]  base_lr: 5.4928e-05 lr: 5.4928e-05  eta: 5:27:50  time: 0.7808  data_time: 0.0218  memory: 5634  loss: 0.4572  decode.loss_ce: 0.4572  decode.acc_seg: 81.9854\n",
      "03/09 13:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 13:33:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15000/40000]  base_lr: 5.4890e-05 lr: 5.4890e-05  eta: 5:26:31  time: 0.7869  data_time: 0.0228  memory: 5634  loss: 0.4558  decode.loss_ce: 0.4558  decode.acc_seg: 92.5486\n",
      "03/09 13:35:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15100/40000]  base_lr: 5.4852e-05 lr: 5.4852e-05  eta: 5:25:12  time: 0.7782  data_time: 0.0217  memory: 5632  loss: 0.4130  decode.loss_ce: 0.4130  decode.acc_seg: 77.5247\n",
      "03/09 13:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15200/40000]  base_lr: 5.4814e-05 lr: 5.4814e-05  eta: 5:23:53  time: 0.7859  data_time: 0.0225  memory: 5633  loss: 0.3479  decode.loss_ce: 0.3479  decode.acc_seg: 55.3991\n",
      "03/09 13:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15300/40000]  base_lr: 5.4776e-05 lr: 5.4776e-05  eta: 5:22:34  time: 0.7793  data_time: 0.0220  memory: 5634  loss: 0.3468  decode.loss_ce: 0.3468  decode.acc_seg: 88.4016\n",
      "03/09 13:39:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15400/40000]  base_lr: 5.4739e-05 lr: 5.4739e-05  eta: 5:21:15  time: 0.7815  data_time: 0.0221  memory: 5633  loss: 0.4886  decode.loss_ce: 0.4886  decode.acc_seg: 71.4054\n",
      "03/09 13:40:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15500/40000]  base_lr: 5.4701e-05 lr: 5.4701e-05  eta: 5:19:56  time: 0.7832  data_time: 0.0231  memory: 5634  loss: 0.4204  decode.loss_ce: 0.4204  decode.acc_seg: 71.5548\n",
      "03/09 13:41:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15600/40000]  base_lr: 5.4663e-05 lr: 5.4663e-05  eta: 5:18:38  time: 0.7822  data_time: 0.0227  memory: 5632  loss: 0.2938  decode.loss_ce: 0.2938  decode.acc_seg: 84.1335\n",
      "03/09 13:42:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15700/40000]  base_lr: 5.4625e-05 lr: 5.4625e-05  eta: 5:17:20  time: 0.7799  data_time: 0.0227  memory: 5634  loss: 0.3866  decode.loss_ce: 0.3866  decode.acc_seg: 60.2794\n",
      "03/09 13:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15800/40000]  base_lr: 5.4587e-05 lr: 5.4587e-05  eta: 5:16:01  time: 0.7791  data_time: 0.0216  memory: 5633  loss: 0.4657  decode.loss_ce: 0.4657  decode.acc_seg: 63.3831\n",
      "03/09 13:45:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15900/40000]  base_lr: 5.4549e-05 lr: 5.4549e-05  eta: 5:14:42  time: 0.7785  data_time: 0.0219  memory: 5634  loss: 0.3682  decode.loss_ce: 0.3682  decode.acc_seg: 82.0732\n",
      "03/09 13:46:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 13:46:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16000/40000]  base_lr: 5.4511e-05 lr: 5.4511e-05  eta: 5:13:23  time: 0.7801  data_time: 0.0223  memory: 5633  loss: 0.6331  decode.loss_ce: 0.6331  decode.acc_seg: 86.3853\n",
      "03/09 13:48:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16100/40000]  base_lr: 5.4474e-05 lr: 5.4474e-05  eta: 5:12:04  time: 0.7822  data_time: 0.0227  memory: 5634  loss: 0.5377  decode.loss_ce: 0.5377  decode.acc_seg: 90.1736\n",
      "03/09 13:49:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16200/40000]  base_lr: 5.4436e-05 lr: 5.4436e-05  eta: 5:10:45  time: 0.7774  data_time: 0.0212  memory: 5632  loss: 0.2892  decode.loss_ce: 0.2892  decode.acc_seg: 79.7009\n",
      "03/09 13:50:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16300/40000]  base_lr: 5.4398e-05 lr: 5.4398e-05  eta: 5:09:27  time: 0.7833  data_time: 0.0232  memory: 5634  loss: 0.6396  decode.loss_ce: 0.6396  decode.acc_seg: 97.8944\n",
      "03/09 13:52:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16400/40000]  base_lr: 5.4360e-05 lr: 5.4360e-05  eta: 5:08:08  time: 0.7817  data_time: 0.0230  memory: 5632  loss: 0.4718  decode.loss_ce: 0.4718  decode.acc_seg: 96.7316\n",
      "03/09 13:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16500/40000]  base_lr: 5.4322e-05 lr: 5.4322e-05  eta: 5:06:49  time: 0.7782  data_time: 0.0218  memory: 5632  loss: 0.3718  decode.loss_ce: 0.3718  decode.acc_seg: 79.6587\n",
      "03/09 13:54:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16600/40000]  base_lr: 5.4284e-05 lr: 5.4284e-05  eta: 5:05:30  time: 0.7786  data_time: 0.0218  memory: 5632  loss: 0.4737  decode.loss_ce: 0.4737  decode.acc_seg: 91.3168\n",
      "03/09 13:55:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16700/40000]  base_lr: 5.4246e-05 lr: 5.4246e-05  eta: 5:04:12  time: 0.7795  data_time: 0.0220  memory: 5634  loss: 0.5096  decode.loss_ce: 0.5096  decode.acc_seg: 75.7959\n",
      "03/09 13:57:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16800/40000]  base_lr: 5.4209e-05 lr: 5.4209e-05  eta: 5:02:53  time: 0.7814  data_time: 0.0222  memory: 5634  loss: 0.3741  decode.loss_ce: 0.3741  decode.acc_seg: 89.0450\n",
      "03/09 13:58:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16900/40000]  base_lr: 5.4171e-05 lr: 5.4171e-05  eta: 5:01:34  time: 0.7805  data_time: 0.0220  memory: 5634  loss: 0.2619  decode.loss_ce: 0.2619  decode.acc_seg: 81.7032\n",
      "03/09 13:59:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 13:59:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17000/40000]  base_lr: 5.4133e-05 lr: 5.4133e-05  eta: 5:00:15  time: 0.7842  data_time: 0.0225  memory: 5634  loss: 0.4572  decode.loss_ce: 0.4572  decode.acc_seg: 65.1594\n",
      "03/09 14:01:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17100/40000]  base_lr: 5.4095e-05 lr: 5.4095e-05  eta: 4:58:57  time: 0.7783  data_time: 0.0222  memory: 5632  loss: 0.4679  decode.loss_ce: 0.4679  decode.acc_seg: 27.9456\n",
      "03/09 14:02:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17200/40000]  base_lr: 5.4057e-05 lr: 5.4057e-05  eta: 4:57:38  time: 0.7895  data_time: 0.0240  memory: 5634  loss: 0.3820  decode.loss_ce: 0.3820  decode.acc_seg: 85.4307\n",
      "03/09 14:03:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17300/40000]  base_lr: 5.4019e-05 lr: 5.4019e-05  eta: 4:56:20  time: 0.7785  data_time: 0.0221  memory: 5634  loss: 0.5295  decode.loss_ce: 0.5295  decode.acc_seg: 75.3783\n",
      "03/09 14:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17400/40000]  base_lr: 5.3981e-05 lr: 5.3981e-05  eta: 4:55:01  time: 0.7811  data_time: 0.0224  memory: 5632  loss: 0.3885  decode.loss_ce: 0.3885  decode.acc_seg: 75.6838\n",
      "03/09 14:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17500/40000]  base_lr: 5.3944e-05 lr: 5.3944e-05  eta: 4:53:42  time: 0.7809  data_time: 0.0222  memory: 5634  loss: 0.4064  decode.loss_ce: 0.4064  decode.acc_seg: 84.6149\n",
      "03/09 14:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17600/40000]  base_lr: 5.3906e-05 lr: 5.3906e-05  eta: 4:52:24  time: 0.7785  data_time: 0.0219  memory: 5632  loss: 0.3021  decode.loss_ce: 0.3021  decode.acc_seg: 90.7434\n",
      "03/09 14:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17700/40000]  base_lr: 5.3868e-05 lr: 5.3868e-05  eta: 4:51:05  time: 0.7806  data_time: 0.0219  memory: 5632  loss: 0.3164  decode.loss_ce: 0.3164  decode.acc_seg: 86.4903\n",
      "03/09 14:10:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17800/40000]  base_lr: 5.3830e-05 lr: 5.3830e-05  eta: 4:49:47  time: 0.7826  data_time: 0.0225  memory: 5632  loss: 0.2928  decode.loss_ce: 0.2928  decode.acc_seg: 73.5653\n",
      "03/09 14:11:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17900/40000]  base_lr: 5.3792e-05 lr: 5.3792e-05  eta: 4:48:29  time: 0.7836  data_time: 0.0225  memory: 5634  loss: 0.3575  decode.loss_ce: 0.3575  decode.acc_seg: 88.2539\n",
      "03/09 14:12:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 14:12:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18000/40000]  base_lr: 5.3754e-05 lr: 5.3754e-05  eta: 4:47:11  time: 0.7894  data_time: 0.0233  memory: 5632  loss: 0.5635  decode.loss_ce: 0.5635  decode.acc_seg: 80.2841\n",
      "03/09 14:14:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18100/40000]  base_lr: 5.3716e-05 lr: 5.3716e-05  eta: 4:45:53  time: 0.7860  data_time: 0.0227  memory: 5632  loss: 0.2630  decode.loss_ce: 0.2630  decode.acc_seg: 97.1362\n",
      "03/09 14:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18200/40000]  base_lr: 5.3679e-05 lr: 5.3679e-05  eta: 4:44:34  time: 0.7821  data_time: 0.0224  memory: 5633  loss: 0.3977  decode.loss_ce: 0.3977  decode.acc_seg: 72.7161\n",
      "03/09 14:16:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18300/40000]  base_lr: 5.3641e-05 lr: 5.3641e-05  eta: 4:43:16  time: 0.7830  data_time: 0.0225  memory: 5632  loss: 0.4171  decode.loss_ce: 0.4171  decode.acc_seg: 84.8774\n",
      "03/09 14:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18400/40000]  base_lr: 5.3603e-05 lr: 5.3603e-05  eta: 4:41:58  time: 0.7817  data_time: 0.0218  memory: 5633  loss: 0.5991  decode.loss_ce: 0.5991  decode.acc_seg: 86.0774\n",
      "03/09 14:19:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18500/40000]  base_lr: 5.3565e-05 lr: 5.3565e-05  eta: 4:40:40  time: 0.7908  data_time: 0.0231  memory: 5632  loss: 0.4388  decode.loss_ce: 0.4388  decode.acc_seg: 67.9082\n",
      "03/09 14:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18600/40000]  base_lr: 5.3527e-05 lr: 5.3527e-05  eta: 4:39:21  time: 0.7840  data_time: 0.0218  memory: 5634  loss: 0.6504  decode.loss_ce: 0.6504  decode.acc_seg: 72.3789\n",
      "03/09 14:22:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18700/40000]  base_lr: 5.3489e-05 lr: 5.3489e-05  eta: 4:38:03  time: 0.7846  data_time: 0.0226  memory: 5634  loss: 0.4698  decode.loss_ce: 0.4698  decode.acc_seg: 69.8079\n",
      "03/09 14:23:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18800/40000]  base_lr: 5.3451e-05 lr: 5.3451e-05  eta: 4:36:45  time: 0.7831  data_time: 0.0226  memory: 5632  loss: 0.3694  decode.loss_ce: 0.3694  decode.acc_seg: 81.2460\n",
      "03/09 14:24:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18900/40000]  base_lr: 5.3414e-05 lr: 5.3414e-05  eta: 4:35:26  time: 0.7801  data_time: 0.0219  memory: 5634  loss: 0.3919  decode.loss_ce: 0.3919  decode.acc_seg: 79.9793\n",
      "03/09 14:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 14:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19000/40000]  base_lr: 5.3376e-05 lr: 5.3376e-05  eta: 4:34:08  time: 0.7798  data_time: 0.0220  memory: 5634  loss: 0.6558  decode.loss_ce: 0.6558  decode.acc_seg: 78.5572\n",
      "03/09 14:27:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19100/40000]  base_lr: 5.3338e-05 lr: 5.3338e-05  eta: 4:32:50  time: 0.7815  data_time: 0.0223  memory: 5632  loss: 0.4118  decode.loss_ce: 0.4118  decode.acc_seg: 84.5174\n",
      "03/09 14:28:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19200/40000]  base_lr: 5.3300e-05 lr: 5.3300e-05  eta: 4:31:32  time: 0.7849  data_time: 0.0234  memory: 5633  loss: 0.2631  decode.loss_ce: 0.2631  decode.acc_seg: 90.6742\n",
      "03/09 14:29:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19300/40000]  base_lr: 5.3262e-05 lr: 5.3262e-05  eta: 4:30:13  time: 0.7826  data_time: 0.0224  memory: 5632  loss: 0.3577  decode.loss_ce: 0.3577  decode.acc_seg: 85.3992\n",
      "03/09 14:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19400/40000]  base_lr: 5.3224e-05 lr: 5.3224e-05  eta: 4:28:55  time: 0.7864  data_time: 0.0227  memory: 5632  loss: 0.4462  decode.loss_ce: 0.4462  decode.acc_seg: 94.5127\n",
      "03/09 14:32:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19500/40000]  base_lr: 5.3186e-05 lr: 5.3186e-05  eta: 4:27:37  time: 0.7818  data_time: 0.0221  memory: 5634  loss: 0.3791  decode.loss_ce: 0.3791  decode.acc_seg: 90.4117\n",
      "03/09 14:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19600/40000]  base_lr: 5.3149e-05 lr: 5.3149e-05  eta: 4:26:18  time: 0.7832  data_time: 0.0226  memory: 5632  loss: 0.3134  decode.loss_ce: 0.3134  decode.acc_seg: 95.3582\n",
      "03/09 14:35:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19700/40000]  base_lr: 5.3111e-05 lr: 5.3111e-05  eta: 4:25:00  time: 0.7774  data_time: 0.0218  memory: 5632  loss: 0.3810  decode.loss_ce: 0.3810  decode.acc_seg: 72.2574\n",
      "03/09 14:36:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19800/40000]  base_lr: 5.3073e-05 lr: 5.3073e-05  eta: 4:23:42  time: 0.7826  data_time: 0.0219  memory: 5632  loss: 0.5937  decode.loss_ce: 0.5937  decode.acc_seg: 81.5511\n",
      "03/09 14:37:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19900/40000]  base_lr: 5.3035e-05 lr: 5.3035e-05  eta: 4:22:24  time: 0.7831  data_time: 0.0224  memory: 5633  loss: 0.2908  decode.loss_ce: 0.2908  decode.acc_seg: 76.3847\n",
      "03/09 14:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 14:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20000/40000]  base_lr: 5.2997e-05 lr: 5.2997e-05  eta: 4:21:05  time: 0.7845  data_time: 0.0232  memory: 5634  loss: 0.2364  decode.loss_ce: 0.2364  decode.acc_seg: 90.4520\n",
      "03/09 14:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20000 iterations\n",
      "03/09 14:40:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20100/40000]  base_lr: 5.2959e-05 lr: 5.2959e-05  eta: 4:19:52  time: 0.7818  data_time: 0.0223  memory: 5634  loss: 0.4113  decode.loss_ce: 0.4113  decode.acc_seg: 70.3180\n",
      "03/09 14:41:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20200/40000]  base_lr: 5.2921e-05 lr: 5.2921e-05  eta: 4:18:34  time: 0.7814  data_time: 0.0225  memory: 5632  loss: 0.4973  decode.loss_ce: 0.4973  decode.acc_seg: 76.5658\n",
      "03/09 14:42:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20300/40000]  base_lr: 5.2884e-05 lr: 5.2884e-05  eta: 4:17:15  time: 0.7798  data_time: 0.0221  memory: 5632  loss: 0.3582  decode.loss_ce: 0.3582  decode.acc_seg: 98.2340\n",
      "03/09 14:44:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20400/40000]  base_lr: 5.2846e-05 lr: 5.2846e-05  eta: 4:15:57  time: 0.7781  data_time: 0.0217  memory: 5633  loss: 0.3104  decode.loss_ce: 0.3104  decode.acc_seg: 86.8996\n",
      "03/09 14:45:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20500/40000]  base_lr: 5.2808e-05 lr: 5.2808e-05  eta: 4:14:38  time: 0.7828  data_time: 0.0225  memory: 5632  loss: 0.2980  decode.loss_ce: 0.2980  decode.acc_seg: 98.4727\n",
      "03/09 14:46:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20600/40000]  base_lr: 5.2770e-05 lr: 5.2770e-05  eta: 4:13:20  time: 0.7799  data_time: 0.0225  memory: 5634  loss: 0.4460  decode.loss_ce: 0.4460  decode.acc_seg: 87.4173\n",
      "03/09 14:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20700/40000]  base_lr: 5.2732e-05 lr: 5.2732e-05  eta: 4:12:01  time: 0.7866  data_time: 0.0225  memory: 5632  loss: 0.4132  decode.loss_ce: 0.4132  decode.acc_seg: 88.7902\n",
      "03/09 14:49:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20800/40000]  base_lr: 5.2694e-05 lr: 5.2694e-05  eta: 4:10:43  time: 0.7798  data_time: 0.0220  memory: 5634  loss: 0.5331  decode.loss_ce: 0.5331  decode.acc_seg: 90.1004\n",
      "03/09 14:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20900/40000]  base_lr: 5.2656e-05 lr: 5.2656e-05  eta: 4:09:24  time: 0.7849  data_time: 0.0232  memory: 5634  loss: 0.4149  decode.loss_ce: 0.4149  decode.acc_seg: 78.7300\n",
      "03/09 14:52:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 14:52:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21000/40000]  base_lr: 5.2619e-05 lr: 5.2619e-05  eta: 4:08:06  time: 0.7821  data_time: 0.0225  memory: 5634  loss: 0.3007  decode.loss_ce: 0.3007  decode.acc_seg: 87.2419\n",
      "03/09 14:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21100/40000]  base_lr: 5.2581e-05 lr: 5.2581e-05  eta: 4:06:48  time: 0.7888  data_time: 0.0220  memory: 5632  loss: 0.2352  decode.loss_ce: 0.2352  decode.acc_seg: 80.1456\n",
      "03/09 14:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21200/40000]  base_lr: 5.2543e-05 lr: 5.2543e-05  eta: 4:05:29  time: 0.7839  data_time: 0.0221  memory: 5634  loss: 0.3791  decode.loss_ce: 0.3791  decode.acc_seg: 90.4083\n",
      "03/09 14:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21300/40000]  base_lr: 5.2505e-05 lr: 5.2505e-05  eta: 4:04:11  time: 0.7821  data_time: 0.0223  memory: 5632  loss: 0.2746  decode.loss_ce: 0.2746  decode.acc_seg: 85.3704\n",
      "03/09 14:57:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21400/40000]  base_lr: 5.2467e-05 lr: 5.2467e-05  eta: 4:02:52  time: 0.7838  data_time: 0.0227  memory: 5634  loss: 0.4609  decode.loss_ce: 0.4609  decode.acc_seg: 71.9482\n",
      "03/09 14:58:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21500/40000]  base_lr: 5.2429e-05 lr: 5.2429e-05  eta: 4:01:34  time: 0.7835  data_time: 0.0225  memory: 5634  loss: 0.4534  decode.loss_ce: 0.4534  decode.acc_seg: 65.1020\n",
      "03/09 14:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21600/40000]  base_lr: 5.2391e-05 lr: 5.2391e-05  eta: 4:00:16  time: 0.7796  data_time: 0.0223  memory: 5634  loss: 0.4247  decode.loss_ce: 0.4247  decode.acc_seg: 84.1557\n",
      "03/09 15:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21700/40000]  base_lr: 5.2354e-05 lr: 5.2354e-05  eta: 3:58:58  time: 0.7821  data_time: 0.0225  memory: 5632  loss: 0.3477  decode.loss_ce: 0.3477  decode.acc_seg: 83.2536\n",
      "03/09 15:02:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21800/40000]  base_lr: 5.2316e-05 lr: 5.2316e-05  eta: 3:57:39  time: 0.7809  data_time: 0.0235  memory: 5632  loss: 0.2719  decode.loss_ce: 0.2719  decode.acc_seg: 70.9338\n",
      "03/09 15:03:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21900/40000]  base_lr: 5.2278e-05 lr: 5.2278e-05  eta: 3:56:21  time: 0.7849  data_time: 0.0232  memory: 5634  loss: 0.5224  decode.loss_ce: 0.5224  decode.acc_seg: 92.1637\n",
      "03/09 15:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 15:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22000/40000]  base_lr: 5.2240e-05 lr: 5.2240e-05  eta: 3:55:03  time: 0.7874  data_time: 0.0234  memory: 5634  loss: 0.4061  decode.loss_ce: 0.4061  decode.acc_seg: 68.7012\n",
      "03/09 15:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22100/40000]  base_lr: 5.2202e-05 lr: 5.2202e-05  eta: 3:53:45  time: 0.7855  data_time: 0.0231  memory: 5632  loss: 0.3022  decode.loss_ce: 0.3022  decode.acc_seg: 94.1889\n",
      "03/09 15:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22200/40000]  base_lr: 5.2164e-05 lr: 5.2164e-05  eta: 3:52:27  time: 0.7924  data_time: 0.0245  memory: 5634  loss: 0.3624  decode.loss_ce: 0.3624  decode.acc_seg: 93.7575\n",
      "03/09 15:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22300/40000]  base_lr: 5.2127e-05 lr: 5.2127e-05  eta: 3:51:08  time: 0.7809  data_time: 0.0228  memory: 5634  loss: 0.3503  decode.loss_ce: 0.3503  decode.acc_seg: 63.6385\n",
      "03/09 15:10:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22400/40000]  base_lr: 5.2089e-05 lr: 5.2089e-05  eta: 3:49:50  time: 0.7906  data_time: 0.0237  memory: 5634  loss: 0.2566  decode.loss_ce: 0.2566  decode.acc_seg: 85.1538\n",
      "03/09 15:11:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22500/40000]  base_lr: 5.2051e-05 lr: 5.2051e-05  eta: 3:48:32  time: 0.7794  data_time: 0.0223  memory: 5632  loss: 0.4041  decode.loss_ce: 0.4041  decode.acc_seg: 77.1361\n",
      "03/09 15:13:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22600/40000]  base_lr: 5.2013e-05 lr: 5.2013e-05  eta: 3:47:13  time: 0.7830  data_time: 0.0232  memory: 5633  loss: 0.4691  decode.loss_ce: 0.4691  decode.acc_seg: 77.6997\n",
      "03/09 15:14:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22700/40000]  base_lr: 5.1975e-05 lr: 5.1975e-05  eta: 3:45:55  time: 0.7808  data_time: 0.0226  memory: 5634  loss: 0.3632  decode.loss_ce: 0.3632  decode.acc_seg: 77.2874\n",
      "03/09 15:15:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22800/40000]  base_lr: 5.1937e-05 lr: 5.1937e-05  eta: 3:44:37  time: 0.7795  data_time: 0.0220  memory: 5632  loss: 0.3243  decode.loss_ce: 0.3243  decode.acc_seg: 91.0179\n",
      "03/09 15:16:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22900/40000]  base_lr: 5.1899e-05 lr: 5.1899e-05  eta: 3:43:18  time: 0.7803  data_time: 0.0220  memory: 5633  loss: 0.4306  decode.loss_ce: 0.4306  decode.acc_seg: 96.6627\n",
      "03/09 15:18:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 15:18:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23000/40000]  base_lr: 5.1862e-05 lr: 5.1862e-05  eta: 3:41:59  time: 0.7809  data_time: 0.0229  memory: 5632  loss: 0.3307  decode.loss_ce: 0.3307  decode.acc_seg: 90.8463\n",
      "03/09 15:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23100/40000]  base_lr: 5.1824e-05 lr: 5.1824e-05  eta: 3:40:41  time: 0.7844  data_time: 0.0231  memory: 5632  loss: 0.4237  decode.loss_ce: 0.4237  decode.acc_seg: 64.8901\n",
      "03/09 15:20:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23200/40000]  base_lr: 5.1786e-05 lr: 5.1786e-05  eta: 3:39:23  time: 0.7807  data_time: 0.0226  memory: 5632  loss: 0.3169  decode.loss_ce: 0.3169  decode.acc_seg: 78.4219\n",
      "03/09 15:22:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23300/40000]  base_lr: 5.1748e-05 lr: 5.1748e-05  eta: 3:38:05  time: 0.7883  data_time: 0.0228  memory: 5632  loss: 0.2833  decode.loss_ce: 0.2833  decode.acc_seg: 94.4184\n",
      "03/09 15:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23400/40000]  base_lr: 5.1710e-05 lr: 5.1710e-05  eta: 3:36:46  time: 0.7800  data_time: 0.0224  memory: 5633  loss: 0.3837  decode.loss_ce: 0.3837  decode.acc_seg: 63.5530\n",
      "03/09 15:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23500/40000]  base_lr: 5.1672e-05 lr: 5.1672e-05  eta: 3:35:28  time: 0.7897  data_time: 0.0231  memory: 5633  loss: 0.3634  decode.loss_ce: 0.3634  decode.acc_seg: 60.2953\n",
      "03/09 15:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23600/40000]  base_lr: 5.1634e-05 lr: 5.1634e-05  eta: 3:34:09  time: 0.7786  data_time: 0.0224  memory: 5634  loss: 0.2693  decode.loss_ce: 0.2693  decode.acc_seg: 78.1132\n",
      "03/09 15:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23700/40000]  base_lr: 5.1597e-05 lr: 5.1597e-05  eta: 3:32:51  time: 0.7843  data_time: 0.0229  memory: 5634  loss: 0.3171  decode.loss_ce: 0.3171  decode.acc_seg: 40.5175\n",
      "03/09 15:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23800/40000]  base_lr: 5.1559e-05 lr: 5.1559e-05  eta: 3:31:33  time: 0.7802  data_time: 0.0225  memory: 5634  loss: 0.4598  decode.loss_ce: 0.4598  decode.acc_seg: 84.0936\n",
      "03/09 15:30:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23900/40000]  base_lr: 5.1521e-05 lr: 5.1521e-05  eta: 3:30:14  time: 0.7802  data_time: 0.0225  memory: 5634  loss: 0.3133  decode.loss_ce: 0.3133  decode.acc_seg: 75.2615\n",
      "03/09 15:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 15:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24000/40000]  base_lr: 5.1483e-05 lr: 5.1483e-05  eta: 3:28:56  time: 0.7827  data_time: 0.0231  memory: 5633  loss: 0.2704  decode.loss_ce: 0.2704  decode.acc_seg: 96.7089\n",
      "03/09 15:32:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24100/40000]  base_lr: 5.1445e-05 lr: 5.1445e-05  eta: 3:27:38  time: 0.7844  data_time: 0.0233  memory: 5632  loss: 0.5537  decode.loss_ce: 0.5537  decode.acc_seg: 37.1509\n",
      "03/09 15:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24200/40000]  base_lr: 5.1407e-05 lr: 5.1407e-05  eta: 3:26:19  time: 0.7820  data_time: 0.0227  memory: 5634  loss: 0.4058  decode.loss_ce: 0.4058  decode.acc_seg: 98.8703\n",
      "03/09 15:35:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24300/40000]  base_lr: 5.1369e-05 lr: 5.1369e-05  eta: 3:25:01  time: 0.7807  data_time: 0.0226  memory: 5634  loss: 0.3623  decode.loss_ce: 0.3623  decode.acc_seg: 58.4823\n",
      "03/09 15:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24400/40000]  base_lr: 5.1332e-05 lr: 5.1332e-05  eta: 3:23:42  time: 0.7840  data_time: 0.0229  memory: 5632  loss: 0.7513  decode.loss_ce: 0.7513  decode.acc_seg: 57.7016\n",
      "03/09 15:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24500/40000]  base_lr: 5.1294e-05 lr: 5.1294e-05  eta: 3:22:24  time: 0.7839  data_time: 0.0229  memory: 5634  loss: 0.3080  decode.loss_ce: 0.3080  decode.acc_seg: 88.5066\n",
      "03/09 15:39:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24600/40000]  base_lr: 5.1256e-05 lr: 5.1256e-05  eta: 3:21:06  time: 0.7858  data_time: 0.0240  memory: 5634  loss: 0.2308  decode.loss_ce: 0.2308  decode.acc_seg: 92.7862\n",
      "03/09 15:40:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24700/40000]  base_lr: 5.1218e-05 lr: 5.1218e-05  eta: 3:19:48  time: 0.7790  data_time: 0.0223  memory: 5634  loss: 0.3629  decode.loss_ce: 0.3629  decode.acc_seg: 90.1156\n",
      "03/09 15:41:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24800/40000]  base_lr: 5.1180e-05 lr: 5.1180e-05  eta: 3:18:30  time: 0.7860  data_time: 0.0231  memory: 5634  loss: 0.7479  decode.loss_ce: 0.7479  decode.acc_seg: 90.5500\n",
      "03/09 15:43:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24900/40000]  base_lr: 5.1142e-05 lr: 5.1142e-05  eta: 3:17:11  time: 0.7870  data_time: 0.0227  memory: 5634  loss: 0.4071  decode.loss_ce: 0.4071  decode.acc_seg: 92.7232\n",
      "03/09 15:44:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 15:44:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25000/40000]  base_lr: 5.1104e-05 lr: 5.1104e-05  eta: 3:15:53  time: 0.7849  data_time: 0.0232  memory: 5634  loss: 0.3498  decode.loss_ce: 0.3498  decode.acc_seg: 72.6182\n",
      "03/09 15:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25100/40000]  base_lr: 5.1067e-05 lr: 5.1067e-05  eta: 3:14:35  time: 0.7840  data_time: 0.0228  memory: 5634  loss: 0.3235  decode.loss_ce: 0.3235  decode.acc_seg: 82.5031\n",
      "03/09 15:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25200/40000]  base_lr: 5.1029e-05 lr: 5.1029e-05  eta: 3:13:17  time: 0.7860  data_time: 0.0228  memory: 5634  loss: 0.4591  decode.loss_ce: 0.4591  decode.acc_seg: 67.5619\n",
      "03/09 15:48:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25300/40000]  base_lr: 5.0991e-05 lr: 5.0991e-05  eta: 3:11:59  time: 0.7854  data_time: 0.0233  memory: 5634  loss: 0.2659  decode.loss_ce: 0.2659  decode.acc_seg: 86.0006\n",
      "03/09 15:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25400/40000]  base_lr: 5.0953e-05 lr: 5.0953e-05  eta: 3:10:40  time: 0.7821  data_time: 0.0233  memory: 5632  loss: 0.2637  decode.loss_ce: 0.2637  decode.acc_seg: 98.2136\n",
      "03/09 15:50:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25500/40000]  base_lr: 5.0915e-05 lr: 5.0915e-05  eta: 3:09:22  time: 0.7848  data_time: 0.0223  memory: 5634  loss: 0.2891  decode.loss_ce: 0.2891  decode.acc_seg: 88.7403\n",
      "03/09 15:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25600/40000]  base_lr: 5.0877e-05 lr: 5.0877e-05  eta: 3:08:04  time: 0.7834  data_time: 0.0227  memory: 5634  loss: 0.2858  decode.loss_ce: 0.2858  decode.acc_seg: 82.4666\n",
      "03/09 15:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25700/40000]  base_lr: 5.0839e-05 lr: 5.0839e-05  eta: 3:06:45  time: 0.7849  data_time: 0.0228  memory: 5632  loss: 0.3022  decode.loss_ce: 0.3022  decode.acc_seg: 97.3729\n",
      "03/09 15:54:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25800/40000]  base_lr: 5.0802e-05 lr: 5.0802e-05  eta: 3:05:27  time: 0.7819  data_time: 0.0226  memory: 5632  loss: 0.3149  decode.loss_ce: 0.3149  decode.acc_seg: 93.1423\n",
      "03/09 15:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25900/40000]  base_lr: 5.0764e-05 lr: 5.0764e-05  eta: 3:04:08  time: 0.7821  data_time: 0.0226  memory: 5632  loss: 0.4371  decode.loss_ce: 0.4371  decode.acc_seg: 72.2134\n",
      "03/09 15:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 15:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26000/40000]  base_lr: 5.0726e-05 lr: 5.0726e-05  eta: 3:02:50  time: 0.7786  data_time: 0.0229  memory: 5634  loss: 0.2567  decode.loss_ce: 0.2567  decode.acc_seg: 92.2848\n",
      "03/09 15:58:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26100/40000]  base_lr: 5.0688e-05 lr: 5.0688e-05  eta: 3:01:31  time: 0.7795  data_time: 0.0226  memory: 5634  loss: 0.2368  decode.loss_ce: 0.2368  decode.acc_seg: 94.9693\n",
      "03/09 16:00:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26200/40000]  base_lr: 5.0650e-05 lr: 5.0650e-05  eta: 3:00:13  time: 0.7807  data_time: 0.0220  memory: 5633  loss: 0.3976  decode.loss_ce: 0.3976  decode.acc_seg: 84.2523\n",
      "03/09 16:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26300/40000]  base_lr: 5.0612e-05 lr: 5.0612e-05  eta: 2:58:55  time: 0.7826  data_time: 0.0229  memory: 5632  loss: 0.2612  decode.loss_ce: 0.2612  decode.acc_seg: 75.2576\n",
      "03/09 16:02:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26400/40000]  base_lr: 5.0574e-05 lr: 5.0574e-05  eta: 2:57:36  time: 0.7805  data_time: 0.0228  memory: 5632  loss: 0.2645  decode.loss_ce: 0.2645  decode.acc_seg: 89.9628\n",
      "03/09 16:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26500/40000]  base_lr: 5.0537e-05 lr: 5.0537e-05  eta: 2:56:18  time: 0.7849  data_time: 0.0226  memory: 5634  loss: 0.3585  decode.loss_ce: 0.3585  decode.acc_seg: 92.5219\n",
      "03/09 16:05:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26600/40000]  base_lr: 5.0499e-05 lr: 5.0499e-05  eta: 2:54:59  time: 0.7879  data_time: 0.0231  memory: 5634  loss: 0.4674  decode.loss_ce: 0.4674  decode.acc_seg: 90.5141\n",
      "03/09 16:06:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26700/40000]  base_lr: 5.0461e-05 lr: 5.0461e-05  eta: 2:53:41  time: 0.7849  data_time: 0.0224  memory: 5634  loss: 0.7365  decode.loss_ce: 0.7365  decode.acc_seg: 44.8925\n",
      "03/09 16:07:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26800/40000]  base_lr: 5.0423e-05 lr: 5.0423e-05  eta: 2:52:23  time: 0.7947  data_time: 0.0248  memory: 5634  loss: 0.3422  decode.loss_ce: 0.3422  decode.acc_seg: 80.3506\n",
      "03/09 16:09:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26900/40000]  base_lr: 5.0385e-05 lr: 5.0385e-05  eta: 2:51:04  time: 0.7830  data_time: 0.0221  memory: 5632  loss: 0.2740  decode.loss_ce: 0.2740  decode.acc_seg: 98.8660\n",
      "03/09 16:10:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 16:10:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27000/40000]  base_lr: 5.0347e-05 lr: 5.0347e-05  eta: 2:49:46  time: 0.7840  data_time: 0.0217  memory: 5634  loss: 0.4301  decode.loss_ce: 0.4301  decode.acc_seg: 95.3968\n",
      "03/09 16:11:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27100/40000]  base_lr: 5.0309e-05 lr: 5.0309e-05  eta: 2:48:27  time: 0.7809  data_time: 0.0229  memory: 5632  loss: 0.3509  decode.loss_ce: 0.3509  decode.acc_seg: 89.7596\n",
      "03/09 16:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27200/40000]  base_lr: 5.0272e-05 lr: 5.0272e-05  eta: 2:47:09  time: 0.7797  data_time: 0.0230  memory: 5634  loss: 0.2606  decode.loss_ce: 0.2606  decode.acc_seg: 95.6307\n",
      "03/09 16:14:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27300/40000]  base_lr: 5.0234e-05 lr: 5.0234e-05  eta: 2:45:51  time: 0.7802  data_time: 0.0220  memory: 5632  loss: 0.3460  decode.loss_ce: 0.3460  decode.acc_seg: 54.5900\n",
      "03/09 16:15:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27400/40000]  base_lr: 5.0196e-05 lr: 5.0196e-05  eta: 2:44:32  time: 0.7804  data_time: 0.0223  memory: 5633  loss: 0.4426  decode.loss_ce: 0.4426  decode.acc_seg: 76.2844\n",
      "03/09 16:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27500/40000]  base_lr: 5.0158e-05 lr: 5.0158e-05  eta: 2:43:14  time: 0.7801  data_time: 0.0221  memory: 5634  loss: 0.3370  decode.loss_ce: 0.3370  decode.acc_seg: 70.4467\n",
      "03/09 16:18:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27600/40000]  base_lr: 5.0120e-05 lr: 5.0120e-05  eta: 2:41:55  time: 0.7810  data_time: 0.0228  memory: 5632  loss: 0.3372  decode.loss_ce: 0.3372  decode.acc_seg: 93.4460\n",
      "03/09 16:19:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27700/40000]  base_lr: 5.0082e-05 lr: 5.0082e-05  eta: 2:40:37  time: 0.7845  data_time: 0.0235  memory: 5634  loss: 0.2956  decode.loss_ce: 0.2956  decode.acc_seg: 91.2418\n",
      "03/09 16:20:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27800/40000]  base_lr: 5.0044e-05 lr: 5.0044e-05  eta: 2:39:18  time: 0.7788  data_time: 0.0221  memory: 5632  loss: 0.3349  decode.loss_ce: 0.3349  decode.acc_seg: 95.3463\n",
      "03/09 16:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27900/40000]  base_lr: 5.0007e-05 lr: 5.0007e-05  eta: 2:38:00  time: 0.7870  data_time: 0.0234  memory: 5632  loss: 0.5103  decode.loss_ce: 0.5103  decode.acc_seg: 92.8465\n",
      "03/09 16:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 16:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28000/40000]  base_lr: 4.9969e-05 lr: 4.9969e-05  eta: 2:36:42  time: 0.7790  data_time: 0.0224  memory: 5632  loss: 0.6322  decode.loss_ce: 0.6322  decode.acc_seg: 91.3194\n",
      "03/09 16:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28100/40000]  base_lr: 4.9931e-05 lr: 4.9931e-05  eta: 2:35:23  time: 0.7847  data_time: 0.0230  memory: 5634  loss: 0.3201  decode.loss_ce: 0.3201  decode.acc_seg: 87.2182\n",
      "03/09 16:26:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28200/40000]  base_lr: 4.9893e-05 lr: 4.9893e-05  eta: 2:34:05  time: 0.7807  data_time: 0.0222  memory: 5632  loss: 0.2370  decode.loss_ce: 0.2370  decode.acc_seg: 91.8055\n",
      "03/09 16:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28300/40000]  base_lr: 4.9855e-05 lr: 4.9855e-05  eta: 2:32:46  time: 0.7823  data_time: 0.0229  memory: 5634  loss: 0.3930  decode.loss_ce: 0.3930  decode.acc_seg: 65.0232\n",
      "03/09 16:28:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28400/40000]  base_lr: 4.9817e-05 lr: 4.9817e-05  eta: 2:31:28  time: 0.7803  data_time: 0.0227  memory: 5632  loss: 0.5027  decode.loss_ce: 0.5027  decode.acc_seg: 98.3736\n",
      "03/09 16:30:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28500/40000]  base_lr: 4.9779e-05 lr: 4.9779e-05  eta: 2:30:09  time: 0.7769  data_time: 0.0218  memory: 5632  loss: 0.3375  decode.loss_ce: 0.3375  decode.acc_seg: 92.1091\n",
      "03/09 16:31:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28600/40000]  base_lr: 4.9742e-05 lr: 4.9742e-05  eta: 2:28:51  time: 0.7803  data_time: 0.0218  memory: 5632  loss: 0.3499  decode.loss_ce: 0.3499  decode.acc_seg: 61.9732\n",
      "03/09 16:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28700/40000]  base_lr: 4.9704e-05 lr: 4.9704e-05  eta: 2:27:33  time: 0.7792  data_time: 0.0226  memory: 5632  loss: 0.3111  decode.loss_ce: 0.3111  decode.acc_seg: 82.0049\n",
      "03/09 16:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28800/40000]  base_lr: 4.9666e-05 lr: 4.9666e-05  eta: 2:26:14  time: 0.7874  data_time: 0.0227  memory: 5634  loss: 0.2149  decode.loss_ce: 0.2149  decode.acc_seg: 80.7507\n",
      "03/09 16:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28900/40000]  base_lr: 4.9628e-05 lr: 4.9628e-05  eta: 2:24:56  time: 0.7821  data_time: 0.0225  memory: 5632  loss: 0.3264  decode.loss_ce: 0.3264  decode.acc_seg: 93.8854\n",
      "03/09 16:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 16:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29000/40000]  base_lr: 4.9590e-05 lr: 4.9590e-05  eta: 2:23:37  time: 0.7852  data_time: 0.0231  memory: 5634  loss: 0.8114  decode.loss_ce: 0.8114  decode.acc_seg: 68.3302\n",
      "03/09 16:37:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29100/40000]  base_lr: 4.9552e-05 lr: 4.9552e-05  eta: 2:22:19  time: 0.7839  data_time: 0.0226  memory: 5634  loss: 0.2291  decode.loss_ce: 0.2291  decode.acc_seg: 96.1960\n",
      "03/09 16:39:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29200/40000]  base_lr: 4.9515e-05 lr: 4.9515e-05  eta: 2:21:01  time: 0.7855  data_time: 0.0228  memory: 5632  loss: 0.2636  decode.loss_ce: 0.2636  decode.acc_seg: 90.4221\n",
      "03/09 16:40:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29300/40000]  base_lr: 4.9477e-05 lr: 4.9477e-05  eta: 2:19:42  time: 0.7820  data_time: 0.0220  memory: 5633  loss: 0.2605  decode.loss_ce: 0.2605  decode.acc_seg: 70.5499\n",
      "03/09 16:41:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29400/40000]  base_lr: 4.9439e-05 lr: 4.9439e-05  eta: 2:18:24  time: 0.7794  data_time: 0.0223  memory: 5634  loss: 0.5245  decode.loss_ce: 0.5245  decode.acc_seg: 90.7355\n",
      "03/09 16:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29500/40000]  base_lr: 4.9401e-05 lr: 4.9401e-05  eta: 2:17:06  time: 0.7784  data_time: 0.0226  memory: 5634  loss: 0.3126  decode.loss_ce: 0.3126  decode.acc_seg: 89.7148\n",
      "03/09 16:44:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29600/40000]  base_lr: 4.9363e-05 lr: 4.9363e-05  eta: 2:15:47  time: 0.7835  data_time: 0.0228  memory: 5634  loss: 0.2599  decode.loss_ce: 0.2599  decode.acc_seg: 92.5787\n",
      "03/09 16:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29700/40000]  base_lr: 4.9325e-05 lr: 4.9325e-05  eta: 2:14:29  time: 0.7822  data_time: 0.0238  memory: 5634  loss: 0.3110  decode.loss_ce: 0.3110  decode.acc_seg: 81.5655\n",
      "03/09 16:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29800/40000]  base_lr: 4.9287e-05 lr: 4.9287e-05  eta: 2:13:10  time: 0.7808  data_time: 0.0230  memory: 5632  loss: 0.2938  decode.loss_ce: 0.2938  decode.acc_seg: 91.2992\n",
      "03/09 16:48:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29900/40000]  base_lr: 4.9250e-05 lr: 4.9250e-05  eta: 2:11:52  time: 0.7910  data_time: 0.0242  memory: 5634  loss: 0.2160  decode.loss_ce: 0.2160  decode.acc_seg: 89.9084\n",
      "03/09 16:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 16:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30000/40000]  base_lr: 4.9212e-05 lr: 4.9212e-05  eta: 2:10:34  time: 0.7792  data_time: 0.0222  memory: 5632  loss: 0.3086  decode.loss_ce: 0.3086  decode.acc_seg: 94.0163\n",
      "03/09 16:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30000 iterations\n",
      "03/09 16:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30100/40000]  base_lr: 4.9174e-05 lr: 4.9174e-05  eta: 2:09:17  time: 0.7833  data_time: 0.0224  memory: 5634  loss: 0.2591  decode.loss_ce: 0.2591  decode.acc_seg: 87.8887\n",
      "03/09 16:52:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30200/40000]  base_lr: 4.9136e-05 lr: 4.9136e-05  eta: 2:07:59  time: 0.7802  data_time: 0.0225  memory: 5634  loss: 0.3058  decode.loss_ce: 0.3058  decode.acc_seg: 89.1233\n",
      "03/09 16:53:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30300/40000]  base_lr: 4.9098e-05 lr: 4.9098e-05  eta: 2:06:40  time: 0.7934  data_time: 0.0237  memory: 5632  loss: 0.3055  decode.loss_ce: 0.3055  decode.acc_seg: 82.6957\n",
      "03/09 16:54:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30400/40000]  base_lr: 4.9060e-05 lr: 4.9060e-05  eta: 2:05:22  time: 0.7856  data_time: 0.0231  memory: 5634  loss: 0.3583  decode.loss_ce: 0.3583  decode.acc_seg: 95.3093\n",
      "03/09 16:56:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30500/40000]  base_lr: 4.9022e-05 lr: 4.9022e-05  eta: 2:04:04  time: 0.7921  data_time: 0.0241  memory: 5634  loss: 0.2794  decode.loss_ce: 0.2794  decode.acc_seg: 80.7865\n",
      "03/09 16:57:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30600/40000]  base_lr: 4.8985e-05 lr: 4.8985e-05  eta: 2:02:46  time: 0.7813  data_time: 0.0226  memory: 5634  loss: 0.1979  decode.loss_ce: 0.1979  decode.acc_seg: 94.6118\n",
      "03/09 16:58:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30700/40000]  base_lr: 4.8947e-05 lr: 4.8947e-05  eta: 2:01:27  time: 0.7915  data_time: 0.0236  memory: 5634  loss: 0.3082  decode.loss_ce: 0.3082  decode.acc_seg: 69.2327\n",
      "03/09 17:00:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30800/40000]  base_lr: 4.8909e-05 lr: 4.8909e-05  eta: 2:00:09  time: 0.7816  data_time: 0.0225  memory: 5634  loss: 0.3098  decode.loss_ce: 0.3098  decode.acc_seg: 85.9197\n",
      "03/09 17:01:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30900/40000]  base_lr: 4.8871e-05 lr: 4.8871e-05  eta: 1:58:51  time: 0.7786  data_time: 0.0220  memory: 5632  loss: 0.3098  decode.loss_ce: 0.3098  decode.acc_seg: 86.0569\n",
      "03/09 17:02:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 17:02:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31000/40000]  base_lr: 4.8833e-05 lr: 4.8833e-05  eta: 1:57:32  time: 0.7810  data_time: 0.0220  memory: 5632  loss: 0.2376  decode.loss_ce: 0.2376  decode.acc_seg: 94.9018\n",
      "03/09 17:04:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31100/40000]  base_lr: 4.8795e-05 lr: 4.8795e-05  eta: 1:56:14  time: 0.7816  data_time: 0.0224  memory: 5632  loss: 0.1562  decode.loss_ce: 0.1562  decode.acc_seg: 87.9059\n",
      "03/09 17:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31200/40000]  base_lr: 4.8757e-05 lr: 4.8757e-05  eta: 1:54:55  time: 0.7806  data_time: 0.0224  memory: 5632  loss: 0.2962  decode.loss_ce: 0.2962  decode.acc_seg: 92.8693\n",
      "03/09 17:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31300/40000]  base_lr: 4.8720e-05 lr: 4.8720e-05  eta: 1:53:37  time: 0.7789  data_time: 0.0220  memory: 5633  loss: 0.2274  decode.loss_ce: 0.2274  decode.acc_seg: 88.0083\n",
      "03/09 17:08:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31400/40000]  base_lr: 4.8682e-05 lr: 4.8682e-05  eta: 1:52:19  time: 0.7850  data_time: 0.0226  memory: 5632  loss: 0.3285  decode.loss_ce: 0.3285  decode.acc_seg: 73.5987\n",
      "03/09 17:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31500/40000]  base_lr: 4.8644e-05 lr: 4.8644e-05  eta: 1:51:00  time: 0.7816  data_time: 0.0230  memory: 5634  loss: 0.3735  decode.loss_ce: 0.3735  decode.acc_seg: 77.4899\n",
      "03/09 17:10:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31600/40000]  base_lr: 4.8606e-05 lr: 4.8606e-05  eta: 1:49:42  time: 0.7892  data_time: 0.0230  memory: 5632  loss: 0.4246  decode.loss_ce: 0.4246  decode.acc_seg: 72.7320\n",
      "03/09 17:11:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31700/40000]  base_lr: 4.8568e-05 lr: 4.8568e-05  eta: 1:48:23  time: 0.7856  data_time: 0.0228  memory: 5634  loss: 0.4221  decode.loss_ce: 0.4221  decode.acc_seg: 82.0046\n",
      "03/09 17:13:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31800/40000]  base_lr: 4.8530e-05 lr: 4.8530e-05  eta: 1:47:05  time: 0.7835  data_time: 0.0223  memory: 5633  loss: 0.2416  decode.loss_ce: 0.2416  decode.acc_seg: 87.4206\n",
      "03/09 17:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31900/40000]  base_lr: 4.8492e-05 lr: 4.8492e-05  eta: 1:45:47  time: 0.7815  data_time: 0.0224  memory: 5634  loss: 0.3609  decode.loss_ce: 0.3609  decode.acc_seg: 76.8227\n",
      "03/09 17:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 17:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32000/40000]  base_lr: 4.8455e-05 lr: 4.8455e-05  eta: 1:44:28  time: 0.8044  data_time: 0.0229  memory: 5633  loss: 0.3011  decode.loss_ce: 0.3011  decode.acc_seg: 86.9254\n",
      "03/09 17:17:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32100/40000]  base_lr: 4.8417e-05 lr: 4.8417e-05  eta: 1:43:10  time: 0.7819  data_time: 0.0228  memory: 5632  loss: 0.3974  decode.loss_ce: 0.3974  decode.acc_seg: 70.7369\n",
      "03/09 17:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32200/40000]  base_lr: 4.8379e-05 lr: 4.8379e-05  eta: 1:41:52  time: 0.7798  data_time: 0.0224  memory: 5634  loss: 0.2067  decode.loss_ce: 0.2067  decode.acc_seg: 99.5231\n",
      "03/09 17:19:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32300/40000]  base_lr: 4.8341e-05 lr: 4.8341e-05  eta: 1:40:33  time: 0.7816  data_time: 0.0223  memory: 5632  loss: 0.5127  decode.loss_ce: 0.5127  decode.acc_seg: 78.1392\n",
      "03/09 17:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32400/40000]  base_lr: 4.8303e-05 lr: 4.8303e-05  eta: 1:39:15  time: 0.7811  data_time: 0.0222  memory: 5634  loss: 0.3003  decode.loss_ce: 0.3003  decode.acc_seg: 79.9984\n",
      "03/09 17:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32500/40000]  base_lr: 4.8265e-05 lr: 4.8265e-05  eta: 1:37:57  time: 0.7823  data_time: 0.0226  memory: 5632  loss: 0.1942  decode.loss_ce: 0.1942  decode.acc_seg: 87.1015\n",
      "03/09 17:23:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32600/40000]  base_lr: 4.8227e-05 lr: 4.8227e-05  eta: 1:36:38  time: 0.7792  data_time: 0.0223  memory: 5632  loss: 0.3461  decode.loss_ce: 0.3461  decode.acc_seg: 95.8548\n",
      "03/09 17:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32700/40000]  base_lr: 4.8190e-05 lr: 4.8190e-05  eta: 1:35:20  time: 0.7827  data_time: 0.0223  memory: 5633  loss: 0.3155  decode.loss_ce: 0.3155  decode.acc_seg: 81.0022\n",
      "03/09 17:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32800/40000]  base_lr: 4.8152e-05 lr: 4.8152e-05  eta: 1:34:01  time: 0.7798  data_time: 0.0223  memory: 5632  loss: 0.3200  decode.loss_ce: 0.3200  decode.acc_seg: 84.0996\n",
      "03/09 17:27:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32900/40000]  base_lr: 4.8114e-05 lr: 4.8114e-05  eta: 1:32:43  time: 0.7840  data_time: 0.0232  memory: 5634  loss: 0.3925  decode.loss_ce: 0.3925  decode.acc_seg: 85.2536\n",
      "03/09 17:28:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 17:28:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33000/40000]  base_lr: 4.8076e-05 lr: 4.8076e-05  eta: 1:31:25  time: 0.7826  data_time: 0.0230  memory: 5634  loss: 0.3865  decode.loss_ce: 0.3865  decode.acc_seg: 94.4684\n",
      "03/09 17:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33100/40000]  base_lr: 4.8038e-05 lr: 4.8038e-05  eta: 1:30:06  time: 0.7780  data_time: 0.0219  memory: 5632  loss: 0.2450  decode.loss_ce: 0.2450  decode.acc_seg: 97.1891\n",
      "03/09 17:31:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33200/40000]  base_lr: 4.8000e-05 lr: 4.8000e-05  eta: 1:28:48  time: 0.7815  data_time: 0.0225  memory: 5634  loss: 0.4614  decode.loss_ce: 0.4614  decode.acc_seg: 87.3146\n",
      "03/09 17:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33300/40000]  base_lr: 4.7962e-05 lr: 4.7962e-05  eta: 1:27:29  time: 0.7852  data_time: 0.0230  memory: 5633  loss: 0.2651  decode.loss_ce: 0.2651  decode.acc_seg: 88.0377\n",
      "03/09 17:34:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33400/40000]  base_lr: 4.7925e-05 lr: 4.7925e-05  eta: 1:26:11  time: 0.7853  data_time: 0.0238  memory: 5634  loss: 0.3145  decode.loss_ce: 0.3145  decode.acc_seg: 60.2459\n",
      "03/09 17:35:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33500/40000]  base_lr: 4.7887e-05 lr: 4.7887e-05  eta: 1:24:53  time: 0.7833  data_time: 0.0229  memory: 5634  loss: 0.3026  decode.loss_ce: 0.3026  decode.acc_seg: 89.6837\n",
      "03/09 17:36:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33600/40000]  base_lr: 4.7849e-05 lr: 4.7849e-05  eta: 1:23:35  time: 0.7909  data_time: 0.0235  memory: 5634  loss: 0.2220  decode.loss_ce: 0.2220  decode.acc_seg: 71.4891\n",
      "03/09 17:38:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33700/40000]  base_lr: 4.7811e-05 lr: 4.7811e-05  eta: 1:22:16  time: 0.7852  data_time: 0.0232  memory: 5634  loss: 0.5552  decode.loss_ce: 0.5552  decode.acc_seg: 89.7289\n",
      "03/09 17:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33800/40000]  base_lr: 4.7773e-05 lr: 4.7773e-05  eta: 1:20:58  time: 0.7876  data_time: 0.0231  memory: 5634  loss: 0.3538  decode.loss_ce: 0.3538  decode.acc_seg: 85.9344\n",
      "03/09 17:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33900/40000]  base_lr: 4.7735e-05 lr: 4.7735e-05  eta: 1:19:40  time: 0.7816  data_time: 0.0228  memory: 5634  loss: 0.2598  decode.loss_ce: 0.2598  decode.acc_seg: 80.9931\n",
      "03/09 17:41:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 17:41:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34000/40000]  base_lr: 4.7697e-05 lr: 4.7697e-05  eta: 1:18:21  time: 0.7916  data_time: 0.0241  memory: 5632  loss: 0.3274  decode.loss_ce: 0.3274  decode.acc_seg: 76.7027\n",
      "03/09 17:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34100/40000]  base_lr: 4.7660e-05 lr: 4.7660e-05  eta: 1:17:03  time: 0.7832  data_time: 0.0230  memory: 5634  loss: 0.1366  decode.loss_ce: 0.1366  decode.acc_seg: 89.8872\n",
      "03/09 17:44:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34200/40000]  base_lr: 4.7622e-05 lr: 4.7622e-05  eta: 1:15:44  time: 0.7822  data_time: 0.0233  memory: 5632  loss: 0.3900  decode.loss_ce: 0.3900  decode.acc_seg: 85.2991\n",
      "03/09 17:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34300/40000]  base_lr: 4.7584e-05 lr: 4.7584e-05  eta: 1:14:26  time: 0.7811  data_time: 0.0223  memory: 5632  loss: 0.2592  decode.loss_ce: 0.2592  decode.acc_seg: 88.3539\n",
      "03/09 17:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34400/40000]  base_lr: 4.7546e-05 lr: 4.7546e-05  eta: 1:13:08  time: 0.7791  data_time: 0.0223  memory: 5632  loss: 0.2686  decode.loss_ce: 0.2686  decode.acc_seg: 97.8474\n",
      "03/09 17:48:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34500/40000]  base_lr: 4.7508e-05 lr: 4.7508e-05  eta: 1:11:49  time: 0.7812  data_time: 0.0223  memory: 5633  loss: 0.4419  decode.loss_ce: 0.4419  decode.acc_seg: 84.8290\n",
      "03/09 17:49:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34600/40000]  base_lr: 4.7470e-05 lr: 4.7470e-05  eta: 1:10:31  time: 0.7810  data_time: 0.0227  memory: 5634  loss: 0.3749  decode.loss_ce: 0.3749  decode.acc_seg: 81.8062\n",
      "03/09 17:51:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34700/40000]  base_lr: 4.7432e-05 lr: 4.7432e-05  eta: 1:09:13  time: 0.7798  data_time: 0.0228  memory: 5632  loss: 0.2739  decode.loss_ce: 0.2739  decode.acc_seg: 88.4595\n",
      "03/09 17:52:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34800/40000]  base_lr: 4.7395e-05 lr: 4.7395e-05  eta: 1:07:54  time: 0.7815  data_time: 0.0225  memory: 5634  loss: 0.3076  decode.loss_ce: 0.3076  decode.acc_seg: 90.8736\n",
      "03/09 17:53:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34900/40000]  base_lr: 4.7357e-05 lr: 4.7357e-05  eta: 1:06:36  time: 0.7838  data_time: 0.0240  memory: 5632  loss: 0.5568  decode.loss_ce: 0.5568  decode.acc_seg: 61.3826\n",
      "03/09 17:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 17:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35000/40000]  base_lr: 4.7319e-05 lr: 4.7319e-05  eta: 1:05:17  time: 0.7831  data_time: 0.0229  memory: 5632  loss: 0.2746  decode.loss_ce: 0.2746  decode.acc_seg: 88.9680\n",
      "03/09 17:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35100/40000]  base_lr: 4.7281e-05 lr: 4.7281e-05  eta: 1:03:59  time: 0.7872  data_time: 0.0236  memory: 5634  loss: 0.2227  decode.loss_ce: 0.2227  decode.acc_seg: 88.7199\n",
      "03/09 17:57:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35200/40000]  base_lr: 4.7243e-05 lr: 4.7243e-05  eta: 1:02:41  time: 0.7791  data_time: 0.0226  memory: 5634  loss: 0.3686  decode.loss_ce: 0.3686  decode.acc_seg: 80.7989\n",
      "03/09 17:58:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35300/40000]  base_lr: 4.7205e-05 lr: 4.7205e-05  eta: 1:01:22  time: 0.7837  data_time: 0.0226  memory: 5634  loss: 0.1419  decode.loss_ce: 0.1419  decode.acc_seg: 90.5191\n",
      "03/09 18:00:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35400/40000]  base_lr: 4.7167e-05 lr: 4.7167e-05  eta: 1:00:04  time: 0.7812  data_time: 0.0226  memory: 5634  loss: 0.3220  decode.loss_ce: 0.3220  decode.acc_seg: 84.3353\n",
      "03/09 18:01:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35500/40000]  base_lr: 4.7130e-05 lr: 4.7130e-05  eta: 0:58:46  time: 0.7796  data_time: 0.0228  memory: 5632  loss: 0.2284  decode.loss_ce: 0.2284  decode.acc_seg: 92.7614\n",
      "03/09 18:02:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35600/40000]  base_lr: 4.7092e-05 lr: 4.7092e-05  eta: 0:57:27  time: 0.7827  data_time: 0.0237  memory: 5634  loss: 0.6486  decode.loss_ce: 0.6486  decode.acc_seg: 69.2513\n",
      "03/09 18:04:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35700/40000]  base_lr: 4.7054e-05 lr: 4.7054e-05  eta: 0:56:09  time: 0.7806  data_time: 0.0225  memory: 5632  loss: 0.3276  decode.loss_ce: 0.3276  decode.acc_seg: 91.0761\n",
      "03/09 18:05:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35800/40000]  base_lr: 4.7016e-05 lr: 4.7016e-05  eta: 0:54:50  time: 0.7845  data_time: 0.0230  memory: 5632  loss: 0.3611  decode.loss_ce: 0.3611  decode.acc_seg: 95.6931\n",
      "03/09 18:06:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35900/40000]  base_lr: 4.6978e-05 lr: 4.6978e-05  eta: 0:53:32  time: 0.7809  data_time: 0.0230  memory: 5632  loss: 0.2939  decode.loss_ce: 0.2939  decode.acc_seg: 94.9897\n",
      "03/09 18:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 18:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36000/40000]  base_lr: 4.6940e-05 lr: 4.6940e-05  eta: 0:52:14  time: 0.7839  data_time: 0.0238  memory: 5634  loss: 0.5783  decode.loss_ce: 0.5783  decode.acc_seg: 78.4108\n",
      "03/09 18:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36100/40000]  base_lr: 4.6903e-05 lr: 4.6903e-05  eta: 0:50:55  time: 0.7812  data_time: 0.0224  memory: 5634  loss: 0.2532  decode.loss_ce: 0.2532  decode.acc_seg: 78.8517\n",
      "03/09 18:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36200/40000]  base_lr: 4.6865e-05 lr: 4.6865e-05  eta: 0:49:37  time: 0.7875  data_time: 0.0219  memory: 5634  loss: 0.3705  decode.loss_ce: 0.3705  decode.acc_seg: 80.5128\n",
      "03/09 18:11:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36300/40000]  base_lr: 4.6827e-05 lr: 4.6827e-05  eta: 0:48:19  time: 0.7821  data_time: 0.0233  memory: 5634  loss: 0.2255  decode.loss_ce: 0.2255  decode.acc_seg: 97.0915\n",
      "03/09 18:13:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36400/40000]  base_lr: 4.6789e-05 lr: 4.6789e-05  eta: 0:47:00  time: 0.7802  data_time: 0.0224  memory: 5632  loss: 0.2760  decode.loss_ce: 0.2760  decode.acc_seg: 41.7261\n",
      "03/09 18:14:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36500/40000]  base_lr: 4.6751e-05 lr: 4.6751e-05  eta: 0:45:42  time: 0.7805  data_time: 0.0226  memory: 5634  loss: 0.4241  decode.loss_ce: 0.4241  decode.acc_seg: 82.0473\n",
      "03/09 18:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36600/40000]  base_lr: 4.6713e-05 lr: 4.6713e-05  eta: 0:44:24  time: 0.7846  data_time: 0.0228  memory: 5632  loss: 0.2500  decode.loss_ce: 0.2500  decode.acc_seg: 91.2572\n",
      "03/09 18:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36700/40000]  base_lr: 4.6675e-05 lr: 4.6675e-05  eta: 0:43:05  time: 0.7812  data_time: 0.0221  memory: 5634  loss: 0.3078  decode.loss_ce: 0.3078  decode.acc_seg: 88.8085\n",
      "03/09 18:18:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36800/40000]  base_lr: 4.6638e-05 lr: 4.6638e-05  eta: 0:41:47  time: 0.7798  data_time: 0.0224  memory: 5634  loss: 0.2441  decode.loss_ce: 0.2441  decode.acc_seg: 97.7205\n",
      "03/09 18:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36900/40000]  base_lr: 4.6600e-05 lr: 4.6600e-05  eta: 0:40:28  time: 0.7876  data_time: 0.0238  memory: 5632  loss: 0.2300  decode.loss_ce: 0.2300  decode.acc_seg: 86.1686\n",
      "03/09 18:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 18:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37000/40000]  base_lr: 4.6562e-05 lr: 4.6562e-05  eta: 0:39:10  time: 0.7851  data_time: 0.0228  memory: 5634  loss: 0.2456  decode.loss_ce: 0.2456  decode.acc_seg: 87.2548\n",
      "03/09 18:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37100/40000]  base_lr: 4.6524e-05 lr: 4.6524e-05  eta: 0:37:52  time: 0.7873  data_time: 0.0241  memory: 5633  loss: 0.3062  decode.loss_ce: 0.3062  decode.acc_seg: 93.1264\n",
      "03/09 18:23:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37200/40000]  base_lr: 4.6486e-05 lr: 4.6486e-05  eta: 0:36:33  time: 0.7808  data_time: 0.0228  memory: 5633  loss: 0.2632  decode.loss_ce: 0.2632  decode.acc_seg: 91.6960\n",
      "03/09 18:25:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37300/40000]  base_lr: 4.6448e-05 lr: 4.6448e-05  eta: 0:35:15  time: 0.7876  data_time: 0.0238  memory: 5634  loss: 0.2718  decode.loss_ce: 0.2718  decode.acc_seg: 83.7353\n",
      "03/09 18:26:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37400/40000]  base_lr: 4.6410e-05 lr: 4.6410e-05  eta: 0:33:57  time: 0.7852  data_time: 0.0229  memory: 5634  loss: 0.2662  decode.loss_ce: 0.2662  decode.acc_seg: 92.5199\n",
      "03/09 18:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37500/40000]  base_lr: 4.6373e-05 lr: 4.6373e-05  eta: 0:32:38  time: 0.7810  data_time: 0.0223  memory: 5634  loss: 0.2340  decode.loss_ce: 0.2340  decode.acc_seg: 83.1363\n",
      "03/09 18:28:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37600/40000]  base_lr: 4.6335e-05 lr: 4.6335e-05  eta: 0:31:20  time: 0.7818  data_time: 0.0228  memory: 5632  loss: 0.2606  decode.loss_ce: 0.2606  decode.acc_seg: 93.9025\n",
      "03/09 18:30:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37700/40000]  base_lr: 4.6297e-05 lr: 4.6297e-05  eta: 0:30:02  time: 0.7789  data_time: 0.0218  memory: 5632  loss: 0.3253  decode.loss_ce: 0.3253  decode.acc_seg: 95.1275\n",
      "03/09 18:31:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37800/40000]  base_lr: 4.6259e-05 lr: 4.6259e-05  eta: 0:28:43  time: 0.7812  data_time: 0.0230  memory: 5632  loss: 0.2672  decode.loss_ce: 0.2672  decode.acc_seg: 85.3909\n",
      "03/09 18:32:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37900/40000]  base_lr: 4.6221e-05 lr: 4.6221e-05  eta: 0:27:25  time: 0.7853  data_time: 0.0233  memory: 5633  loss: 0.2421  decode.loss_ce: 0.2421  decode.acc_seg: 91.9457\n",
      "03/09 18:34:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 18:34:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38000/40000]  base_lr: 4.6183e-05 lr: 4.6183e-05  eta: 0:26:07  time: 0.7834  data_time: 0.0227  memory: 5634  loss: 0.5410  decode.loss_ce: 0.5410  decode.acc_seg: 94.0733\n",
      "03/09 18:35:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38100/40000]  base_lr: 4.6145e-05 lr: 4.6145e-05  eta: 0:24:48  time: 0.7804  data_time: 0.0222  memory: 5634  loss: 0.2181  decode.loss_ce: 0.2181  decode.acc_seg: 81.8022\n",
      "03/09 18:36:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38200/40000]  base_lr: 4.6108e-05 lr: 4.6108e-05  eta: 0:23:30  time: 0.7894  data_time: 0.0240  memory: 5634  loss: 0.2487  decode.loss_ce: 0.2487  decode.acc_seg: 82.1669\n",
      "03/09 18:38:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38300/40000]  base_lr: 4.6070e-05 lr: 4.6070e-05  eta: 0:22:12  time: 0.7814  data_time: 0.0223  memory: 5634  loss: 0.3332  decode.loss_ce: 0.3332  decode.acc_seg: 64.7912\n",
      "03/09 18:39:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38400/40000]  base_lr: 4.6032e-05 lr: 4.6032e-05  eta: 0:20:53  time: 0.7866  data_time: 0.0240  memory: 5632  loss: 0.4832  decode.loss_ce: 0.4832  decode.acc_seg: 91.6306\n",
      "03/09 18:40:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38500/40000]  base_lr: 4.5994e-05 lr: 4.5994e-05  eta: 0:19:35  time: 0.7819  data_time: 0.0220  memory: 5632  loss: 0.4060  decode.loss_ce: 0.4060  decode.acc_seg: 92.1288\n",
      "03/09 18:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38600/40000]  base_lr: 4.5956e-05 lr: 4.5956e-05  eta: 0:18:16  time: 0.7932  data_time: 0.0230  memory: 5632  loss: 0.4032  decode.loss_ce: 0.4032  decode.acc_seg: 79.8439\n",
      "03/09 18:43:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38700/40000]  base_lr: 4.5918e-05 lr: 4.5918e-05  eta: 0:16:58  time: 0.7813  data_time: 0.0221  memory: 5634  loss: 0.2908  decode.loss_ce: 0.2908  decode.acc_seg: 74.2948\n",
      "03/09 18:44:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38800/40000]  base_lr: 4.5880e-05 lr: 4.5880e-05  eta: 0:15:40  time: 0.7813  data_time: 0.0226  memory: 5634  loss: 0.3057  decode.loss_ce: 0.3057  decode.acc_seg: 97.8849\n",
      "03/09 18:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38900/40000]  base_lr: 4.5843e-05 lr: 4.5843e-05  eta: 0:14:21  time: 0.7805  data_time: 0.0226  memory: 5633  loss: 0.2322  decode.loss_ce: 0.2322  decode.acc_seg: 96.5351\n",
      "03/09 18:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 18:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39000/40000]  base_lr: 4.5805e-05 lr: 4.5805e-05  eta: 0:13:03  time: 0.7828  data_time: 0.0228  memory: 5634  loss: 0.2837  decode.loss_ce: 0.2837  decode.acc_seg: 80.6709\n",
      "03/09 18:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39100/40000]  base_lr: 4.5767e-05 lr: 4.5767e-05  eta: 0:11:45  time: 0.7829  data_time: 0.0235  memory: 5634  loss: 0.2283  decode.loss_ce: 0.2283  decode.acc_seg: 91.8232\n",
      "03/09 18:49:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39200/40000]  base_lr: 4.5729e-05 lr: 4.5729e-05  eta: 0:10:26  time: 0.7835  data_time: 0.0227  memory: 5632  loss: 0.3360  decode.loss_ce: 0.3360  decode.acc_seg: 79.3223\n",
      "03/09 18:51:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39300/40000]  base_lr: 4.5691e-05 lr: 4.5691e-05  eta: 0:09:08  time: 0.7831  data_time: 0.0219  memory: 5632  loss: 0.3539  decode.loss_ce: 0.3539  decode.acc_seg: 66.2965\n",
      "03/09 18:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39400/40000]  base_lr: 4.5653e-05 lr: 4.5653e-05  eta: 0:07:50  time: 0.7815  data_time: 0.0225  memory: 5632  loss: 0.5437  decode.loss_ce: 0.5437  decode.acc_seg: 94.0075\n",
      "03/09 18:53:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39500/40000]  base_lr: 4.5615e-05 lr: 4.5615e-05  eta: 0:06:31  time: 0.7882  data_time: 0.0239  memory: 5634  loss: 0.1785  decode.loss_ce: 0.1785  decode.acc_seg: 86.6288\n",
      "03/09 18:55:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39600/40000]  base_lr: 4.5578e-05 lr: 4.5578e-05  eta: 0:05:13  time: 0.7821  data_time: 0.0226  memory: 5634  loss: 0.2318  decode.loss_ce: 0.2318  decode.acc_seg: 86.0960\n",
      "03/09 18:56:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39700/40000]  base_lr: 4.5540e-05 lr: 4.5540e-05  eta: 0:03:55  time: 0.7836  data_time: 0.0226  memory: 5632  loss: 0.6219  decode.loss_ce: 0.6219  decode.acc_seg: 62.0386\n",
      "03/09 18:57:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39800/40000]  base_lr: 4.5502e-05 lr: 4.5502e-05  eta: 0:02:36  time: 0.7804  data_time: 0.0224  memory: 5634  loss: 0.2700  decode.loss_ce: 0.2700  decode.acc_seg: 96.8345\n",
      "03/09 18:58:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39900/40000]  base_lr: 4.5464e-05 lr: 4.5464e-05  eta: 0:01:18  time: 0.7791  data_time: 0.0228  memory: 5634  loss: 0.1785  decode.loss_ce: 0.1785  decode.acc_seg: 89.5643\n",
      "03/09 19:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240309_101652\n",
      "03/09 19:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40000/40000]  base_lr: 4.5426e-05 lr: 4.5426e-05  eta: 0:00:00  time: 0.7834  data_time: 0.0228  memory: 5634  loss: 0.3062  decode.loss_ce: 0.3062  decode.acc_seg: 81.6179\n",
      "03/09 19:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40000 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (data_preprocessor): SegDataPreProcessor()\n",
       "  (backbone): MixVisionTransformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (12): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (13): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (14): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (15): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (16): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (17): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (18): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (19): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (20): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (21): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (22): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (23): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (24): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (25): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (26): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (27): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (28): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (29): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (30): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (31): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (32): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (33): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (34): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (35): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (36): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (37): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (38): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (39): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'}\n",
       "  (decode_head): UPerHead(\n",
       "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (conv_seg): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (psp_modules): PPM(\n",
       "      (0): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=1)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=2)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=3)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): AdaptiveAvgPool2d(output_size=6)\n",
       "        (1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck): ConvModule(\n",
       "      (conv): Conv2d(1536, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (fpn_bottleneck): ConvModule(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/vit/upernet_deit-s16_512x512_80k_ade20k/upernet_deit-s16_512x512_80k_ade20k_20210624_095228-afc93ec2.pth'}\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7bfebe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-09T19:00:21.455004Z",
     "iopub.status.busy": "2024-03-09T19:00:21.454620Z",
     "iopub.status.idle": "2024-03-09T19:04:16.205532Z",
     "shell.execute_reply": "2024-03-09T19:04:16.204321Z"
    },
    "papermill": {
     "duration": 234.965947,
     "end_time": "2024-03-09T19:04:16.207935",
     "exception": false,
     "start_time": "2024-03-09T19:00:21.241988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/datasets/transforms/loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/09 19:01:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/450]    eta: 0:03:08  time: 0.5414  data_time: 0.3515  memory: 9967  \n",
      "03/09 19:02:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/450]    eta: 0:02:15  time: 0.6470  data_time: 0.4529  memory: 2677  \n",
      "03/09 19:03:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/450]    eta: 0:01:20  time: 0.4893  data_time: 0.2789  memory: 2666  \n",
      "03/09 19:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/450]    eta: 0:00:26  time: 0.4757  data_time: 0.2703  memory: 2499  \n",
      "03/09 19:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "03/09 19:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 20.34 | 24.31 |  33.8 |  33.8  |    55.4   | 24.31  |\n",
      "| BuildingFlooded | 69.53 | 89.65 | 82.03 | 82.03  |   75.59   | 89.65  |\n",
      "|   BNonFlooded   | 56.71 | 71.76 | 72.37 | 72.37  |   72.99   | 71.76  |\n",
      "|   RoadFlooded   | 37.91 | 40.71 | 54.98 | 54.98  |   84.66   | 40.71  |\n",
      "|   RNonFlooded   | 70.64 |  75.6 | 82.79 | 82.79  |    91.5   |  75.6  |\n",
      "|      Water      | 62.21 | 80.47 | 76.71 | 76.71  |   73.28   | 80.47  |\n",
      "|       Tree      |  76.5 | 84.68 | 86.69 | 86.69  |   88.79   | 84.68  |\n",
      "|      Vecile     | 12.56 | 13.16 | 22.31 | 22.31  |   73.24   | 13.16  |\n",
      "|       Pool      | 40.03 | 42.61 | 57.17 | 57.17  |   86.85   | 42.61  |\n",
      "|      Grass      | 83.86 | 94.13 | 91.22 | 91.22  |   88.49   | 94.13  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "03/09 19:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/450]    aAcc: 85.6700  mIoU: 53.0300  mAcc: 61.7100  mDice: 66.0100  mFscore: 66.0100  mPrecision: 79.0800  mRecall: 61.7100  data_time: 0.3161  time: 0.5183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aAcc': 85.67,\n",
       " 'mIoU': 53.03,\n",
       " 'mAcc': 61.71,\n",
       " 'mDice': 66.01,\n",
       " 'mFscore': 66.01,\n",
       " 'mPrecision': 79.08,\n",
       " 'mRecall': 61.71}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac4c63",
   "metadata": {
    "papermill": {
     "duration": 0.210189,
     "end_time": "2024-03-09T19:04:16.631480",
     "exception": false,
     "start_time": "2024-03-09T19:04:16.421291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2963587,
     "sourceId": 5104516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31869.766928,
   "end_time": "2024-03-09T19:04:19.843934",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-09T10:13:10.077006",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
