{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20825665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:56:06.847786Z",
     "iopub.status.busy": "2023-07-27T07:56:06.846767Z",
     "iopub.status.idle": "2023-07-27T07:56:07.807926Z",
     "shell.execute_reply": "2023-07-27T07:56:07.806698Z"
    },
    "papermill": {
     "duration": 0.971419,
     "end_time": "2023-07-27T07:56:07.810806",
     "exception": false,
     "start_time": "2023-07-27T07:56:06.839387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\r\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\r\n",
      "Cuda compilation tools, release 11.8, V11.8.89\r\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f54ff0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:56:07.823980Z",
     "iopub.status.busy": "2023-07-27T07:56:07.823602Z",
     "iopub.status.idle": "2023-07-27T07:56:08.822378Z",
     "shell.execute_reply": "2023-07-27T07:56:08.821185Z"
    },
    "papermill": {
     "duration": 1.008802,
     "end_time": "2023-07-27T07:56:08.825262",
     "exception": false,
     "start_time": "2023-07-27T07:56:07.816460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul 27 07:56:08 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8def4ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:56:08.839531Z",
     "iopub.status.busy": "2023-07-27T07:56:08.838570Z",
     "iopub.status.idle": "2023-07-27T07:56:08.846493Z",
     "shell.execute_reply": "2023-07-27T07:56:08.845271Z"
    },
    "papermill": {
     "duration": 0.017399,
     "end_time": "2023-07-27T07:56:08.848801",
     "exception": false,
     "start_time": "2023-07-27T07:56:08.831402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7120914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:56:08.862825Z",
     "iopub.status.busy": "2023-07-27T07:56:08.862005Z",
     "iopub.status.idle": "2023-07-27T07:57:20.182913Z",
     "shell.execute_reply": "2023-07-27T07:57:20.181721Z"
    },
    "papermill": {
     "duration": 71.330478,
     "end_time": "2023-07-27T07:57:20.185416",
     "exception": false,
     "start_time": "2023-07-27T07:56:08.854938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.12.0\r\n",
      "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m811.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchvision==0.13.0\r\n",
      "  Downloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchaudio==0.12.0\r\n",
      "  Downloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl (3.7 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.12.0) (4.6.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (1.23.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (2023.5.7)\r\n",
      "Installing collected packages: torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.0.0\r\n",
      "    Uninstalling torch-2.0.0:\r\n",
      "      Successfully uninstalled torch-2.0.0\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.15.1\r\n",
      "    Uninstalling torchvision-0.15.1:\r\n",
      "      Successfully uninstalled torchvision-0.15.1\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.0.1\r\n",
      "    Uninstalling torchaudio-2.0.1:\r\n",
      "      Successfully uninstalled torchaudio-2.0.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0 torchaudio-0.12.0 torchvision-0.13.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.7.0 torchvision==0.8.0\n",
    "!pip install torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5ef6b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:57:20.255039Z",
     "iopub.status.busy": "2023-07-27T07:57:20.254627Z",
     "iopub.status.idle": "2023-07-27T07:58:16.149382Z",
     "shell.execute_reply": "2023-07-27T07:58:16.148193Z"
    },
    "papermill": {
     "duration": 55.932383,
     "end_time": "2023-07-27T07:58:16.151925",
     "exception": false,
     "start_time": "2023-07-27T07:57:20.219542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Click in /opt/conda/lib/python3.10/site-packages (from openmim) (8.1.3)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim) (0.4.6)\r\n",
      "Collecting model-index (from openmim)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Collecting opendatalab (from openmim)\r\n",
      "  Downloading opendatalab-0.0.9-py3-none-any.whl (29 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from openmim) (1.5.3)\r\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.10/site-packages (from openmim) (23.1.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openmim) (2.31.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim) (13.4.2)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (6.0)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (3.4.3)\r\n",
      "Collecting ordered-set (from model-index->openmim)\r\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (3.18.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (4.65.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2023.5.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.3)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (1.23.5)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\r\n",
      "Installing collected packages: ordered-set, model-index, opendatalab, openmim\r\n",
      "Successfully installed model-index-0.1.11 opendatalab-0.0.9 openmim-0.3.9 ordered-set-4.1.0\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmengine\r\n",
      "  Downloading mmengine-0.8.2-py3-none-any.whl (433 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting addict (from mmengine)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine) (3.7.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmengine) (1.23.5)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmengine) (6.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine) (2.3.0)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmengine) (0.40.1)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine) (4.8.0.74)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.15.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (6.7.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (3.8.1)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.15.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\r\n",
      "Installing collected packages: addict, mmengine\r\n",
      "Successfully installed addict-2.4.0 mmengine-0.8.2\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmcv>=2.0.0rc1\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/mmcv-2.0.1-cp310-cp310-manylinux1_x86_64.whl (58.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.8.2)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (1.23.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (6.0)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.40.1)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (4.8.0.74)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.7.1)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.3.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv>=2.0.0rc1) (3.0.9)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (6.7.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (3.8.1)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc1) (3.15.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.4.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.2.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.15.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.1.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.16.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openmim\n",
    "# Install mmengine\n",
    "!mim install mmengine\n",
    "# Install MMCV\n",
    "!mim install 'mmcv >= 2.0.0rc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9432fbf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:16.255364Z",
     "iopub.status.busy": "2023-07-27T07:58:16.254986Z",
     "iopub.status.idle": "2023-07-27T07:58:17.185098Z",
     "shell.execute_reply": "2023-07-27T07:58:17.183880Z"
    },
    "papermill": {
     "duration": 0.98483,
     "end_time": "2023-07-27T07:58:17.187458",
     "exception": false,
     "start_time": "2023-07-27T07:58:16.202628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "0.13.0+cu102\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc921e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:17.290552Z",
     "iopub.status.busy": "2023-07-27T07:58:17.289986Z",
     "iopub.status.idle": "2023-07-27T07:58:39.471918Z",
     "shell.execute_reply": "2023-07-27T07:58:39.470523Z"
    },
    "papermill": {
     "duration": 22.236045,
     "end_time": "2023-07-27T07:58:39.474389",
     "exception": false,
     "start_time": "2023-07-27T07:58:17.238344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'mmsegmentation': No such file or directory\r\n",
      "Cloning into 'mmsegmentation'...\r\n",
      "remote: Enumerating objects: 1530, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1530/1530), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (765/765), done.\u001b[K\r\n",
      "remote: Total 1530 (delta 771), reused 1502 (delta 743), pack-reused 0\u001b[K\r\n",
      "Receiving objects: 100% (1530/1530), 5.36 MiB | 21.29 MiB/s, done.\r\n",
      "Resolving deltas: 100% (771/771), done.\r\n",
      "/kaggle/working/mmsegmentation\n",
      "running build\r\n",
      "running build_py\r\n",
      "creating build\r\n",
      "creating build/lib\r\n",
      "creating build/lib/mmseg\r\n",
      "copying mmseg/version.py -> build/lib/mmseg\r\n",
      "copying mmseg/__init__.py -> build/lib/mmseg\r\n",
      "creating build/lib/tests\r\n",
      "copying tests/test_config.py -> build/lib/tests\r\n",
      "copying tests/test_sampler.py -> build/lib/tests\r\n",
      "copying tests/__init__.py -> build/lib/tests\r\n",
      "copying tests/test_digit_version.py -> build/lib/tests\r\n",
      "creating build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/__init__.py -> build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/seg_data_sample.py -> build/lib/mmseg/structures\r\n",
      "creating build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/local_visualizer.py -> build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/__init__.py -> build/lib/mmseg/visualization\r\n",
      "creating build/lib/mmseg/evaluation\r\n",
      "copying mmseg/evaluation/__init__.py -> build/lib/mmseg/evaluation\r\n",
      "creating build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/io.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/misc.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/class_names.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/collect_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/__init__.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/set_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/typing_utils.py -> build/lib/mmseg/utils\r\n",
      "creating build/lib/mmseg/models\r\n",
      "copying mmseg/models/data_preprocessor.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/builder.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/__init__.py -> build/lib/mmseg/models\r\n",
      "creating build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/decathlon.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isaid.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/basesegdataset.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/chase_db1.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/pascal_context.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dataset_wrappers.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/potsdam.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/lip.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dark_zurich.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/mapillary.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/cityscapes.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/night_driving.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/voc.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hrf.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/__init__.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/synapse.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isprs.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/coco_stuff.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/stare.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/loveda.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/refuge.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/ade.py -> build/lib/mmseg/datasets\r\n",
      "creating build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/registry.py -> build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/__init__.py -> build/lib/mmseg/registry\r\n",
      "creating build/lib/mmseg/engine\r\n",
      "copying mmseg/engine/__init__.py -> build/lib/mmseg/engine\r\n",
      "creating build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/inference.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/__init__.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/mmseg_inferencer.py -> build/lib/mmseg/apis\r\n",
      "creating build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/base_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/builder.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/__init__.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/ohem_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "creating build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/citys_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/iou_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/__init__.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "creating build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/seg_tta.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/cascade_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/__init__.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/base.py -> build/lib/mmseg/models/segmentors\r\n",
      "creating build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/accuracy.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/tversky_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/boundary_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/focal_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/ohem_cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/__init__.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/utils.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/lovasz_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/dice_loss.py -> build/lib/mmseg/models/losses\r\n",
      "creating build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/__init__.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/featurepyramid.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/ic_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/multilevel_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/jpu.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/fpn.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/mla_neck.py -> build/lib/mmseg/models/necks\r\n",
      "creating build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ema_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_up_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/maskformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/knet_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/lraspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/stdc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/point_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dnl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cascade_decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_mla_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/da_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ocr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ham_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dpt_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fpn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/__init__.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/isa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/gc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ann_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/enc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segmenter_mask_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/pid_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dm_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/apc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/uper_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/mask2former_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/nl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "creating build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/up_conv_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/inverted_residual.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/embed.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/ppm.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/basic_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/se_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/encoding.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/res_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/wrappers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/__init__.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/self_attention_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/make_divisible.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/shape_convert.py -> build/lib/mmseg/models/utils\r\n",
      "creating build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/stdc.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/pidnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/unet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnest.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnext.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mae.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/swin.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/timm_backbone.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/__init__.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/fast_scnn.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/hrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mscan.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v3.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/twins.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/erfnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/cgnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv1.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/beit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/icnet.py -> build/lib/mmseg/models/backbones\r\n",
      "creating build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/formatting.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/loading.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/transforms.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/__init__.py -> build/lib/mmseg/datasets/transforms\r\n",
      "creating build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/layer_decay_optimizer_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/__init__.py -> build/lib/mmseg/engine/optimizers\r\n",
      "creating build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/visualization_hook.py -> build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/__init__.py -> build/lib/mmseg/engine/hooks\r\n",
      "creating build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_forward.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_data_preprocessor.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/__init__.py -> build/lib/tests/test_models\r\n",
      "creating build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_embed.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_shape_convert.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/__init__.py -> build/lib/tests/test_models/test_utils\r\n",
      "creating build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv2.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_cgnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mobilenet_v3.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_timm_backbone.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_swin.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_twins.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_hrnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_stdc.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_icnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnest.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mae.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_fast_scnn.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_blocks.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv1.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_erfnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/__init__.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_pidnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_beit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/utils.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mscan.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_unet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnext.py -> build/lib/tests/test_models/test_backbones\r\n",
      "creating build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_seg_tta_model.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_cascade_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/__init__.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/utils.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "creating build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_feature2pyramid.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_jpu.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_ic_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_mla_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/__init__.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_multilevel_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_fpn.py -> build/lib/tests/test_models/test_necks\r\n",
      "creating build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_uper_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_isa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_up_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_mla_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dm_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_maskformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_nl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_apc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ocr_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dnl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_gc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dpt_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_fcn_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ema_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_decode_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_mask2former_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/__init__.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ann_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/utils.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_pidnet_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_cc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_lraspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ham_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_aspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segmenter_mask_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "running egg_info\r\n",
      "creating mmsegmentation.egg-info\r\n",
      "writing mmsegmentation.egg-info/PKG-INFO\r\n",
      "writing dependency_links to mmsegmentation.egg-info/dependency_links.txt\r\n",
      "writing requirements to mmsegmentation.egg-info/requires.txt\r\n",
      "writing top-level names to mmsegmentation.egg-info/top_level.txt\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "reading manifest template 'MANIFEST.in'\r\n",
      "warning: no files found matching 'mmseg/.mim/model-index.yml'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.yaml' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/tools'\r\n",
      "warning: no files found matching '*.sh' under directory 'mmseg/.mim/tools'\r\n",
      "adding license file 'LICENSE'\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "creating build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_inferencer.py -> build/lib/tests/test_apis\r\n",
      "creating build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset_builder.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_formatting.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_loading.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_transform.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_tta.py -> build/lib/tests/test_datasets\r\n",
      "creating build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_layer_decay_optimizer_constructor.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_optimizer.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_visualization_hook.py -> build/lib/tests/test_engine\r\n",
      "creating build/lib/tests/test_evaluation\r\n",
      "creating build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_citys_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_iou_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "creating build/lib/tests/test_structures\r\n",
      "copying tests/test_structures/test_seg_data_sample.py -> build/lib/tests/test_structures\r\n",
      "creating build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_io.py -> build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_set_env.py -> build/lib/tests/test_utils\r\n",
      "creating build/lib/tests/test_visualization\r\n",
      "copying tests/test_visualization/test_local_visualizer.py -> build/lib/tests/test_visualization\r\n",
      "creating build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_tversky_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "Processing /kaggle/working/mmsegmentation\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (3.7.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (1.23.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (21.3)\r\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (3.8.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.0.0) (1.11.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (4.40.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (1.4.4)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.0.0) (2.8.2)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->mmsegmentation==1.0.0) (0.2.6)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.0.0) (1.16.0)\r\n",
      "Building wheels for collected packages: mmsegmentation\r\n",
      "  Building wheel for mmsegmentation (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmsegmentation: filename=mmsegmentation-1.0.0-py3-none-any.whl size=931329 sha256=c3c04dde6186f43b5809cc26b8bdb39b92a99d9edbeeec0e89f67fbd5f5d4506\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0w01s_1k/wheels/43/47/68/4f234c90f5372e6bde61cb1d00ac67ba84723d1e9801de501d\r\n",
      "Successfully built mmsegmentation\r\n",
      "Installing collected packages: mmsegmentation\r\n",
      "Successfully installed mmsegmentation-1.0.0\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r mmsegmentation\n",
    "!git clone https://github.com/alirafiqmalik/mmsegmentation.git \n",
    "%cd mmsegmentation\n",
    "# !pip install -v -e .\n",
    "!python setup.py build\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2a736d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:39.638437Z",
     "iopub.status.busy": "2023-07-27T07:58:39.637995Z",
     "iopub.status.idle": "2023-07-27T07:58:40.459729Z",
     "shell.execute_reply": "2023-07-27T07:58:40.458760Z"
    },
    "papermill": {
     "duration": 0.908582,
     "end_time": "2023-07-27T07:58:40.462050",
     "exception": false,
     "start_time": "2023-07-27T07:58:39.553468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0 2.0.1 0.8.2\n"
     ]
    }
   ],
   "source": [
    "# Check MMSegmentation installation\n",
    "import mmseg,mmcv,mmengine\n",
    "print(mmseg.__version__,mmcv.__version__,mmengine.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fbec5fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:40.573556Z",
     "iopub.status.busy": "2023-07-27T07:58:40.573189Z",
     "iopub.status.idle": "2023-07-27T07:58:40.577802Z",
     "shell.execute_reply": "2023-07-27T07:58:40.576864Z"
    },
    "papermill": {
     "duration": 0.062539,
     "end_time": "2023-07-27T07:58:40.579927",
     "exception": false,
     "start_time": "2023-07-27T07:58:40.517388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import mmengine\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ceaa0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:40.689563Z",
     "iopub.status.busy": "2023-07-27T07:58:40.689202Z",
     "iopub.status.idle": "2023-07-27T07:58:40.694246Z",
     "shell.execute_reply": "2023-07-27T07:58:40.693171Z"
    },
    "papermill": {
     "duration": 0.062673,
     "end_time": "2023-07-27T07:58:40.696680",
     "exception": false,
     "start_time": "2023-07-27T07:58:40.634007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset root and directory for images and annotations\n",
    "data_root = '/kaggle/input/floodnet-mydata-output12gb/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e15347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:40.805430Z",
     "iopub.status.busy": "2023-07-27T07:58:40.805068Z",
     "iopub.status.idle": "2023-07-27T07:58:40.857655Z",
     "shell.execute_reply": "2023-07-27T07:58:40.856459Z"
    },
    "papermill": {
     "duration": 0.111075,
     "end_time": "2023-07-27T07:58:40.861332",
     "exception": false,
     "start_time": "2023-07-27T07:58:40.750257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes 10\n",
      "0         Background\n",
      "1    BuildingFlooded\n",
      "2        BNonFlooded\n",
      "3        RoadFlooded\n",
      "4        RNonFlooded\n",
      "5              Water\n",
      "6               Tree\n",
      "7             Vecile\n",
      "8               Pool\n",
      "9              Grass\n",
      "Name: name, dtype: object\n",
      "[[  0   0   0]\n",
      " [255   0   0]\n",
      " [181  72  72]\n",
      " [150 150   0]\n",
      " [135 135 135]\n",
      " [  0 224 224]\n",
      " [  0   0 225]\n",
      " [204   0 204]\n",
      " [237 237   0]\n",
      " [  0 225   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# define class and palette for better visualization\n",
    "df=pd.read_csv('/kaggle/input/floodnet-mydata-output12gb/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/Now_class_dict_seg_10clss.csv')\n",
    "classes = df['name']\n",
    "palette = df[[' r', ' g', ' b']].values\n",
    "id2label = classes.to_dict()\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(\"classes\", len(id2label))\n",
    "print(classes)\n",
    "print(palette)\n",
    "classes=list(classes)\n",
    "palette=list(palette)\n",
    "num_classes=len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c25e62e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:40.972301Z",
     "iopub.status.busy": "2023-07-27T07:58:40.971943Z",
     "iopub.status.idle": "2023-07-27T07:58:41.409443Z",
     "shell.execute_reply": "2023-07-27T07:58:41.408475Z"
    },
    "papermill": {
     "duration": 0.494067,
     "end_time": "2023-07-27T07:58:41.411805",
     "exception": false,
     "start_time": "2023-07-27T07:58:40.917738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from mmseg.registry import DATASETS\n",
    "from mmseg.datasets import BaseSegDataset\n",
    "\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ImageSegmentationDataset(BaseSegDataset):\n",
    "    METAINFO = dict(classes = classes, palette = palette)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(img_suffix='.jpg', seg_map_suffix=\"_lab.png\", **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d32b2",
   "metadata": {
    "papermill": {
     "duration": 0.053316,
     "end_time": "2023-07-27T07:58:41.519261",
     "exception": false,
     "start_time": "2023-07-27T07:58:41.465945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f3458eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:41.629149Z",
     "iopub.status.busy": "2023-07-27T07:58:41.628793Z",
     "iopub.status.idle": "2023-07-27T07:58:41.674916Z",
     "shell.execute_reply": "2023-07-27T07:58:41.673861Z"
    },
    "papermill": {
     "duration": 0.1038,
     "end_time": "2023-07-27T07:58:41.677310",
     "exception": false,
     "start_time": "2023-07-27T07:58:41.573510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('/kaggle/input/trained-models-swint-finetuning-folk/checkpoint/swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512.py')\n",
    "# cfg.checkpoint_file=\"/home/haris/Desktop/checkpoint/iter_9000.pth\"\n",
    "# cfg.model.backbone.init_cfg=cfg.checkpoint_file\n",
    "cfg.load_from = \"/kaggle/input/trained-models-swint-finetuning-folk/checkpoint/iter_6000.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a6a9733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:41.786401Z",
     "iopub.status.busy": "2023-07-27T07:58:41.786036Z",
     "iopub.status.idle": "2023-07-27T07:58:55.870867Z",
     "shell.execute_reply": "2023-07-27T07:58:55.869824Z"
    },
    "papermill": {
     "duration": 14.142179,
     "end_time": "2023-07-27T07:58:55.873285",
     "exception": false,
     "start_time": "2023-07-27T07:58:41.731106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27 07:58:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n",
      "    CUDA available: True\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0: Tesla P100-PCIE-16GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "    GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0\n",
      "    PyTorch: 1.12.0+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.0+cu102\n",
      "    OpenCV: 4.8.0\n",
      "    MMEngine: 0.8.2\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "07/27 07:58:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
      "data_preprocessor = dict(\n",
      "    type='SegDataPreProcessor',\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    bgr_to_rgb=True,\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ))\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    data_preprocessor=dict(\n",
      "        type='SegDataPreProcessor',\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        bgr_to_rgb=True,\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        )),\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer',\n",
      "        pretrain_img_size=384,\n",
      "        embed_dims=128,\n",
      "        patch_size=4,\n",
      "        window_size=12,\n",
      "        mlp_ratio=4,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            18,\n",
      "            2,\n",
      "        ],\n",
      "        num_heads=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        strides=(\n",
      "            4,\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        patch_norm=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.3,\n",
      "        use_abs_pos_embed=False,\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        norm_cfg=dict(type='LN', requires_grad=True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth'\n",
      "        )),\n",
      "    decode_head=dict(\n",
      "        type='UPerHead',\n",
      "        in_channels=[\n",
      "            128,\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        pool_scales=(\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            6,\n",
      "        ),\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=150,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=512,\n",
      "        in_index=2,\n",
      "        channels=256,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=10,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'ImageSegmentationDataset'\n",
      "data_root = '/kaggle/input/floodnet-mydata-output12gb/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "    dict(\n",
      "        type='RandomResize',\n",
      "        scale=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomCrop', crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), keep_ratio=True),\n",
      "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "tta_pipeline = [\n",
      "    dict(type='LoadImageFromFile', backend_args=None),\n",
      "    dict(\n",
      "        type='TestTimeAug',\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(type='Resize', scale_factor=0.5, keep_ratio=True),\n",
      "                dict(type='Resize', scale_factor=0.75, keep_ratio=True),\n",
      "                dict(type='Resize', scale_factor=1.0, keep_ratio=True),\n",
      "                dict(type='Resize', scale_factor=1.25, keep_ratio=True),\n",
      "                dict(type='Resize', scale_factor=1.5, keep_ratio=True),\n",
      "                dict(type='Resize', scale_factor=1.75, keep_ratio=True),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='RandomFlip', prob=0.0, direction='horizontal'),\n",
      "                dict(type='RandomFlip', prob=1.0, direction='horizontal'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ]),\n",
      "]\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(type='InfiniteSampler', shuffle=True),\n",
      "    dataset=dict(\n",
      "        type='ImageSegmentationDataset',\n",
      "        data_root=\n",
      "        '/kaggle/input/floodnet-mydata-output12gb/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "            dict(\n",
      "                type='RandomResize',\n",
      "                scale=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ),\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                keep_ratio=True),\n",
      "            dict(\n",
      "                type='RandomCrop', crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', prob=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ]))\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='ImageSegmentationDataset',\n",
      "        data_root=\n",
      "        '/kaggle/input/floodnet-mydata-output12gb/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ]))\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
      "    dataset=dict(\n",
      "        type='ImageSegmentationDataset',\n",
      "        data_root=\n",
      "        '/kaggle/input/floodnet-mydata-output12gb/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), keep_ratio=True),\n",
      "            dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ]))\n",
      "val_evaluator = dict(\n",
      "    type='IoUMetric', iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ])\n",
      "test_evaluator = dict(\n",
      "    type='IoUMetric', iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ])\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
      "    dist_cfg=dict(backend='nccl'))\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ],\n",
      "    name='visualizer')\n",
      "log_processor = dict(by_epoch=False)\n",
      "log_level = 'INFO'\n",
      "load_from = '/kaggle/input/trained-models-swint-finetuning-folk/checkpoint/iter_6000.pth'\n",
      "resume = False\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optim_wrapper = dict(\n",
      "    type='OptimWrapper',\n",
      "    optimizer=dict(\n",
      "        type='AdamW', lr=6e-05, betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        type='LinearLR', start_factor=1e-06, by_epoch=False, begin=0,\n",
      "        end=1500),\n",
      "    dict(\n",
      "        type='PolyLR',\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        begin=1500,\n",
      "        end=160000,\n",
      "        by_epoch=False),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    type='IterBasedTrainLoop', max_iters=10000, val_interval=20000)\n",
      "val_cfg = dict(type='ValLoop')\n",
      "test_cfg = dict(type='TestLoop')\n",
      "default_hooks = dict(\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    logger=dict(type='LoggerHook', interval=100, log_metric_by_epoch=False),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    checkpoint=dict(type='CheckpointHook', by_epoch=False, interval=1000),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth'\n",
      "work_dir = './checkpoint'\n",
      "randomness = dict(seed=0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:235: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27 07:58:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/27 07:58:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:61: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8413c7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T07:58:55.985156Z",
     "iopub.status.busy": "2023-07-27T07:58:55.984445Z",
     "iopub.status.idle": "2023-07-27T08:03:12.691888Z",
     "shell.execute_reply": "2023-07-27T08:03:12.690889Z"
    },
    "papermill": {
     "duration": 256.766211,
     "end_time": "2023-07-27T08:03:12.694082",
     "exception": false,
     "start_time": "2023-07-27T07:58:55.927871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/datasets/transforms/loading.py:78: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/27 07:58:56 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "Loads checkpoint by local backend from path: /kaggle/input/trained-models-swint-finetuning-folk/checkpoint/iter_6000.pth\n",
      "07/27 07:59:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /kaggle/input/trained-models-swint-finetuning-folk/checkpoint/iter_6000.pth\n",
      "07/27 08:00:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/450]    eta: 0:03:04  time: 0.4885  data_time: 0.2516  memory: 9209  \n",
      "07/27 08:01:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/450]    eta: 0:02:13  time: 0.6142  data_time: 0.3707  memory: 9214  \n",
      "07/27 08:01:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/450]    eta: 0:01:19  time: 0.4998  data_time: 0.2422  memory: 9203  \n",
      "07/27 08:02:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/450]    eta: 0:00:26  time: 0.4948  data_time: 0.2418  memory: 7910  \n",
      "07/27 08:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "07/27 08:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 17.17 | 23.12 | 29.31 | 29.31  |   40.01   | 23.12  |\n",
      "| BuildingFlooded | 71.77 | 96.65 | 83.56 | 83.56  |    73.6   | 96.65  |\n",
      "|   BNonFlooded   | 77.65 | 84.64 | 87.42 | 87.42  |   90.39   | 84.64  |\n",
      "|   RoadFlooded   |  58.7 | 84.75 | 73.98 | 73.98  |   65.63   | 84.75  |\n",
      "|   RNonFlooded   | 78.33 |  86.0 | 87.85 | 87.85  |   89.77   |  86.0  |\n",
      "|      Water      | 67.64 | 82.63 | 80.69 | 80.69  |   78.85   | 82.63  |\n",
      "|       Tree      | 73.55 | 76.75 | 84.76 | 84.76  |   94.65   | 76.75  |\n",
      "|      Vecile     |  30.9 | 36.08 | 47.21 | 47.21  |   68.24   | 36.08  |\n",
      "|       Pool      | 49.58 | 72.25 | 66.29 | 66.29  |   61.24   | 72.25  |\n",
      "|      Grass      | 85.27 | 94.59 | 92.05 | 92.05  |   89.65   | 94.59  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "07/27 08:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/450]    aAcc: 87.1100  mIoU: 61.0600  mAcc: 73.7500  mDice: 73.3100  mFscore: 73.3100  mPrecision: 75.2000  mRecall: 73.7500  data_time: 0.2705  time: 0.5231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aAcc': 87.11,\n",
       " 'mIoU': 61.06,\n",
       " 'mAcc': 73.75,\n",
       " 'mDice': 73.31,\n",
       " 'mFscore': 73.31,\n",
       " 'mPrecision': 75.2,\n",
       " 'mRecall': 73.75}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb8850",
   "metadata": {
    "papermill": {
     "duration": 0.056288,
     "end_time": "2023-07-27T08:03:12.805909",
     "exception": false,
     "start_time": "2023-07-27T08:03:12.749621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546f239",
   "metadata": {
    "papermill": {
     "duration": 0.055388,
     "end_time": "2023-07-27T08:03:12.916986",
     "exception": false,
     "start_time": "2023-07-27T08:03:12.861598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b18b4a",
   "metadata": {
    "papermill": {
     "duration": 0.055209,
     "end_time": "2023-07-27T08:03:13.027487",
     "exception": false,
     "start_time": "2023-07-27T08:03:12.972278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 438.435541,
   "end_time": "2023-07-27T08:03:14.708970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-27T07:55:56.273429",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
