{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef15032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:24:01.161045Z",
     "iopub.status.busy": "2024-03-05T17:24:01.160184Z",
     "iopub.status.idle": "2024-03-05T17:24:02.228502Z",
     "shell.execute_reply": "2024-03-05T17:24:02.227387Z"
    },
    "papermill": {
     "duration": 1.083984,
     "end_time": "2024-03-05T17:24:02.231131",
     "exception": false,
     "start_time": "2024-03-05T17:24:01.147147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\r\n",
      "Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436bb029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:24:02.257239Z",
     "iopub.status.busy": "2024-03-05T17:24:02.256832Z",
     "iopub.status.idle": "2024-03-05T17:24:03.387264Z",
     "shell.execute_reply": "2024-03-05T17:24:03.386057Z"
    },
    "papermill": {
     "duration": 1.146983,
     "end_time": "2024-03-05T17:24:03.390283",
     "exception": false,
     "start_time": "2024-03-05T17:24:02.243300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar  5 17:24:03 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   36C    P0              25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370df161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:24:03.423996Z",
     "iopub.status.busy": "2024-03-05T17:24:03.423601Z",
     "iopub.status.idle": "2024-03-05T17:24:04.493483Z",
     "shell.execute_reply": "2024-03-05T17:24:04.492418Z"
    },
    "papermill": {
     "duration": 1.089064,
     "end_time": "2024-03-05T17:24:04.496295",
     "exception": false,
     "start_time": "2024-03-05T17:24:03.407231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a903cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:24:04.521601Z",
     "iopub.status.busy": "2024-03-05T17:24:04.520831Z",
     "iopub.status.idle": "2024-03-05T17:24:04.528155Z",
     "shell.execute_reply": "2024-03-05T17:24:04.527099Z"
    },
    "papermill": {
     "duration": 0.022273,
     "end_time": "2024-03-05T17:24:04.530432",
     "exception": false,
     "start_time": "2024-03-05T17:24:04.508159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "871d90d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:24:04.554152Z",
     "iopub.status.busy": "2024-03-05T17:24:04.553838Z",
     "iopub.status.idle": "2024-03-05T17:25:22.792848Z",
     "shell.execute_reply": "2024-03-05T17:25:22.791481Z"
    },
    "papermill": {
     "duration": 78.253721,
     "end_time": "2024-03-05T17:25:22.795530",
     "exception": false,
     "start_time": "2024-03-05T17:24:04.541809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.12.0\r\n",
      "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\r\n",
      "Collecting torchvision==0.13.0\r\n",
      "  Downloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting torchaudio==0.12.0\r\n",
      "  Downloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.12.0) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (2024.2.2)\r\n",
      "Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl (3.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.2.0.post0 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "stable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.12.0 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0 torchaudio-0.12.0 torchvision-0.13.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.7.0 torchvision==0.8.0\n",
    "!pip install torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc15cf7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:25:22.875921Z",
     "iopub.status.busy": "2024-03-05T17:25:22.875543Z",
     "iopub.status.idle": "2024-03-05T17:26:47.569701Z",
     "shell.execute_reply": "2024-03-05T17:26:47.568528Z"
    },
    "papermill": {
     "duration": 84.737002,
     "end_time": "2024-03-05T17:26:47.572485",
     "exception": false,
     "start_time": "2024-03-05T17:25:22.835483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.10/site-packages (from openmim) (8.1.7)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim) (0.4.6)\r\n",
      "Collecting model-index (from openmim)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from openmim) (2.1.4)\r\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.10/site-packages (from openmim) (23.3.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openmim) (2.31.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim) (13.7.0)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (6.0.1)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (3.5.2)\r\n",
      "Requirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (4.1.0)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (3.20.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (4.66.1)\r\n",
      "Collecting openxlab (from opendatalab->openmim)\r\n",
      "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2024.2.2)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.4)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting requests (from openmim)\r\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting rich (from openmim)\r\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting tqdm (from opendatalab->openmim)\r\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\r\n",
      "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.7)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\r\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading openxlab-0.0.34-py3-none-any.whl (299 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core\r\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=84f1d8b9e83875cb0c0a6208a18fbe20477284981118009074baf33da5b49af7\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=4e754f727077af3177d5d28456970cbb56527d2466de75e08cf375b1a84cda6a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\r\n",
      "Successfully built oss2 aliyun-python-sdk-core\r\n",
      "Installing collected packages: tqdm, setuptools, requests, model-index, jmespath, rich, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.1\r\n",
      "    Uninstalling tqdm-4.66.1:\r\n",
      "      Successfully uninstalled tqdm-4.66.1\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 69.0.3\r\n",
      "    Uninstalling setuptools-69.0.3:\r\n",
      "      Successfully uninstalled setuptools-69.0.3\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.31.0\r\n",
      "    Uninstalling requests-2.31.0:\r\n",
      "      Successfully uninstalled requests-2.31.0\r\n",
      "  Attempting uninstall: jmespath\r\n",
      "    Found existing installation: jmespath 1.0.1\r\n",
      "    Uninstalling jmespath-1.0.1:\r\n",
      "      Successfully uninstalled jmespath-1.0.1\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 13.7.0\r\n",
      "    Uninstalling rich-13.7.0:\r\n",
      "      Successfully uninstalled rich-13.7.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.8.1 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\r\n",
      "boto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.34.34 which is incompatible.\r\n",
      "gcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2024.2.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\r\n",
      "jupyterlab-server 2.25.2 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pytorch-lightning 2.2.0.post0 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.34 oss2-2.17.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmengine\r\n",
      "  Downloading mmengine-0.10.3-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting addict (from mmengine)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmengine) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmengine) (6.0.1)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine) (2.4.0)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmengine) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine) (4.9.0.80)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.17.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\r\n",
      "Downloading mmengine-0.10.3-py3-none-any.whl (451 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Installing collected packages: addict, mmengine\r\n",
      "Successfully installed addict-2.4.0 mmengine-0.10.3\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmcv>=2.0.0rc1\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (58.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.10.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (6.0.1)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv>=2.0.0rc1) (4.9.0.80)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.7.5)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.4.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv>=2.0.0rc1) (3.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv>=2.0.0rc1) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv>=2.0.0rc1) (3.17.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.4.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.8.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv>=2.0.0rc1) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv>=2.0.0rc1) (1.16.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openmim\n",
    "# Install mmengine\n",
    "!mim install mmengine\n",
    "# Install MMCV\n",
    "!mim install 'mmcv >= 2.0.0rc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d8aacf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:26:47.704038Z",
     "iopub.status.busy": "2024-03-05T17:26:47.703657Z",
     "iopub.status.idle": "2024-03-05T17:26:47.708328Z",
     "shell.execute_reply": "2024-03-05T17:26:47.707550Z"
    },
    "papermill": {
     "duration": 0.07135,
     "end_time": "2024-03-05T17:26:47.710542",
     "exception": false,
     "start_time": "2024-03-05T17:26:47.639192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install mmcv>=2.0.0rc4 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486129e",
   "metadata": {
    "papermill": {
     "duration": 0.061853,
     "end_time": "2024-03-05T17:26:47.834840",
     "exception": false,
     "start_time": "2024-03-05T17:26:47.772987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **RESTART KERNEL BEFORE GOING FURTHER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9c48b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:26:47.968654Z",
     "iopub.status.busy": "2024-03-05T17:26:47.967874Z",
     "iopub.status.idle": "2024-03-05T17:26:49.033549Z",
     "shell.execute_reply": "2024-03-05T17:26:49.032103Z"
    },
    "papermill": {
     "duration": 1.13612,
     "end_time": "2024-03-05T17:26:49.036076",
     "exception": false,
     "start_time": "2024-03-05T17:26:47.899956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "0.13.0+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25a9a709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:26:49.228825Z",
     "iopub.status.busy": "2024-03-05T17:26:49.228280Z",
     "iopub.status.idle": "2024-03-05T17:27:17.515803Z",
     "shell.execute_reply": "2024-03-05T17:27:17.514328Z"
    },
    "papermill": {
     "duration": 28.413009,
     "end_time": "2024-03-05T17:27:17.518159",
     "exception": false,
     "start_time": "2024-03-05T17:26:49.105150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'mmsegmentation': No such file or directory\r\n",
      "Cloning into 'mmsegmentation'...\r\n",
      "remote: Enumerating objects: 16444, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (116/116), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (96/96), done.\u001b[K\r\n",
      "remote: Total 16444 (delta 37), reused 60 (delta 18), pack-reused 16328\u001b[K\r\n",
      "Receiving objects: 100% (16444/16444), 43.82 MiB | 37.74 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11417/11417), done.\r\n",
      "/kaggle/working/mmsegmentation\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools_scm/_integration/setuptools.py:30: RuntimeWarning: \r\n",
      "ERROR: setuptools==60.2.0 is used in combination with setuptools_scm>=8.x\r\n",
      "\r\n",
      "Your build configuration is incomplete and previously worked by accident!\r\n",
      "setuptools_scm requires setuptools>=61\r\n",
      "\r\n",
      "Suggested workaround if applicable:\r\n",
      " - migrating from the deprecated setup_requires mechanism to pep517/518\r\n",
      "   and using a pyproject.toml to declare build dependencies\r\n",
      "   which are reliably pre-installed before running the build tools\r\n",
      "\r\n",
      "  warnings.warn(\r\n",
      "running build\r\n",
      "running build_py\r\n",
      "creating build\r\n",
      "creating build/lib\r\n",
      "creating build/lib/tests\r\n",
      "copying tests/test_digit_version.py -> build/lib/tests\r\n",
      "copying tests/test_sampler.py -> build/lib/tests\r\n",
      "copying tests/test_config.py -> build/lib/tests\r\n",
      "copying tests/__init__.py -> build/lib/tests\r\n",
      "creating build/lib/mmseg\r\n",
      "copying mmseg/version.py -> build/lib/mmseg\r\n",
      "copying mmseg/__init__.py -> build/lib/mmseg\r\n",
      "creating build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_forward.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_data_preprocessor.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/__init__.py -> build/lib/tests/test_models\r\n",
      "creating build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_fcn_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_apc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_mask2former_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ocr_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_pidnet_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dm_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ema_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_lraspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/utils.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_mla_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ham_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dnl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_cc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dpt_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_vpd_depth_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_maskformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ann_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_isa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_nl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_san_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_gc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_up_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_decode_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segmenter_mask_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_aspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_uper_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/__init__.py -> build/lib/tests/test_models/test_heads\r\n",
      "creating build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_embed.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_shape_convert.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/__init__.py -> build/lib/tests/test_models/test_utils\r\n",
      "creating build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_feature2pyramid.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_jpu.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_mla_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_ic_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_fpn.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_multilevel_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/__init__.py -> build/lib/tests/test_models/test_necks\r\n",
      "creating build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_timm_backbone.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_icnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_twins.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_blocks.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_cgnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/utils.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnest.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mscan.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv2.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_erfnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_hrnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_unet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mobilenet_v3.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv1.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_fast_scnn.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vpd.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_swin.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mae.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_clip_text_encoder.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnext.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_beit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_pidnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/__init__.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_stdc.py -> build/lib/tests/test_models/test_backbones\r\n",
      "creating build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_multimodal_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/utils.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_cascade_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_seg_tta_model.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_depth_estimator.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/__init__.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "creating build/lib/mmseg/engine\r\n",
      "copying mmseg/engine/__init__.py -> build/lib/mmseg/engine\r\n",
      "creating build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/inference.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/mmseg_inferencer.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/remote_sense_inferencer.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/utils.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/__init__.py -> build/lib/mmseg/apis\r\n",
      "creating build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/local_visualizer.py -> build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/__init__.py -> build/lib/mmseg/visualization\r\n",
      "creating build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/registry.py -> build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/__init__.py -> build/lib/mmseg/registry\r\n",
      "creating build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/class_names.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/collect_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/tokenizer.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/misc.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/io.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/mask_classification.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/get_templates.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/set_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/typing_utils.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/__init__.py -> build/lib/mmseg/utils\r\n",
      "creating build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isaid.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/refuge.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isprs.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/mapillary.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/bdd100k.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/cityscapes.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/chase_db1.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/nyu.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/voc.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/night_driving.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/ade.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dark_zurich.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/decathlon.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dsdl.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/pascal_context.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/synapse.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/coco_stuff.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/loveda.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/levir.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/stare.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/basesegdataset.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/lip.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/potsdam.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hrf.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dataset_wrappers.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/__init__.py -> build/lib/mmseg/datasets\r\n",
      "creating build/lib/mmseg/evaluation\r\n",
      "copying mmseg/evaluation/__init__.py -> build/lib/mmseg/evaluation\r\n",
      "creating build/lib/mmseg/models\r\n",
      "copying mmseg/models/data_preprocessor.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/builder.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/__init__.py -> build/lib/mmseg/models\r\n",
      "creating build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/seg_data_sample.py -> build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/__init__.py -> build/lib/mmseg/structures\r\n",
      "creating build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/visualization_hook.py -> build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/__init__.py -> build/lib/mmseg/engine/hooks\r\n",
      "creating build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/layer_decay_optimizer_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/force_default_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/__init__.py -> build/lib/mmseg/engine/optimizers\r\n",
      "creating build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/poly_ratio_scheduler.py -> build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/__init__.py -> build/lib/mmseg/engine/schedulers\r\n",
      "creating build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/transforms.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/loading.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/formatting.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/__init__.py -> build/lib/mmseg/datasets/transforms\r\n",
      "creating build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/depth_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/iou_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/citys_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/__init__.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "creating build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/clip_text_encoder.py -> build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/__init__.py -> build/lib/mmseg/models/text_encoder\r\n",
      "creating build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/twins.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/swin.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/hrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/timm_backbone.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/icnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/cgnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vpd.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/erfnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/stdc.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv1.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/unet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/ddrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnext.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/pidnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnest.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/fast_scnn.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/beit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v3.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mscan.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/__init__.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mae.py -> build/lib/mmseg/models/backbones\r\n",
      "creating build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/hungarian_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/base_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/match_cost.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/__init__.py -> build/lib/mmseg/models/assigners\r\n",
      "creating build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/multilevel_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/jpu.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/ic_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/fpn.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/featurepyramid.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/mla_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/__init__.py -> build/lib/mmseg/models/necks\r\n",
      "creating build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/point_sample.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/se_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/embed.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/inverted_residual.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/ppm.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/res_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/make_divisible.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/encoding.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/self_attention_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/shape_convert.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/san_layers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/up_conv_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/wrappers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/basic_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/__init__.py -> build/lib/mmseg/models/utils\r\n",
      "creating build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/cascade_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/depth_estimator.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/base.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/multimodal_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/seg_tta.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/__init__.py -> build/lib/mmseg/models/segmentors\r\n",
      "creating build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/accuracy.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/lovasz_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/boundary_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/utils.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/dice_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/focal_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/kldiv_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/silog_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/huasdorff_distance_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/tversky_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/ohem_cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/__init__.py -> build/lib/mmseg/models/losses\r\n",
      "creating build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/lraspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ham_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/point_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cascade_decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ema_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/da_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/knet_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fpn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/pid_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/san_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/nl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/uper_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/gc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_up_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/enc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dpt_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ddr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/mask2former_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_mla_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/vpd_depth_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dnl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ocr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/isa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ann_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/maskformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/apc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dm_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/stdc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/__init__.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segmenter_mask_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "creating build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/base_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/builder.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/ohem_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/__init__.py -> build/lib/mmseg/structures/sampler\r\n",
      "running egg_info\r\n",
      "creating mmsegmentation.egg-info\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "warning: no files found matching 'mmseg/.mim/model-index.yml'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.yaml' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/tools'\r\n",
      "warning: no files found matching '*.sh' under directory 'mmseg/.mim/tools'\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "creating build/lib/tests/data\r\n",
      "copying tests/data/biomedical.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.npy -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.pkl -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical_ann.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/color.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/dataset.json -> build/lib/tests/data\r\n",
      "copying tests/data/gray.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/seg.png -> build/lib/tests/data\r\n",
      "creating build/lib/tests/data/dsdl_seg\r\n",
      "copying tests/data/dsdl_seg/config.py -> build/lib/tests/data/dsdl_seg\r\n",
      "creating build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/class-dom.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/segmentation-def.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "creating build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train.yaml -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train_samples.json -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/0004a4c0-d4dff0ad.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00054602-3bf57337.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00067cfb-e535423e.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d06fefd-f7be05a6.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d128593-0ccfea4c.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d15b18b-1e0d6e3f.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d2f7975-e0c1c5a7.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d06fefd-f7be05a6.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_instanceIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelTrainIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png -> build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_dataset\r\n",
      "creating build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00000_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00001_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00002_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00003_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00004_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "creating build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00000_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00001_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00002_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00003_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00004_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "creating build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/train.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/val.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1024_1920_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1536_2432_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1024_1920.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1536_2432.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/train.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/val.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "copying tests/data/pseudo_lip_dataset/train_images/684_2150041.jpg -> build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/train_segmentations/684_2150041.png -> build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "copying tests/data/pseudo_lip_dataset/val_images/86_185913.jpg -> build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/val_segmentations/86_185913.png -> build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "copying tests/data/pseudo_mapillary_dataset/images/__CRyFzoDOXn6unQ6a3DnQ.jpg -> build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v1.2/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v2.0/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "copying tests/data/pseudo_nyu_dataset/annotations/bookstore_0001d_00001.png -> build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "copying tests/data/pseudo_nyu_dataset/images/bookstore_0001d_00001.jpg -> build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/ann_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/img_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/ann_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/img_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice000.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice001.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice000.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice001.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/ann_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/img_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "creating build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_rs_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/utils.py -> build/lib/tests/test_apis\r\n",
      "creating build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset_builder.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_formatting.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_loading.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_transform.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_tta.py -> build/lib/tests/test_datasets\r\n",
      "creating build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_layer_decay_optimizer_constructor.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_optimizer.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_visualization_hook.py -> build/lib/tests/test_engine\r\n",
      "creating build/lib/tests/test_evaluation\r\n",
      "creating build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_citys_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_depth_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_iou_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "creating build/lib/tests/test_structures\r\n",
      "copying tests/test_structures/test_seg_data_sample.py -> build/lib/tests/test_structures\r\n",
      "creating build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_io.py -> build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_set_env.py -> build/lib/tests/test_utils\r\n",
      "creating build/lib/tests/test_visualization\r\n",
      "copying tests/test_visualization/test_local_visualizer.py -> build/lib/tests/test_visualization\r\n",
      "creating build/lib/tests/test_models/test_assigners\r\n",
      "copying tests/test_models/test_assigners/test_hungarian_assigner.py -> build/lib/tests/test_models/test_assigners\r\n",
      "creating build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_cross_entropy_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_dice_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_huasdorff_distance_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_kldiv_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_silog_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_tversky_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying mmseg/utils/bpe_simple_vocab_16e6.txt.gz -> build/lib/mmseg/utils\r\n",
      "Processing /kaggle/working/mmsegmentation\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (21.3)\r\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.9.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.11.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (2.8.2)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->mmsegmentation==1.2.2) (0.2.13)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.2.2) (1.16.0)\r\n",
      "Building wheels for collected packages: mmsegmentation\r\n",
      "  Building wheel for mmsegmentation (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmsegmentation: filename=mmsegmentation-1.2.2-py3-none-any.whl size=9540045 sha256=23159e65249974c1db35a2587701c3735fdd61560305ad5c7788fccfa45c361b\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckvkpvb0/wheels/43/47/68/4f234c90f5372e6bde61cb1d00ac67ba84723d1e9801de501d\r\n",
      "Successfully built mmsegmentation\r\n",
      "Installing collected packages: mmsegmentation\r\n",
      "Successfully installed mmsegmentation-1.2.2\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r mmsegmentation\n",
    "#!git clone https://github.com/alirafiqmalik/mmsegmentation.git \n",
    "!git clone -b main https://github.com/open-mmlab/mmsegmentation.git \n",
    "%cd mmsegmentation\n",
    "# !pip install -v -e .\n",
    "!python setup.py build\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da18c6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:17.657105Z",
     "iopub.status.busy": "2024-03-05T17:27:17.656324Z",
     "iopub.status.idle": "2024-03-05T17:27:18.592487Z",
     "shell.execute_reply": "2024-03-05T17:27:18.591422Z"
    },
    "papermill": {
     "duration": 1.008586,
     "end_time": "2024-03-05T17:27:18.594978",
     "exception": false,
     "start_time": "2024-03-05T17:27:17.586392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMSegmentation installation\n",
    "import mmseg\n",
    "print(mmseg.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f5e119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:18.737572Z",
     "iopub.status.busy": "2024-03-05T17:27:18.736432Z",
     "iopub.status.idle": "2024-03-05T17:27:18.742283Z",
     "shell.execute_reply": "2024-03-05T17:27:18.741181Z"
    },
    "papermill": {
     "duration": 0.079921,
     "end_time": "2024-03-05T17:27:18.744675",
     "exception": false,
     "start_time": "2024-03-05T17:27:18.664754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2 2.1.0 0.10.3\n"
     ]
    }
   ],
   "source": [
    "# Check MMSegmentation installation\n",
    "import mmseg,mmcv,mmengine\n",
    "print(mmseg.__version__,mmcv.__version__,mmengine.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85bf920",
   "metadata": {
    "papermill": {
     "duration": 0.070224,
     "end_time": "2024-03-05T17:27:18.885917",
     "exception": false,
     "start_time": "2024-03-05T17:27:18.815693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **DATASET LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d029c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:19.024786Z",
     "iopub.status.busy": "2024-03-05T17:27:19.024069Z",
     "iopub.status.idle": "2024-03-05T17:27:19.028488Z",
     "shell.execute_reply": "2024-03-05T17:27:19.027575Z"
    },
    "papermill": {
     "duration": 0.07449,
     "end_time": "2024-03-05T17:27:19.030679",
     "exception": false,
     "start_time": "2024-03-05T17:27:18.956189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import mmengine\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d4fd175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:19.171935Z",
     "iopub.status.busy": "2024-03-05T17:27:19.171086Z",
     "iopub.status.idle": "2024-03-05T17:27:19.176046Z",
     "shell.execute_reply": "2024-03-05T17:27:19.175077Z"
    },
    "papermill": {
     "duration": 0.07757,
     "end_time": "2024-03-05T17:27:19.178088",
     "exception": false,
     "start_time": "2024-03-05T17:27:19.100518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset root and directory for images and annotations\n",
    "data_root = '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f053e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:19.320338Z",
     "iopub.status.busy": "2024-03-05T17:27:19.319613Z",
     "iopub.status.idle": "2024-03-05T17:27:19.693468Z",
     "shell.execute_reply": "2024-03-05T17:27:19.692179Z"
    },
    "papermill": {
     "duration": 0.44856,
     "end_time": "2024-03-05T17:27:19.696148",
     "exception": false,
     "start_time": "2024-03-05T17:27:19.247588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes 10\n",
      "0         Background\n",
      "1    BuildingFlooded\n",
      "2        BNonFlooded\n",
      "3        RoadFlooded\n",
      "4        RNonFlooded\n",
      "5              Water\n",
      "6               Tree\n",
      "7             Vecile\n",
      "8               Pool\n",
      "9              Grass\n",
      "Name: name, dtype: object\n",
      "[[  0   0   0]\n",
      " [255   0   0]\n",
      " [181  72  72]\n",
      " [150 150   0]\n",
      " [135 135 135]\n",
      " [  0 224 224]\n",
      " [  0   0 225]\n",
      " [204   0 204]\n",
      " [237 237   0]\n",
      " [  0 225   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# define class and palette for better visualization\n",
    "df=pd.read_csv('/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/Now_class_dict_seg_10clss.csv')\n",
    "classes = df['name']\n",
    "palette = df[[' r', ' g', ' b']].values\n",
    "id2label = classes.to_dict()\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(\"classes\", len(id2label))\n",
    "print(classes)\n",
    "print(palette)\n",
    "classes=list(classes)\n",
    "palette=list(palette)\n",
    "num_classes=len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86245b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:19.846835Z",
     "iopub.status.busy": "2024-03-05T17:27:19.846432Z",
     "iopub.status.idle": "2024-03-05T17:27:22.036803Z",
     "shell.execute_reply": "2024-03-05T17:27:22.035787Z"
    },
    "papermill": {
     "duration": 2.266521,
     "end_time": "2024-03-05T17:27:22.039770",
     "exception": false,
     "start_time": "2024-03-05T17:27:19.773249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAH/CAYAAAAVCPOeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoY0lEQVR4nO3deVxWZd7H8e8NyKYCKpskKKLivqRpuKQoLqiZ1eS4VOC4p6Zpbi1uOeGWS+YyTiVWWpM9apor7mlom2SaMWouZSKiAW4oy3n+CM54C5goCsLn/Xrdr/G+znXO+Z3rAR+/Xedcx2IYhiEAAAAAQLFnU9AFAAAAAAAKBwIiAAAAAEASAREAAAAAkImACAAAAACQREAEAAAAAGQiIAIAAAAAJBEQAQAAAACZCIgAAAAAAEkERAAAAABAJgIiAAAAAEBSIQ+I8+fPV6VKleTo6KgmTZro66+/LuiSAAAAAKDIKrQB8T//+Y9GjBihCRMm6Pvvv1e9evXUvn17xcfHF3RpAAAAAFAkWQzDMAq6iJw0adJEjzzyiN555x1JUkZGhnx9fTV06FCNHTu2gKsDAAAAgKLHrqALyMn169f13Xffady4cWabjY2NQkJCFB0dneM+165d07Vr18zvGRkZunDhgsqVKyeLxXLPawYAAMCtGYahixcvysfHRzY2BXcjW3p6ulJTUwvs/MD9ZGtrqxIlStx2/0IZEBMSEpSeni4vLy+rdi8vL/3888857hMREaFJkybdj/IAAABwF3799VdVqFDhvp/XMAzFxcUpKSlJhfQmOuCecHBwkLu7u1xcXP6yb6EMiHdi3LhxGjFihPk9KSlJfn5+srW1ZQYRAACgEDAMQ+np6SpdunSBnD8pKUmJiYny8PBQyZIl+TciijzDMJSamqqkpCSdPn1akv4yJBbKgOju7i5bW1udPXvWqv3s2bPy9vbOcR8HBwc5ODhka7dYLPzyAwAAFCIF8W8zwzAUHx8vFxcXubu73/fzAwXFyclJpUuX1m+//aaEhIS/DIiFchVTe3t7NWzYUFu3bjXbMjIytHXrVgUFBRVgZQAAAHgQpaenKz09/bZusQOKGovFIldXV127du0vn78tlDOIkjRixAiFhYWpUaNGaty4sebMmaPLly+rd+/eBV0aAAAAHjBpaWmSJDu7QvvPX+CeylqoJj09/ZaL1hTa35C///3vOnfunMaPH6+4uDjVr19fGzduzLZwDQAAAHC7ePQIxdXt/uwX2oAoSUOGDNGQIUMKugwAAAAAKBYK5TOIAAAAAAq/SpUqqXPnzgVdRoGxWCyaOHFiQZeRrwr1DCIAAABwr506dUoJCQkFXYbc3d3l5+d3R/tGRkZmW6vDw8NDtWrV0ujRoxUaGpofJaIYICACAACg2Dp16pQCAwOVkpJS0KXI0dFRsbGxdxwSJWny5Mny9/eXYRg6e/asIiMj1bFjR61du7ZYz/Th9hEQAQAAUGwlJCQUinAoSSkpKUpISLirgBgaGqpGjRqZ3/v06SMvLy99/PHHD2xAvHz5skqWLFnQZRQbPIMIAAAAFFFubm5ycnKyer3HzJkz1bRpU5UrV05OTk5q2LChPvvssxz3/+ijj9S4cWM5OzurTJkyeuyxx7R58+ZbnnPp0qWys7PTqFGjzLbz58/rueeek4uLi9zc3BQWFqYffvhBFotFkZGRZr/w8HCVKlVKx44dU8eOHVW6dGn16tVL0p9BceTIkfL19ZWDg4MCAwM1c+ZMGYZh7n/ixIlsx8xy8/OCEydOlMVi0dGjRxUeHi43Nze5urqqd+/eunLlitW+165d00svvSQPDw+VLl1aXbp00W+//XbLcXhQMYMIAAAAFBFJSUlKSEiQYRiKj4/XvHnzdOnSJT377LNmn7lz56pLly7q1auXrl+/rk8++UTPPPOMvvjiC3Xq1MnsN2nSJE2cOFFNmzbV5MmTZW9vr3379mnbtm1q165djudfvHixBg4cqFdeeUVTpkyRJGVkZOjxxx/X119/rUGDBql69er6/PPPFRYWluMx0tLS1L59ezVv3lwzZ86Us7OzDMNQly5dtH37dvXp00f169fXpk2bNGrUKJ0+fVqzZ8++4zHr1q2b/P39FRERoe+//17vvvuuPD09NW3aNLNP37599dFHH6lnz55q2rSptm3bZjVWRQkBEQAAACgiQkJCrL47ODjo/fffV9u2bc22//73v3JycjK/DxkyRA8//LBmzZplhp6jR49q8uTJevLJJ/XZZ5/JxuZ/Nx7eOGN3o7ffflvDhw/X5MmT9dprr5ntq1evVnR0tObMmaNhw4ZJkgYNGmRV042uXbumZ555RhEREWbb559/rm3btmnKlCl69dVXJUmDBw/WM888o7lz52rIkCEKCAi4rTG6WYMGDfTee++Z38+fP6/33nvPDIg//PCDPvroI73wwguaP3++ee5evXrpwIEDd3TOwoxbTAEAAIAiYv78+YqKilJUVJQ++ugjBQcHq2/fvlq5cqXZ58Zw+McffygpKUktWrTQ999/b7avXr1aGRkZGj9+vFU4lHJ+4fr06dM1bNgwTZs2zSocStLGjRtVokQJ9evXz2yzsbHR4MGDc72OQYMGWX1fv369bG1t9eKLL1q1jxw5UoZhaMOGDbke668MHDjQ6nuLFi10/vx5JScnm+eWlO3cw4cPv+NzFmbMIAIAAABFROPGja0WqenRo4caNGigIUOGqHPnzrK3t9cXX3yhKVOmKCYmRteuXTP73hj8jh07JhsbG9WsWfMvz7lz506tW7dOY8aMsXruMMvJkydVvnx5OTs7W7VXqVIlx+PZ2dmpQoUK2Y7h4+Oj0qVLW7XXqFHD3H6nbl4UqEyZMpL+DM8uLi46efKkbGxsss1QBgYG3vE5CzNmEAEAAIAiysbGRsHBwTpz5oyOHDmiL7/8Ul26dJGjo6MWLFig9evXKyoqSj179sz11tG/UqtWLQUGBurDDz/U8ePH77pmBweHbLOWtyun2U1JSk9Pz3UfW1vbHNvvdDwedAREAAAAoAhLS0uTJF26dEn/93//J0dHR23atEn/+Mc/FBoamu25RUkKCAhQRkaGfvrpp788vru7u7Zs2aISJUqoTZs2+v333622V6xYUWfOnMm2MujRo0dv+xoqVqyo33//XRcvXrRq//nnn83t0v9m/xITE6363c0MY8WKFZWRkaFjx45ZtcfGxt7xMQszAiIAAABQRKWmpmrz5s2yt7dXjRo1ZGtrK4vFYjWjduLECa1evdpqv65du8rGxkaTJ09WRkaG1bacZtYqVKigLVu26OrVq2rbtq3Onz9vbmvfvr1SU1P173//22zLyMgwF3y5HR07dlR6erreeecdq/bZs2fLYrEoNDRUkuTi4iJ3d3ft2rXLqt+CBQtu+1w3yzr222+/bdU+Z86cOz5mYcYziAAAAEARsWHDBnNWLT4+XsuXL9eRI0c0duxYubi4qFOnTpo1a5Y6dOignj17Kj4+XvPnz1eVKlWsVuSsUqWKXn31Vb3xxhtq0aKFnnrqKTk4OOibb76Rj4+P1QqjN+6zefNmtWrVSu3bt9e2bdvk4uKirl27qnHjxho5cqSOHj2q6tWra82aNbpw4YKk3G8LvdHjjz+u4OBgvfrqqzpx4oTq1aunzZs36/PPP9fw4cOtng/s27evpk6dqr59+6pRo0batWuX/vvf/97xmNavX189evTQggULlJSUpKZNm2rr1q15mgF9kBAQAQAAgCJi/Pjx5p8dHR1VvXp1LVy4UAMGDJAktW7dWu+9956mTp2q4cOHy9/fX9OmTdOJEyeyvbJh8uTJ8vf317x58/Tqq6/K2dlZdevW1XPPPZfr+evUqaMNGzYoJCREjz/+uDZu3CgnJyetW7dOw4YN09KlS2VjY6Mnn3xSEyZMULNmzeTo6PiX12VjY6M1a9Zo/Pjx+s9//qMlS5aoUqVKmjFjhkaOHJltDM6dO6fPPvtMn376qUJDQ7VhwwZ5enrmZSitvP/++/Lw8NCyZcu0evVqtW7dWuvWrZOvr+8dH7OwshhF9OnL5ORkubq6ys7O7rb+qwQAAADuLcMwlJaWpqSkJLm4uNzXc6ekpOj48ePy9/e3CiSnTp1SYGCgUlJS7ms9OXF0dFRsbGy2VTWLqtWrV+vJJ5/U7t271axZs4Iup8jL7XfgZswgAgAAoNjy8/NTbGysEhISCroUubu7F9lwePXqVav3L6anp2vevHlycXHRww8/XICV4WYERAAAABRrfn5+RTaYFRZDhw7V1atXFRQUpGvXrmnlypX66quv9Oabb1oFRxQ8AiIAAACAe6p169Z666239MUXXyglJUVVqlTRvHnzNGTIkIIuDTchIAIAAAC4p3r27KmePXsWdBm4DbwHEQAAAAAgiYAIAAAAAMhEQAQAAAAASCIgAgAAAAAyERABAAAAAJIIiAAAAACATAREAAAAAIAkAiIAAACAHEycOFEWi8WqrVKlSgoPD//LfSMjI2WxWHTixAmzrVWrVmrVqlX+FnmHwsPDValSpQI59+2O4e06ceKELBaLIiMj8+V4BEQAAADgAZcVyG78eHp6Kjg4WBs2bCjo8u6brLCU0+fRRx8t6PIeCHYFXQAAAABQoE6dkhISCroKyd1d8vO7q0NMnjxZ/v7+MgxDZ8+eVWRkpDp27Ki1a9eqc+fOeTrWa6+9prFjx95VPTfavHlzvh3rr/To0UMdO3a0avPw8Lhv53+QERABAABQfJ06JQUGSikpBV2J5OgoxcbeVUgMDQ1Vo0aNzO99+vSRl5eXPv744zwHRDs7O9nZ5V9csLe3z7dj/ZWHH35Yzz777H07X1HCLaYAAAAovhISCkc4lP6sI59nMt3c3OTk5GQGvR07dshisWjHjh1W/XJ6ji2nZxBzcujQIbVu3VpOTk6qUKGCpkyZooyMjGz9bn4GMauWTz/9VP/85z9VoUIFOTo6qk2bNjp69Gi2/efPn6/KlSvLyclJjRs31pdffpmvzzVevnxZI0eOlK+vrxwcHBQYGKiZM2fKMAyrfmlpaXrjjTcUEBAgBwcHVapUSa+88oquXbtm1c8wDE2ZMkUVKlSQs7OzgoODdejQoRzPnZiYqOHDh5vnrlKliqZNm5ZtHBMTExUeHi5XV1e5ubkpLCxMiYmJ+XL9WZhBBAAAAIqIpKQkJSQkyDAMxcfHa968ebp06dI9m02Li4tTcHCw0tLSNHbsWJUsWVKLFy+Wk5PTbR9j6tSpsrGx0csvv6ykpCRNnz5dvXr10r59+8w+Cxcu1JAhQ9SiRQu99NJLOnHihLp27aoyZcqoQoUK2Y555coVJdwUtl1dXVWiRIkcazAMQ126dNH27dvVp08f1a9fX5s2bdKoUaN0+vRpzZ492+zbt29fLV26VH/72980cuRI7du3TxERETp8+LBWrVpl9hs/frymTJmijh07qmPHjvr+++/Vrl07Xb9+PVutLVu21OnTpzVgwAD5+fnpq6++0rhx43TmzBnNmTPHrPGJJ57Q7t27NXDgQNWoUUOrVq1SWFjYbY/17SAgAgAAAEVESEiI1XcHBwe9//77atu27T0537Rp03Tu3Dnt27dPjRs3liSFhYWpatWqt32MlJQUxcTEmLeglilTRsOGDdPBgwdVu3ZtXb9+Xa+//roeeeQRbdu2zZwNrVu3rsLDw3MMiBMmTNCECROs2rZv357rbOOaNWu0bds2TZkyRa+++qokafDgwXrmmWc0d+5cDRkyRAEBAfrhhx+0dOlS9e3bV//+978lSS+88II8PT01c+ZMbd++XcHBwTp37pymT5+uTp06ae3ateZM7Kuvvqo333zT6tyzZs3SsWPHtH//fnPcBgwYIB8fH82YMcOc1VyzZo127dql6dOna9SoUZKkQYMGKTg4+LbH+nZwiykAAABQRMyfP19RUVGKiorSRx99pODgYPXt21crV668J+dbv369Hn30UTMcSn8uBtOrV6/bPkbv3r2tnk9s0aKFJOmXX36RJH377bc6f/68+vXrZ/VMZK9evVSmTJkcj9m/f39zHLI+9erVu+V12Nra6sUXX7RqHzlypAzDMFeCXb9+vSRpxIgR2fpJ0rp16yRJW7Zs0fXr1zV06FCr23SHDx+e7dwrVqxQixYtVKZMGSUkJJifkJAQpaena9euXea57ezsNGjQIHNfW1tbDR06NNfruhPMIAIAAABFROPGja0WqenRo4caNGigIUOG5HmRmttx8uRJNWnSJFt7YGDgbR/D76ZFebJC3x9//GGeQ5KqVKli1c/Ozi7XdxlWrVo122zqrZw8eVI+Pj4qXbq0VXuNGjWsajh58qRsbGyy1eLt7S03Nzerfll13MjDwyNbqD1y5IgOHDiQ6yqr8fHx5jHLly+vUqVKWW3Py1jfDgIiAAAAUETZ2NgoODhYc+fO1ZEjR3JddCY9Pf0+V/Y/tra2ObbfvDhMYXI7i/fcroyMDLVt21ajR4/OcXu1atXy7Vy3g4AIAAAAFGFpaWmSpEuXLpmzVzevfJk145VXFStW1JEjR7K1x8bG3tHxcjuHJB09etTqebu0tDSdOHFCdevWzZdzbNmyRRcvXrSaRfz555+taqhYsaIyMjJ05MgRc3ZRks6ePavExESrftKfs4OVK1c2+507d86cGc0SEBCgS5cu/eWMZ8WKFbV161ZdunTJahYxP8da4hlEAAAAoMhKTU3V5s2bZW9vrxo1aqhixYqytbU1n2vLsmDBgjs6fseOHbV37159/fXXZtu5c+e0bNmyu6r7Ro0aNVK5cuX073//2wy7krRs2bJsYetOdezYUenp6XrnnXes2mfPni2LxaLQ0FCznyRzZdEss2bNkiR16tRJ0p+LBZUoUULz5s2zmgm9eT9J6tatm6Kjo7Vp06Zs2xITE81r7tixo9LS0rRw4UJze3p6uubNm5fHq701ZhABAACAImLDhg3mrFd8fLyWL1+uI0eOaOzYsXJxcZEkPfPMM5o3b54sFosCAgL0xRdfmM+55dXo0aP14YcfqkOHDho2bJj5mouKFSvqwIED+XJN9vb2mjhxooYOHarWrVurW7duOnHihCIjIxUQEJAvt3s+/vjjCg4O1quvvqoTJ06oXr162rx5sz7//HMNHz5cAQEBkqR69eopLCxMixcvVmJiolq2bKmvv/5aS5cuVdeuXc0ZTg8PD7388suKiIhQ586d1bFjR+3fv18bNmyQu7u71blHjRqlNWvWqHPnzgoPD1fDhg11+fJl/fjjj/rss8904sQJubu76/HHH1ezZs00duxYnThxQjVr1tTKlSuVlJR019d/IwIiAAAAUESMHz/e/LOjo6OqV6+uhQsXasCAAWb7vHnzlJqaqkWLFsnBwUHdunXTjBkzVLt27Tyfr3z58tq+fbuGDh2qqVOnqly5cho4cKB8fHzUp0+ffLkmSRoyZIgMw9Bbb72ll19+WfXq1dOaNWv04osvytHR8a6Pb2NjozVr1mj8+PH6z3/+oyVLlqhSpUrmayZu9O6776py5cqKjIzUqlWr5O3trXHjxmV7rcaUKVPk6OioRYsWafv27WrSpIk2b95szjJmcXZ21s6dO/Xmm29qxYoV+uCDD+Ti4qJq1app0qRJcnV1tapx+PDh+uijj2SxWNSlSxe99dZbatCgwV2PQRaLUZif/rwLycnJcnV1lZ2dXb4+RAoAAIA7YxiG0tLSlJSUZM5m3S8pKSk6fvy4/P39rQPFqVNSYKCUknJf68mRo6MUGyvdtKoncpaRkSEPDw899dRT5jsJkbtcfwduwgwiAAAAii8/vz9DWUJCQVciubsTDnORkpIiBwcHq4mfDz74QBcuXFCrVq0KrrAiiIAIAACA4s3Pj2BWyO3du1cvvfSSnnnmGZUrV07ff/+93nvvPdWuXVvPPPNMQZdXpBAQAQAAABRqlSpVkq+vr95++21duHBBZcuW1fPPP6+pU6fK3t6+oMsrUgiIAAAAAAq1SpUqac2aNQVdRrHAexABAAAAAJIIiAAAAACATAREAAAAAIAkAiIAAAAAIBMBEQAAAAAgiYAIAAAAAMhEQAQAAAAASCIgAgAAAAAyERABAAAAFDqRkZGyWCw6ceLEfT93eHi4KlWqlK/HrFSpksLDw/P1mPeCXUEXAAAAABSkq/Hxup6cXNBlyN7FRU6enne0b2RkpHr37m3V5uHhoVq1amn06NEKDQ012y0WiyRp5syZGjlyZI7H+eabb9SoUaM7quV2VKpUSSdPnsxx29WrV+Xo6HjPzo1bIyACAACg2LoaH6+dffsqIzW1oEuRTYkSavnuu3ccEiVp8uTJ8vf3l2EYOnv2rCIjI9WxY0etXbtWnTt3tuo7Y8YMDRo0SM7Ozndb+h2pX79+toAqSfb29gVQDbIQEAEAAFBsXU9OLhThUJIyUlN1PTn5rgJiaGio1cxfnz595OXlpY8//tgqINavX18xMTFatGiRRowYcVd136mHHnpIzz77bIGcG7njGUQAAACgiHJzc5OTk5Ps7KznhZo1a6bWrVtr+vTpunr16l8eZ9u2bWrRooVKliwpNzc3PfHEEzp8+LBVn4kTJ8pisejo0aMKDw+Xm5ubXF1d1bt3b125ciXfrmnBggWqVauWHBwc5OPjo8GDBysxMTFbvxUrVqhhw4ZycnKSu7u7nn32WZ0+fTpbv9WrV6t27dpydHRU7dq1tWrVqhzPm5GRoTlz5qhWrVpydHSUl5eXBgwYoD/++MOqn2EYmjJliipUqCBnZ2cFBwfr0KFD+XLt9wMBEQAAACgikpKSlJCQoHPnzunQoUMaNGiQLl26lONM3cSJE3X27FktXLjwlsfcsmWL2rdvr/j4eE2cOFEjRozQV199pWbNmuW4gEy3bt108eJFRUREqFu3boqMjNSkSZOy9UtNTVVCQoLV56+C5MSJEzV48GD5+Pjorbfe0tNPP61//etfateunVJvmAmOjIxUt27dZGtrq4iICPXr108rV65U8+bNrcLk5s2b9fTTT8tisSgiIkJdu3ZV79699e2332Y794ABAzRq1Cg1a9ZMc+fOVe/evbVs2TK1b9/e6tzjx4/X66+/rnr16mnGjBmqXLmy2rVrp8uXL9/y2goLbjEFAAAAioiQkBCr7w4ODnr//ffVtm3bbH1btGih4OBg81lEJyenHI85atQolS1bVtHR0SpbtqwkqWvXrmrQoIEmTJigpUuXWvVv0KCB3nvvPfP7+fPn9d5772natGlW/TZv3iwPDw+rtgkTJmjixIk51nHu3DlFRESoXbt22rBhg2xs/pzrql69uoYMGaKPPvpIvXv3VmpqqsaMGaPatWtr165d5oI3zZs3V+fOnTV79mwzsI4ZM0ZeXl7avXu3XF1dJUktW7ZUu3btVLFiRfPcu3fv1rvvvqtly5apZ8+eZntwcLA6dOigFStWqGfPnjp37pymT5+uTp06ae3ateaCQK+++qrefPPNHK+rsGEGEQAAACgi5s+fr6ioKEVFRemjjz5ScHCw+vbtq5UrV+bYf+LEiYqLi9OiRYty3H7mzBnFxMQoPDzcDIeSVLduXbVt21br16/Pts/AgQOtvrdo0ULnz59X8k0rxTZp0sSsNevz/PPP53ptW7Zs0fXr1zV8+HAzHEpSv3795OLionXr1kmSvv32W8XHx+uFF16wWg21U6dOql69utkv69rCwsLMcChJbdu2Vc2aNa3OvWLFCrm6uqpt27ZWM54NGzZUqVKltH37dqsahw4daoZDSRo+fHiu11XYMIMIAAAAFBGNGze2WqSmR48eatCggYYMGaLOnTtnWyH0scceU3BwsKZPn54t2EkyX0URGBiYbVuNGjW0adMmXb58WSVLljTb/fz8rPqVKVNGkvTHH3/IxcXFbHd3d88243krudVib2+vypUrm9tvVXP16tW1e/duq35Vq1bN1i8wMFDff/+9+f3IkSNKSkqSZy4LCMXHx9/ymB4eHuY4FHYERAAAAKCIsrGxUXBwsObOnasjR46oVq1a2fpMmDBBrVq10r/+9S+5ubnd9TltbW1zbDcM466PXVAyMjLk6empZcuW5bj95ltlH2QERAAAAKAIS0tLkyRdunQpx+0tW7ZUq1atNG3aNI0fP95qW9ZzeLGxsdn2+/nnn+Xu7m41e3gv3VhL5cqVzfbr16/r+PHj5mzkjf1at25tdYzY2Fhze9b/HjlyJNu5br7egIAAbdmyRc2aNcv1Wc2bj3ljjefOncu22mlhxTOIAAAAQBGVmpqqzZs3y97eXjVq1Mi1X9aziIsXL7ZqL1++vOrXr6+lS5darf558OBBbd68WR07drxXpWcTEhIie3t7vf3221azke+9956SkpLUqVMnSVKjRo3k6empRYsW6dq1a2a/DRs26PDhw2a/G68tKSnJ7BcVFaWffvrJ6tzdunVTenq63njjjWx1paWlmWMTEhKiEiVKaN68eVY1zpkz566v/35hBhEAAAAoIjZs2KCff/5Z0p/PxS1fvlxHjhzR2LFjrZ7/u1nLli3VsmVL7dy5M9u2GTNmKDQ0VEFBQerTp4+uXr2qefPmydXVNdcVR+8FDw8PjRs3TpMmTVKHDh3UpUsXxcbGasGCBXrkkUfMV3mUKFFC06ZNU+/evdWyZUv16NFDZ8+e1dy5c1WpUiW99NJL5jEjIiLUqVMnNW/eXP/4xz904cIFzZs3T7Vq1bKacW3ZsqUGDBigiIgIxcTEqF27dipRooSOHDmiFStWaO7cufrb3/4mDw8Pvfzyy4qIiFDnzp3VsWNH7d+/Xxs2bJC7u/t9G6u7ke8ziFkvyLzxU716dXN7SkqKBg8erHLlyqlUqVJ6+umndfbsWatjnDp1Sp06dZKzs7M8PT01atQoc2ocAAAAQM7Gjx+v5557Ts8995xeffVVpaena+HChbf1ioXcwl5ISIg2btyocuXKafz48Zo5c6YeffRR7dmzR/7+/vl8BX9d4zvvvKNTp07ppZde0qeffqr+/ftr8+bNKlGihNkvPDxc//nPf3T9+nWNGTNG//rXv/Tkk09q9+7dVs9ZZr2iIj09XePGjdPKlSu1ZMkSq4V+sixatEiLFy9WfHy8XnnlFY0bN07btm3Ts88+q2bNmpn9pkyZokmTJmn//v0aNWqUjh07ps2bN9+3W3HvlsXI56dFJ06cqM8++0xbtmwx2+zs7MzEPGjQIK1bt06RkZFydXXVkCFDZGNjoz179kiS0tPTVb9+fXl7e2vGjBk6c+aMnn/+efXr1y9P7w5JTk6Wq6ur7OzsrJaYBQAAQMEwDENpaWlKSkq65WzWvZCSkqLjx4/L39/f6tUHV+PjtbNvX2Xc8KLzgmJTooRavvuunHJZKRO4G7n9DtzsntxiamdnJ29v72ztSUlJeu+997R8+XLzgdElS5aoRo0a2rt3rx599FFt3rxZP/30k7Zs2SIvLy/Vr19fb7zxhsaMGaOJEydmW5oXAAAAuFNOnp5q+e67un7TO/oKgr2LC+EQBe6eBMQjR47Ix8dHjo6OCgoKUkREhPz8/PTdd98pNTXV6n0n1atXl5+fn6Kjo/Xoo48qOjpaderUkZeXl9mnffv2GjRokA4dOqQGDRrkeM5r165ZPYR684s4AQAAgJw4eXoSzIBM+f4MYpMmTRQZGamNGzdq4cKFOn78uFq0aKGLFy8qLi5O9vb22d6v4uXlpbi4OElSXFycVTjM2p61LTcRERFydXU1P76+vvl7YQAAAABQxOX7DGJoaKj557p166pJkyaqWLGiPv3001u+M+RujRs3TiNGjDC/JycnExIBAAAAIA/u+XsQ3dzcVK1aNR09elTe3t66fv261TtUJOns2bPmM4ve3t7ZVjXN+p7Tc41ZHBwc5OLiYvUBAAAAANy+ex4QL126pGPHjql8+fJq2LChSpQooa1bt5rbY2NjderUKQUFBUmSgoKC9OOPPyo+Pt7sExUVJRcXF9WsWfNelwsAAAAAxVa+32L68ssv6/HHH1fFihX1+++/a8KECbK1tVWPHj3k6uqqPn36aMSIESpbtqxcXFw0dOhQBQUF6dFHH5UktWvXTjVr1tRzzz2n6dOnKy4uTq+99poGDx4sBweH/C4XAAAAAJAp3wPib7/9ph49euj8+fPy8PBQ8+bNtXfvXnl4eEiSZs+eLRsbGz399NO6du2a2rdvrwULFpj729ra6osvvtCgQYMUFBSkkiVLKiwsTJMnT87vUgEAAAAAN7AYhmEUdBH3QnJyslxdXWVnZyeLxVLQ5QAAABR7hmEoLS1NSUlJ9329iNt9SThQVN3u78A9fwYRAAAAAPBgICACAAAAACQREAEAAADks8jISFksFp04cSJP++3YsUMWi0U7duy4J3XdysSJE/P90bRWrVqpVatW+XrMey3fF6kBAAAAHiQXL55SSkpCQZchR0d3lS7td0f7RkZGqnfv3uZ3W1tbeXl5qW3btvrnP/+phx56KL/KvGOtWrXSzp07c9x2+PBhVa9e/T5XhJwQEAEAAFBsXbx4Sh9/HKj09JSCLkW2to7q0SP2jkOiJE2ePFn+/v5KSUnR3r17FRkZqd27d+vgwYOFYnGeChUqKCIiIlu7j49PAVSDnBAQAQAAUGylpCQUinAoSenpKUpJSbirgBgaGqpGjRpJkvr27St3d3dNmzZNa9asUbdu3fKr1Dvm6uqqZ599tqDLwC3wDCIAAABQRLVo0UKSdOzYMbNt27ZtatGihUqWLCk3Nzc98cQTOnz4sNV+J0+e1AsvvKDAwEA5OTmpXLlyeuaZZ3J8pvDQoUNq3bq1nJycVKFCBU2ZMkUZGRn5eh0rVqxQw4YN5eTkJHd3dz377LM6ffp0tn63c22StHv3bj3yyCNydHRUQECA/vWvf+V67o8++sg8d9myZdW9e3f9+uuv2fotXrxYAQEBcnJyUuPGjfXll1/e3UUXEGYQAQAAgCIqK9CVKVNGkrRlyxaFhoaqcuXKmjhxoq5evap58+apWbNm+v7771WpUiVJ0jfffKOvvvpK3bt3V4UKFXTixAktXLhQrVq10k8//SRnZ2dJUlxcnIKDg5WWlqaxY8eqZMmSWrx4sZycnHKsJz09XQkJ1s97Ojo6qlSpUrleQ9bzlY888ogiIiJ09uxZzZ07V3v27NH+/fvl5uaWp2v78ccf1a5dO3l4eGjixIlKS0vThAkT5OXlle3c//znP/X666+rW7du6tu3r86dO6d58+bpscceszr3e++9pwEDBqhp06YaPny4fvnlF3Xp0kVly5aVr6/v7fyfqtAgIAIAAABFRFJSkhISEpSSkqJ9+/Zp0qRJcnBwUOfOnSVJo0aNUtmyZRUdHa2yZctKkrp27aoGDRpowoQJWrp0qSSpU6dO+tvf/mZ17Mcff1xBQUH6v//7Pz333HOSpGnTpuncuXPat2+fGjduLEkKCwtT1apVc6zv559/loeHh1VbWFiYIiMjc+yfmpqqMWPGqHbt2tq1a5f5HGXz5s3VuXNnzZ49W5MmTcrTtY0fP16GYejLL7+Un9+ft/M+/fTTqlOnjtW5T548qQkTJmjKlCl65ZVXzPannnpKDRo00IIFC/TKK68oNTVVr7zyiurXr6/t27fL3t5eklSzZk3179//gQuI3GIKAAAAFBEhISHy8PCQr6+v/va3v6lkyZJas2aNKlSooDNnzigmJkbh4eFmgJKkunXrqm3btlq/fr3ZduMMYGpqqs6fP68qVarIzc1N33//vblt/fr1evTRR81wKEkeHh7q1atXjvVVqlRJUVFRVp/Ro0fnej3ffvut4uPj9cILL1gtstOpUydVr15d69atk6Tbvrb09HRt2rRJXbt2NcOhJNWoUUPt27e3OvfKlSuVkZGhbt26KSEhwfx4e3uratWq2r59u1WNAwcONMOhJIWHh8vV1TXXayusmEEEAAAAioj58+erWrVqSkpK0vvvv69du3bJwcFB0p8zYpIUGBiYbb8aNWpo06ZNunz5skqWLKmrV68qIiJCS5Ys0enTp2UYhtk3KSnJ/PPJkyfVpEmTbMfL6RySVLJkSYWEhNz29dyq5urVq2v37t15uraLFy/q6tWrOc5wBgYGWoXkI0eOyDCMXGdDS5QoYXXum/uVKFFClStX/strLGwIiAAAAEAR0bhxY3MV065du6p58+bq2bOnYmNj83ScoUOHasmSJRo+fLiCgoLk6uoqi8Wi7t275/sCNIVVRkaGLBaLNmzYIFtb22zbb/Xc5IOMgAgAAAAUQba2toqIiFBwcLDeeecdhYWFSVKOYfHnn3+Wu7u7SpYsKUn67LPPFBYWprfeesvsk5KSosTERKv9KlasqCNHjmQ7Xl4DaW4qVqxoHq9169bZzpG1/cZ+N7vx2hwdHeXk5HRbNQcEBMgwDPn7+6tatWp/WeORI0esakxNTdXx48dVr16927nUQoNnEAEAAIAiqlWrVmrcuLHmzJmjMmXKqH79+lq6dKlV0Dt48KA2b96sjh07mm22trZWt5VK0rx585Senm7V1rFjR+3du1dff/212Xbu3DktW7YsX+pv1KiRPD09tWjRIl27ds1s37Bhgw4fPqxOnTpJksqXL39b12Zra6v27dtr9erVOnXqlNnv8OHD2rRpk9W5n3rqKdna2mrSpEnZxsIwDJ0/f96s0cPDQ4sWLdL169fNPpGRkdkC9YOAGUQAAACgCBs1apSeeeYZRUZGasaMGQoNDVVQUJD69OljvgrC1dVVEydONPfp3LmzPvzwQ7m6uqpmzZqKjo7Wli1bVK5cOatjjx49Wh9++KE6dOigYcOGma+5qFixog4cOHDXtZcoUULTpk1T79691bJlS/Xo0cN8zUWlSpX00ksvmX1v99omTZqkjRs3qkWLFnrhhReUlpamefPmqVatWlY1BwQEaMqUKRo3bpxOnDihrl27qnTp0jp+/LhWrVql/v376+WXX1aJEiU0ZcoUDRgwQK1bt9bf//53HT9+XEuWLOEZRAAAAACFy1NPPaWAgADNnDlTsbGx2rhxoyZMmKDx48erRIkSatmypaZNmyZ/f39zn7lz58rW1lbLli1TSkqKmjVrpi1btmRb6bN8+fLavn27hg4dqqlTp6pcuXIaOHCgfHx81KdPn3ypPzw8XM7Ozpo6darGjBmjkiVL6sknn9S0adPM9xBKf67gejvXVrduXW3atEkjRozQ+PHjVaFCBU2aNElnzpzJFmrHjh2ratWqWb1Ow9fXV+3atVOXLl3Mfv3791d6erpmzJihUaNGqU6dOlqzZo1ef/31fBmD+8li3DxfWkQkJyfL1dVVdnZ2slgsBV0OAABAsWcYhtLS0pSUlCQXF5f7eu6UlBQdP35c/v7+Vq9LuHjxlD7+OFDp6Sn3tZ6c2No6qkePWJUu7ffXnYE8yu134GbMIAIAAKDYKl3aTz16xColJaGgS5GjozvhEAWOgAgAAIBirXRpP4IZkIlVTAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAAqhEydOyGKxKDIy8r6fOzIyUhaLRSdOnMi3Y4aHh6tSpUr5drx7hYAIAAAAPOCyAk3Wx87OTg899JDCw8N1+vRpq76tWrWSxWLR448/nu04WaFs5syZ97Te8PBwq3pv/GzcuPGenhu3ZlfQBQAAAAAFKSkpSVevXi3oMuTk5CRXV9e7OsbkyZPl7++vlJQU7d27V5GRkdq9e7cOHjwoR0dHq75ffPGFvvvuOzVs2PCuznmnHBwc9O6772Zrr1evXgFUgywERAAAABRbSUlJWrx4sdLT0wu6FNna2qp///53FRJDQ0PVqFEjSVLfvn3l7u6uadOmac2aNerWrZvZz8/PTxcvXtSkSZO0Zs2au679TtjZ2enZZ58tkHMjd9xiCgAAgGLr6tWrhSIcSlJ6enq+z2S2aNFCknTs2DGr9tKlS+ull17S2rVr9f333//lcX755Rc988wzKlu2rJydnfXoo49q3bp1Vn127Nghi8WiTz/9VP/85z9VoUIFOTo6qk2bNjp69Gi+XdO2bdvUokULlSxZUm5ubnriiSd0+PDhbP3279+v0NBQubi4qFSpUmrTpo327t2brd+hQ4fUunVrOTk5qUKFCpoyZYoyMjJyPPeGDRvMc5cuXVqdOnXSoUOHsvVbvXq1ateuLUdHR9WuXVurVq26+wu/T5hBBAAAAIqorEVWypQpk23bsGHDNHv2bE2cOPGWs4hnz55V06ZNdeXKFb344osqV66cli5dqi5duuizzz7Tk08+adV/6tSpsrGx0csvv6ykpCRNnz5dvXr10r59+7IdOyEhwep7iRIlbjmDumXLFoWGhqpy5cqaOHGirl69qnnz5qlZs2b6/vvvzUVgDh06pBYtWsjFxUWjR49WiRIl9K9//UutWrXSzp071aRJE0lSXFycgoODlZaWprFjx6pkyZJavHixnJycsp37ww8/VFhYmNq3b69p06bpypUrWrhwoZo3b679+/eb5968ebOefvpp1axZUxERETp//rx69+6tChUq5HpdhQkBEQAAACgikpKSlJCQoJSUFO3bt0+TJk2Sg4ODOnfunK2vi4uLhg8frgkTJuj777/Xww8/nOMxp06dqrNnz+rLL79U8+bNJUn9+vVT3bp1NWLECD3xxBOysfnfjYkpKSmKiYmRvb29pD/D6bBhw3Tw4EHVrl3b7Hf58mV5eHhYnatly5basWNHrtc3atQolS1bVtHR0SpbtqwkqWvXrmrQoIEmTJigpUuXSpJee+01paamavfu3apcubIk6fnnn1dgYKBGjx6tnTt3SpKmTZumc+fOad++fWrcuLEkKSwsTFWrVrU676VLl/Tiiy+qb9++Wrx4sdkeFhamwMBAvfnmm2b7mDFj5OXlpd27d5tht2XLlmrXrp0qVqyY67UVFtxiCgAAABQRISEh8vDwkK+vr/72t7+pZMmSWrNmTa6zV8OGDVOZMmU0adKkXI+5fv16NW7c2AyHklSqVCn1799fJ06c0E8//WTVv3fv3mY4lP53m+svv/xi1c/R0VFRUVFWn7feeivXOs6cOaOYmBiFh4eb4VCS6tatq7Zt22r9+vWS/rxVd/PmzeratasZDiWpfPny6tmzp3bv3q3k5GTz2h599FEzHEqSh4eHevXqZXXuqKgoJSYmqkePHkpISDA/tra2atKkibZv325VY1hYmNVMaNu2bVWzZs1cr60wYQYRAAAAKCLmz5+vatWqKSkpSe+//7527dolBweHXPu7urqas4j79+/P8VbUkydPmrdk3qhGjRrm9htnBv38/Kz6ZR3zjz/+sGq3tbVVSEjIbV/byZMnJUmBgYE51rJp0yZdvnxZFy9e1JUrV3Ltl5GRoV9//VW1atXK9dpu3vfIkSOSpNatW+dYm4uLi1WNN89AZh3zdp73LGgERAAAAKCIaNy4sbmKadeuXdW8eXP17NlTsbGxKlWqVI77ZD2LOGnSJM2ZM+eua7C1tc2x3TCMuz52QclatObDDz+Ut7d3tu12dkUnVhWdKwEAAABgsrW1VUREhIKDg/XOO+9o7NixOfbLmkWcOHGiwsLCsm2vWLGiYmNjs7X//PPP5vb7Ies8udXi7u6ukiVLytHRUc7Ozrn2s7Gxka+vr3nMrNnBG928b0BAgCTJ09PzlrOeWTXezjELK55BBAAAAIqoVq1aqXHjxpozZ45SUlJy7Td8+HC5ublp8uTJ2bZ17NhRX3/9taKjo822y5cva/HixapUqdJ9e7aufPnyql+/vpYuXarExESz/eDBg9q8ebM6duwo6c9g3K5dO33++efmKq7Sn6uxLl++XM2bNzdvCe3YsaP27t2rr7/+2ux37tw5LVu2zOrc7du3l4uLi958802lpqZmq+3cuXPZakxKSjK3R0VFZXtWs7AiIAIAAABF2KhRo3T27FlFRkbm2sfV1VXDhg1TTExMtm1jx46Vl5eXQkNDNX78eM2ZM0fNmzfX8ePHNWvWLKsVTO+1GTNm6Pz58woKCtLMmTP1xhtvqHXr1nJ1ddXEiRPNflOmTJGdnZ2aN2+uN998U9OnT1fTpk117do1TZ8+3ew3evRolStXTh06dNCkSZM0c+ZMNWvWLNusqIuLixYuXKgvv/xSDz/8sP75z39q8eLFeu2119SgQQOrRX4iIiJ09uxZNW/eXLNnz9brr7+uZ555RrVq1brn45MfCIgAAABAEfbUU08pICBAM2fOVHp6eq79hg8fnuM7CL28vPTVV1+pbdu2mjdvnsaNGyd7e3utXbs22zsQ77WQkBBt3LhR5cqV0/jx4zVz5kw9+uij2rNnj/z9/c1+tWrV0pdffqnatWsrIiJCkyZNUsWKFbV9+3arRWnKly+v7du3q27dupo6darmzJmj559/XsOGDct27p49e2rr1q166KGHNGPGDA0bNkyffPKJ6tevr969e5v9OnTooBUrVig9PV3jxo3TypUrtWTJEvPZ0MLOYjzIT4veQnJyslxdXWVnZyeLxVLQ5QAAABR7hmEoLS1NSUlJ5i1+90tKSoqOHz8uf39/OTo6mu1JSUlavHjxLYPT/WJra6v+/fvf8kXxwJ3K7XfgZixSAwAAgGLL1dVV/fv319WrVwu6FDk5OREOUeAIiAAAACjWXF1dCWZAJp5BBAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkiS7gi4AAAAAKEin0tKUkJ5e0GXI3dZWfnZ5/+f5p59+qr///e9auXKlnnzySatt9erV04EDB7Rt2zYFBwdbbfPz81OFChX01Vdf3dZ5FixYIGdnZ4WHh+e5Rjw4CIgAAAAotk6lpSnw9GmlFHQhkhwlxT70UJ5DYvPmzSVJu3fvtgqIycnJOnjwoOzs7LRnzx6rgPjrr7/q119/Vffu3W/7PAsWLJC7uzsBsYjjFlMAAAAUWwnp6YUiHEpSinRHM5k+Pj7y9/fX7t27rdqjo6NlGIaeeeaZbNuyvmeFy4KSlpam69evF2gNsEZABAAAAB5wzZs31/79+3X16lWzbc+ePapVq5ZCQ0O1d+9eZWRkWG2zWCxq1qyZlixZotatW8vT01MODg6qWbOmFi5caHX8SpUq6dChQ9q5c6csFossFotatWplbk9MTNTw4cPl6+srBwcHValSRdOmTbM654kTJ2SxWDRz5kzNmTNHAQEBcnBw0E8//XTvBgZ5xi2mAAAAwAOuefPm+vDDD7Vv3z4zuO3Zs0dNmzZV06ZNlZSUpIMHD6pu3brmturVq6tcuXJauHChatWqpS5dusjOzk5r167VCy+8oIyMDA0ePFiSNGfOHA0dOlSlSpXSq6++Kkny8vKSJF25ckUtW7bU6dOnNWDAAPn5+emrr77SuHHjdObMGc2ZM8eq1iVLliglJUX9+/eXg4ODypYte38GCbeFgAgAAAA84G58DrFVq1ZKS0vTvn37FBYWpoCAAHl5eWn37t2qW7euLl68qB9//FH/+Mc/JEk7d+6Uk5OTeawhQ4aoQ4cOmjVrlhkQu3btqtdee03u7u569tlnrc49a9YsHTt2TPv371fVqlUlSQMGDJCPj49mzJihkSNHytfX1+z/22+/6ejRo/Lw8LinY4I7wy2mAAAAwAOuRo0aKleunPls4Q8//KDLly+radOmkqSmTZtqz549kv58NjE9Pd0MlTeGw6SkJCUkJKhly5b65ZdflJSU9JfnXrFihVq0aKEyZcooISHB/ISEhCg9PV27du2y6v/0008TDgsxZhABAACAB5zFYlHTpk21a9cuZWRkaM+ePfL09FSVKlUk/RkQ33nnHUkyg2JWQNyzZ48mTJig6OhoXblyxeq4SUlJcnV1veW5jxw5ogMHDuQa+uLj462++/v75/0Ccd8QEAEAAIAioHnz5lq7dq1+/PFH8/nDLE2bNtWoUaN0+vRp7d69Wz4+PqpcubKOHTumNm3aqHr16po1a5Z8fX1lb2+v9evXa/bs2VaLzOQmIyNDbdu21ejRo3PcXq1aNavvN85YovAhIAIAAABFwI3PIe7Zs0fDhw83tzVs2FAODg7asWOH9u3bp44dO0qS1q5dq2vXrmnNmjXy8/Mz+2/fvj3b8S0WS47nDQgI0KVLlxQSEpKPV4OCkudnEHft2qXHH39cPj4+slgsWr16tdV2wzA0fvx4lS9fXk5OTgoJCdGRI0es+ly4cEG9evWSi4uL3Nzc1KdPH126dMmqz4EDB9SiRQs5OjrK19dX06dPz/vVAQAAAMVEo0aN5OjoqGXLlun06dNWM4gODg56+OGHNX/+fF2+fNkMk7a2tpL+/Dd8lqSkJC1ZsiTb8UuWLKnExMRs7d26dVN0dLQ2bdqUbVtiYqLS0tLu9tJwH+U5IF6+fFn16tXT/Pnzc9w+ffp0vf3221q0aJH27dunkiVLqn379kpJ+d8rSHv16qVDhw4pKipKX3zxhXbt2qX+/fub25OTk9WuXTtVrFhR3333nWbMmKGJEydq8eLFd3CJAAAAQNFnb2+vRx55RNHR0XJwcFDDhg2ttjdt2lTR0dGS/jfb2K5dO9nb2+vxxx/X/PnzNW3aNDVs2FCenp7Zjt+wYUMdOHBAU6ZM0SeffKJt27ZJkkaNGqWHH35YnTt3Vr9+/bRo0SK99dZbCg8PV4UKFXIMlSi88nyLaWhoqEJDQ3PcZhiG5syZo9dee01PPPGEJOmDDz6Ql5eXVq9ere7du+vw4cPauHGjvvnmGzVq1EiSNG/ePHXs2FEzZ86Uj4+Pli1bpuvXr+v999+Xvb29atWqpZiYGM2aNcsqSAIAAAD4n+bNm+vLL780bym9UbNmzfTWW2+pdOnSqlevniQpMDBQn332mV577TW9/PLL8vb21qBBg+Th4WG+BiPL+PHjdfLkSU2fPl0XL15Uy5Yt1bp1azk7O2vnzp168803tWLFCn3wwQdycXFRtWrVNGnSpL9c5AaFi8W4cT45rztbLFq1apW6du0qSfrll18UEBCg/fv3q379+ma/li1bqn79+po7d67ef/99jRw5Un/88Ye5PS0tTY6OjlqxYoWefPJJPf/880pOTra6fXX79u1q3bq1Lly4oDJlymSr5dq1a7p27Zr5PTk5Wb6+vrKzs8v1fmkAAADcP4ZhKC0tTUlJSXJxcbmv505JSdHx48fl7+8vR0dHs/1UWpoCT59Wyi32vV8cJcU+9JD87FgmBPkvt9+Bm+XrT19cXJwkycvLy6rdy8vL3BYXF5dtytrOzk5ly5a16nPz8rdZx4yLi8sxIEZERGjSpEn5cyEAAAAoFvzs7BT70ENKSE8v6FLkbmtLOESBKzI/gePGjdOIESPM71kziAAAAMCt+NnZEcyATHlepOZWvL29JUlnz561aj979qy5zdvbO9vLMtPS0nThwgWrPjkd48Zz3MzBwUEuLi5WHwAAAADA7cvXgOjv7y9vb29t3brVbEtOTta+ffsUFBQkSQoKClJiYqK+++47s8+2bduUkZGhJk2amH127dql1NRUs09UVJQCAwNzvL0UAAAAAHD38hwQL126pJiYGMXExEiSjh8/rpiYGJ06dUoWi0XDhw/XlClTtGbNGv344496/vnn5ePjYy5kU6NGDXXo0EH9+vXT119/rT179mjIkCHq3r27fHx8JEk9e/aUvb29+vTpo0OHDuk///mP5s6da3ULKQAAAAAgf+X5Zutvv/1WwcHB5ves0BYWFqbIyEiNHj1aly9fVv/+/ZWYmKjmzZtr48aNVivlLFu2TEOGDFGbNm1kY2Ojp59+Wm+//ba53dXVVZs3b9bgwYPVsGFDubu7a/z48bziAgAAAADuobt6zUVhlpycLFdXV15zAQAAUEgUxtdcAMXF7f4O5OsziAAAAACABxcBEQAAAAAgiYAIAAAAAMhEQAQAAAAASCIgAgAAAAAy5fk1FwAAAEBRcupUmhISMgq6DLm728jPL2//PL/d1fq3b9+uVq1a3UFVKG4IiAAAACi2Tp1KU2Dg70pJKehKJEdHKTbWJ08h8cMPP7T6/sEHHygqKipbe40aNfKlRhR9BEQAAAAUWwkJGYUiHEpSSsqf9fj53f4+zz77rNX3vXv3KioqKlv7za5cuSJnZ+c7KRNFHM8gAgAAAEVYq1atVLt2bX333Xd67LHH5OzsrFdeeUWSdO3aNU2YMEFVqlSRg4ODfH19NXr0aF27di3bcT766CM1bNhQTk5OKlu2rLp3765ff/31fl8O7jFmEAEAAIAi7vz58woNDVX37t317LPPysvLSxkZGerSpYt2796t/v37q0aNGvrxxx81e/Zs/fe//9Xq1avN/f/5z3/q9ddfV7du3dS3b1+dO3dO8+bN02OPPab9+/fLzc2twK4N+YuACAAAABRxcXFxWrRokQYMGGC2ffTRR9qyZYt27typ5s2bm+21a9fWwIED9dVXX6lp06Y6efKkJkyYoClTppgzj5L01FNPqUGDBlqwYIFVOx5s3GIKAAAAFHEODg7q3bu3VduKFStUo0YNVa9eXQkJCeandevWkv5c+VSSVq5cqYyMDHXr1s2qn7e3t6pWrWr2Q9HADCIAAABQxD300EOyt7e3ajty5IgOHz4sDw+PHPeJj483+xmGoapVq+bYr0SJEvlbLAoUAREAAAAo4pycnLK1ZWRkqE6dOpo1a1aO+/j6+pr9LBaLNmzYIFtb22z9SpUqlb/FokAREAEAAIBiKCAgQD/88IPatGkji8Vyy36GYcjf31/VqlW7jxWiIPAMIgAAAFAMdevWTadPn9a///3vbNuuXr2qy5cvS/pzMRpbW1tNmjRJhmFY9TMMQ+fPn78v9eL+YAYRAAAAKIaee+45ffrppxo4cKC2b9+uZs2aKT09XT///LM+/fRTbdq0SY0aNVJAQICmTJmicePG6cSJE+ratatKly6t48ePa9WqVerfv79efvnlgr4c5BMCIgAAAFAM2djYaPXq1Zo9e7Y++OADrVq1Ss7OzqpcubKGDRtmdTvp2LFjVa1aNc2ePVuTJk2S9Ocziu3atVOXLl0K6hJwD1iMm+eJi4jk5GS5urrKzs7ulvdUAwAA4P4wDENpaWlKSkqSi4vLfT13SkqKjh8/Ln9/fzk6Oprtp06lKTDwd6Wk3NdycuToKMXG+sjPjzkc5L/cfgduxk8fAAAAii0/PzvFxvooISGjoEuRu7sN4RAFjp9AAAAAFGt+fnby8yvoKoDCgVVMAQAAAACSCIgAAAAAgEwERAAAAACAJAIiAAAAACATAREAAAAAIImACAAAAADIREAEAAAAAEgiIAIAAAAAMhEQAQAAAACSCIgAAAAA8qhSpUoKDw83v+/YsUMWi0U7duwosJqQPwiIAAAAwAOqS5cucnZ21sWLF3Pt06tXL9nb2+v8+fP3sTI8qOwKugAAAACgIF0/dV1pCWkFXYbs3O1k72efp3169eqltWvXatWqVXr++eezbb9y5Yo+//xzdejQQeXKlcuvUhUbGysbG+aaiiICIgAAAIqt66eu62DgQRkpRkGXIoujRbVja+cpJHbp0kWlS5fW8uXLcwyIn3/+uS5fvqxevXrlZ6lycHDI1+Oh8CD2AwAAoNhKS0grFOFQkowUI88zmU5OTnrqqae0detWxcfHZ9u+fPlylS5dWl26dFFiYqKGDx8uX19fOTg4qEqVKpo2bZoyMjKs9snIyNDcuXNVp04dOTo6ysPDQx06dNC3335r9rn5GcTc7Nu3Tx06dJCrq6ucnZ3VsmVL7dmzJ0/XiPuLgAgAAAA8wHr16qW0tDR9+umnVu0XLlzQpk2b9OSTT8owDLVs2VIfffSRnn/+eb399ttq1qyZxo0bpxEjRljt16dPHzNITps2TWPHjpWjo6P27t2bp7q2bdumxx57TMnJyZowYYLefPNNJSYmqnXr1vr666/v+rpxb3CLKQAAAPAAa926tcqXL6/ly5dryJAhZvuKFSuUmpqqXr16adasWTp27Jj279+vqlWrSpIGDBggHx8fzZgxQyNHjpSvr6+2b9+uyMhIvfjii5o7d655rJEjR8owbn+m1TAMDRw4UMHBwdqwYYMsFot5zlq1aum1117T5s2b82kEkJ+YQQQAAAAeYLa2turevbuio6N14sQJs3358uXy8vJSmzZttGLFCrVo0UJlypRRQkKC+QkJCVF6erp27dolSfq///s/WSwWTZgwIdt5skLe7YiJidGRI0fUs2dPnT9/3jzf5cuX1aZNG+3atSvbra0oHJhBBAAAAB5wvXr10uzZs7V8+XK98sor+u233/Tll1/qxRdflK2trY4cOaIDBw7Iw8Mjx/2znl88duyYfHx8VLZs2buq58iRI5KksLCwXPskJSWpTJkyd3Ue5D8CIgAAAPCAa9iwoapXr66PP/5Yr7zyij7++GMZhmGuXpqRkaG2bdtq9OjROe5frVq1fK0na3ZwxowZql+/fo59SpUqla/nRP4gIAIAAABFQK9evfT666/rwIEDWr58uapWrapHHnlEkhQQEKBLly4pJCTklscICAjQpk2bdOHChbuaRQwICJAkubi4/OU5UbjwDCIAAABQBGTNFo4fP14xMTFW7z7s1q2boqOjtWnTpmz7JSYmKi3tz9drPP300zIMQ5MmTcrWLy+L1DRs2FABAQGaOXOmLl26lG37uXPnbvtYuL+YQQQAAACKAH9/fzVt2lSff/65JFkFxFGjRmnNmjXq3LmzwsPD1bBhQ12+fFk//vijPvvsM504cULu7u4KDg7Wc889p7fffltHjhxRhw4dlJGRoS+//FLBwcFWq6Teio2Njd59912FhoaqVq1a6t27tx566CGdPn1a27dvl4uLi9auXXtPxgF3h4AIAAAAFBG9evXSV199pcaNG6tKlSpmu7Ozs3bu3Kk333xTK1as0AcffCAXFxdVq1ZNkyZNkqurq9l3yZIlqlu3rt577z2NGjVKrq6uatSokZo2bZqnWlq1aqXo6Gi98cYbeuedd3Tp0iV5e3urSZMmGjBgQL5dM/KXxcjLXPEDJDk5Wa6urrKzs8vTkrwAAAC4NwzDUFpampKSkuTi4nJfz52SkqLjx4/L399fjo6OZvv1U9d1MPCgjJSC/yexxdGi2rG1Ze9nX9CloAjK7XfgZswgAgAAoNiy97NX7djaSktIK+hSZOduRzhEgSMgAgAAoFiz97MnmAGZWMUUAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAKEaK6CvAgb90uz/7BEQAAAAUeSVKlJAkXblypYArAQrG5cuXZbFYzN+F3PAeRAAAABR5tra2cnNzU3x8vCTJ2dlZFoulgKsC7i3DMJSWlqbk5GQlJyfLzc1Ntra2t9yHgAgAAIBiwdvbW5LMkAgUF7a2tipfvrxcXV3/si8BEQAAAMWCxWJR+fLl5enpqdTU1IIuB7gv7OzsZGtre9sz5gREAAAAFCu2trZ/eZsdUFyxSA0AAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAECmPAfEXbt26fHHH5ePj48sFotWr15ttT08PFwWi8Xq06FDB6s+Fy5cUK9eveTi4iI3Nzf16dNHly5dsupz4MABtWjRQo6OjvL19dX06dPzfnUAAAAAgNuW54B4+fJl1atXT/Pnz8+1T4cOHXTmzBnz8/HHH1tt79Wrlw4dOqSoqCh98cUX2rVrl/r3729uT05OVrt27VSxYkV99913mjFjhiZOnKjFixfntVwAAAAAwG2yy+sOoaGhCg0NvWUfBwcHeXt757jt8OHD2rhxo7755hs1atRIkjRv3jx17NhRM2fOlI+Pj5YtW6br16/r/fffl729vWrVqqWYmBjNmjXLKkgCAAAAAPLPPXkGcceOHfL09FRgYKAGDRqk8+fPm9uio6Pl5uZmhkNJCgkJkY2Njfbt22f2eeyxx2Rvb2/2ad++vWJjY/XHH3/keM5r164pOTnZ6gMAAAAAuH35HhA7dOigDz74QFu3btW0adO0c+dOhYaGKj09XZIUFxcnT09Pq33s7OxUtmxZxcXFmX28vLys+mR9z+pzs4iICLm6upofX1/f/L40AAAAACjS8nyL6V/p3r27+ec6deqobt26CggI0I4dO9SmTZv8Pp1p3LhxGjFihPk9OTmZkAgAAAAAeXDPX3NRuXJlubu76+jRo5Ikb29vxcfHW/VJS0vThQsXzOcWvb29dfbsWas+Wd9ze7bRwcFBLi4uVh8AAAAAwO275wHxt99+0/nz51W+fHlJUlBQkBITE/Xdd9+ZfbZt26aMjAw1adLE7LNr1y6lpqaafaKiohQYGKgyZcrc65IBAAAAoFjKc0C8dOmSYmJiFBMTI0k6fvy4YmJidOrUKV26dEmjRo3S3r17deLECW3dulVPPPGEqlSpovbt20uSatSooQ4dOqhfv376+uuvtWfPHg0ZMkTdu3eXj4+PJKlnz56yt7dXnz59dOjQIf3nP//R3LlzrW4hBQAAAADkL4thGEZedtixY4eCg4OztYeFhWnhwoXq2rWr9u/fr8TERPn4+Khdu3Z64403rBaduXDhgoYMGaK1a9fKxsZGTz/9tN5++22VKlXK7HPgwAENHjxY33zzjdzd3TV06FCNGTPmtutMTk6Wq6ur7OzsZLFY8nKJAAAAuAcMw1BaWpqSkpJ4HAgopPIcEB8UBEQAAIDChYAIFH73/BlEAAAAAMCDgYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJBEQAQAAAAAZCIgAgAAAAAkERABAAAAAJkIiAAAAAAASQREAAAAAEAmAiIAAAAAQBIBEQAAAACQiYAIAAAAAJCUx4AYERGhRx55RKVLl5anp6e6du2q2NhYqz4pKSkaPHiwypUrp1KlSunpp5/W2bNnrfqcOnVKnTp1krOzszw9PTVq1CilpaVZ9dmxY4cefvhhOTg4qEqVKoqMjLyzKwQAAAAA3JY8BcSdO3dq8ODB2rt3r6KiopSamqp27drp8uXLZp+XXnpJa9eu1YoVK7Rz5079/vvveuqpp8zt6enp6tSpk65fv66vvvpKS5cuVWRkpMaPH2/2OX78uDp16qTg4GDFxMRo+PDh6tu3rzZt2pQPlwwAAAAAyInFMAzjTnc+d+6cPD09tXPnTj322GNKSkqSh4eHli9frr/97W+SpJ9//lk1atRQdHS0Hn30UW3YsEGdO3fW77//Li8vL0nSokWLNGbMGJ07d0729vYaM2aM1q1bp4MHD5rn6t69uxITE7Vx48bbqi05OVmurq6ys7OTxWK500sEAABAPjEMQ2lpaUpKSpKLi0tBlwMgB3f1DGJSUpIkqWzZspKk7777TqmpqQoJCTH7VK9eXX5+foqOjpYkRUdHq06dOmY4lKT27dsrOTlZhw4dMvvceIysPlnHyMm1a9eUnJxs9QEAAAAA3L47DogZGRkaPny4mjVrptq1a0uS4uLiZG9vLzc3N6u+Xl5eiouLM/vcGA6ztmdtu1Wf5ORkXb16Ncd6IiIi5Orqan58fX3v9NIAAAAAoFi644A4ePBgHTx4UJ988kl+1nPHxo0bp6SkJPPz66+/FnRJAAAAAPBAsbuTnYYMGaIvvvhCu3btUoUKFcx2b29vXb9+XYmJiVaziGfPnpW3t7fZ5+uvv7Y6XtYqpzf2uXnl07Nnz8rFxUVOTk451uTg4CAHB4c7uRwAAAAAgPI4g2gYhoYMGaJVq1Zp27Zt8vf3t9resGFDlShRQlu3bjXbYmNjderUKQUFBUmSgoKC9OOPPyo+Pt7sExUVJRcXF9WsWdPsc+MxsvpkHQMAAAAAkP/ytIrpCy+8oOXLl+vzzz9XYGCg2e7q6mrO7A0aNEjr169XZGSkXFxcNHToUEnSV199JenP11zUr19fPj4+mj59uuLi4vTcc8+pb9++evPNNyX9+ZqL2rVra/DgwfrHP/6hbdu26cUXX9S6devUvn3726qVVUwBAAAKF1YxBQq/PAXE3ILWkiVLFB4eLklKSUnRyJEj9fHHH+vatWtq3769FixYYN4+KkknT57UoEGDtGPHDpUsWVJhYWGaOnWq7Oz+d8frjh079NJLL+mnn35ShQoV9Prrr5vnuB0ERAAAgMKFgAgUfnf1HsTCjIAIAABQuBAQgcLvrt6DCAAAAAAoOgiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJBEQAAAAAQCYCIgAAAABAEgERAAAAAJCJgAgAAAAAkERABAAAAABkIiACAAAAACQREAEAAAAAmQiIAAAAAABJeQyIEREReuSRR1S6dGl5enqqa9euio2NterTqlUrWSwWq8/AgQOt+pw6dUqdOnWSs7OzPD09NWrUKKWlpVn12bFjhx5++GE5ODioSpUqioyMvLMrBAAAAADcljwFxJ07d2rw4MHau3evoqKilJqaqnbt2uny5ctW/fr166czZ86Yn+nTp5vb0tPT1alTJ12/fl1fffWVli5dqsjISI0fP97sc/z4cXXq1EnBwcGKiYnR8OHD1bdvX23atOkuLxcAAAAAkBuLYRjGne587tw5eXp6aufOnXrsscck/TmDWL9+fc2ZMyfHfTZs2KDOnTvr999/l5eXlyRp0aJFGjNmjM6dOyd7e3uNGTNG69at08GDB839unfvrsTERG3cuPG2aktOTparq6vs7OxksVju9BIBAACQTwzDUFpampKSkuTi4lLQ5QDIwV09g5iUlCRJKlu2rFX7smXL5O7urtq1a2vcuHG6cuWKuS06Olp16tQxw6EktW/fXsnJyTp06JDZJyQkxOqY7du3V3R0dK61XLt2TcnJyVYfAAAAAMDts7vTHTMyMjR8+HA1a9ZMtWvXNtt79uypihUrysfHRwcOHNCYMWMUGxurlStXSpLi4uKswqEk83tcXNwt+yQnJ+vq1atycnLKVk9ERIQmTZp0p5cDAAAAAMXeHQfEwYMH6+DBg9q9e7dVe//+/c0/16lTR+XLl1ebNm107NgxBQQE3Hmlf2HcuHEaMWKE+T05OVm+vr737HwAAAAAUNTc0S2mQ4YM0RdffKHt27erQoUKt+zbpEkTSdLRo0clSd7e3jp79qxVn6zv3t7et+zj4uKS4+yhJDk4OMjFxcXqAwAAAAC4fXkKiIZhaMiQIVq1apW2bdsmf3//v9wnJiZGklS+fHlJUlBQkH788UfFx8ebfaKiouTi4qKaNWuafbZu3Wp1nKioKAUFBeWlXAAAAABAHuRpFdMXXnhBy5cv1+eff67AwECz3dXVVU5OTjp27JiWL1+ujh07qly5cjpw4IBeeuklVahQQTt37pT052su6tevLx8fH02fPl1xcXF67rnn1LdvX7355puS/nzNRe3atTV48GD94x//0LZt2/Tiiy9q3bp1at++/W3VyiqmAAAAhQurmAKFX54CYm5Ba8mSJQoPD9evv/6qZ599VgcPHtTly5fl6+urJ598Uq+99prVXwInT57UoEGDtGPHDpUsWVJhYWGaOnWq7Oz+90jkjh079NJLL+mnn35ShQoV9Prrrys8PPy2L4yACAAAULgQEIHC767eg1iYERABAAAKFwIiUPjd1XsQAQAAAABFBwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADIREAEAAAAAkgiIAAAAAIBMBEQAAAAAgCQCIgAAAAAgEwERAAAAACCJgAgAAAAAyERABAAAAABIIiACAAAAADLZFXQB94phGFb/CwAAgILFv8+Awq/IBsTz589LktLT0wu4EgAAANzo4sWLcnV1LegyAOSgyAbEsmXLSpJOnTrFX0C3KTk5Wb6+vvr111/l4uJS0OU8EBizvGPM8o4xyzvGLO8Ys7xjzPLOMAxdvHhRPj4+BV0KgFwU2YBoY/Pn45Wurq78pZ1HLi4ujFkeMWZ5x5jlHWOWd4xZ3jFmeceY5Q3/4R4o3FikBgAAAAAgiYAIAAAAAMhUZAOig4ODJkyYIAcHh4Iu5YHBmOUdY5Z3jFneMWZ5x5jlHWOWd4wZgKLIYrDOMAAAAABARXgGEQAAAACQNwREAAAAAIAkAiIAAAAAIBMBEQAAAAAgqYgGxPnz56tSpUpydHRUkyZN9PXXXxd0SQVm4sSJslgsVp/q1aub21NSUjR48GCVK1dOpUqV0tNPP62zZ89aHePUqVPq1KmTnJ2d5enpqVGjRiktLe1+X8o9s2vXLj3++OPy8fGRxWLR6tWrrbYbhqHx48erfPnycnJyUkhIiI4cOWLV58KFC+rVq5dcXFzk5uamPn366NKlS1Z9Dhw4oBYtWsjR0VG+vr6aPn36vb60e+avxiw8PDzbz12HDh2s+hSnMYuIiNAjjzyi0qVLy9PTU127dlVsbKxVn/z6XdyxY4cefvhhOTg4qEqVKoqMjLzXl3dP3M6YtWrVKtvP2cCBA636FKcxW7hwoerWrWu+tD0oKEgbNmwwt/Mzlt1fjRk/YwCKJaOI+eSTTwx7e3vj/fffNw4dOmT069fPcHNzM86ePVvQpRWICRMmGLVq1TLOnDljfs6dO2duHzhwoOHr62ts3brV+Pbbb41HH33UaNq0qbk9LS3NqF27thESEmLs37/fWL9+veHu7m6MGzeuIC7nnli/fr3x6quvGitXrjQkGatWrbLaPnXqVMPV1dVYvXq18cMPPxhdunQx/P39jatXr5p9OnToYNSrV8/Yu3ev8eWXXxpVqlQxevToYW5PSkoyvLy8jF69ehkHDx40Pv74Y8PJycn417/+db8uM1/91ZiFhYUZHTp0sPq5u3DhglWf4jRm7du3N5YsWWIcPHjQiImJMTp27Gj4+fkZly5dMvvkx+/iL7/8Yjg7OxsjRowwfvrpJ2PevHmGra2tsXHjxvt6vfnhdsasZcuWRr9+/ax+zpKSksztxW3M1qxZY6xbt87473//a8TGxhqvvPKKUaJECePgwYOGYfAzlpO/GjN+xgAUR0UuIDZu3NgYPHiw+T09Pd3w8fExIiIiCrCqgjNhwgSjXr16OW5LTEw0SpQoYaxYscJsO3z4sCHJiI6ONgzjzyBgY2NjxMXFmX0WLlxouLi4GNeuXbuntReEm8NORkaG4e3tbcyYMcNsS0xMNBwcHIyPP/7YMAzD+OmnnwxJxjfffGP22bBhg2GxWIzTp08bhmEYCxYsMMqUKWM1ZmPGjDECAwPv8RXde7kFxCeeeCLXfYr7mMXHxxuSjJ07dxqGkX+/i6NHjzZq1aplda6///3vRvv27e/1Jd1zN4+ZYfz5j/dhw4bluk9xHzPDMIwyZcoY7777Lj9jeZA1ZobBzxiA4qlI3WJ6/fp1fffddwoJCTHbbGxsFBISoujo6AKsrGAdOXJEPj4+qly5snr16qVTp05Jkr777julpqZajVf16tXl5+dnjld0dLTq1KkjLy8vs0/79u2VnJysQ4cO3d8LKQDHjx9XXFyc1Ri5urqqSZMmVmPk5uamRo0amX1CQkJkY2Ojffv2mX0ee+wx2dvbm33at2+v2NhY/fHHH/fpau6vHTt2yNPTU4GBgRo0aJDOnz9vbivuY5aUlCRJKlu2rKT8+12Mjo62OkZWn6Lw99/NY5Zl2bJlcnd3V+3atTVu3DhduXLF3Facxyw9PV2ffPKJLl++rKCgIH7GbsPNY5aFnzEAxY1dQReQnxISEpSenm71F7UkeXl56eeffy6gqgpWkyZNFBkZqcDAQJ05c0aTJk1SixYtdPDgQcXFxcne3l5ubm5W+3h5eSkuLk6SFBcXl+N4Zm0r6rKuMacxuHGMPD09rbbb2dmpbNmyVn38/f2zHSNrW5kyZe5J/QWlQ4cOeuqpp+Tv769jx47plVdeUWhoqKKjo2Vra1usxywjI0PDhw9Xs2bNVLt2bUnKt9/F3PokJyfr6tWrcnJyuheXdM/lNGaS1LNnT1WsWFE+Pj46cOCAxowZo9jYWK1cuVJS8RyzH3/8UUFBQUpJSVGpUqW0atUq1axZUzExMfyM5SK3MZP4GQNQPBWpgIjsQkNDzT/XrVtXTZo0UcWKFfXpp5/y/5Rwz3Tv3t38c506dVS3bl0FBARox44datOmTQFWVvAGDx6sgwcPavfu3QVdygMjtzHr37+/+ec6deqofPnyatOmjY4dO6aAgID7XWahEBgYqJiYGCUlJemzzz5TWFiYdu7cWdBlFWq5jVnNmjX5GQNQLBWpW0zd3d1la2ubbVW2s2fPytvbu4CqKlzc3NxUrVo1HT16VN7e3rp+/boSExOt+tw4Xt7e3jmOZ9a2oi7rGm/1M+Xt7a34+Hir7Wlpabpw4QLjmKly5cpyd3fX0aNHJRXfMRsyZIi++OILbd++XRUqVDDb8+t3Mbc+Li4uD+x/EMptzHLSpEkTSbL6OStuY2Zvb68qVaqoYcOGioiIUL169TR37lx+xm4htzHLCT9jAIqDIhUQ7e3t1bBhQ23dutVsy8jI0NatW62eJyjOLl26pGPHjql8+fJq2LChSpQoYTVesbGxOnXqlDleQUFB+vHHH63+MR8VFSUXFxfzFpyizN/fX97e3lZjlJycrH379lmNUWJior777juzz7Zt25SRkWH+YyIoKEi7du1Samqq2ScqKkqBgYEP7K2SefHbb7/p/PnzKl++vKTiN2aGYWjIkCFatWqVtm3blu3W2fz6XQwKCrI6RlafB/Hvv78as5zExMRIktXPWXEas5xkZGTo2rVr/IzlQdaY5YSfMQDFQkGvkpPfPvnkE8PBwcGIjIw0fvrpJ6N///6Gm5ub1QpjxcnIkSONHTt2GMePHzf27NljhISEGO7u7kZ8fLxhGH8ue+7n52ds27bN+Pbbb42goCAjKCjI3D9rCe927doZMTExxsaNGw0PD48i9ZqLixcvGvv37zf2799vSDJmzZpl7N+/3zh58qRhGH++5sLNzc34/PPPjQMHDhhPPPFEjq+5aNCggbFv3z5j9+7dRtWqVa1e2ZCYmGh4eXkZzz33nHHw4EHjk08+MZydnR/IVzYYxq3H7OLFi8bLL79sREdHG8ePHze2bNliPPzww0bVqlWNlJQU8xjFacwGDRpkuLq6Gjt27LBaLv/KlStmn/z4XcxaTn/UqFHG4cOHjfnz5z+wy+n/1ZgdPXrUmDx5svHtt98ax48fNz7//HOjcuXKxmOPPWYeo7iN2dixY42dO3cax48fNw4cOGCMHTvWsFgsxubNmw3D4GcsJ7caM37GABRXRS4gGoZhzJs3z/Dz8zPs7e2Nxo0bG3v37i3okgrM3//+d6N8+fKGvb298dBDDxl///vfjaNHj5rbr169arzwwgtGmTJlDGdnZ+PJJ580zpw5Y3WMEydOGKGhoYaTk5Ph7u5ujBw50khNTb3fl3LPbN++3ZCU7RMWFmYYxp+vunj99dcNLy8vw8HBwWjTpo0RGxtrdYzz588bPXr0MEqVKmW4uLgYvXv3Ni5evGjV54cffjCaN29uODg4GA899JAxderU+3WJ+e5WY3blyhWjXbt2hoeHh1GiRAmjYsWKRr9+/bL9R5riNGY5jZUkY8mSJWaf/Ppd3L59u1G/fn3D3t7eqFy5stU5HiR/NWanTp0yHnvsMaNs2bKGg4ODUaVKFWPUqFFW76gzjOI1Zv/4xz+MihUrGvb29oaHh4fRpk0bMxwaBj9jObnVmPEzBqC4shiGYdy/+UoAAAAAQGFVpJ5BBAAAAADcOQIiAAAAAEASAREAAAAAkImACAAAAACQREAEAAAAAGQiIAIAAAAAJBEQAQAAAACZCIgAAAAAAEkERAAAAABAJgIiAAAAAEASAREAAAAAkImACAAAAACQJP0/8oKJmaIHfpsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "img = Image.open('/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/annotations/training/10166_lab.png')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(8)]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d631e879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:22.186868Z",
     "iopub.status.busy": "2024-03-05T17:27:22.186471Z",
     "iopub.status.idle": "2024-03-05T17:27:22.193224Z",
     "shell.execute_reply": "2024-03-05T17:27:22.192226Z"
    },
    "papermill": {
     "duration": 0.083357,
     "end_time": "2024-03-05T17:27:22.195543",
     "exception": false,
     "start_time": "2024-03-05T17:27:22.112186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Background',\n",
       " 'BuildingFlooded',\n",
       " 'BNonFlooded',\n",
       " 'RoadFlooded',\n",
       " 'RNonFlooded',\n",
       " 'Water',\n",
       " 'Tree',\n",
       " 'Vecile',\n",
       " 'Pool',\n",
       " 'Grass']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a37ff49c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:22.345318Z",
     "iopub.status.busy": "2024-03-05T17:27:22.344920Z",
     "iopub.status.idle": "2024-03-05T17:27:22.352883Z",
     "shell.execute_reply": "2024-03-05T17:27:22.351719Z"
    },
    "papermill": {
     "duration": 0.085752,
     "end_time": "2024-03-05T17:27:22.355193",
     "exception": false,
     "start_time": "2024-03-05T17:27:22.269441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0]),\n",
       " array([255,   0,   0]),\n",
       " array([181,  72,  72]),\n",
       " array([150, 150,   0]),\n",
       " array([135, 135, 135]),\n",
       " array([  0, 224, 224]),\n",
       " array([  0,   0, 225]),\n",
       " array([204,   0, 204]),\n",
       " array([237, 237,   0]),\n",
       " array([  0, 225,   0])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfea65d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:22.503155Z",
     "iopub.status.busy": "2024-03-05T17:27:22.502775Z",
     "iopub.status.idle": "2024-03-05T17:27:37.014801Z",
     "shell.execute_reply": "2024-03-05T17:27:37.013426Z"
    },
    "papermill": {
     "duration": 14.589287,
     "end_time": "2024-03-05T17:27:37.017726",
     "exception": false,
     "start_time": "2024-03-05T17:27:22.428439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\r\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.13)\r\n",
      "Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ftfy\r\n",
      "Successfully installed ftfy-6.1.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0f4f060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:37.170159Z",
     "iopub.status.busy": "2024-03-05T17:27:37.169753Z",
     "iopub.status.idle": "2024-03-05T17:27:41.320213Z",
     "shell.execute_reply": "2024-03-05T17:27:41.319215Z"
    },
    "papermill": {
     "duration": 4.230204,
     "end_time": "2024-03-05T17:27:41.322974",
     "exception": false,
     "start_time": "2024-03-05T17:27:37.092770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmseg.registry import DATASETS\n",
    "from mmseg.datasets import BaseSegDataset\n",
    "\n",
    "## should be run only once\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ImageSegmentationDataset(BaseSegDataset):\n",
    "    METAINFO = dict(classes = classes, palette = palette)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(img_suffix='.jpg', seg_map_suffix=\"_lab.png\", **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2ffe81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:41.472577Z",
     "iopub.status.busy": "2024-03-05T17:27:41.471404Z",
     "iopub.status.idle": "2024-03-05T17:27:41.478331Z",
     "shell.execute_reply": "2024-03-05T17:27:41.477248Z"
    },
    "papermill": {
     "duration": 0.084121,
     "end_time": "2024-03-05T17:27:41.480716",
     "exception": false,
     "start_time": "2024-03-05T17:27:41.396595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64e1b2a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:41.629878Z",
     "iopub.status.busy": "2024-03-05T17:27:41.629477Z",
     "iopub.status.idle": "2024-03-05T17:27:43.756158Z",
     "shell.execute_reply": "2024-03-05T17:27:43.754833Z"
    },
    "papermill": {
     "duration": 2.204691,
     "end_time": "2024-03-05T17:27:43.759175",
     "exception": false,
     "start_time": "2024-03-05T17:27:41.554484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'checkpoint': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r checkpoint\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3579a",
   "metadata": {
    "papermill": {
     "duration": 0.07385,
     "end_time": "2024-03-05T17:27:43.904295",
     "exception": false,
     "start_time": "2024-03-05T17:27:43.830445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bc9bcab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:44.054592Z",
     "iopub.status.busy": "2024-03-05T17:27:44.054141Z",
     "iopub.status.idle": "2024-03-05T17:27:44.767779Z",
     "shell.execute_reply": "2024-03-05T17:27:44.766746Z"
    },
    "papermill": {
     "duration": 0.793011,
     "end_time": "2024-03-05T17:27:44.772386",
     "exception": false,
     "start_time": "2024-03-05T17:27:43.979375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/ade/ADEChallengeData2016'\n",
      "dataset_type = 'ADE20KDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=150,\n",
      "        type='SegformerHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from mmengine import Config\n",
    "cfg = Config.fromfile('/kaggle/working/mmsegmentation/configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-512x512.py')\n",
    "#cfg = Config.fromfile('/kaggle/working/mmsegmentation/configs/segformer/segformer_mit-b5_8xb2-160k_ade20k-640x640.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3532165c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:44.942888Z",
     "iopub.status.busy": "2024-03-05T17:27:44.942476Z",
     "iopub.status.idle": "2024-03-05T17:27:44.949566Z",
     "shell.execute_reply": "2024-03-05T17:27:44.948425Z"
    },
    "papermill": {
     "duration": 0.084433,
     "end_time": "2024-03-05T17:27:44.951818",
     "exception": false,
     "start_time": "2024-03-05T17:27:44.867385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.decode_head.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4f903d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:45.098226Z",
     "iopub.status.busy": "2024-03-05T17:27:45.097838Z",
     "iopub.status.idle": "2024-03-05T17:27:45.103155Z",
     "shell.execute_reply": "2024-03-05T17:27:45.102123Z"
    },
    "papermill": {
     "duration": 0.080272,
     "end_time": "2024-03-05T17:27:45.105399",
     "exception": false,
     "start_time": "2024-03-05T17:27:45.025127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.model.pretrained None\n"
     ]
    }
   ],
   "source": [
    "#cfg.model.pretrained = True\n",
    "print(\"cfg.model.pretrained\", cfg.model.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e416c88b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:45.250700Z",
     "iopub.status.busy": "2024-03-05T17:27:45.250232Z",
     "iopub.status.idle": "2024-03-05T17:27:46.912911Z",
     "shell.execute_reply": "2024-03-05T17:27:46.911797Z"
    },
    "papermill": {
     "duration": 1.743246,
     "end_time": "2024-03-05T17:27:46.920456",
     "exception": false,
     "start_time": "2024-03-05T17:27:45.177210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
      "dataset_type = 'ImageSegmentationDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=2000, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=10,\n",
      "        type='SegformerHead'),\n",
      "    pretrained=\n",
      "    'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=40000, type='IterBasedTrainLoop', val_interval=80000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/kaggle/working/checkpoint'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 10\n",
    "#cfg.model.auxiliary_head.num_classes = 10\n",
    "\n",
    "\n",
    "#cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_640x640_160k_ade20k/segformer_mit-b5_640x640_160k_ade20k_20210801_121243-41d2845b.pth'\n",
    "cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth'\n",
    "\n",
    "cfg.val_evaluator = dict(type='IoUMetric',\n",
    "                         iou_metrics=['mIoU', 'mDice', 'mFscore'],\n",
    "#                          format_only=True,\n",
    "#                          output_dir='/kaggle/working/results'\n",
    "                        )\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# # Modify dataset type and path\n",
    "cfg.dataset_type = 'ImageSegmentationDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "\n",
    "cfg.train_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.val_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.test_dataloader.dataset.type=cfg.dataset_type\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(\n",
    "        type='RandomResize',\n",
    "        scale=(\n",
    "            512,\n",
    "            512,\n",
    "        ),\n",
    "        ratio_range=(\n",
    "            0.5,\n",
    "            2.0,\n",
    "        ),\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomCrop', crop_size=(\n",
    "        512,\n",
    "        512,\n",
    "    ), cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='PackSegInputs'),\n",
    "]\n",
    "\n",
    "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
    "\n",
    "cfg.test_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "cfg.train_dataloader.dataset.data_root =data_root \n",
    "cfg.val_dataloader.dataset.data_root =data_root \n",
    "cfg.test_dataloader.dataset.data_root=data_root\n",
    "\n",
    "cfg.train_dataloader.num_workers=1\n",
    "cfg.train_dataloader.batch_size = 2\n",
    "cfg.train_dataloader.persistent_workers=False\n",
    "\n",
    "\n",
    "cfg.val_dataloader.batch_size = 1\n",
    "cfg.val_dataloader.num_workers=1\n",
    "cfg.val_dataloader.persistent_workers=False\n",
    "\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.test_dataloader.num_workers=1\n",
    "cfg.test_dataloader.persistent_workers=False\n",
    "\n",
    "#cfg.work_dir = './checkpoint'\n",
    "cfg.work_dir = '/kaggle/working/checkpoint'\n",
    "\n",
    "cfg.train_cfg.max_iters = 40000\n",
    "cfg.train_cfg.val_interval = 80000\n",
    "cfg.default_hooks.logger.interval =100\n",
    "cfg.default_hooks.checkpoint.interval = 2000\n",
    "\n",
    "# Set seed to facilitate reproducing the result\n",
    "cfg['randomness'] = dict(seed=0)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d6fa106",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:47.069892Z",
     "iopub.status.busy": "2024-03-05T17:27:47.069510Z",
     "iopub.status.idle": "2024-03-05T17:27:47.074908Z",
     "shell.execute_reply": "2024-03-05T17:27:47.073770Z"
    },
    "papermill": {
     "duration": 0.080084,
     "end_time": "2024-03-05T17:27:47.077110",
     "exception": false,
     "start_time": "2024-03-05T17:27:46.997026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\n"
     ]
    }
   ],
   "source": [
    "print(cfg.model.pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68121c51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:47.223818Z",
     "iopub.status.busy": "2024-03-05T17:27:47.223429Z",
     "iopub.status.idle": "2024-03-05T17:27:48.971353Z",
     "shell.execute_reply": "2024-03-05T17:27:48.970375Z"
    },
    "papermill": {
     "duration": 1.823954,
     "end_time": "2024-03-05T17:27:48.973841",
     "exception": false,
     "start_time": "2024-03-05T17:27:47.149887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.dump('/kaggle/working/my_config_file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "940a1cd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:49.127359Z",
     "iopub.status.busy": "2024-03-05T17:27:49.126927Z",
     "iopub.status.idle": "2024-03-05T17:27:49.136771Z",
     "shell.execute_reply": "2024-03-05T17:27:49.135811Z"
    },
    "papermill": {
     "duration": 0.088799,
     "end_time": "2024-03-05T17:27:49.138877",
     "exception": false,
     "start_time": "2024-03-05T17:27:49.050078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'EncoderDecoder',\n",
       " 'data_preprocessor': {'type': 'SegDataPreProcessor',\n",
       "  'mean': [123.675, 116.28, 103.53],\n",
       "  'std': [58.395, 57.12, 57.375],\n",
       "  'bgr_to_rgb': True,\n",
       "  'pad_val': 0,\n",
       "  'seg_pad_val': 255,\n",
       "  'size': (512, 512)},\n",
       " 'pretrained': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth',\n",
       " 'backbone': {'type': 'MixVisionTransformer',\n",
       "  'in_channels': 3,\n",
       "  'embed_dims': 64,\n",
       "  'num_stages': 4,\n",
       "  'num_layers': [3, 6, 40, 3],\n",
       "  'num_heads': [1, 2, 5, 8],\n",
       "  'patch_sizes': [7, 3, 3, 3],\n",
       "  'sr_ratios': [8, 4, 2, 1],\n",
       "  'out_indices': (0, 1, 2, 3),\n",
       "  'mlp_ratio': 4,\n",
       "  'qkv_bias': True,\n",
       "  'drop_rate': 0.0,\n",
       "  'attn_drop_rate': 0.0,\n",
       "  'drop_path_rate': 0.1,\n",
       "  'init_cfg': {'type': 'Pretrained',\n",
       "   'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}},\n",
       " 'decode_head': {'type': 'SegformerHead',\n",
       "  'in_channels': [64, 128, 320, 512],\n",
       "  'in_index': [0, 1, 2, 3],\n",
       "  'channels': 256,\n",
       "  'dropout_ratio': 0.1,\n",
       "  'num_classes': 10,\n",
       "  'norm_cfg': {'type': 'SyncBN', 'requires_grad': True},\n",
       "  'align_corners': False,\n",
       "  'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "   'use_sigmoid': False,\n",
       "   'loss_weight': 1.0}},\n",
       " 'train_cfg': {},\n",
       " 'test_cfg': {'mode': 'whole'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09c7e785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:49.293629Z",
     "iopub.status.busy": "2024-03-05T17:27:49.293179Z",
     "iopub.status.idle": "2024-03-05T17:27:49.300321Z",
     "shell.execute_reply": "2024-03-05T17:27:49.299364Z"
    },
    "papermill": {
     "duration": 0.086895,
     "end_time": "2024-03-05T17:27:49.302622",
     "exception": false,
     "start_time": "2024-03-05T17:27:49.215727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Pretrained',\n",
       " 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model['backbone'].pop('init_cfg', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94322985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:27:49.457012Z",
     "iopub.status.busy": "2024-03-05T17:27:49.456614Z",
     "iopub.status.idle": "2024-03-05T17:28:00.525909Z",
     "shell.execute_reply": "2024-03-05T17:28:00.524926Z"
    },
    "papermill": {
     "duration": 11.149717,
     "end_time": "2024-03-05T17:28:00.528592",
     "exception": false,
     "start_time": "2024-03-05T17:27:49.378875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/05 17:27:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0: Tesla P100-PCIE-16GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.0+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.0+cu102\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.3\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "03/05 17:27:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
      "dataset_type = 'ImageSegmentationDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=2000, type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=64,\n",
      "        in_channels=3,\n",
      "        mlp_ratio=4,\n",
      "        num_heads=[\n",
      "            1,\n",
      "            2,\n",
      "            5,\n",
      "            8,\n",
      "        ],\n",
      "        num_layers=[\n",
      "            3,\n",
      "            6,\n",
      "            40,\n",
      "            3,\n",
      "        ],\n",
      "        num_stages=4,\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_sizes=[\n",
      "            7,\n",
      "            3,\n",
      "            3,\n",
      "            3,\n",
      "        ],\n",
      "        qkv_bias=True,\n",
      "        sr_ratios=[\n",
      "            8,\n",
      "            4,\n",
      "            2,\n",
      "            1,\n",
      "        ],\n",
      "        type='MixVisionTransformer'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=10,\n",
      "        type='SegformerHead'),\n",
      "    pretrained=\n",
      "    'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=40000, type='IterBasedTrainLoop', val_interval=80000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/kaggle/working/checkpoint'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/backbones/mit.py:365: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/builder.py:36: UserWarning: ``build_loss`` would be deprecated soon, please use ``mmseg.registry.MODELS.build()`` \n",
      "  warnings.warn('``build_loss`` would be deprecated soon, please use '\n",
      "/opt/conda/lib/python3.10/site-packages/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/05 17:27:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "03/05 17:27:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91fb18dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T17:28:00.684306Z",
     "iopub.status.busy": "2024-03-05T17:28:00.683938Z",
     "iopub.status.idle": "2024-03-06T00:50:51.545508Z",
     "shell.execute_reply": "2024-03-06T00:50:51.544304Z"
    },
    "papermill": {
     "duration": 26570.944921,
     "end_time": "2024-03-06T00:50:51.550933",
     "exception": false,
     "start_time": "2024-03-05T17:28:00.606012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/datasets/transforms/loading.py:83: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.0.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.0.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.1.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.0.1.2.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.0.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.0.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.1.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.2.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.3.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.4.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.1.1.5.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.0.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.0.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.1.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.2.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.3.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.4.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.5.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.6.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.7.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.8.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.9.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.10.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.11.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.12.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:lr=6e-05\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.13.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.14.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.15.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.16.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.17.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.18.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.19.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.20.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.21.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.22.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.23.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.24.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.25.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.26.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.27.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.28.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.29.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.30.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.31.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.32.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.33.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.34.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.35.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.36.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.37.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.38.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.attn.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.2.1.39.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.0.norm.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.0.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.1.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm1.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.weight:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:lr=6e-05\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:weight_decay=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.layers.3.1.2.norm2.bias:decay_mult=0.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.conv_seg.bias:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.conv.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.conv.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.conv.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.bn.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.bn.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.bn.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.bn.bias:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.bn.bias:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.0.bn.bias:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.conv.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.conv.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.conv.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.bn.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.bn.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.bn.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.bn.bias:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.bn.bias:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.1.bn.bias:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.conv.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.conv.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.conv.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.bn.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.bn.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.bn.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.bn.bias:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.bn.bias:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.2.bn.bias:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.conv.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.conv.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.conv.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.bn.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.bn.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.bn.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.bn.bias:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.bn.bias:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.convs.3.bn.bias:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.conv.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.conv.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.conv.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.bn.weight:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.bn.weight:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.bn.weight:lr_mult=10.0\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.bn.bias:lr=0.0006000000000000001\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.bn.bias:weight_decay=0.01\n",
      "03/05 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- decode_head.fusion_conv.bn.bias:lr_mult=10.0\n",
      "03/05 17:28:05 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "03/05 17:28:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\n",
      "03/05 17:28:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\" to /root/.cache/torch/hub/checkpoints/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/05 17:28:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.layers.0.0.projection.weight, backbone.layers.0.0.projection.bias, backbone.layers.0.0.norm.weight, backbone.layers.0.0.norm.bias, backbone.layers.0.1.0.norm1.weight, backbone.layers.0.1.0.norm1.bias, backbone.layers.0.1.0.attn.attn.in_proj_weight, backbone.layers.0.1.0.attn.attn.in_proj_bias, backbone.layers.0.1.0.attn.attn.out_proj.weight, backbone.layers.0.1.0.attn.attn.out_proj.bias, backbone.layers.0.1.0.attn.sr.weight, backbone.layers.0.1.0.attn.sr.bias, backbone.layers.0.1.0.attn.norm.weight, backbone.layers.0.1.0.attn.norm.bias, backbone.layers.0.1.0.norm2.weight, backbone.layers.0.1.0.norm2.bias, backbone.layers.0.1.0.ffn.layers.0.weight, backbone.layers.0.1.0.ffn.layers.0.bias, backbone.layers.0.1.0.ffn.layers.1.weight, backbone.layers.0.1.0.ffn.layers.1.bias, backbone.layers.0.1.0.ffn.layers.4.weight, backbone.layers.0.1.0.ffn.layers.4.bias, backbone.layers.0.1.1.norm1.weight, backbone.layers.0.1.1.norm1.bias, backbone.layers.0.1.1.attn.attn.in_proj_weight, backbone.layers.0.1.1.attn.attn.in_proj_bias, backbone.layers.0.1.1.attn.attn.out_proj.weight, backbone.layers.0.1.1.attn.attn.out_proj.bias, backbone.layers.0.1.1.attn.sr.weight, backbone.layers.0.1.1.attn.sr.bias, backbone.layers.0.1.1.attn.norm.weight, backbone.layers.0.1.1.attn.norm.bias, backbone.layers.0.1.1.norm2.weight, backbone.layers.0.1.1.norm2.bias, backbone.layers.0.1.1.ffn.layers.0.weight, backbone.layers.0.1.1.ffn.layers.0.bias, backbone.layers.0.1.1.ffn.layers.1.weight, backbone.layers.0.1.1.ffn.layers.1.bias, backbone.layers.0.1.1.ffn.layers.4.weight, backbone.layers.0.1.1.ffn.layers.4.bias, backbone.layers.0.1.2.norm1.weight, backbone.layers.0.1.2.norm1.bias, backbone.layers.0.1.2.attn.attn.in_proj_weight, backbone.layers.0.1.2.attn.attn.in_proj_bias, backbone.layers.0.1.2.attn.attn.out_proj.weight, backbone.layers.0.1.2.attn.attn.out_proj.bias, backbone.layers.0.1.2.attn.sr.weight, backbone.layers.0.1.2.attn.sr.bias, backbone.layers.0.1.2.attn.norm.weight, backbone.layers.0.1.2.attn.norm.bias, backbone.layers.0.1.2.norm2.weight, backbone.layers.0.1.2.norm2.bias, backbone.layers.0.1.2.ffn.layers.0.weight, backbone.layers.0.1.2.ffn.layers.0.bias, backbone.layers.0.1.2.ffn.layers.1.weight, backbone.layers.0.1.2.ffn.layers.1.bias, backbone.layers.0.1.2.ffn.layers.4.weight, backbone.layers.0.1.2.ffn.layers.4.bias, backbone.layers.0.2.weight, backbone.layers.0.2.bias, backbone.layers.1.0.projection.weight, backbone.layers.1.0.projection.bias, backbone.layers.1.0.norm.weight, backbone.layers.1.0.norm.bias, backbone.layers.1.1.0.norm1.weight, backbone.layers.1.1.0.norm1.bias, backbone.layers.1.1.0.attn.attn.in_proj_weight, backbone.layers.1.1.0.attn.attn.in_proj_bias, backbone.layers.1.1.0.attn.attn.out_proj.weight, backbone.layers.1.1.0.attn.attn.out_proj.bias, backbone.layers.1.1.0.attn.sr.weight, backbone.layers.1.1.0.attn.sr.bias, backbone.layers.1.1.0.attn.norm.weight, backbone.layers.1.1.0.attn.norm.bias, backbone.layers.1.1.0.norm2.weight, backbone.layers.1.1.0.norm2.bias, backbone.layers.1.1.0.ffn.layers.0.weight, backbone.layers.1.1.0.ffn.layers.0.bias, backbone.layers.1.1.0.ffn.layers.1.weight, backbone.layers.1.1.0.ffn.layers.1.bias, backbone.layers.1.1.0.ffn.layers.4.weight, backbone.layers.1.1.0.ffn.layers.4.bias, backbone.layers.1.1.1.norm1.weight, backbone.layers.1.1.1.norm1.bias, backbone.layers.1.1.1.attn.attn.in_proj_weight, backbone.layers.1.1.1.attn.attn.in_proj_bias, backbone.layers.1.1.1.attn.attn.out_proj.weight, backbone.layers.1.1.1.attn.attn.out_proj.bias, backbone.layers.1.1.1.attn.sr.weight, backbone.layers.1.1.1.attn.sr.bias, backbone.layers.1.1.1.attn.norm.weight, backbone.layers.1.1.1.attn.norm.bias, backbone.layers.1.1.1.norm2.weight, backbone.layers.1.1.1.norm2.bias, backbone.layers.1.1.1.ffn.layers.0.weight, backbone.layers.1.1.1.ffn.layers.0.bias, backbone.layers.1.1.1.ffn.layers.1.weight, backbone.layers.1.1.1.ffn.layers.1.bias, backbone.layers.1.1.1.ffn.layers.4.weight, backbone.layers.1.1.1.ffn.layers.4.bias, backbone.layers.1.1.2.norm1.weight, backbone.layers.1.1.2.norm1.bias, backbone.layers.1.1.2.attn.attn.in_proj_weight, backbone.layers.1.1.2.attn.attn.in_proj_bias, backbone.layers.1.1.2.attn.attn.out_proj.weight, backbone.layers.1.1.2.attn.attn.out_proj.bias, backbone.layers.1.1.2.attn.sr.weight, backbone.layers.1.1.2.attn.sr.bias, backbone.layers.1.1.2.attn.norm.weight, backbone.layers.1.1.2.attn.norm.bias, backbone.layers.1.1.2.norm2.weight, backbone.layers.1.1.2.norm2.bias, backbone.layers.1.1.2.ffn.layers.0.weight, backbone.layers.1.1.2.ffn.layers.0.bias, backbone.layers.1.1.2.ffn.layers.1.weight, backbone.layers.1.1.2.ffn.layers.1.bias, backbone.layers.1.1.2.ffn.layers.4.weight, backbone.layers.1.1.2.ffn.layers.4.bias, backbone.layers.1.1.3.norm1.weight, backbone.layers.1.1.3.norm1.bias, backbone.layers.1.1.3.attn.attn.in_proj_weight, backbone.layers.1.1.3.attn.attn.in_proj_bias, backbone.layers.1.1.3.attn.attn.out_proj.weight, backbone.layers.1.1.3.attn.attn.out_proj.bias, backbone.layers.1.1.3.attn.sr.weight, backbone.layers.1.1.3.attn.sr.bias, backbone.layers.1.1.3.attn.norm.weight, backbone.layers.1.1.3.attn.norm.bias, backbone.layers.1.1.3.norm2.weight, backbone.layers.1.1.3.norm2.bias, backbone.layers.1.1.3.ffn.layers.0.weight, backbone.layers.1.1.3.ffn.layers.0.bias, backbone.layers.1.1.3.ffn.layers.1.weight, backbone.layers.1.1.3.ffn.layers.1.bias, backbone.layers.1.1.3.ffn.layers.4.weight, backbone.layers.1.1.3.ffn.layers.4.bias, backbone.layers.1.1.4.norm1.weight, backbone.layers.1.1.4.norm1.bias, backbone.layers.1.1.4.attn.attn.in_proj_weight, backbone.layers.1.1.4.attn.attn.in_proj_bias, backbone.layers.1.1.4.attn.attn.out_proj.weight, backbone.layers.1.1.4.attn.attn.out_proj.bias, backbone.layers.1.1.4.attn.sr.weight, backbone.layers.1.1.4.attn.sr.bias, backbone.layers.1.1.4.attn.norm.weight, backbone.layers.1.1.4.attn.norm.bias, backbone.layers.1.1.4.norm2.weight, backbone.layers.1.1.4.norm2.bias, backbone.layers.1.1.4.ffn.layers.0.weight, backbone.layers.1.1.4.ffn.layers.0.bias, backbone.layers.1.1.4.ffn.layers.1.weight, backbone.layers.1.1.4.ffn.layers.1.bias, backbone.layers.1.1.4.ffn.layers.4.weight, backbone.layers.1.1.4.ffn.layers.4.bias, backbone.layers.1.1.5.norm1.weight, backbone.layers.1.1.5.norm1.bias, backbone.layers.1.1.5.attn.attn.in_proj_weight, backbone.layers.1.1.5.attn.attn.in_proj_bias, backbone.layers.1.1.5.attn.attn.out_proj.weight, backbone.layers.1.1.5.attn.attn.out_proj.bias, backbone.layers.1.1.5.attn.sr.weight, backbone.layers.1.1.5.attn.sr.bias, backbone.layers.1.1.5.attn.norm.weight, backbone.layers.1.1.5.attn.norm.bias, backbone.layers.1.1.5.norm2.weight, backbone.layers.1.1.5.norm2.bias, backbone.layers.1.1.5.ffn.layers.0.weight, backbone.layers.1.1.5.ffn.layers.0.bias, backbone.layers.1.1.5.ffn.layers.1.weight, backbone.layers.1.1.5.ffn.layers.1.bias, backbone.layers.1.1.5.ffn.layers.4.weight, backbone.layers.1.1.5.ffn.layers.4.bias, backbone.layers.1.1.6.norm1.weight, backbone.layers.1.1.6.norm1.bias, backbone.layers.1.1.6.attn.attn.in_proj_weight, backbone.layers.1.1.6.attn.attn.in_proj_bias, backbone.layers.1.1.6.attn.attn.out_proj.weight, backbone.layers.1.1.6.attn.attn.out_proj.bias, backbone.layers.1.1.6.attn.sr.weight, backbone.layers.1.1.6.attn.sr.bias, backbone.layers.1.1.6.attn.norm.weight, backbone.layers.1.1.6.attn.norm.bias, backbone.layers.1.1.6.norm2.weight, backbone.layers.1.1.6.norm2.bias, backbone.layers.1.1.6.ffn.layers.0.weight, backbone.layers.1.1.6.ffn.layers.0.bias, backbone.layers.1.1.6.ffn.layers.1.weight, backbone.layers.1.1.6.ffn.layers.1.bias, backbone.layers.1.1.6.ffn.layers.4.weight, backbone.layers.1.1.6.ffn.layers.4.bias, backbone.layers.1.1.7.norm1.weight, backbone.layers.1.1.7.norm1.bias, backbone.layers.1.1.7.attn.attn.in_proj_weight, backbone.layers.1.1.7.attn.attn.in_proj_bias, backbone.layers.1.1.7.attn.attn.out_proj.weight, backbone.layers.1.1.7.attn.attn.out_proj.bias, backbone.layers.1.1.7.attn.sr.weight, backbone.layers.1.1.7.attn.sr.bias, backbone.layers.1.1.7.attn.norm.weight, backbone.layers.1.1.7.attn.norm.bias, backbone.layers.1.1.7.norm2.weight, backbone.layers.1.1.7.norm2.bias, backbone.layers.1.1.7.ffn.layers.0.weight, backbone.layers.1.1.7.ffn.layers.0.bias, backbone.layers.1.1.7.ffn.layers.1.weight, backbone.layers.1.1.7.ffn.layers.1.bias, backbone.layers.1.1.7.ffn.layers.4.weight, backbone.layers.1.1.7.ffn.layers.4.bias, backbone.layers.1.2.weight, backbone.layers.1.2.bias, backbone.layers.2.0.projection.weight, backbone.layers.2.0.projection.bias, backbone.layers.2.0.norm.weight, backbone.layers.2.0.norm.bias, backbone.layers.2.1.0.norm1.weight, backbone.layers.2.1.0.norm1.bias, backbone.layers.2.1.0.attn.attn.in_proj_weight, backbone.layers.2.1.0.attn.attn.in_proj_bias, backbone.layers.2.1.0.attn.attn.out_proj.weight, backbone.layers.2.1.0.attn.attn.out_proj.bias, backbone.layers.2.1.0.attn.sr.weight, backbone.layers.2.1.0.attn.sr.bias, backbone.layers.2.1.0.attn.norm.weight, backbone.layers.2.1.0.attn.norm.bias, backbone.layers.2.1.0.norm2.weight, backbone.layers.2.1.0.norm2.bias, backbone.layers.2.1.0.ffn.layers.0.weight, backbone.layers.2.1.0.ffn.layers.0.bias, backbone.layers.2.1.0.ffn.layers.1.weight, backbone.layers.2.1.0.ffn.layers.1.bias, backbone.layers.2.1.0.ffn.layers.4.weight, backbone.layers.2.1.0.ffn.layers.4.bias, backbone.layers.2.1.1.norm1.weight, backbone.layers.2.1.1.norm1.bias, backbone.layers.2.1.1.attn.attn.in_proj_weight, backbone.layers.2.1.1.attn.attn.in_proj_bias, backbone.layers.2.1.1.attn.attn.out_proj.weight, backbone.layers.2.1.1.attn.attn.out_proj.bias, backbone.layers.2.1.1.attn.sr.weight, backbone.layers.2.1.1.attn.sr.bias, backbone.layers.2.1.1.attn.norm.weight, backbone.layers.2.1.1.attn.norm.bias, backbone.layers.2.1.1.norm2.weight, backbone.layers.2.1.1.norm2.bias, backbone.layers.2.1.1.ffn.layers.0.weight, backbone.layers.2.1.1.ffn.layers.0.bias, backbone.layers.2.1.1.ffn.layers.1.weight, backbone.layers.2.1.1.ffn.layers.1.bias, backbone.layers.2.1.1.ffn.layers.4.weight, backbone.layers.2.1.1.ffn.layers.4.bias, backbone.layers.2.1.2.norm1.weight, backbone.layers.2.1.2.norm1.bias, backbone.layers.2.1.2.attn.attn.in_proj_weight, backbone.layers.2.1.2.attn.attn.in_proj_bias, backbone.layers.2.1.2.attn.attn.out_proj.weight, backbone.layers.2.1.2.attn.attn.out_proj.bias, backbone.layers.2.1.2.attn.sr.weight, backbone.layers.2.1.2.attn.sr.bias, backbone.layers.2.1.2.attn.norm.weight, backbone.layers.2.1.2.attn.norm.bias, backbone.layers.2.1.2.norm2.weight, backbone.layers.2.1.2.norm2.bias, backbone.layers.2.1.2.ffn.layers.0.weight, backbone.layers.2.1.2.ffn.layers.0.bias, backbone.layers.2.1.2.ffn.layers.1.weight, backbone.layers.2.1.2.ffn.layers.1.bias, backbone.layers.2.1.2.ffn.layers.4.weight, backbone.layers.2.1.2.ffn.layers.4.bias, backbone.layers.2.1.3.norm1.weight, backbone.layers.2.1.3.norm1.bias, backbone.layers.2.1.3.attn.attn.in_proj_weight, backbone.layers.2.1.3.attn.attn.in_proj_bias, backbone.layers.2.1.3.attn.attn.out_proj.weight, backbone.layers.2.1.3.attn.attn.out_proj.bias, backbone.layers.2.1.3.attn.sr.weight, backbone.layers.2.1.3.attn.sr.bias, backbone.layers.2.1.3.attn.norm.weight, backbone.layers.2.1.3.attn.norm.bias, backbone.layers.2.1.3.norm2.weight, backbone.layers.2.1.3.norm2.bias, backbone.layers.2.1.3.ffn.layers.0.weight, backbone.layers.2.1.3.ffn.layers.0.bias, backbone.layers.2.1.3.ffn.layers.1.weight, backbone.layers.2.1.3.ffn.layers.1.bias, backbone.layers.2.1.3.ffn.layers.4.weight, backbone.layers.2.1.3.ffn.layers.4.bias, backbone.layers.2.1.4.norm1.weight, backbone.layers.2.1.4.norm1.bias, backbone.layers.2.1.4.attn.attn.in_proj_weight, backbone.layers.2.1.4.attn.attn.in_proj_bias, backbone.layers.2.1.4.attn.attn.out_proj.weight, backbone.layers.2.1.4.attn.attn.out_proj.bias, backbone.layers.2.1.4.attn.sr.weight, backbone.layers.2.1.4.attn.sr.bias, backbone.layers.2.1.4.attn.norm.weight, backbone.layers.2.1.4.attn.norm.bias, backbone.layers.2.1.4.norm2.weight, backbone.layers.2.1.4.norm2.bias, backbone.layers.2.1.4.ffn.layers.0.weight, backbone.layers.2.1.4.ffn.layers.0.bias, backbone.layers.2.1.4.ffn.layers.1.weight, backbone.layers.2.1.4.ffn.layers.1.bias, backbone.layers.2.1.4.ffn.layers.4.weight, backbone.layers.2.1.4.ffn.layers.4.bias, backbone.layers.2.1.5.norm1.weight, backbone.layers.2.1.5.norm1.bias, backbone.layers.2.1.5.attn.attn.in_proj_weight, backbone.layers.2.1.5.attn.attn.in_proj_bias, backbone.layers.2.1.5.attn.attn.out_proj.weight, backbone.layers.2.1.5.attn.attn.out_proj.bias, backbone.layers.2.1.5.attn.sr.weight, backbone.layers.2.1.5.attn.sr.bias, backbone.layers.2.1.5.attn.norm.weight, backbone.layers.2.1.5.attn.norm.bias, backbone.layers.2.1.5.norm2.weight, backbone.layers.2.1.5.norm2.bias, backbone.layers.2.1.5.ffn.layers.0.weight, backbone.layers.2.1.5.ffn.layers.0.bias, backbone.layers.2.1.5.ffn.layers.1.weight, backbone.layers.2.1.5.ffn.layers.1.bias, backbone.layers.2.1.5.ffn.layers.4.weight, backbone.layers.2.1.5.ffn.layers.4.bias, backbone.layers.2.1.6.norm1.weight, backbone.layers.2.1.6.norm1.bias, backbone.layers.2.1.6.attn.attn.in_proj_weight, backbone.layers.2.1.6.attn.attn.in_proj_bias, backbone.layers.2.1.6.attn.attn.out_proj.weight, backbone.layers.2.1.6.attn.attn.out_proj.bias, backbone.layers.2.1.6.attn.sr.weight, backbone.layers.2.1.6.attn.sr.bias, backbone.layers.2.1.6.attn.norm.weight, backbone.layers.2.1.6.attn.norm.bias, backbone.layers.2.1.6.norm2.weight, backbone.layers.2.1.6.norm2.bias, backbone.layers.2.1.6.ffn.layers.0.weight, backbone.layers.2.1.6.ffn.layers.0.bias, backbone.layers.2.1.6.ffn.layers.1.weight, backbone.layers.2.1.6.ffn.layers.1.bias, backbone.layers.2.1.6.ffn.layers.4.weight, backbone.layers.2.1.6.ffn.layers.4.bias, backbone.layers.2.1.7.norm1.weight, backbone.layers.2.1.7.norm1.bias, backbone.layers.2.1.7.attn.attn.in_proj_weight, backbone.layers.2.1.7.attn.attn.in_proj_bias, backbone.layers.2.1.7.attn.attn.out_proj.weight, backbone.layers.2.1.7.attn.attn.out_proj.bias, backbone.layers.2.1.7.attn.sr.weight, backbone.layers.2.1.7.attn.sr.bias, backbone.layers.2.1.7.attn.norm.weight, backbone.layers.2.1.7.attn.norm.bias, backbone.layers.2.1.7.norm2.weight, backbone.layers.2.1.7.norm2.bias, backbone.layers.2.1.7.ffn.layers.0.weight, backbone.layers.2.1.7.ffn.layers.0.bias, backbone.layers.2.1.7.ffn.layers.1.weight, backbone.layers.2.1.7.ffn.layers.1.bias, backbone.layers.2.1.7.ffn.layers.4.weight, backbone.layers.2.1.7.ffn.layers.4.bias, backbone.layers.2.1.8.norm1.weight, backbone.layers.2.1.8.norm1.bias, backbone.layers.2.1.8.attn.attn.in_proj_weight, backbone.layers.2.1.8.attn.attn.in_proj_bias, backbone.layers.2.1.8.attn.attn.out_proj.weight, backbone.layers.2.1.8.attn.attn.out_proj.bias, backbone.layers.2.1.8.attn.sr.weight, backbone.layers.2.1.8.attn.sr.bias, backbone.layers.2.1.8.attn.norm.weight, backbone.layers.2.1.8.attn.norm.bias, backbone.layers.2.1.8.norm2.weight, backbone.layers.2.1.8.norm2.bias, backbone.layers.2.1.8.ffn.layers.0.weight, backbone.layers.2.1.8.ffn.layers.0.bias, backbone.layers.2.1.8.ffn.layers.1.weight, backbone.layers.2.1.8.ffn.layers.1.bias, backbone.layers.2.1.8.ffn.layers.4.weight, backbone.layers.2.1.8.ffn.layers.4.bias, backbone.layers.2.1.9.norm1.weight, backbone.layers.2.1.9.norm1.bias, backbone.layers.2.1.9.attn.attn.in_proj_weight, backbone.layers.2.1.9.attn.attn.in_proj_bias, backbone.layers.2.1.9.attn.attn.out_proj.weight, backbone.layers.2.1.9.attn.attn.out_proj.bias, backbone.layers.2.1.9.attn.sr.weight, backbone.layers.2.1.9.attn.sr.bias, backbone.layers.2.1.9.attn.norm.weight, backbone.layers.2.1.9.attn.norm.bias, backbone.layers.2.1.9.norm2.weight, backbone.layers.2.1.9.norm2.bias, backbone.layers.2.1.9.ffn.layers.0.weight, backbone.layers.2.1.9.ffn.layers.0.bias, backbone.layers.2.1.9.ffn.layers.1.weight, backbone.layers.2.1.9.ffn.layers.1.bias, backbone.layers.2.1.9.ffn.layers.4.weight, backbone.layers.2.1.9.ffn.layers.4.bias, backbone.layers.2.1.10.norm1.weight, backbone.layers.2.1.10.norm1.bias, backbone.layers.2.1.10.attn.attn.in_proj_weight, backbone.layers.2.1.10.attn.attn.in_proj_bias, backbone.layers.2.1.10.attn.attn.out_proj.weight, backbone.layers.2.1.10.attn.attn.out_proj.bias, backbone.layers.2.1.10.attn.sr.weight, backbone.layers.2.1.10.attn.sr.bias, backbone.layers.2.1.10.attn.norm.weight, backbone.layers.2.1.10.attn.norm.bias, backbone.layers.2.1.10.norm2.weight, backbone.layers.2.1.10.norm2.bias, backbone.layers.2.1.10.ffn.layers.0.weight, backbone.layers.2.1.10.ffn.layers.0.bias, backbone.layers.2.1.10.ffn.layers.1.weight, backbone.layers.2.1.10.ffn.layers.1.bias, backbone.layers.2.1.10.ffn.layers.4.weight, backbone.layers.2.1.10.ffn.layers.4.bias, backbone.layers.2.1.11.norm1.weight, backbone.layers.2.1.11.norm1.bias, backbone.layers.2.1.11.attn.attn.in_proj_weight, backbone.layers.2.1.11.attn.attn.in_proj_bias, backbone.layers.2.1.11.attn.attn.out_proj.weight, backbone.layers.2.1.11.attn.attn.out_proj.bias, backbone.layers.2.1.11.attn.sr.weight, backbone.layers.2.1.11.attn.sr.bias, backbone.layers.2.1.11.attn.norm.weight, backbone.layers.2.1.11.attn.norm.bias, backbone.layers.2.1.11.norm2.weight, backbone.layers.2.1.11.norm2.bias, backbone.layers.2.1.11.ffn.layers.0.weight, backbone.layers.2.1.11.ffn.layers.0.bias, backbone.layers.2.1.11.ffn.layers.1.weight, backbone.layers.2.1.11.ffn.layers.1.bias, backbone.layers.2.1.11.ffn.layers.4.weight, backbone.layers.2.1.11.ffn.layers.4.bias, backbone.layers.2.1.12.norm1.weight, backbone.layers.2.1.12.norm1.bias, backbone.layers.2.1.12.attn.attn.in_proj_weight, backbone.layers.2.1.12.attn.attn.in_proj_bias, backbone.layers.2.1.12.attn.attn.out_proj.weight, backbone.layers.2.1.12.attn.attn.out_proj.bias, backbone.layers.2.1.12.attn.sr.weight, backbone.layers.2.1.12.attn.sr.bias, backbone.layers.2.1.12.attn.norm.weight, backbone.layers.2.1.12.attn.norm.bias, backbone.layers.2.1.12.norm2.weight, backbone.layers.2.1.12.norm2.bias, backbone.layers.2.1.12.ffn.layers.0.weight, backbone.layers.2.1.12.ffn.layers.0.bias, backbone.layers.2.1.12.ffn.layers.1.weight, backbone.layers.2.1.12.ffn.layers.1.bias, backbone.layers.2.1.12.ffn.layers.4.weight, backbone.layers.2.1.12.ffn.layers.4.bias, backbone.layers.2.1.13.norm1.weight, backbone.layers.2.1.13.norm1.bias, backbone.layers.2.1.13.attn.attn.in_proj_weight, backbone.layers.2.1.13.attn.attn.in_proj_bias, backbone.layers.2.1.13.attn.attn.out_proj.weight, backbone.layers.2.1.13.attn.attn.out_proj.bias, backbone.layers.2.1.13.attn.sr.weight, backbone.layers.2.1.13.attn.sr.bias, backbone.layers.2.1.13.attn.norm.weight, backbone.layers.2.1.13.attn.norm.bias, backbone.layers.2.1.13.norm2.weight, backbone.layers.2.1.13.norm2.bias, backbone.layers.2.1.13.ffn.layers.0.weight, backbone.layers.2.1.13.ffn.layers.0.bias, backbone.layers.2.1.13.ffn.layers.1.weight, backbone.layers.2.1.13.ffn.layers.1.bias, backbone.layers.2.1.13.ffn.layers.4.weight, backbone.layers.2.1.13.ffn.layers.4.bias, backbone.layers.2.1.14.norm1.weight, backbone.layers.2.1.14.norm1.bias, backbone.layers.2.1.14.attn.attn.in_proj_weight, backbone.layers.2.1.14.attn.attn.in_proj_bias, backbone.layers.2.1.14.attn.attn.out_proj.weight, backbone.layers.2.1.14.attn.attn.out_proj.bias, backbone.layers.2.1.14.attn.sr.weight, backbone.layers.2.1.14.attn.sr.bias, backbone.layers.2.1.14.attn.norm.weight, backbone.layers.2.1.14.attn.norm.bias, backbone.layers.2.1.14.norm2.weight, backbone.layers.2.1.14.norm2.bias, backbone.layers.2.1.14.ffn.layers.0.weight, backbone.layers.2.1.14.ffn.layers.0.bias, backbone.layers.2.1.14.ffn.layers.1.weight, backbone.layers.2.1.14.ffn.layers.1.bias, backbone.layers.2.1.14.ffn.layers.4.weight, backbone.layers.2.1.14.ffn.layers.4.bias, backbone.layers.2.1.15.norm1.weight, backbone.layers.2.1.15.norm1.bias, backbone.layers.2.1.15.attn.attn.in_proj_weight, backbone.layers.2.1.15.attn.attn.in_proj_bias, backbone.layers.2.1.15.attn.attn.out_proj.weight, backbone.layers.2.1.15.attn.attn.out_proj.bias, backbone.layers.2.1.15.attn.sr.weight, backbone.layers.2.1.15.attn.sr.bias, backbone.layers.2.1.15.attn.norm.weight, backbone.layers.2.1.15.attn.norm.bias, backbone.layers.2.1.15.norm2.weight, backbone.layers.2.1.15.norm2.bias, backbone.layers.2.1.15.ffn.layers.0.weight, backbone.layers.2.1.15.ffn.layers.0.bias, backbone.layers.2.1.15.ffn.layers.1.weight, backbone.layers.2.1.15.ffn.layers.1.bias, backbone.layers.2.1.15.ffn.layers.4.weight, backbone.layers.2.1.15.ffn.layers.4.bias, backbone.layers.2.1.16.norm1.weight, backbone.layers.2.1.16.norm1.bias, backbone.layers.2.1.16.attn.attn.in_proj_weight, backbone.layers.2.1.16.attn.attn.in_proj_bias, backbone.layers.2.1.16.attn.attn.out_proj.weight, backbone.layers.2.1.16.attn.attn.out_proj.bias, backbone.layers.2.1.16.attn.sr.weight, backbone.layers.2.1.16.attn.sr.bias, backbone.layers.2.1.16.attn.norm.weight, backbone.layers.2.1.16.attn.norm.bias, backbone.layers.2.1.16.norm2.weight, backbone.layers.2.1.16.norm2.bias, backbone.layers.2.1.16.ffn.layers.0.weight, backbone.layers.2.1.16.ffn.layers.0.bias, backbone.layers.2.1.16.ffn.layers.1.weight, backbone.layers.2.1.16.ffn.layers.1.bias, backbone.layers.2.1.16.ffn.layers.4.weight, backbone.layers.2.1.16.ffn.layers.4.bias, backbone.layers.2.1.17.norm1.weight, backbone.layers.2.1.17.norm1.bias, backbone.layers.2.1.17.attn.attn.in_proj_weight, backbone.layers.2.1.17.attn.attn.in_proj_bias, backbone.layers.2.1.17.attn.attn.out_proj.weight, backbone.layers.2.1.17.attn.attn.out_proj.bias, backbone.layers.2.1.17.attn.sr.weight, backbone.layers.2.1.17.attn.sr.bias, backbone.layers.2.1.17.attn.norm.weight, backbone.layers.2.1.17.attn.norm.bias, backbone.layers.2.1.17.norm2.weight, backbone.layers.2.1.17.norm2.bias, backbone.layers.2.1.17.ffn.layers.0.weight, backbone.layers.2.1.17.ffn.layers.0.bias, backbone.layers.2.1.17.ffn.layers.1.weight, backbone.layers.2.1.17.ffn.layers.1.bias, backbone.layers.2.1.17.ffn.layers.4.weight, backbone.layers.2.1.17.ffn.layers.4.bias, backbone.layers.2.1.18.norm1.weight, backbone.layers.2.1.18.norm1.bias, backbone.layers.2.1.18.attn.attn.in_proj_weight, backbone.layers.2.1.18.attn.attn.in_proj_bias, backbone.layers.2.1.18.attn.attn.out_proj.weight, backbone.layers.2.1.18.attn.attn.out_proj.bias, backbone.layers.2.1.18.attn.sr.weight, backbone.layers.2.1.18.attn.sr.bias, backbone.layers.2.1.18.attn.norm.weight, backbone.layers.2.1.18.attn.norm.bias, backbone.layers.2.1.18.norm2.weight, backbone.layers.2.1.18.norm2.bias, backbone.layers.2.1.18.ffn.layers.0.weight, backbone.layers.2.1.18.ffn.layers.0.bias, backbone.layers.2.1.18.ffn.layers.1.weight, backbone.layers.2.1.18.ffn.layers.1.bias, backbone.layers.2.1.18.ffn.layers.4.weight, backbone.layers.2.1.18.ffn.layers.4.bias, backbone.layers.2.1.19.norm1.weight, backbone.layers.2.1.19.norm1.bias, backbone.layers.2.1.19.attn.attn.in_proj_weight, backbone.layers.2.1.19.attn.attn.in_proj_bias, backbone.layers.2.1.19.attn.attn.out_proj.weight, backbone.layers.2.1.19.attn.attn.out_proj.bias, backbone.layers.2.1.19.attn.sr.weight, backbone.layers.2.1.19.attn.sr.bias, backbone.layers.2.1.19.attn.norm.weight, backbone.layers.2.1.19.attn.norm.bias, backbone.layers.2.1.19.norm2.weight, backbone.layers.2.1.19.norm2.bias, backbone.layers.2.1.19.ffn.layers.0.weight, backbone.layers.2.1.19.ffn.layers.0.bias, backbone.layers.2.1.19.ffn.layers.1.weight, backbone.layers.2.1.19.ffn.layers.1.bias, backbone.layers.2.1.19.ffn.layers.4.weight, backbone.layers.2.1.19.ffn.layers.4.bias, backbone.layers.2.1.20.norm1.weight, backbone.layers.2.1.20.norm1.bias, backbone.layers.2.1.20.attn.attn.in_proj_weight, backbone.layers.2.1.20.attn.attn.in_proj_bias, backbone.layers.2.1.20.attn.attn.out_proj.weight, backbone.layers.2.1.20.attn.attn.out_proj.bias, backbone.layers.2.1.20.attn.sr.weight, backbone.layers.2.1.20.attn.sr.bias, backbone.layers.2.1.20.attn.norm.weight, backbone.layers.2.1.20.attn.norm.bias, backbone.layers.2.1.20.norm2.weight, backbone.layers.2.1.20.norm2.bias, backbone.layers.2.1.20.ffn.layers.0.weight, backbone.layers.2.1.20.ffn.layers.0.bias, backbone.layers.2.1.20.ffn.layers.1.weight, backbone.layers.2.1.20.ffn.layers.1.bias, backbone.layers.2.1.20.ffn.layers.4.weight, backbone.layers.2.1.20.ffn.layers.4.bias, backbone.layers.2.1.21.norm1.weight, backbone.layers.2.1.21.norm1.bias, backbone.layers.2.1.21.attn.attn.in_proj_weight, backbone.layers.2.1.21.attn.attn.in_proj_bias, backbone.layers.2.1.21.attn.attn.out_proj.weight, backbone.layers.2.1.21.attn.attn.out_proj.bias, backbone.layers.2.1.21.attn.sr.weight, backbone.layers.2.1.21.attn.sr.bias, backbone.layers.2.1.21.attn.norm.weight, backbone.layers.2.1.21.attn.norm.bias, backbone.layers.2.1.21.norm2.weight, backbone.layers.2.1.21.norm2.bias, backbone.layers.2.1.21.ffn.layers.0.weight, backbone.layers.2.1.21.ffn.layers.0.bias, backbone.layers.2.1.21.ffn.layers.1.weight, backbone.layers.2.1.21.ffn.layers.1.bias, backbone.layers.2.1.21.ffn.layers.4.weight, backbone.layers.2.1.21.ffn.layers.4.bias, backbone.layers.2.1.22.norm1.weight, backbone.layers.2.1.22.norm1.bias, backbone.layers.2.1.22.attn.attn.in_proj_weight, backbone.layers.2.1.22.attn.attn.in_proj_bias, backbone.layers.2.1.22.attn.attn.out_proj.weight, backbone.layers.2.1.22.attn.attn.out_proj.bias, backbone.layers.2.1.22.attn.sr.weight, backbone.layers.2.1.22.attn.sr.bias, backbone.layers.2.1.22.attn.norm.weight, backbone.layers.2.1.22.attn.norm.bias, backbone.layers.2.1.22.norm2.weight, backbone.layers.2.1.22.norm2.bias, backbone.layers.2.1.22.ffn.layers.0.weight, backbone.layers.2.1.22.ffn.layers.0.bias, backbone.layers.2.1.22.ffn.layers.1.weight, backbone.layers.2.1.22.ffn.layers.1.bias, backbone.layers.2.1.22.ffn.layers.4.weight, backbone.layers.2.1.22.ffn.layers.4.bias, backbone.layers.2.1.23.norm1.weight, backbone.layers.2.1.23.norm1.bias, backbone.layers.2.1.23.attn.attn.in_proj_weight, backbone.layers.2.1.23.attn.attn.in_proj_bias, backbone.layers.2.1.23.attn.attn.out_proj.weight, backbone.layers.2.1.23.attn.attn.out_proj.bias, backbone.layers.2.1.23.attn.sr.weight, backbone.layers.2.1.23.attn.sr.bias, backbone.layers.2.1.23.attn.norm.weight, backbone.layers.2.1.23.attn.norm.bias, backbone.layers.2.1.23.norm2.weight, backbone.layers.2.1.23.norm2.bias, backbone.layers.2.1.23.ffn.layers.0.weight, backbone.layers.2.1.23.ffn.layers.0.bias, backbone.layers.2.1.23.ffn.layers.1.weight, backbone.layers.2.1.23.ffn.layers.1.bias, backbone.layers.2.1.23.ffn.layers.4.weight, backbone.layers.2.1.23.ffn.layers.4.bias, backbone.layers.2.1.24.norm1.weight, backbone.layers.2.1.24.norm1.bias, backbone.layers.2.1.24.attn.attn.in_proj_weight, backbone.layers.2.1.24.attn.attn.in_proj_bias, backbone.layers.2.1.24.attn.attn.out_proj.weight, backbone.layers.2.1.24.attn.attn.out_proj.bias, backbone.layers.2.1.24.attn.sr.weight, backbone.layers.2.1.24.attn.sr.bias, backbone.layers.2.1.24.attn.norm.weight, backbone.layers.2.1.24.attn.norm.bias, backbone.layers.2.1.24.norm2.weight, backbone.layers.2.1.24.norm2.bias, backbone.layers.2.1.24.ffn.layers.0.weight, backbone.layers.2.1.24.ffn.layers.0.bias, backbone.layers.2.1.24.ffn.layers.1.weight, backbone.layers.2.1.24.ffn.layers.1.bias, backbone.layers.2.1.24.ffn.layers.4.weight, backbone.layers.2.1.24.ffn.layers.4.bias, backbone.layers.2.1.25.norm1.weight, backbone.layers.2.1.25.norm1.bias, backbone.layers.2.1.25.attn.attn.in_proj_weight, backbone.layers.2.1.25.attn.attn.in_proj_bias, backbone.layers.2.1.25.attn.attn.out_proj.weight, backbone.layers.2.1.25.attn.attn.out_proj.bias, backbone.layers.2.1.25.attn.sr.weight, backbone.layers.2.1.25.attn.sr.bias, backbone.layers.2.1.25.attn.norm.weight, backbone.layers.2.1.25.attn.norm.bias, backbone.layers.2.1.25.norm2.weight, backbone.layers.2.1.25.norm2.bias, backbone.layers.2.1.25.ffn.layers.0.weight, backbone.layers.2.1.25.ffn.layers.0.bias, backbone.layers.2.1.25.ffn.layers.1.weight, backbone.layers.2.1.25.ffn.layers.1.bias, backbone.layers.2.1.25.ffn.layers.4.weight, backbone.layers.2.1.25.ffn.layers.4.bias, backbone.layers.2.1.26.norm1.weight, backbone.layers.2.1.26.norm1.bias, backbone.layers.2.1.26.attn.attn.in_proj_weight, backbone.layers.2.1.26.attn.attn.in_proj_bias, backbone.layers.2.1.26.attn.attn.out_proj.weight, backbone.layers.2.1.26.attn.attn.out_proj.bias, backbone.layers.2.1.26.attn.sr.weight, backbone.layers.2.1.26.attn.sr.bias, backbone.layers.2.1.26.attn.norm.weight, backbone.layers.2.1.26.attn.norm.bias, backbone.layers.2.1.26.norm2.weight, backbone.layers.2.1.26.norm2.bias, backbone.layers.2.1.26.ffn.layers.0.weight, backbone.layers.2.1.26.ffn.layers.0.bias, backbone.layers.2.1.26.ffn.layers.1.weight, backbone.layers.2.1.26.ffn.layers.1.bias, backbone.layers.2.1.26.ffn.layers.4.weight, backbone.layers.2.1.26.ffn.layers.4.bias, backbone.layers.2.2.weight, backbone.layers.2.2.bias, backbone.layers.3.0.projection.weight, backbone.layers.3.0.projection.bias, backbone.layers.3.0.norm.weight, backbone.layers.3.0.norm.bias, backbone.layers.3.1.0.norm1.weight, backbone.layers.3.1.0.norm1.bias, backbone.layers.3.1.0.attn.attn.in_proj_weight, backbone.layers.3.1.0.attn.attn.in_proj_bias, backbone.layers.3.1.0.attn.attn.out_proj.weight, backbone.layers.3.1.0.attn.attn.out_proj.bias, backbone.layers.3.1.0.norm2.weight, backbone.layers.3.1.0.norm2.bias, backbone.layers.3.1.0.ffn.layers.0.weight, backbone.layers.3.1.0.ffn.layers.0.bias, backbone.layers.3.1.0.ffn.layers.1.weight, backbone.layers.3.1.0.ffn.layers.1.bias, backbone.layers.3.1.0.ffn.layers.4.weight, backbone.layers.3.1.0.ffn.layers.4.bias, backbone.layers.3.1.1.norm1.weight, backbone.layers.3.1.1.norm1.bias, backbone.layers.3.1.1.attn.attn.in_proj_weight, backbone.layers.3.1.1.attn.attn.in_proj_bias, backbone.layers.3.1.1.attn.attn.out_proj.weight, backbone.layers.3.1.1.attn.attn.out_proj.bias, backbone.layers.3.1.1.norm2.weight, backbone.layers.3.1.1.norm2.bias, backbone.layers.3.1.1.ffn.layers.0.weight, backbone.layers.3.1.1.ffn.layers.0.bias, backbone.layers.3.1.1.ffn.layers.1.weight, backbone.layers.3.1.1.ffn.layers.1.bias, backbone.layers.3.1.1.ffn.layers.4.weight, backbone.layers.3.1.1.ffn.layers.4.bias, backbone.layers.3.1.2.norm1.weight, backbone.layers.3.1.2.norm1.bias, backbone.layers.3.1.2.attn.attn.in_proj_weight, backbone.layers.3.1.2.attn.attn.in_proj_bias, backbone.layers.3.1.2.attn.attn.out_proj.weight, backbone.layers.3.1.2.attn.attn.out_proj.bias, backbone.layers.3.1.2.norm2.weight, backbone.layers.3.1.2.norm2.bias, backbone.layers.3.1.2.ffn.layers.0.weight, backbone.layers.3.1.2.ffn.layers.0.bias, backbone.layers.3.1.2.ffn.layers.1.weight, backbone.layers.3.1.2.ffn.layers.1.bias, backbone.layers.3.1.2.ffn.layers.4.weight, backbone.layers.3.1.2.ffn.layers.4.bias, backbone.layers.3.2.weight, backbone.layers.3.2.bias, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.convs.0.conv.weight, decode_head.convs.0.bn.weight, decode_head.convs.0.bn.bias, decode_head.convs.0.bn.running_mean, decode_head.convs.0.bn.running_var, decode_head.convs.0.bn.num_batches_tracked, decode_head.convs.1.conv.weight, decode_head.convs.1.bn.weight, decode_head.convs.1.bn.bias, decode_head.convs.1.bn.running_mean, decode_head.convs.1.bn.running_var, decode_head.convs.1.bn.num_batches_tracked, decode_head.convs.2.conv.weight, decode_head.convs.2.bn.weight, decode_head.convs.2.bn.bias, decode_head.convs.2.bn.running_mean, decode_head.convs.2.bn.running_var, decode_head.convs.2.bn.num_batches_tracked, decode_head.convs.3.conv.weight, decode_head.convs.3.bn.weight, decode_head.convs.3.bn.bias, decode_head.convs.3.bn.running_mean, decode_head.convs.3.bn.running_var, decode_head.convs.3.bn.num_batches_tracked, decode_head.fusion_conv.conv.weight, decode_head.fusion_conv.bn.weight, decode_head.fusion_conv.bn.bias, decode_head.fusion_conv.bn.running_mean, decode_head.fusion_conv.bn.running_var, decode_head.fusion_conv.bn.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: layers.0.0.projection.weight, layers.0.0.projection.bias, layers.0.0.norm.weight, layers.0.0.norm.bias, layers.0.1.0.norm1.weight, layers.0.1.0.norm1.bias, layers.0.1.0.attn.attn.in_proj_weight, layers.0.1.0.attn.attn.in_proj_bias, layers.0.1.0.attn.attn.out_proj.weight, layers.0.1.0.attn.attn.out_proj.bias, layers.0.1.0.attn.sr.weight, layers.0.1.0.attn.sr.bias, layers.0.1.0.attn.norm.weight, layers.0.1.0.attn.norm.bias, layers.0.1.0.norm2.weight, layers.0.1.0.norm2.bias, layers.0.1.0.ffn.layers.0.weight, layers.0.1.0.ffn.layers.0.bias, layers.0.1.0.ffn.layers.1.weight, layers.0.1.0.ffn.layers.1.bias, layers.0.1.0.ffn.layers.4.weight, layers.0.1.0.ffn.layers.4.bias, layers.0.1.1.norm1.weight, layers.0.1.1.norm1.bias, layers.0.1.1.attn.attn.in_proj_weight, layers.0.1.1.attn.attn.in_proj_bias, layers.0.1.1.attn.attn.out_proj.weight, layers.0.1.1.attn.attn.out_proj.bias, layers.0.1.1.attn.sr.weight, layers.0.1.1.attn.sr.bias, layers.0.1.1.attn.norm.weight, layers.0.1.1.attn.norm.bias, layers.0.1.1.norm2.weight, layers.0.1.1.norm2.bias, layers.0.1.1.ffn.layers.0.weight, layers.0.1.1.ffn.layers.0.bias, layers.0.1.1.ffn.layers.1.weight, layers.0.1.1.ffn.layers.1.bias, layers.0.1.1.ffn.layers.4.weight, layers.0.1.1.ffn.layers.4.bias, layers.0.1.2.norm1.weight, layers.0.1.2.norm1.bias, layers.0.1.2.attn.attn.in_proj_weight, layers.0.1.2.attn.attn.in_proj_bias, layers.0.1.2.attn.attn.out_proj.weight, layers.0.1.2.attn.attn.out_proj.bias, layers.0.1.2.attn.sr.weight, layers.0.1.2.attn.sr.bias, layers.0.1.2.attn.norm.weight, layers.0.1.2.attn.norm.bias, layers.0.1.2.norm2.weight, layers.0.1.2.norm2.bias, layers.0.1.2.ffn.layers.0.weight, layers.0.1.2.ffn.layers.0.bias, layers.0.1.2.ffn.layers.1.weight, layers.0.1.2.ffn.layers.1.bias, layers.0.1.2.ffn.layers.4.weight, layers.0.1.2.ffn.layers.4.bias, layers.0.2.weight, layers.0.2.bias, layers.1.0.projection.weight, layers.1.0.projection.bias, layers.1.0.norm.weight, layers.1.0.norm.bias, layers.1.1.0.norm1.weight, layers.1.1.0.norm1.bias, layers.1.1.0.attn.attn.in_proj_weight, layers.1.1.0.attn.attn.in_proj_bias, layers.1.1.0.attn.attn.out_proj.weight, layers.1.1.0.attn.attn.out_proj.bias, layers.1.1.0.attn.sr.weight, layers.1.1.0.attn.sr.bias, layers.1.1.0.attn.norm.weight, layers.1.1.0.attn.norm.bias, layers.1.1.0.norm2.weight, layers.1.1.0.norm2.bias, layers.1.1.0.ffn.layers.0.weight, layers.1.1.0.ffn.layers.0.bias, layers.1.1.0.ffn.layers.1.weight, layers.1.1.0.ffn.layers.1.bias, layers.1.1.0.ffn.layers.4.weight, layers.1.1.0.ffn.layers.4.bias, layers.1.1.1.norm1.weight, layers.1.1.1.norm1.bias, layers.1.1.1.attn.attn.in_proj_weight, layers.1.1.1.attn.attn.in_proj_bias, layers.1.1.1.attn.attn.out_proj.weight, layers.1.1.1.attn.attn.out_proj.bias, layers.1.1.1.attn.sr.weight, layers.1.1.1.attn.sr.bias, layers.1.1.1.attn.norm.weight, layers.1.1.1.attn.norm.bias, layers.1.1.1.norm2.weight, layers.1.1.1.norm2.bias, layers.1.1.1.ffn.layers.0.weight, layers.1.1.1.ffn.layers.0.bias, layers.1.1.1.ffn.layers.1.weight, layers.1.1.1.ffn.layers.1.bias, layers.1.1.1.ffn.layers.4.weight, layers.1.1.1.ffn.layers.4.bias, layers.1.1.2.norm1.weight, layers.1.1.2.norm1.bias, layers.1.1.2.attn.attn.in_proj_weight, layers.1.1.2.attn.attn.in_proj_bias, layers.1.1.2.attn.attn.out_proj.weight, layers.1.1.2.attn.attn.out_proj.bias, layers.1.1.2.attn.sr.weight, layers.1.1.2.attn.sr.bias, layers.1.1.2.attn.norm.weight, layers.1.1.2.attn.norm.bias, layers.1.1.2.norm2.weight, layers.1.1.2.norm2.bias, layers.1.1.2.ffn.layers.0.weight, layers.1.1.2.ffn.layers.0.bias, layers.1.1.2.ffn.layers.1.weight, layers.1.1.2.ffn.layers.1.bias, layers.1.1.2.ffn.layers.4.weight, layers.1.1.2.ffn.layers.4.bias, layers.1.1.3.norm1.weight, layers.1.1.3.norm1.bias, layers.1.1.3.attn.attn.in_proj_weight, layers.1.1.3.attn.attn.in_proj_bias, layers.1.1.3.attn.attn.out_proj.weight, layers.1.1.3.attn.attn.out_proj.bias, layers.1.1.3.attn.sr.weight, layers.1.1.3.attn.sr.bias, layers.1.1.3.attn.norm.weight, layers.1.1.3.attn.norm.bias, layers.1.1.3.norm2.weight, layers.1.1.3.norm2.bias, layers.1.1.3.ffn.layers.0.weight, layers.1.1.3.ffn.layers.0.bias, layers.1.1.3.ffn.layers.1.weight, layers.1.1.3.ffn.layers.1.bias, layers.1.1.3.ffn.layers.4.weight, layers.1.1.3.ffn.layers.4.bias, layers.1.1.4.norm1.weight, layers.1.1.4.norm1.bias, layers.1.1.4.attn.attn.in_proj_weight, layers.1.1.4.attn.attn.in_proj_bias, layers.1.1.4.attn.attn.out_proj.weight, layers.1.1.4.attn.attn.out_proj.bias, layers.1.1.4.attn.sr.weight, layers.1.1.4.attn.sr.bias, layers.1.1.4.attn.norm.weight, layers.1.1.4.attn.norm.bias, layers.1.1.4.norm2.weight, layers.1.1.4.norm2.bias, layers.1.1.4.ffn.layers.0.weight, layers.1.1.4.ffn.layers.0.bias, layers.1.1.4.ffn.layers.1.weight, layers.1.1.4.ffn.layers.1.bias, layers.1.1.4.ffn.layers.4.weight, layers.1.1.4.ffn.layers.4.bias, layers.1.1.5.norm1.weight, layers.1.1.5.norm1.bias, layers.1.1.5.attn.attn.in_proj_weight, layers.1.1.5.attn.attn.in_proj_bias, layers.1.1.5.attn.attn.out_proj.weight, layers.1.1.5.attn.attn.out_proj.bias, layers.1.1.5.attn.sr.weight, layers.1.1.5.attn.sr.bias, layers.1.1.5.attn.norm.weight, layers.1.1.5.attn.norm.bias, layers.1.1.5.norm2.weight, layers.1.1.5.norm2.bias, layers.1.1.5.ffn.layers.0.weight, layers.1.1.5.ffn.layers.0.bias, layers.1.1.5.ffn.layers.1.weight, layers.1.1.5.ffn.layers.1.bias, layers.1.1.5.ffn.layers.4.weight, layers.1.1.5.ffn.layers.4.bias, layers.1.2.weight, layers.1.2.bias, layers.2.0.projection.weight, layers.2.0.projection.bias, layers.2.0.norm.weight, layers.2.0.norm.bias, layers.2.1.0.norm1.weight, layers.2.1.0.norm1.bias, layers.2.1.0.attn.attn.in_proj_weight, layers.2.1.0.attn.attn.in_proj_bias, layers.2.1.0.attn.attn.out_proj.weight, layers.2.1.0.attn.attn.out_proj.bias, layers.2.1.0.attn.sr.weight, layers.2.1.0.attn.sr.bias, layers.2.1.0.attn.norm.weight, layers.2.1.0.attn.norm.bias, layers.2.1.0.norm2.weight, layers.2.1.0.norm2.bias, layers.2.1.0.ffn.layers.0.weight, layers.2.1.0.ffn.layers.0.bias, layers.2.1.0.ffn.layers.1.weight, layers.2.1.0.ffn.layers.1.bias, layers.2.1.0.ffn.layers.4.weight, layers.2.1.0.ffn.layers.4.bias, layers.2.1.1.norm1.weight, layers.2.1.1.norm1.bias, layers.2.1.1.attn.attn.in_proj_weight, layers.2.1.1.attn.attn.in_proj_bias, layers.2.1.1.attn.attn.out_proj.weight, layers.2.1.1.attn.attn.out_proj.bias, layers.2.1.1.attn.sr.weight, layers.2.1.1.attn.sr.bias, layers.2.1.1.attn.norm.weight, layers.2.1.1.attn.norm.bias, layers.2.1.1.norm2.weight, layers.2.1.1.norm2.bias, layers.2.1.1.ffn.layers.0.weight, layers.2.1.1.ffn.layers.0.bias, layers.2.1.1.ffn.layers.1.weight, layers.2.1.1.ffn.layers.1.bias, layers.2.1.1.ffn.layers.4.weight, layers.2.1.1.ffn.layers.4.bias, layers.2.1.2.norm1.weight, layers.2.1.2.norm1.bias, layers.2.1.2.attn.attn.in_proj_weight, layers.2.1.2.attn.attn.in_proj_bias, layers.2.1.2.attn.attn.out_proj.weight, layers.2.1.2.attn.attn.out_proj.bias, layers.2.1.2.attn.sr.weight, layers.2.1.2.attn.sr.bias, layers.2.1.2.attn.norm.weight, layers.2.1.2.attn.norm.bias, layers.2.1.2.norm2.weight, layers.2.1.2.norm2.bias, layers.2.1.2.ffn.layers.0.weight, layers.2.1.2.ffn.layers.0.bias, layers.2.1.2.ffn.layers.1.weight, layers.2.1.2.ffn.layers.1.bias, layers.2.1.2.ffn.layers.4.weight, layers.2.1.2.ffn.layers.4.bias, layers.2.1.3.norm1.weight, layers.2.1.3.norm1.bias, layers.2.1.3.attn.attn.in_proj_weight, layers.2.1.3.attn.attn.in_proj_bias, layers.2.1.3.attn.attn.out_proj.weight, layers.2.1.3.attn.attn.out_proj.bias, layers.2.1.3.attn.sr.weight, layers.2.1.3.attn.sr.bias, layers.2.1.3.attn.norm.weight, layers.2.1.3.attn.norm.bias, layers.2.1.3.norm2.weight, layers.2.1.3.norm2.bias, layers.2.1.3.ffn.layers.0.weight, layers.2.1.3.ffn.layers.0.bias, layers.2.1.3.ffn.layers.1.weight, layers.2.1.3.ffn.layers.1.bias, layers.2.1.3.ffn.layers.4.weight, layers.2.1.3.ffn.layers.4.bias, layers.2.1.4.norm1.weight, layers.2.1.4.norm1.bias, layers.2.1.4.attn.attn.in_proj_weight, layers.2.1.4.attn.attn.in_proj_bias, layers.2.1.4.attn.attn.out_proj.weight, layers.2.1.4.attn.attn.out_proj.bias, layers.2.1.4.attn.sr.weight, layers.2.1.4.attn.sr.bias, layers.2.1.4.attn.norm.weight, layers.2.1.4.attn.norm.bias, layers.2.1.4.norm2.weight, layers.2.1.4.norm2.bias, layers.2.1.4.ffn.layers.0.weight, layers.2.1.4.ffn.layers.0.bias, layers.2.1.4.ffn.layers.1.weight, layers.2.1.4.ffn.layers.1.bias, layers.2.1.4.ffn.layers.4.weight, layers.2.1.4.ffn.layers.4.bias, layers.2.1.5.norm1.weight, layers.2.1.5.norm1.bias, layers.2.1.5.attn.attn.in_proj_weight, layers.2.1.5.attn.attn.in_proj_bias, layers.2.1.5.attn.attn.out_proj.weight, layers.2.1.5.attn.attn.out_proj.bias, layers.2.1.5.attn.sr.weight, layers.2.1.5.attn.sr.bias, layers.2.1.5.attn.norm.weight, layers.2.1.5.attn.norm.bias, layers.2.1.5.norm2.weight, layers.2.1.5.norm2.bias, layers.2.1.5.ffn.layers.0.weight, layers.2.1.5.ffn.layers.0.bias, layers.2.1.5.ffn.layers.1.weight, layers.2.1.5.ffn.layers.1.bias, layers.2.1.5.ffn.layers.4.weight, layers.2.1.5.ffn.layers.4.bias, layers.2.1.6.norm1.weight, layers.2.1.6.norm1.bias, layers.2.1.6.attn.attn.in_proj_weight, layers.2.1.6.attn.attn.in_proj_bias, layers.2.1.6.attn.attn.out_proj.weight, layers.2.1.6.attn.attn.out_proj.bias, layers.2.1.6.attn.sr.weight, layers.2.1.6.attn.sr.bias, layers.2.1.6.attn.norm.weight, layers.2.1.6.attn.norm.bias, layers.2.1.6.norm2.weight, layers.2.1.6.norm2.bias, layers.2.1.6.ffn.layers.0.weight, layers.2.1.6.ffn.layers.0.bias, layers.2.1.6.ffn.layers.1.weight, layers.2.1.6.ffn.layers.1.bias, layers.2.1.6.ffn.layers.4.weight, layers.2.1.6.ffn.layers.4.bias, layers.2.1.7.norm1.weight, layers.2.1.7.norm1.bias, layers.2.1.7.attn.attn.in_proj_weight, layers.2.1.7.attn.attn.in_proj_bias, layers.2.1.7.attn.attn.out_proj.weight, layers.2.1.7.attn.attn.out_proj.bias, layers.2.1.7.attn.sr.weight, layers.2.1.7.attn.sr.bias, layers.2.1.7.attn.norm.weight, layers.2.1.7.attn.norm.bias, layers.2.1.7.norm2.weight, layers.2.1.7.norm2.bias, layers.2.1.7.ffn.layers.0.weight, layers.2.1.7.ffn.layers.0.bias, layers.2.1.7.ffn.layers.1.weight, layers.2.1.7.ffn.layers.1.bias, layers.2.1.7.ffn.layers.4.weight, layers.2.1.7.ffn.layers.4.bias, layers.2.1.8.norm1.weight, layers.2.1.8.norm1.bias, layers.2.1.8.attn.attn.in_proj_weight, layers.2.1.8.attn.attn.in_proj_bias, layers.2.1.8.attn.attn.out_proj.weight, layers.2.1.8.attn.attn.out_proj.bias, layers.2.1.8.attn.sr.weight, layers.2.1.8.attn.sr.bias, layers.2.1.8.attn.norm.weight, layers.2.1.8.attn.norm.bias, layers.2.1.8.norm2.weight, layers.2.1.8.norm2.bias, layers.2.1.8.ffn.layers.0.weight, layers.2.1.8.ffn.layers.0.bias, layers.2.1.8.ffn.layers.1.weight, layers.2.1.8.ffn.layers.1.bias, layers.2.1.8.ffn.layers.4.weight, layers.2.1.8.ffn.layers.4.bias, layers.2.1.9.norm1.weight, layers.2.1.9.norm1.bias, layers.2.1.9.attn.attn.in_proj_weight, layers.2.1.9.attn.attn.in_proj_bias, layers.2.1.9.attn.attn.out_proj.weight, layers.2.1.9.attn.attn.out_proj.bias, layers.2.1.9.attn.sr.weight, layers.2.1.9.attn.sr.bias, layers.2.1.9.attn.norm.weight, layers.2.1.9.attn.norm.bias, layers.2.1.9.norm2.weight, layers.2.1.9.norm2.bias, layers.2.1.9.ffn.layers.0.weight, layers.2.1.9.ffn.layers.0.bias, layers.2.1.9.ffn.layers.1.weight, layers.2.1.9.ffn.layers.1.bias, layers.2.1.9.ffn.layers.4.weight, layers.2.1.9.ffn.layers.4.bias, layers.2.1.10.norm1.weight, layers.2.1.10.norm1.bias, layers.2.1.10.attn.attn.in_proj_weight, layers.2.1.10.attn.attn.in_proj_bias, layers.2.1.10.attn.attn.out_proj.weight, layers.2.1.10.attn.attn.out_proj.bias, layers.2.1.10.attn.sr.weight, layers.2.1.10.attn.sr.bias, layers.2.1.10.attn.norm.weight, layers.2.1.10.attn.norm.bias, layers.2.1.10.norm2.weight, layers.2.1.10.norm2.bias, layers.2.1.10.ffn.layers.0.weight, layers.2.1.10.ffn.layers.0.bias, layers.2.1.10.ffn.layers.1.weight, layers.2.1.10.ffn.layers.1.bias, layers.2.1.10.ffn.layers.4.weight, layers.2.1.10.ffn.layers.4.bias, layers.2.1.11.norm1.weight, layers.2.1.11.norm1.bias, layers.2.1.11.attn.attn.in_proj_weight, layers.2.1.11.attn.attn.in_proj_bias, layers.2.1.11.attn.attn.out_proj.weight, layers.2.1.11.attn.attn.out_proj.bias, layers.2.1.11.attn.sr.weight, layers.2.1.11.attn.sr.bias, layers.2.1.11.attn.norm.weight, layers.2.1.11.attn.norm.bias, layers.2.1.11.norm2.weight, layers.2.1.11.norm2.bias, layers.2.1.11.ffn.layers.0.weight, layers.2.1.11.ffn.layers.0.bias, layers.2.1.11.ffn.layers.1.weight, layers.2.1.11.ffn.layers.1.bias, layers.2.1.11.ffn.layers.4.weight, layers.2.1.11.ffn.layers.4.bias, layers.2.1.12.norm1.weight, layers.2.1.12.norm1.bias, layers.2.1.12.attn.attn.in_proj_weight, layers.2.1.12.attn.attn.in_proj_bias, layers.2.1.12.attn.attn.out_proj.weight, layers.2.1.12.attn.attn.out_proj.bias, layers.2.1.12.attn.sr.weight, layers.2.1.12.attn.sr.bias, layers.2.1.12.attn.norm.weight, layers.2.1.12.attn.norm.bias, layers.2.1.12.norm2.weight, layers.2.1.12.norm2.bias, layers.2.1.12.ffn.layers.0.weight, layers.2.1.12.ffn.layers.0.bias, layers.2.1.12.ffn.layers.1.weight, layers.2.1.12.ffn.layers.1.bias, layers.2.1.12.ffn.layers.4.weight, layers.2.1.12.ffn.layers.4.bias, layers.2.1.13.norm1.weight, layers.2.1.13.norm1.bias, layers.2.1.13.attn.attn.in_proj_weight, layers.2.1.13.attn.attn.in_proj_bias, layers.2.1.13.attn.attn.out_proj.weight, layers.2.1.13.attn.attn.out_proj.bias, layers.2.1.13.attn.sr.weight, layers.2.1.13.attn.sr.bias, layers.2.1.13.attn.norm.weight, layers.2.1.13.attn.norm.bias, layers.2.1.13.norm2.weight, layers.2.1.13.norm2.bias, layers.2.1.13.ffn.layers.0.weight, layers.2.1.13.ffn.layers.0.bias, layers.2.1.13.ffn.layers.1.weight, layers.2.1.13.ffn.layers.1.bias, layers.2.1.13.ffn.layers.4.weight, layers.2.1.13.ffn.layers.4.bias, layers.2.1.14.norm1.weight, layers.2.1.14.norm1.bias, layers.2.1.14.attn.attn.in_proj_weight, layers.2.1.14.attn.attn.in_proj_bias, layers.2.1.14.attn.attn.out_proj.weight, layers.2.1.14.attn.attn.out_proj.bias, layers.2.1.14.attn.sr.weight, layers.2.1.14.attn.sr.bias, layers.2.1.14.attn.norm.weight, layers.2.1.14.attn.norm.bias, layers.2.1.14.norm2.weight, layers.2.1.14.norm2.bias, layers.2.1.14.ffn.layers.0.weight, layers.2.1.14.ffn.layers.0.bias, layers.2.1.14.ffn.layers.1.weight, layers.2.1.14.ffn.layers.1.bias, layers.2.1.14.ffn.layers.4.weight, layers.2.1.14.ffn.layers.4.bias, layers.2.1.15.norm1.weight, layers.2.1.15.norm1.bias, layers.2.1.15.attn.attn.in_proj_weight, layers.2.1.15.attn.attn.in_proj_bias, layers.2.1.15.attn.attn.out_proj.weight, layers.2.1.15.attn.attn.out_proj.bias, layers.2.1.15.attn.sr.weight, layers.2.1.15.attn.sr.bias, layers.2.1.15.attn.norm.weight, layers.2.1.15.attn.norm.bias, layers.2.1.15.norm2.weight, layers.2.1.15.norm2.bias, layers.2.1.15.ffn.layers.0.weight, layers.2.1.15.ffn.layers.0.bias, layers.2.1.15.ffn.layers.1.weight, layers.2.1.15.ffn.layers.1.bias, layers.2.1.15.ffn.layers.4.weight, layers.2.1.15.ffn.layers.4.bias, layers.2.1.16.norm1.weight, layers.2.1.16.norm1.bias, layers.2.1.16.attn.attn.in_proj_weight, layers.2.1.16.attn.attn.in_proj_bias, layers.2.1.16.attn.attn.out_proj.weight, layers.2.1.16.attn.attn.out_proj.bias, layers.2.1.16.attn.sr.weight, layers.2.1.16.attn.sr.bias, layers.2.1.16.attn.norm.weight, layers.2.1.16.attn.norm.bias, layers.2.1.16.norm2.weight, layers.2.1.16.norm2.bias, layers.2.1.16.ffn.layers.0.weight, layers.2.1.16.ffn.layers.0.bias, layers.2.1.16.ffn.layers.1.weight, layers.2.1.16.ffn.layers.1.bias, layers.2.1.16.ffn.layers.4.weight, layers.2.1.16.ffn.layers.4.bias, layers.2.1.17.norm1.weight, layers.2.1.17.norm1.bias, layers.2.1.17.attn.attn.in_proj_weight, layers.2.1.17.attn.attn.in_proj_bias, layers.2.1.17.attn.attn.out_proj.weight, layers.2.1.17.attn.attn.out_proj.bias, layers.2.1.17.attn.sr.weight, layers.2.1.17.attn.sr.bias, layers.2.1.17.attn.norm.weight, layers.2.1.17.attn.norm.bias, layers.2.1.17.norm2.weight, layers.2.1.17.norm2.bias, layers.2.1.17.ffn.layers.0.weight, layers.2.1.17.ffn.layers.0.bias, layers.2.1.17.ffn.layers.1.weight, layers.2.1.17.ffn.layers.1.bias, layers.2.1.17.ffn.layers.4.weight, layers.2.1.17.ffn.layers.4.bias, layers.2.1.18.norm1.weight, layers.2.1.18.norm1.bias, layers.2.1.18.attn.attn.in_proj_weight, layers.2.1.18.attn.attn.in_proj_bias, layers.2.1.18.attn.attn.out_proj.weight, layers.2.1.18.attn.attn.out_proj.bias, layers.2.1.18.attn.sr.weight, layers.2.1.18.attn.sr.bias, layers.2.1.18.attn.norm.weight, layers.2.1.18.attn.norm.bias, layers.2.1.18.norm2.weight, layers.2.1.18.norm2.bias, layers.2.1.18.ffn.layers.0.weight, layers.2.1.18.ffn.layers.0.bias, layers.2.1.18.ffn.layers.1.weight, layers.2.1.18.ffn.layers.1.bias, layers.2.1.18.ffn.layers.4.weight, layers.2.1.18.ffn.layers.4.bias, layers.2.1.19.norm1.weight, layers.2.1.19.norm1.bias, layers.2.1.19.attn.attn.in_proj_weight, layers.2.1.19.attn.attn.in_proj_bias, layers.2.1.19.attn.attn.out_proj.weight, layers.2.1.19.attn.attn.out_proj.bias, layers.2.1.19.attn.sr.weight, layers.2.1.19.attn.sr.bias, layers.2.1.19.attn.norm.weight, layers.2.1.19.attn.norm.bias, layers.2.1.19.norm2.weight, layers.2.1.19.norm2.bias, layers.2.1.19.ffn.layers.0.weight, layers.2.1.19.ffn.layers.0.bias, layers.2.1.19.ffn.layers.1.weight, layers.2.1.19.ffn.layers.1.bias, layers.2.1.19.ffn.layers.4.weight, layers.2.1.19.ffn.layers.4.bias, layers.2.1.20.norm1.weight, layers.2.1.20.norm1.bias, layers.2.1.20.attn.attn.in_proj_weight, layers.2.1.20.attn.attn.in_proj_bias, layers.2.1.20.attn.attn.out_proj.weight, layers.2.1.20.attn.attn.out_proj.bias, layers.2.1.20.attn.sr.weight, layers.2.1.20.attn.sr.bias, layers.2.1.20.attn.norm.weight, layers.2.1.20.attn.norm.bias, layers.2.1.20.norm2.weight, layers.2.1.20.norm2.bias, layers.2.1.20.ffn.layers.0.weight, layers.2.1.20.ffn.layers.0.bias, layers.2.1.20.ffn.layers.1.weight, layers.2.1.20.ffn.layers.1.bias, layers.2.1.20.ffn.layers.4.weight, layers.2.1.20.ffn.layers.4.bias, layers.2.1.21.norm1.weight, layers.2.1.21.norm1.bias, layers.2.1.21.attn.attn.in_proj_weight, layers.2.1.21.attn.attn.in_proj_bias, layers.2.1.21.attn.attn.out_proj.weight, layers.2.1.21.attn.attn.out_proj.bias, layers.2.1.21.attn.sr.weight, layers.2.1.21.attn.sr.bias, layers.2.1.21.attn.norm.weight, layers.2.1.21.attn.norm.bias, layers.2.1.21.norm2.weight, layers.2.1.21.norm2.bias, layers.2.1.21.ffn.layers.0.weight, layers.2.1.21.ffn.layers.0.bias, layers.2.1.21.ffn.layers.1.weight, layers.2.1.21.ffn.layers.1.bias, layers.2.1.21.ffn.layers.4.weight, layers.2.1.21.ffn.layers.4.bias, layers.2.1.22.norm1.weight, layers.2.1.22.norm1.bias, layers.2.1.22.attn.attn.in_proj_weight, layers.2.1.22.attn.attn.in_proj_bias, layers.2.1.22.attn.attn.out_proj.weight, layers.2.1.22.attn.attn.out_proj.bias, layers.2.1.22.attn.sr.weight, layers.2.1.22.attn.sr.bias, layers.2.1.22.attn.norm.weight, layers.2.1.22.attn.norm.bias, layers.2.1.22.norm2.weight, layers.2.1.22.norm2.bias, layers.2.1.22.ffn.layers.0.weight, layers.2.1.22.ffn.layers.0.bias, layers.2.1.22.ffn.layers.1.weight, layers.2.1.22.ffn.layers.1.bias, layers.2.1.22.ffn.layers.4.weight, layers.2.1.22.ffn.layers.4.bias, layers.2.1.23.norm1.weight, layers.2.1.23.norm1.bias, layers.2.1.23.attn.attn.in_proj_weight, layers.2.1.23.attn.attn.in_proj_bias, layers.2.1.23.attn.attn.out_proj.weight, layers.2.1.23.attn.attn.out_proj.bias, layers.2.1.23.attn.sr.weight, layers.2.1.23.attn.sr.bias, layers.2.1.23.attn.norm.weight, layers.2.1.23.attn.norm.bias, layers.2.1.23.norm2.weight, layers.2.1.23.norm2.bias, layers.2.1.23.ffn.layers.0.weight, layers.2.1.23.ffn.layers.0.bias, layers.2.1.23.ffn.layers.1.weight, layers.2.1.23.ffn.layers.1.bias, layers.2.1.23.ffn.layers.4.weight, layers.2.1.23.ffn.layers.4.bias, layers.2.1.24.norm1.weight, layers.2.1.24.norm1.bias, layers.2.1.24.attn.attn.in_proj_weight, layers.2.1.24.attn.attn.in_proj_bias, layers.2.1.24.attn.attn.out_proj.weight, layers.2.1.24.attn.attn.out_proj.bias, layers.2.1.24.attn.sr.weight, layers.2.1.24.attn.sr.bias, layers.2.1.24.attn.norm.weight, layers.2.1.24.attn.norm.bias, layers.2.1.24.norm2.weight, layers.2.1.24.norm2.bias, layers.2.1.24.ffn.layers.0.weight, layers.2.1.24.ffn.layers.0.bias, layers.2.1.24.ffn.layers.1.weight, layers.2.1.24.ffn.layers.1.bias, layers.2.1.24.ffn.layers.4.weight, layers.2.1.24.ffn.layers.4.bias, layers.2.1.25.norm1.weight, layers.2.1.25.norm1.bias, layers.2.1.25.attn.attn.in_proj_weight, layers.2.1.25.attn.attn.in_proj_bias, layers.2.1.25.attn.attn.out_proj.weight, layers.2.1.25.attn.attn.out_proj.bias, layers.2.1.25.attn.sr.weight, layers.2.1.25.attn.sr.bias, layers.2.1.25.attn.norm.weight, layers.2.1.25.attn.norm.bias, layers.2.1.25.norm2.weight, layers.2.1.25.norm2.bias, layers.2.1.25.ffn.layers.0.weight, layers.2.1.25.ffn.layers.0.bias, layers.2.1.25.ffn.layers.1.weight, layers.2.1.25.ffn.layers.1.bias, layers.2.1.25.ffn.layers.4.weight, layers.2.1.25.ffn.layers.4.bias, layers.2.1.26.norm1.weight, layers.2.1.26.norm1.bias, layers.2.1.26.attn.attn.in_proj_weight, layers.2.1.26.attn.attn.in_proj_bias, layers.2.1.26.attn.attn.out_proj.weight, layers.2.1.26.attn.attn.out_proj.bias, layers.2.1.26.attn.sr.weight, layers.2.1.26.attn.sr.bias, layers.2.1.26.attn.norm.weight, layers.2.1.26.attn.norm.bias, layers.2.1.26.norm2.weight, layers.2.1.26.norm2.bias, layers.2.1.26.ffn.layers.0.weight, layers.2.1.26.ffn.layers.0.bias, layers.2.1.26.ffn.layers.1.weight, layers.2.1.26.ffn.layers.1.bias, layers.2.1.26.ffn.layers.4.weight, layers.2.1.26.ffn.layers.4.bias, layers.2.1.27.norm1.weight, layers.2.1.27.norm1.bias, layers.2.1.27.attn.attn.in_proj_weight, layers.2.1.27.attn.attn.in_proj_bias, layers.2.1.27.attn.attn.out_proj.weight, layers.2.1.27.attn.attn.out_proj.bias, layers.2.1.27.attn.sr.weight, layers.2.1.27.attn.sr.bias, layers.2.1.27.attn.norm.weight, layers.2.1.27.attn.norm.bias, layers.2.1.27.norm2.weight, layers.2.1.27.norm2.bias, layers.2.1.27.ffn.layers.0.weight, layers.2.1.27.ffn.layers.0.bias, layers.2.1.27.ffn.layers.1.weight, layers.2.1.27.ffn.layers.1.bias, layers.2.1.27.ffn.layers.4.weight, layers.2.1.27.ffn.layers.4.bias, layers.2.1.28.norm1.weight, layers.2.1.28.norm1.bias, layers.2.1.28.attn.attn.in_proj_weight, layers.2.1.28.attn.attn.in_proj_bias, layers.2.1.28.attn.attn.out_proj.weight, layers.2.1.28.attn.attn.out_proj.bias, layers.2.1.28.attn.sr.weight, layers.2.1.28.attn.sr.bias, layers.2.1.28.attn.norm.weight, layers.2.1.28.attn.norm.bias, layers.2.1.28.norm2.weight, layers.2.1.28.norm2.bias, layers.2.1.28.ffn.layers.0.weight, layers.2.1.28.ffn.layers.0.bias, layers.2.1.28.ffn.layers.1.weight, layers.2.1.28.ffn.layers.1.bias, layers.2.1.28.ffn.layers.4.weight, layers.2.1.28.ffn.layers.4.bias, layers.2.1.29.norm1.weight, layers.2.1.29.norm1.bias, layers.2.1.29.attn.attn.in_proj_weight, layers.2.1.29.attn.attn.in_proj_bias, layers.2.1.29.attn.attn.out_proj.weight, layers.2.1.29.attn.attn.out_proj.bias, layers.2.1.29.attn.sr.weight, layers.2.1.29.attn.sr.bias, layers.2.1.29.attn.norm.weight, layers.2.1.29.attn.norm.bias, layers.2.1.29.norm2.weight, layers.2.1.29.norm2.bias, layers.2.1.29.ffn.layers.0.weight, layers.2.1.29.ffn.layers.0.bias, layers.2.1.29.ffn.layers.1.weight, layers.2.1.29.ffn.layers.1.bias, layers.2.1.29.ffn.layers.4.weight, layers.2.1.29.ffn.layers.4.bias, layers.2.1.30.norm1.weight, layers.2.1.30.norm1.bias, layers.2.1.30.attn.attn.in_proj_weight, layers.2.1.30.attn.attn.in_proj_bias, layers.2.1.30.attn.attn.out_proj.weight, layers.2.1.30.attn.attn.out_proj.bias, layers.2.1.30.attn.sr.weight, layers.2.1.30.attn.sr.bias, layers.2.1.30.attn.norm.weight, layers.2.1.30.attn.norm.bias, layers.2.1.30.norm2.weight, layers.2.1.30.norm2.bias, layers.2.1.30.ffn.layers.0.weight, layers.2.1.30.ffn.layers.0.bias, layers.2.1.30.ffn.layers.1.weight, layers.2.1.30.ffn.layers.1.bias, layers.2.1.30.ffn.layers.4.weight, layers.2.1.30.ffn.layers.4.bias, layers.2.1.31.norm1.weight, layers.2.1.31.norm1.bias, layers.2.1.31.attn.attn.in_proj_weight, layers.2.1.31.attn.attn.in_proj_bias, layers.2.1.31.attn.attn.out_proj.weight, layers.2.1.31.attn.attn.out_proj.bias, layers.2.1.31.attn.sr.weight, layers.2.1.31.attn.sr.bias, layers.2.1.31.attn.norm.weight, layers.2.1.31.attn.norm.bias, layers.2.1.31.norm2.weight, layers.2.1.31.norm2.bias, layers.2.1.31.ffn.layers.0.weight, layers.2.1.31.ffn.layers.0.bias, layers.2.1.31.ffn.layers.1.weight, layers.2.1.31.ffn.layers.1.bias, layers.2.1.31.ffn.layers.4.weight, layers.2.1.31.ffn.layers.4.bias, layers.2.1.32.norm1.weight, layers.2.1.32.norm1.bias, layers.2.1.32.attn.attn.in_proj_weight, layers.2.1.32.attn.attn.in_proj_bias, layers.2.1.32.attn.attn.out_proj.weight, layers.2.1.32.attn.attn.out_proj.bias, layers.2.1.32.attn.sr.weight, layers.2.1.32.attn.sr.bias, layers.2.1.32.attn.norm.weight, layers.2.1.32.attn.norm.bias, layers.2.1.32.norm2.weight, layers.2.1.32.norm2.bias, layers.2.1.32.ffn.layers.0.weight, layers.2.1.32.ffn.layers.0.bias, layers.2.1.32.ffn.layers.1.weight, layers.2.1.32.ffn.layers.1.bias, layers.2.1.32.ffn.layers.4.weight, layers.2.1.32.ffn.layers.4.bias, layers.2.1.33.norm1.weight, layers.2.1.33.norm1.bias, layers.2.1.33.attn.attn.in_proj_weight, layers.2.1.33.attn.attn.in_proj_bias, layers.2.1.33.attn.attn.out_proj.weight, layers.2.1.33.attn.attn.out_proj.bias, layers.2.1.33.attn.sr.weight, layers.2.1.33.attn.sr.bias, layers.2.1.33.attn.norm.weight, layers.2.1.33.attn.norm.bias, layers.2.1.33.norm2.weight, layers.2.1.33.norm2.bias, layers.2.1.33.ffn.layers.0.weight, layers.2.1.33.ffn.layers.0.bias, layers.2.1.33.ffn.layers.1.weight, layers.2.1.33.ffn.layers.1.bias, layers.2.1.33.ffn.layers.4.weight, layers.2.1.33.ffn.layers.4.bias, layers.2.1.34.norm1.weight, layers.2.1.34.norm1.bias, layers.2.1.34.attn.attn.in_proj_weight, layers.2.1.34.attn.attn.in_proj_bias, layers.2.1.34.attn.attn.out_proj.weight, layers.2.1.34.attn.attn.out_proj.bias, layers.2.1.34.attn.sr.weight, layers.2.1.34.attn.sr.bias, layers.2.1.34.attn.norm.weight, layers.2.1.34.attn.norm.bias, layers.2.1.34.norm2.weight, layers.2.1.34.norm2.bias, layers.2.1.34.ffn.layers.0.weight, layers.2.1.34.ffn.layers.0.bias, layers.2.1.34.ffn.layers.1.weight, layers.2.1.34.ffn.layers.1.bias, layers.2.1.34.ffn.layers.4.weight, layers.2.1.34.ffn.layers.4.bias, layers.2.1.35.norm1.weight, layers.2.1.35.norm1.bias, layers.2.1.35.attn.attn.in_proj_weight, layers.2.1.35.attn.attn.in_proj_bias, layers.2.1.35.attn.attn.out_proj.weight, layers.2.1.35.attn.attn.out_proj.bias, layers.2.1.35.attn.sr.weight, layers.2.1.35.attn.sr.bias, layers.2.1.35.attn.norm.weight, layers.2.1.35.attn.norm.bias, layers.2.1.35.norm2.weight, layers.2.1.35.norm2.bias, layers.2.1.35.ffn.layers.0.weight, layers.2.1.35.ffn.layers.0.bias, layers.2.1.35.ffn.layers.1.weight, layers.2.1.35.ffn.layers.1.bias, layers.2.1.35.ffn.layers.4.weight, layers.2.1.35.ffn.layers.4.bias, layers.2.1.36.norm1.weight, layers.2.1.36.norm1.bias, layers.2.1.36.attn.attn.in_proj_weight, layers.2.1.36.attn.attn.in_proj_bias, layers.2.1.36.attn.attn.out_proj.weight, layers.2.1.36.attn.attn.out_proj.bias, layers.2.1.36.attn.sr.weight, layers.2.1.36.attn.sr.bias, layers.2.1.36.attn.norm.weight, layers.2.1.36.attn.norm.bias, layers.2.1.36.norm2.weight, layers.2.1.36.norm2.bias, layers.2.1.36.ffn.layers.0.weight, layers.2.1.36.ffn.layers.0.bias, layers.2.1.36.ffn.layers.1.weight, layers.2.1.36.ffn.layers.1.bias, layers.2.1.36.ffn.layers.4.weight, layers.2.1.36.ffn.layers.4.bias, layers.2.1.37.norm1.weight, layers.2.1.37.norm1.bias, layers.2.1.37.attn.attn.in_proj_weight, layers.2.1.37.attn.attn.in_proj_bias, layers.2.1.37.attn.attn.out_proj.weight, layers.2.1.37.attn.attn.out_proj.bias, layers.2.1.37.attn.sr.weight, layers.2.1.37.attn.sr.bias, layers.2.1.37.attn.norm.weight, layers.2.1.37.attn.norm.bias, layers.2.1.37.norm2.weight, layers.2.1.37.norm2.bias, layers.2.1.37.ffn.layers.0.weight, layers.2.1.37.ffn.layers.0.bias, layers.2.1.37.ffn.layers.1.weight, layers.2.1.37.ffn.layers.1.bias, layers.2.1.37.ffn.layers.4.weight, layers.2.1.37.ffn.layers.4.bias, layers.2.1.38.norm1.weight, layers.2.1.38.norm1.bias, layers.2.1.38.attn.attn.in_proj_weight, layers.2.1.38.attn.attn.in_proj_bias, layers.2.1.38.attn.attn.out_proj.weight, layers.2.1.38.attn.attn.out_proj.bias, layers.2.1.38.attn.sr.weight, layers.2.1.38.attn.sr.bias, layers.2.1.38.attn.norm.weight, layers.2.1.38.attn.norm.bias, layers.2.1.38.norm2.weight, layers.2.1.38.norm2.bias, layers.2.1.38.ffn.layers.0.weight, layers.2.1.38.ffn.layers.0.bias, layers.2.1.38.ffn.layers.1.weight, layers.2.1.38.ffn.layers.1.bias, layers.2.1.38.ffn.layers.4.weight, layers.2.1.38.ffn.layers.4.bias, layers.2.1.39.norm1.weight, layers.2.1.39.norm1.bias, layers.2.1.39.attn.attn.in_proj_weight, layers.2.1.39.attn.attn.in_proj_bias, layers.2.1.39.attn.attn.out_proj.weight, layers.2.1.39.attn.attn.out_proj.bias, layers.2.1.39.attn.sr.weight, layers.2.1.39.attn.sr.bias, layers.2.1.39.attn.norm.weight, layers.2.1.39.attn.norm.bias, layers.2.1.39.norm2.weight, layers.2.1.39.norm2.bias, layers.2.1.39.ffn.layers.0.weight, layers.2.1.39.ffn.layers.0.bias, layers.2.1.39.ffn.layers.1.weight, layers.2.1.39.ffn.layers.1.bias, layers.2.1.39.ffn.layers.4.weight, layers.2.1.39.ffn.layers.4.bias, layers.2.2.weight, layers.2.2.bias, layers.3.0.projection.weight, layers.3.0.projection.bias, layers.3.0.norm.weight, layers.3.0.norm.bias, layers.3.1.0.norm1.weight, layers.3.1.0.norm1.bias, layers.3.1.0.attn.attn.in_proj_weight, layers.3.1.0.attn.attn.in_proj_bias, layers.3.1.0.attn.attn.out_proj.weight, layers.3.1.0.attn.attn.out_proj.bias, layers.3.1.0.norm2.weight, layers.3.1.0.norm2.bias, layers.3.1.0.ffn.layers.0.weight, layers.3.1.0.ffn.layers.0.bias, layers.3.1.0.ffn.layers.1.weight, layers.3.1.0.ffn.layers.1.bias, layers.3.1.0.ffn.layers.4.weight, layers.3.1.0.ffn.layers.4.bias, layers.3.1.1.norm1.weight, layers.3.1.1.norm1.bias, layers.3.1.1.attn.attn.in_proj_weight, layers.3.1.1.attn.attn.in_proj_bias, layers.3.1.1.attn.attn.out_proj.weight, layers.3.1.1.attn.attn.out_proj.bias, layers.3.1.1.norm2.weight, layers.3.1.1.norm2.bias, layers.3.1.1.ffn.layers.0.weight, layers.3.1.1.ffn.layers.0.bias, layers.3.1.1.ffn.layers.1.weight, layers.3.1.1.ffn.layers.1.bias, layers.3.1.1.ffn.layers.4.weight, layers.3.1.1.ffn.layers.4.bias, layers.3.1.2.norm1.weight, layers.3.1.2.norm1.bias, layers.3.1.2.attn.attn.in_proj_weight, layers.3.1.2.attn.attn.in_proj_bias, layers.3.1.2.attn.attn.out_proj.weight, layers.3.1.2.attn.attn.out_proj.bias, layers.3.1.2.norm2.weight, layers.3.1.2.norm2.bias, layers.3.1.2.ffn.layers.0.weight, layers.3.1.2.ffn.layers.0.bias, layers.3.1.2.ffn.layers.1.weight, layers.3.1.2.ffn.layers.1.bias, layers.3.1.2.ffn.layers.4.weight, layers.3.1.2.ffn.layers.4.bias, layers.3.2.weight, layers.3.2.bias\n",
      "\n",
      "03/05 17:28:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "03/05 17:28:21 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "03/05 17:28:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /kaggle/working/checkpoint.\n",
      "03/05 17:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  100/40000]  base_lr: 3.9627e-06 lr: 3.9627e-06  eta: 8:36:02  time: 0.7865  data_time: 0.1519  memory: 5440  loss: 1.5301  decode.loss_ce: 1.5301  decode.acc_seg: 23.3607\n",
      "03/05 17:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  200/40000]  base_lr: 7.9654e-06 lr: 7.9654e-06  eta: 8:31:28  time: 0.7485  data_time: 0.1135  memory: 5440  loss: 1.3016  decode.loss_ce: 1.3016  decode.acc_seg: 43.8037\n",
      "03/05 17:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  300/40000]  base_lr: 1.1968e-05 lr: 1.1968e-05  eta: 8:29:50  time: 0.7957  data_time: 0.1616  memory: 5440  loss: 1.1710  decode.loss_ce: 1.1710  decode.acc_seg: 13.9697\n",
      "03/05 17:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  400/40000]  base_lr: 1.5971e-05 lr: 1.5971e-05  eta: 8:29:21  time: 0.7773  data_time: 0.1391  memory: 5440  loss: 0.9899  decode.loss_ce: 0.9899  decode.acc_seg: 97.4355\n",
      "03/05 17:34:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  500/40000]  base_lr: 1.9973e-05 lr: 1.9973e-05  eta: 8:29:29  time: 0.7990  data_time: 0.1648  memory: 5440  loss: 1.0580  decode.loss_ce: 1.0580  decode.acc_seg: 53.1299\n",
      "03/05 17:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  600/40000]  base_lr: 2.3976e-05 lr: 2.3976e-05  eta: 8:30:14  time: 0.7862  data_time: 0.1543  memory: 5440  loss: 0.9496  decode.loss_ce: 0.9496  decode.acc_seg: 65.1802\n",
      "03/05 17:37:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  700/40000]  base_lr: 2.7979e-05 lr: 2.7979e-05  eta: 8:29:00  time: 0.7757  data_time: 0.1388  memory: 5440  loss: 0.9949  decode.loss_ce: 0.9949  decode.acc_seg: 39.8714\n",
      "03/05 17:37:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 17:38:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  800/40000]  base_lr: 3.1981e-05 lr: 3.1981e-05  eta: 8:20:50  time: 0.6690  data_time: 0.0313  memory: 5440  loss: 0.6754  decode.loss_ce: 0.6754  decode.acc_seg: 78.0656\n",
      "03/05 17:39:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  900/40000]  base_lr: 3.5984e-05 lr: 3.5984e-05  eta: 8:12:09  time: 0.6706  data_time: 0.0255  memory: 5440  loss: 0.7083  decode.loss_ce: 0.7083  decode.acc_seg: 29.6531\n",
      "03/05 17:40:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 17:40:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1000/40000]  base_lr: 3.9987e-05 lr: 3.9987e-05  eta: 8:05:12  time: 0.6610  data_time: 0.0238  memory: 5440  loss: 0.7639  decode.loss_ce: 0.7639  decode.acc_seg: 77.7248\n",
      "03/05 17:41:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1100/40000]  base_lr: 4.3989e-05 lr: 4.3989e-05  eta: 7:59:30  time: 0.6581  data_time: 0.0241  memory: 5440  loss: 0.7635  decode.loss_ce: 0.7635  decode.acc_seg: 67.7121\n",
      "03/05 17:43:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1200/40000]  base_lr: 4.7992e-05 lr: 4.7992e-05  eta: 7:53:56  time: 0.6556  data_time: 0.0242  memory: 5440  loss: 0.7126  decode.loss_ce: 0.7126  decode.acc_seg: 76.2617\n",
      "03/05 17:44:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1300/40000]  base_lr: 5.1995e-05 lr: 5.1995e-05  eta: 7:49:04  time: 0.6528  data_time: 0.0235  memory: 5440  loss: 0.7986  decode.loss_ce: 0.7986  decode.acc_seg: 73.5263\n",
      "03/05 17:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1400/40000]  base_lr: 5.5997e-05 lr: 5.5997e-05  eta: 7:44:42  time: 0.6550  data_time: 0.0232  memory: 5440  loss: 0.9369  decode.loss_ce: 0.9369  decode.acc_seg: 92.0649\n",
      "03/05 17:46:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1500/40000]  base_lr: 6.0000e-05 lr: 6.0000e-05  eta: 7:41:07  time: 0.6524  data_time: 0.0233  memory: 5440  loss: 0.7144  decode.loss_ce: 0.7144  decode.acc_seg: 63.6142\n",
      "03/05 17:47:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1600/40000]  base_lr: 5.9963e-05 lr: 5.9963e-05  eta: 7:37:27  time: 0.6544  data_time: 0.0234  memory: 5440  loss: 1.1596  decode.loss_ce: 1.1596  decode.acc_seg: 17.8539\n",
      "03/05 17:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1700/40000]  base_lr: 5.9925e-05 lr: 5.9925e-05  eta: 7:34:12  time: 0.6591  data_time: 0.0257  memory: 5440  loss: 0.8947  decode.loss_ce: 0.8947  decode.acc_seg: 73.7899\n",
      "03/05 17:49:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1800/40000]  base_lr: 5.9887e-05 lr: 5.9887e-05  eta: 7:31:10  time: 0.6609  data_time: 0.0241  memory: 5440  loss: 0.6424  decode.loss_ce: 0.6424  decode.acc_seg: 85.7607\n",
      "03/05 17:50:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1900/40000]  base_lr: 5.9849e-05 lr: 5.9849e-05  eta: 7:28:20  time: 0.6693  data_time: 0.0256  memory: 5440  loss: 0.7227  decode.loss_ce: 0.7227  decode.acc_seg: 53.1726\n",
      "03/05 17:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 17:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2000/40000]  base_lr: 5.9811e-05 lr: 5.9811e-05  eta: 7:25:41  time: 0.6649  data_time: 0.0248  memory: 5440  loss: 0.7297  decode.loss_ce: 0.7297  decode.acc_seg: 42.6725\n",
      "03/05 17:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2000 iterations\n",
      "03/05 17:53:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2100/40000]  base_lr: 5.9773e-05 lr: 5.9773e-05  eta: 7:25:07  time: 0.6602  data_time: 0.0238  memory: 5440  loss: 0.8234  decode.loss_ce: 0.8234  decode.acc_seg: 81.9128\n",
      "03/05 17:54:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2200/40000]  base_lr: 5.9735e-05 lr: 5.9735e-05  eta: 7:23:02  time: 0.6606  data_time: 0.0252  memory: 5440  loss: 0.8310  decode.loss_ce: 0.8310  decode.acc_seg: 71.8906\n",
      "03/05 17:55:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2300/40000]  base_lr: 5.9698e-05 lr: 5.9698e-05  eta: 7:20:52  time: 0.6594  data_time: 0.0237  memory: 5440  loss: 0.7128  decode.loss_ce: 0.7128  decode.acc_seg: 43.7015\n",
      "03/05 17:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2400/40000]  base_lr: 5.9660e-05 lr: 5.9660e-05  eta: 7:18:46  time: 0.6565  data_time: 0.0242  memory: 5440  loss: 0.7526  decode.loss_ce: 0.7526  decode.acc_seg: 55.2359\n",
      "03/05 17:57:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2500/40000]  base_lr: 5.9622e-05 lr: 5.9622e-05  eta: 7:16:34  time: 0.6570  data_time: 0.0231  memory: 5440  loss: 0.5717  decode.loss_ce: 0.5717  decode.acc_seg: 67.1602\n",
      "03/05 17:58:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2600/40000]  base_lr: 5.9584e-05 lr: 5.9584e-05  eta: 7:14:30  time: 0.6615  data_time: 0.0243  memory: 5440  loss: 0.8698  decode.loss_ce: 0.8698  decode.acc_seg: 37.4648\n",
      "03/05 17:59:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2700/40000]  base_lr: 5.9546e-05 lr: 5.9546e-05  eta: 7:12:41  time: 0.6954  data_time: 0.0500  memory: 5440  loss: 0.5881  decode.loss_ce: 0.5881  decode.acc_seg: 69.2545\n",
      "03/05 18:00:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2800/40000]  base_lr: 5.9508e-05 lr: 5.9508e-05  eta: 7:10:47  time: 0.6666  data_time: 0.0265  memory: 5440  loss: 0.6273  decode.loss_ce: 0.6273  decode.acc_seg: 88.4756\n",
      "03/05 18:01:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2900/40000]  base_lr: 5.9470e-05 lr: 5.9470e-05  eta: 7:08:57  time: 0.6537  data_time: 0.0233  memory: 5440  loss: 0.5463  decode.loss_ce: 0.5463  decode.acc_seg: 58.3539\n",
      "03/05 18:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 18:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3000/40000]  base_lr: 5.9433e-05 lr: 5.9433e-05  eta: 7:07:13  time: 0.6639  data_time: 0.0247  memory: 5440  loss: 0.5982  decode.loss_ce: 0.5982  decode.acc_seg: 81.5181\n",
      "03/05 18:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3100/40000]  base_lr: 5.9395e-05 lr: 5.9395e-05  eta: 7:05:35  time: 0.6553  data_time: 0.0233  memory: 5440  loss: 0.6963  decode.loss_ce: 0.6963  decode.acc_seg: 51.1143\n",
      "03/05 18:05:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3200/40000]  base_lr: 5.9357e-05 lr: 5.9357e-05  eta: 7:03:51  time: 0.6569  data_time: 0.0237  memory: 5440  loss: 0.8973  decode.loss_ce: 0.8973  decode.acc_seg: 50.5524\n",
      "03/05 18:06:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3300/40000]  base_lr: 5.9319e-05 lr: 5.9319e-05  eta: 7:02:05  time: 0.6547  data_time: 0.0240  memory: 5440  loss: 0.6307  decode.loss_ce: 0.6307  decode.acc_seg: 88.2022\n",
      "03/05 18:07:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3400/40000]  base_lr: 5.9281e-05 lr: 5.9281e-05  eta: 7:00:29  time: 0.6673  data_time: 0.0290  memory: 5440  loss: 0.5993  decode.loss_ce: 0.5993  decode.acc_seg: 74.1569\n",
      "03/05 18:08:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3500/40000]  base_lr: 5.9243e-05 lr: 5.9243e-05  eta: 6:58:56  time: 0.6612  data_time: 0.0291  memory: 5440  loss: 0.7464  decode.loss_ce: 0.7464  decode.acc_seg: 87.7548\n",
      "03/05 18:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3600/40000]  base_lr: 5.9205e-05 lr: 5.9205e-05  eta: 6:57:36  time: 0.6939  data_time: 0.0505  memory: 5440  loss: 0.5722  decode.loss_ce: 0.5722  decode.acc_seg: 72.6517\n",
      "03/05 18:10:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3700/40000]  base_lr: 5.9168e-05 lr: 5.9168e-05  eta: 6:56:03  time: 0.6703  data_time: 0.0245  memory: 5440  loss: 0.5918  decode.loss_ce: 0.5918  decode.acc_seg: 68.0272\n",
      "03/05 18:11:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3800/40000]  base_lr: 5.9130e-05 lr: 5.9130e-05  eta: 6:54:35  time: 0.6848  data_time: 0.0518  memory: 5440  loss: 0.9244  decode.loss_ce: 0.9244  decode.acc_seg: 72.8445\n",
      "03/05 18:13:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3900/40000]  base_lr: 5.9092e-05 lr: 5.9092e-05  eta: 6:53:14  time: 0.6657  data_time: 0.0317  memory: 5440  loss: 0.5347  decode.loss_ce: 0.5347  decode.acc_seg: 58.9531\n",
      "03/05 18:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 18:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4000/40000]  base_lr: 5.9054e-05 lr: 5.9054e-05  eta: 6:51:52  time: 0.6609  data_time: 0.0237  memory: 5440  loss: 0.6291  decode.loss_ce: 0.6291  decode.acc_seg: 78.5706\n",
      "03/05 18:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4000 iterations\n",
      "03/05 18:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4100/40000]  base_lr: 5.9016e-05 lr: 5.9016e-05  eta: 6:51:05  time: 0.6571  data_time: 0.0245  memory: 5440  loss: 0.6319  decode.loss_ce: 0.6319  decode.acc_seg: 81.2297\n",
      "03/05 18:16:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4200/40000]  base_lr: 5.8978e-05 lr: 5.8978e-05  eta: 6:49:35  time: 0.6589  data_time: 0.0235  memory: 5440  loss: 0.6188  decode.loss_ce: 0.6188  decode.acc_seg: 90.4365\n",
      "03/05 18:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4300/40000]  base_lr: 5.8940e-05 lr: 5.8940e-05  eta: 6:48:03  time: 0.6585  data_time: 0.0243  memory: 5440  loss: 0.5277  decode.loss_ce: 0.5277  decode.acc_seg: 70.8624\n",
      "03/05 18:18:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4400/40000]  base_lr: 5.8903e-05 lr: 5.8903e-05  eta: 6:46:32  time: 0.6606  data_time: 0.0241  memory: 5440  loss: 0.5726  decode.loss_ce: 0.5726  decode.acc_seg: 59.0276\n",
      "03/05 18:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4500/40000]  base_lr: 5.8865e-05 lr: 5.8865e-05  eta: 6:45:02  time: 0.6716  data_time: 0.0262  memory: 5440  loss: 0.9336  decode.loss_ce: 0.9336  decode.acc_seg: 34.0841\n",
      "03/05 18:20:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4600/40000]  base_lr: 5.8827e-05 lr: 5.8827e-05  eta: 6:43:34  time: 0.6599  data_time: 0.0240  memory: 5440  loss: 0.8817  decode.loss_ce: 0.8817  decode.acc_seg: 56.4999\n",
      "03/05 18:21:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4700/40000]  base_lr: 5.8789e-05 lr: 5.8789e-05  eta: 6:42:05  time: 0.6540  data_time: 0.0232  memory: 5440  loss: 0.6678  decode.loss_ce: 0.6678  decode.acc_seg: 76.9509\n",
      "03/05 18:22:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4800/40000]  base_lr: 5.8751e-05 lr: 5.8751e-05  eta: 6:40:37  time: 0.6552  data_time: 0.0238  memory: 5440  loss: 0.6044  decode.loss_ce: 0.6044  decode.acc_seg: 92.4498\n",
      "03/05 18:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4900/40000]  base_lr: 5.8713e-05 lr: 5.8713e-05  eta: 6:39:12  time: 0.6546  data_time: 0.0235  memory: 5440  loss: 0.5581  decode.loss_ce: 0.5581  decode.acc_seg: 82.5645\n",
      "03/05 18:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 18:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5000/40000]  base_lr: 5.8675e-05 lr: 5.8675e-05  eta: 6:37:44  time: 0.6507  data_time: 0.0232  memory: 5440  loss: 0.5587  decode.loss_ce: 0.5587  decode.acc_seg: 59.7370\n",
      "03/05 18:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5100/40000]  base_lr: 5.8638e-05 lr: 5.8638e-05  eta: 6:36:19  time: 0.6553  data_time: 0.0231  memory: 5440  loss: 0.5581  decode.loss_ce: 0.5581  decode.acc_seg: 89.8275\n",
      "03/05 18:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5200/40000]  base_lr: 5.8600e-05 lr: 5.8600e-05  eta: 6:34:54  time: 0.6539  data_time: 0.0237  memory: 5440  loss: 0.6809  decode.loss_ce: 0.6809  decode.acc_seg: 56.8803\n",
      "03/05 18:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5300/40000]  base_lr: 5.8562e-05 lr: 5.8562e-05  eta: 6:33:30  time: 0.6555  data_time: 0.0236  memory: 5440  loss: 0.4489  decode.loss_ce: 0.4489  decode.acc_seg: 86.1313\n",
      "03/05 18:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5400/40000]  base_lr: 5.8524e-05 lr: 5.8524e-05  eta: 6:32:06  time: 0.6516  data_time: 0.0232  memory: 5440  loss: 0.4074  decode.loss_ce: 0.4074  decode.acc_seg: 83.8677\n",
      "03/05 18:30:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5500/40000]  base_lr: 5.8486e-05 lr: 5.8486e-05  eta: 6:30:43  time: 0.6534  data_time: 0.0237  memory: 5440  loss: 0.5799  decode.loss_ce: 0.5799  decode.acc_seg: 57.0017\n",
      "03/05 18:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5600/40000]  base_lr: 5.8448e-05 lr: 5.8448e-05  eta: 6:29:21  time: 0.6559  data_time: 0.0230  memory: 5440  loss: 0.3805  decode.loss_ce: 0.3805  decode.acc_seg: 87.8650\n",
      "03/05 18:32:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5700/40000]  base_lr: 5.8410e-05 lr: 5.8410e-05  eta: 6:27:59  time: 0.6524  data_time: 0.0233  memory: 5440  loss: 0.5754  decode.loss_ce: 0.5754  decode.acc_seg: 91.0777\n",
      "03/05 18:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5800/40000]  base_lr: 5.8373e-05 lr: 5.8373e-05  eta: 6:26:39  time: 0.6689  data_time: 0.0246  memory: 5440  loss: 0.5587  decode.loss_ce: 0.5587  decode.acc_seg: 73.3581\n",
      "03/05 18:35:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5900/40000]  base_lr: 5.8335e-05 lr: 5.8335e-05  eta: 6:25:20  time: 0.6622  data_time: 0.0238  memory: 5440  loss: 0.4974  decode.loss_ce: 0.4974  decode.acc_seg: 90.8664\n",
      "03/05 18:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 18:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6000/40000]  base_lr: 5.8297e-05 lr: 5.8297e-05  eta: 6:24:00  time: 0.6523  data_time: 0.0233  memory: 5440  loss: 0.9609  decode.loss_ce: 0.9609  decode.acc_seg: 83.1952\n",
      "03/05 18:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6000 iterations\n",
      "03/05 18:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6100/40000]  base_lr: 5.8259e-05 lr: 5.8259e-05  eta: 6:23:07  time: 0.6558  data_time: 0.0240  memory: 5440  loss: 0.5391  decode.loss_ce: 0.5391  decode.acc_seg: 75.4596\n",
      "03/05 18:38:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6200/40000]  base_lr: 5.8221e-05 lr: 5.8221e-05  eta: 6:21:47  time: 0.6513  data_time: 0.0225  memory: 5440  loss: 0.4276  decode.loss_ce: 0.4276  decode.acc_seg: 92.7289\n",
      "03/05 18:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6300/40000]  base_lr: 5.8183e-05 lr: 5.8183e-05  eta: 6:20:28  time: 0.6568  data_time: 0.0236  memory: 5440  loss: 0.4277  decode.loss_ce: 0.4277  decode.acc_seg: 84.7005\n",
      "03/05 18:40:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6400/40000]  base_lr: 5.8145e-05 lr: 5.8145e-05  eta: 6:19:09  time: 0.6515  data_time: 0.0231  memory: 5440  loss: 0.3564  decode.loss_ce: 0.3564  decode.acc_seg: 74.9418\n",
      "03/05 18:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6500/40000]  base_lr: 5.8108e-05 lr: 5.8108e-05  eta: 6:17:51  time: 0.6576  data_time: 0.0234  memory: 5440  loss: 0.6436  decode.loss_ce: 0.6436  decode.acc_seg: 85.8175\n",
      "03/05 18:42:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6600/40000]  base_lr: 5.8070e-05 lr: 5.8070e-05  eta: 6:16:33  time: 0.6501  data_time: 0.0228  memory: 5440  loss: 0.6495  decode.loss_ce: 0.6495  decode.acc_seg: 88.2593\n",
      "03/05 18:43:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6700/40000]  base_lr: 5.8032e-05 lr: 5.8032e-05  eta: 6:15:15  time: 0.6523  data_time: 0.0230  memory: 5440  loss: 0.4668  decode.loss_ce: 0.4668  decode.acc_seg: 95.9467\n",
      "03/05 18:44:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6800/40000]  base_lr: 5.7994e-05 lr: 5.7994e-05  eta: 6:13:57  time: 0.6629  data_time: 0.0240  memory: 5440  loss: 0.6239  decode.loss_ce: 0.6239  decode.acc_seg: 74.5295\n",
      "03/05 18:46:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6900/40000]  base_lr: 5.7956e-05 lr: 5.7956e-05  eta: 6:12:40  time: 0.6638  data_time: 0.0247  memory: 5440  loss: 0.5328  decode.loss_ce: 0.5328  decode.acc_seg: 74.8031\n",
      "03/05 18:47:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 18:47:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7000/40000]  base_lr: 5.7918e-05 lr: 5.7918e-05  eta: 6:11:23  time: 0.6647  data_time: 0.0248  memory: 5440  loss: 0.5305  decode.loss_ce: 0.5305  decode.acc_seg: 54.9391\n",
      "03/05 18:48:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7100/40000]  base_lr: 5.7880e-05 lr: 5.7880e-05  eta: 6:10:08  time: 0.6539  data_time: 0.0232  memory: 5440  loss: 0.5853  decode.loss_ce: 0.5853  decode.acc_seg: 81.2970\n",
      "03/05 18:49:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7200/40000]  base_lr: 5.7843e-05 lr: 5.7843e-05  eta: 6:08:51  time: 0.6584  data_time: 0.0241  memory: 5440  loss: 0.5715  decode.loss_ce: 0.5715  decode.acc_seg: 72.1945\n",
      "03/05 18:50:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7300/40000]  base_lr: 5.7805e-05 lr: 5.7805e-05  eta: 6:07:36  time: 0.6530  data_time: 0.0239  memory: 5440  loss: 0.4169  decode.loss_ce: 0.4169  decode.acc_seg: 80.7113\n",
      "03/05 18:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7400/40000]  base_lr: 5.7767e-05 lr: 5.7767e-05  eta: 6:06:21  time: 0.6530  data_time: 0.0239  memory: 5440  loss: 0.3822  decode.loss_ce: 0.3822  decode.acc_seg: 88.1133\n",
      "03/05 18:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7500/40000]  base_lr: 5.7729e-05 lr: 5.7729e-05  eta: 6:05:06  time: 0.6532  data_time: 0.0238  memory: 5440  loss: 0.7147  decode.loss_ce: 0.7147  decode.acc_seg: 62.7382\n",
      "03/05 18:53:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7600/40000]  base_lr: 5.7691e-05 lr: 5.7691e-05  eta: 6:03:52  time: 0.6535  data_time: 0.0231  memory: 5440  loss: 0.4186  decode.loss_ce: 0.4186  decode.acc_seg: 93.0789\n",
      "03/05 18:54:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7700/40000]  base_lr: 5.7653e-05 lr: 5.7653e-05  eta: 6:02:38  time: 0.6573  data_time: 0.0238  memory: 5440  loss: 0.6806  decode.loss_ce: 0.6806  decode.acc_seg: 85.3287\n",
      "03/05 18:55:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7800/40000]  base_lr: 5.7616e-05 lr: 5.7616e-05  eta: 6:01:25  time: 0.6587  data_time: 0.0240  memory: 5440  loss: 0.4054  decode.loss_ce: 0.4054  decode.acc_seg: 83.6964\n",
      "03/05 18:57:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7900/40000]  base_lr: 5.7578e-05 lr: 5.7578e-05  eta: 6:00:11  time: 0.6599  data_time: 0.0245  memory: 5440  loss: 0.2713  decode.loss_ce: 0.2713  decode.acc_seg: 96.0128\n",
      "03/05 18:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 18:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8000/40000]  base_lr: 5.7540e-05 lr: 5.7540e-05  eta: 5:58:59  time: 0.6557  data_time: 0.0239  memory: 5440  loss: 0.4175  decode.loss_ce: 0.4175  decode.acc_seg: 86.5884\n",
      "03/05 18:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8000 iterations\n",
      "03/05 18:59:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8100/40000]  base_lr: 5.7502e-05 lr: 5.7502e-05  eta: 5:58:05  time: 0.6618  data_time: 0.0248  memory: 5440  loss: 0.4809  decode.loss_ce: 0.4809  decode.acc_seg: 84.1615\n",
      "03/05 19:00:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8200/40000]  base_lr: 5.7464e-05 lr: 5.7464e-05  eta: 5:56:51  time: 0.6540  data_time: 0.0236  memory: 5440  loss: 0.5920  decode.loss_ce: 0.5920  decode.acc_seg: 53.0526\n",
      "03/05 19:01:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8300/40000]  base_lr: 5.7426e-05 lr: 5.7426e-05  eta: 5:55:38  time: 0.6604  data_time: 0.0238  memory: 5440  loss: 0.6557  decode.loss_ce: 0.6557  decode.acc_seg: 60.3723\n",
      "03/05 19:02:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8400/40000]  base_lr: 5.7388e-05 lr: 5.7388e-05  eta: 5:54:26  time: 0.6733  data_time: 0.0443  memory: 5440  loss: 0.4420  decode.loss_ce: 0.4420  decode.acc_seg: 68.8372\n",
      "03/05 19:03:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8500/40000]  base_lr: 5.7351e-05 lr: 5.7351e-05  eta: 5:53:13  time: 0.6553  data_time: 0.0238  memory: 5440  loss: 0.3316  decode.loss_ce: 0.3316  decode.acc_seg: 89.2196\n",
      "03/05 19:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8600/40000]  base_lr: 5.7313e-05 lr: 5.7313e-05  eta: 5:52:00  time: 0.6511  data_time: 0.0231  memory: 5440  loss: 0.4910  decode.loss_ce: 0.4910  decode.acc_seg: 73.5485\n",
      "03/05 19:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8700/40000]  base_lr: 5.7275e-05 lr: 5.7275e-05  eta: 5:50:47  time: 0.6539  data_time: 0.0235  memory: 5440  loss: 0.7222  decode.loss_ce: 0.7222  decode.acc_seg: 61.2633\n",
      "03/05 19:06:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8800/40000]  base_lr: 5.7237e-05 lr: 5.7237e-05  eta: 5:49:35  time: 0.6578  data_time: 0.0230  memory: 5440  loss: 0.3597  decode.loss_ce: 0.3597  decode.acc_seg: 82.5413\n",
      "03/05 19:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8900/40000]  base_lr: 5.7199e-05 lr: 5.7199e-05  eta: 5:48:22  time: 0.6544  data_time: 0.0241  memory: 5440  loss: 0.2936  decode.loss_ce: 0.2936  decode.acc_seg: 89.8771\n",
      "03/05 19:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 19:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9000/40000]  base_lr: 5.7161e-05 lr: 5.7161e-05  eta: 5:47:11  time: 0.6538  data_time: 0.0238  memory: 5440  loss: 0.4164  decode.loss_ce: 0.4164  decode.acc_seg: 67.5950\n",
      "03/05 19:10:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9100/40000]  base_lr: 5.7123e-05 lr: 5.7123e-05  eta: 5:45:59  time: 0.6674  data_time: 0.0246  memory: 5440  loss: 0.5694  decode.loss_ce: 0.5694  decode.acc_seg: 76.4521\n",
      "03/05 19:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9200/40000]  base_lr: 5.7086e-05 lr: 5.7086e-05  eta: 5:44:51  time: 0.6655  data_time: 0.0246  memory: 5440  loss: 0.4831  decode.loss_ce: 0.4831  decode.acc_seg: 78.1554\n",
      "03/05 19:12:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9300/40000]  base_lr: 5.7048e-05 lr: 5.7048e-05  eta: 5:43:40  time: 0.6620  data_time: 0.0242  memory: 5440  loss: 0.5206  decode.loss_ce: 0.5206  decode.acc_seg: 91.2025\n",
      "03/05 19:13:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9400/40000]  base_lr: 5.7010e-05 lr: 5.7010e-05  eta: 5:42:28  time: 0.6528  data_time: 0.0226  memory: 5440  loss: 0.3665  decode.loss_ce: 0.3665  decode.acc_seg: 78.1190\n",
      "03/05 19:14:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9500/40000]  base_lr: 5.6972e-05 lr: 5.6972e-05  eta: 5:41:17  time: 0.6580  data_time: 0.0235  memory: 5440  loss: 0.4257  decode.loss_ce: 0.4257  decode.acc_seg: 64.4615\n",
      "03/05 19:15:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9600/40000]  base_lr: 5.6934e-05 lr: 5.6934e-05  eta: 5:40:05  time: 0.6548  data_time: 0.0238  memory: 5440  loss: 0.4460  decode.loss_ce: 0.4460  decode.acc_seg: 83.3423\n",
      "03/05 19:16:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9700/40000]  base_lr: 5.6896e-05 lr: 5.6896e-05  eta: 5:38:53  time: 0.6549  data_time: 0.0239  memory: 5440  loss: 0.4691  decode.loss_ce: 0.4691  decode.acc_seg: 90.3629\n",
      "03/05 19:17:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9800/40000]  base_lr: 5.6858e-05 lr: 5.6858e-05  eta: 5:37:42  time: 0.6529  data_time: 0.0233  memory: 5440  loss: 0.3711  decode.loss_ce: 0.3711  decode.acc_seg: 89.1897\n",
      "03/05 19:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9900/40000]  base_lr: 5.6821e-05 lr: 5.6821e-05  eta: 5:36:30  time: 0.6513  data_time: 0.0233  memory: 5440  loss: 0.6599  decode.loss_ce: 0.6599  decode.acc_seg: 81.7822\n",
      "03/05 19:20:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 19:20:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10000/40000]  base_lr: 5.6783e-05 lr: 5.6783e-05  eta: 5:35:19  time: 0.6517  data_time: 0.0230  memory: 5440  loss: 0.4180  decode.loss_ce: 0.4180  decode.acc_seg: 90.2082\n",
      "03/05 19:20:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10000 iterations\n",
      "03/05 19:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10100/40000]  base_lr: 5.6745e-05 lr: 5.6745e-05  eta: 5:34:23  time: 0.6609  data_time: 0.0246  memory: 5440  loss: 0.6527  decode.loss_ce: 0.6527  decode.acc_seg: 92.6531\n",
      "03/05 19:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10200/40000]  base_lr: 5.6707e-05 lr: 5.6707e-05  eta: 5:33:13  time: 0.6616  data_time: 0.0249  memory: 5440  loss: 0.3405  decode.loss_ce: 0.3405  decode.acc_seg: 98.0263\n",
      "03/05 19:23:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10300/40000]  base_lr: 5.6669e-05 lr: 5.6669e-05  eta: 5:32:04  time: 0.6664  data_time: 0.0254  memory: 5440  loss: 0.4275  decode.loss_ce: 0.4275  decode.acc_seg: 75.7206\n",
      "03/05 19:24:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10400/40000]  base_lr: 5.6631e-05 lr: 5.6631e-05  eta: 5:30:54  time: 0.6553  data_time: 0.0234  memory: 5440  loss: 0.5226  decode.loss_ce: 0.5226  decode.acc_seg: 77.9493\n",
      "03/05 19:25:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10500/40000]  base_lr: 5.6593e-05 lr: 5.6593e-05  eta: 5:29:43  time: 0.6523  data_time: 0.0238  memory: 5440  loss: 0.2832  decode.loss_ce: 0.2832  decode.acc_seg: 83.0070\n",
      "03/05 19:26:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10600/40000]  base_lr: 5.6556e-05 lr: 5.6556e-05  eta: 5:28:33  time: 0.6596  data_time: 0.0248  memory: 5440  loss: 0.5870  decode.loss_ce: 0.5870  decode.acc_seg: 81.0218\n",
      "03/05 19:27:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10700/40000]  base_lr: 5.6518e-05 lr: 5.6518e-05  eta: 5:27:24  time: 0.6621  data_time: 0.0241  memory: 5440  loss: 0.5943  decode.loss_ce: 0.5943  decode.acc_seg: 76.3943\n",
      "03/05 19:29:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10800/40000]  base_lr: 5.6480e-05 lr: 5.6480e-05  eta: 5:26:14  time: 0.6527  data_time: 0.0235  memory: 5440  loss: 0.5104  decode.loss_ce: 0.5104  decode.acc_seg: 90.4818\n",
      "03/05 19:30:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10900/40000]  base_lr: 5.6442e-05 lr: 5.6442e-05  eta: 5:25:04  time: 0.6517  data_time: 0.0231  memory: 5440  loss: 0.4679  decode.loss_ce: 0.4679  decode.acc_seg: 84.9250\n",
      "03/05 19:31:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 19:31:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11000/40000]  base_lr: 5.6404e-05 lr: 5.6404e-05  eta: 5:23:53  time: 0.6528  data_time: 0.0228  memory: 5440  loss: 0.3737  decode.loss_ce: 0.3737  decode.acc_seg: 81.8706\n",
      "03/05 19:32:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11100/40000]  base_lr: 5.6366e-05 lr: 5.6366e-05  eta: 5:22:43  time: 0.6568  data_time: 0.0247  memory: 5440  loss: 0.3950  decode.loss_ce: 0.3950  decode.acc_seg: 82.6435\n",
      "03/05 19:33:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11200/40000]  base_lr: 5.6328e-05 lr: 5.6328e-05  eta: 5:21:32  time: 0.6508  data_time: 0.0227  memory: 5440  loss: 0.4377  decode.loss_ce: 0.4377  decode.acc_seg: 90.8640\n",
      "03/05 19:34:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11300/40000]  base_lr: 5.6291e-05 lr: 5.6291e-05  eta: 5:20:22  time: 0.6583  data_time: 0.0242  memory: 5440  loss: 0.4025  decode.loss_ce: 0.4025  decode.acc_seg: 88.4790\n",
      "03/05 19:35:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11400/40000]  base_lr: 5.6253e-05 lr: 5.6253e-05  eta: 5:19:13  time: 0.6657  data_time: 0.0253  memory: 5440  loss: 0.4997  decode.loss_ce: 0.4997  decode.acc_seg: 86.4264\n",
      "03/05 19:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11500/40000]  base_lr: 5.6215e-05 lr: 5.6215e-05  eta: 5:18:03  time: 0.6600  data_time: 0.0242  memory: 5440  loss: 0.5588  decode.loss_ce: 0.5588  decode.acc_seg: 73.1677\n",
      "03/05 19:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11600/40000]  base_lr: 5.6177e-05 lr: 5.6177e-05  eta: 5:16:53  time: 0.6654  data_time: 0.0245  memory: 5440  loss: 0.4949  decode.loss_ce: 0.4949  decode.acc_seg: 71.0814\n",
      "03/05 19:38:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11700/40000]  base_lr: 5.6139e-05 lr: 5.6139e-05  eta: 5:15:43  time: 0.6544  data_time: 0.0230  memory: 5440  loss: 0.2558  decode.loss_ce: 0.2558  decode.acc_seg: 91.6237\n",
      "03/05 19:39:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11800/40000]  base_lr: 5.6101e-05 lr: 5.6101e-05  eta: 5:14:33  time: 0.6562  data_time: 0.0234  memory: 5440  loss: 0.3308  decode.loss_ce: 0.3308  decode.acc_seg: 78.7031\n",
      "03/05 19:41:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11900/40000]  base_lr: 5.6063e-05 lr: 5.6063e-05  eta: 5:13:23  time: 0.6555  data_time: 0.0225  memory: 5440  loss: 0.4161  decode.loss_ce: 0.4161  decode.acc_seg: 76.1048\n",
      "03/05 19:42:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 19:42:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12000/40000]  base_lr: 5.6026e-05 lr: 5.6026e-05  eta: 5:12:13  time: 0.6542  data_time: 0.0238  memory: 5440  loss: 0.3326  decode.loss_ce: 0.3326  decode.acc_seg: 64.5021\n",
      "03/05 19:42:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12000 iterations\n",
      "03/05 19:43:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12100/40000]  base_lr: 5.5988e-05 lr: 5.5988e-05  eta: 5:11:14  time: 0.6538  data_time: 0.0233  memory: 5440  loss: 0.5701  decode.loss_ce: 0.5701  decode.acc_seg: 89.1950\n",
      "03/05 19:44:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12200/40000]  base_lr: 5.5950e-05 lr: 5.5950e-05  eta: 5:10:04  time: 0.6590  data_time: 0.0246  memory: 5440  loss: 0.3844  decode.loss_ce: 0.3844  decode.acc_seg: 71.3289\n",
      "03/05 19:45:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12300/40000]  base_lr: 5.5912e-05 lr: 5.5912e-05  eta: 5:08:54  time: 0.6524  data_time: 0.0235  memory: 5440  loss: 0.5104  decode.loss_ce: 0.5104  decode.acc_seg: 93.3266\n",
      "03/05 19:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12400/40000]  base_lr: 5.5874e-05 lr: 5.5874e-05  eta: 5:07:45  time: 0.6531  data_time: 0.0237  memory: 5440  loss: 0.5271  decode.loss_ce: 0.5271  decode.acc_seg: 95.9312\n",
      "03/05 19:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12500/40000]  base_lr: 5.5836e-05 lr: 5.5836e-05  eta: 5:06:36  time: 0.6565  data_time: 0.0251  memory: 5440  loss: 0.3799  decode.loss_ce: 0.3799  decode.acc_seg: 93.3794\n",
      "03/05 19:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12600/40000]  base_lr: 5.5798e-05 lr: 5.5798e-05  eta: 5:05:28  time: 0.6716  data_time: 0.0319  memory: 5440  loss: 0.4908  decode.loss_ce: 0.4908  decode.acc_seg: 96.5132\n",
      "03/05 19:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12700/40000]  base_lr: 5.5761e-05 lr: 5.5761e-05  eta: 5:04:19  time: 0.6707  data_time: 0.0259  memory: 5440  loss: 0.2847  decode.loss_ce: 0.2847  decode.acc_seg: 92.1669\n",
      "03/05 19:51:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12800/40000]  base_lr: 5.5723e-05 lr: 5.5723e-05  eta: 5:03:10  time: 0.6548  data_time: 0.0244  memory: 5440  loss: 0.2827  decode.loss_ce: 0.2827  decode.acc_seg: 83.1599\n",
      "03/05 19:52:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12900/40000]  base_lr: 5.5685e-05 lr: 5.5685e-05  eta: 5:02:00  time: 0.6537  data_time: 0.0246  memory: 5440  loss: 0.3605  decode.loss_ce: 0.3605  decode.acc_seg: 73.6161\n",
      "03/05 19:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 19:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13000/40000]  base_lr: 5.5647e-05 lr: 5.5647e-05  eta: 5:00:51  time: 0.6524  data_time: 0.0236  memory: 5440  loss: 0.3664  decode.loss_ce: 0.3664  decode.acc_seg: 98.8457\n",
      "03/05 19:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13100/40000]  base_lr: 5.5609e-05 lr: 5.5609e-05  eta: 4:59:42  time: 0.6600  data_time: 0.0252  memory: 5440  loss: 0.2730  decode.loss_ce: 0.2730  decode.acc_seg: 94.6179\n",
      "03/05 19:55:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13200/40000]  base_lr: 5.5571e-05 lr: 5.5571e-05  eta: 4:58:33  time: 0.6548  data_time: 0.0240  memory: 5440  loss: 0.2995  decode.loss_ce: 0.2995  decode.acc_seg: 87.3148\n",
      "03/05 19:56:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13300/40000]  base_lr: 5.5533e-05 lr: 5.5533e-05  eta: 4:57:24  time: 0.6554  data_time: 0.0235  memory: 5440  loss: 0.3047  decode.loss_ce: 0.3047  decode.acc_seg: 88.5265\n",
      "03/05 19:57:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13400/40000]  base_lr: 5.5496e-05 lr: 5.5496e-05  eta: 4:56:15  time: 0.6552  data_time: 0.0246  memory: 5440  loss: 0.4528  decode.loss_ce: 0.4528  decode.acc_seg: 81.1471\n",
      "03/05 19:58:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13500/40000]  base_lr: 5.5458e-05 lr: 5.5458e-05  eta: 4:55:05  time: 0.6528  data_time: 0.0235  memory: 5440  loss: 0.5467  decode.loss_ce: 0.5467  decode.acc_seg: 36.6354\n",
      "03/05 19:59:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13600/40000]  base_lr: 5.5420e-05 lr: 5.5420e-05  eta: 4:53:56  time: 0.6557  data_time: 0.0237  memory: 5440  loss: 0.5670  decode.loss_ce: 0.5670  decode.acc_seg: 96.3785\n",
      "03/05 20:00:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13700/40000]  base_lr: 5.5382e-05 lr: 5.5382e-05  eta: 4:52:47  time: 0.6555  data_time: 0.0239  memory: 5440  loss: 0.4064  decode.loss_ce: 0.4064  decode.acc_seg: 40.1705\n",
      "03/05 20:01:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13800/40000]  base_lr: 5.5344e-05 lr: 5.5344e-05  eta: 4:51:39  time: 0.6653  data_time: 0.0265  memory: 5440  loss: 0.2884  decode.loss_ce: 0.2884  decode.acc_seg: 86.1347\n",
      "03/05 20:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13900/40000]  base_lr: 5.5306e-05 lr: 5.5306e-05  eta: 4:50:31  time: 0.6890  data_time: 0.0443  memory: 5440  loss: 0.5228  decode.loss_ce: 0.5228  decode.acc_seg: 88.2405\n",
      "03/05 20:04:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 20:04:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14000/40000]  base_lr: 5.5268e-05 lr: 5.5268e-05  eta: 4:49:26  time: 0.6638  data_time: 0.0317  memory: 5440  loss: 0.5623  decode.loss_ce: 0.5623  decode.acc_seg: 61.7415\n",
      "03/05 20:04:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 14000 iterations\n",
      "03/05 20:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14100/40000]  base_lr: 5.5231e-05 lr: 5.5231e-05  eta: 4:48:28  time: 0.6517  data_time: 0.0238  memory: 5440  loss: 0.4903  decode.loss_ce: 0.4903  decode.acc_seg: 82.4703\n",
      "03/05 20:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14200/40000]  base_lr: 5.5193e-05 lr: 5.5193e-05  eta: 4:47:19  time: 0.6550  data_time: 0.0238  memory: 5440  loss: 0.4200  decode.loss_ce: 0.4200  decode.acc_seg: 87.8161\n",
      "03/05 20:07:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14300/40000]  base_lr: 5.5155e-05 lr: 5.5155e-05  eta: 4:46:10  time: 0.6562  data_time: 0.0246  memory: 5440  loss: 0.4296  decode.loss_ce: 0.4296  decode.acc_seg: 78.4415\n",
      "03/05 20:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14400/40000]  base_lr: 5.5117e-05 lr: 5.5117e-05  eta: 4:45:01  time: 0.6572  data_time: 0.0236  memory: 5440  loss: 0.3059  decode.loss_ce: 0.3059  decode.acc_seg: 67.5571\n",
      "03/05 20:09:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14500/40000]  base_lr: 5.5079e-05 lr: 5.5079e-05  eta: 4:43:53  time: 0.6536  data_time: 0.0241  memory: 5440  loss: 0.4550  decode.loss_ce: 0.4550  decode.acc_seg: 72.0098\n",
      "03/05 20:10:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14600/40000]  base_lr: 5.5041e-05 lr: 5.5041e-05  eta: 4:42:45  time: 0.6582  data_time: 0.0242  memory: 5440  loss: 0.4358  decode.loss_ce: 0.4358  decode.acc_seg: 87.8532\n",
      "03/05 20:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14700/40000]  base_lr: 5.5004e-05 lr: 5.5004e-05  eta: 4:41:36  time: 0.6561  data_time: 0.0238  memory: 5440  loss: 0.2667  decode.loss_ce: 0.2667  decode.acc_seg: 89.8885\n",
      "03/05 20:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14800/40000]  base_lr: 5.4966e-05 lr: 5.4966e-05  eta: 4:40:27  time: 0.6608  data_time: 0.0254  memory: 5440  loss: 0.4088  decode.loss_ce: 0.4088  decode.acc_seg: 88.6358\n",
      "03/05 20:14:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14900/40000]  base_lr: 5.4928e-05 lr: 5.4928e-05  eta: 4:39:19  time: 0.6667  data_time: 0.0251  memory: 5440  loss: 0.4336  decode.loss_ce: 0.4336  decode.acc_seg: 82.7085\n",
      "03/05 20:15:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 20:15:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15000/40000]  base_lr: 5.4890e-05 lr: 5.4890e-05  eta: 4:38:10  time: 0.6563  data_time: 0.0243  memory: 5440  loss: 0.4408  decode.loss_ce: 0.4408  decode.acc_seg: 93.4722\n",
      "03/05 20:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15100/40000]  base_lr: 5.4852e-05 lr: 5.4852e-05  eta: 4:37:02  time: 0.6522  data_time: 0.0233  memory: 5440  loss: 0.3918  decode.loss_ce: 0.3918  decode.acc_seg: 79.1301\n",
      "03/05 20:17:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15200/40000]  base_lr: 5.4814e-05 lr: 5.4814e-05  eta: 4:35:53  time: 0.6590  data_time: 0.0259  memory: 5440  loss: 0.3083  decode.loss_ce: 0.3083  decode.acc_seg: 66.1058\n",
      "03/05 20:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15300/40000]  base_lr: 5.4776e-05 lr: 5.4776e-05  eta: 4:34:45  time: 0.6521  data_time: 0.0233  memory: 5440  loss: 0.2827  decode.loss_ce: 0.2827  decode.acc_seg: 94.7713\n",
      "03/05 20:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15400/40000]  base_lr: 5.4739e-05 lr: 5.4739e-05  eta: 4:33:36  time: 0.6557  data_time: 0.0235  memory: 5440  loss: 0.4732  decode.loss_ce: 0.4732  decode.acc_seg: 68.3577\n",
      "03/05 20:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15500/40000]  base_lr: 5.4701e-05 lr: 5.4701e-05  eta: 4:32:28  time: 0.6541  data_time: 0.0236  memory: 5440  loss: 0.3876  decode.loss_ce: 0.3876  decode.acc_seg: 83.8957\n",
      "03/05 20:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15600/40000]  base_lr: 5.4663e-05 lr: 5.4663e-05  eta: 4:31:20  time: 0.6599  data_time: 0.0243  memory: 5440  loss: 0.2911  decode.loss_ce: 0.2911  decode.acc_seg: 93.1719\n",
      "03/05 20:22:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15700/40000]  base_lr: 5.4625e-05 lr: 5.4625e-05  eta: 4:30:11  time: 0.6538  data_time: 0.0252  memory: 5440  loss: 0.3428  decode.loss_ce: 0.3428  decode.acc_seg: 60.2482\n",
      "03/05 20:24:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15800/40000]  base_lr: 5.4587e-05 lr: 5.4587e-05  eta: 4:29:03  time: 0.6556  data_time: 0.0243  memory: 5440  loss: 0.4585  decode.loss_ce: 0.4585  decode.acc_seg: 63.0585\n",
      "03/05 20:25:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15900/40000]  base_lr: 5.4549e-05 lr: 5.4549e-05  eta: 4:27:54  time: 0.6571  data_time: 0.0235  memory: 5440  loss: 0.3112  decode.loss_ce: 0.3112  decode.acc_seg: 84.5903\n",
      "03/05 20:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 20:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16000/40000]  base_lr: 5.4511e-05 lr: 5.4511e-05  eta: 4:26:46  time: 0.6518  data_time: 0.0232  memory: 5440  loss: 0.5891  decode.loss_ce: 0.5891  decode.acc_seg: 82.0988\n",
      "03/05 20:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16000 iterations\n",
      "03/05 20:27:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16100/40000]  base_lr: 5.4474e-05 lr: 5.4474e-05  eta: 4:25:54  time: 0.7246  data_time: 0.0932  memory: 5440  loss: 0.4865  decode.loss_ce: 0.4865  decode.acc_seg: 90.3213\n",
      "03/05 20:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16200/40000]  base_lr: 5.4436e-05 lr: 5.4436e-05  eta: 4:24:56  time: 0.7188  data_time: 0.0892  memory: 5440  loss: 0.2622  decode.loss_ce: 0.2622  decode.acc_seg: 81.5355\n",
      "03/05 20:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16300/40000]  base_lr: 5.4398e-05 lr: 5.4398e-05  eta: 4:23:57  time: 0.7155  data_time: 0.0780  memory: 5440  loss: 0.5508  decode.loss_ce: 0.5508  decode.acc_seg: 93.1167\n",
      "03/05 20:31:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16400/40000]  base_lr: 5.4360e-05 lr: 5.4360e-05  eta: 4:22:56  time: 0.7167  data_time: 0.0872  memory: 5440  loss: 0.4642  decode.loss_ce: 0.4642  decode.acc_seg: 98.3479\n",
      "03/05 20:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16500/40000]  base_lr: 5.4322e-05 lr: 5.4322e-05  eta: 4:21:56  time: 0.7269  data_time: 0.0974  memory: 5440  loss: 0.3925  decode.loss_ce: 0.3925  decode.acc_seg: 83.5337\n",
      "03/05 20:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16600/40000]  base_lr: 5.4284e-05 lr: 5.4284e-05  eta: 4:20:56  time: 0.7095  data_time: 0.0797  memory: 5440  loss: 0.4187  decode.loss_ce: 0.4187  decode.acc_seg: 92.8788\n",
      "03/05 20:34:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16700/40000]  base_lr: 5.4246e-05 lr: 5.4246e-05  eta: 4:19:49  time: 0.6565  data_time: 0.0246  memory: 5440  loss: 0.4912  decode.loss_ce: 0.4912  decode.acc_seg: 77.3980\n",
      "03/05 20:35:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16800/40000]  base_lr: 5.4209e-05 lr: 5.4209e-05  eta: 4:18:41  time: 0.6594  data_time: 0.0236  memory: 5440  loss: 0.3414  decode.loss_ce: 0.3414  decode.acc_seg: 90.0555\n",
      "03/05 20:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16900/40000]  base_lr: 5.4171e-05 lr: 5.4171e-05  eta: 4:17:32  time: 0.6768  data_time: 0.0268  memory: 5440  loss: 0.2760  decode.loss_ce: 0.2760  decode.acc_seg: 80.2952\n",
      "03/05 20:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 20:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17000/40000]  base_lr: 5.4133e-05 lr: 5.4133e-05  eta: 4:16:24  time: 0.6675  data_time: 0.0260  memory: 5440  loss: 0.4372  decode.loss_ce: 0.4372  decode.acc_seg: 65.2844\n",
      "03/05 20:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17100/40000]  base_lr: 5.4095e-05 lr: 5.4095e-05  eta: 4:15:16  time: 0.6583  data_time: 0.0234  memory: 5440  loss: 0.4052  decode.loss_ce: 0.4052  decode.acc_seg: 69.1662\n",
      "03/05 20:40:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17200/40000]  base_lr: 5.4057e-05 lr: 5.4057e-05  eta: 4:14:07  time: 0.6517  data_time: 0.0241  memory: 5440  loss: 0.3740  decode.loss_ce: 0.3740  decode.acc_seg: 86.3265\n",
      "03/05 20:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17300/40000]  base_lr: 5.4019e-05 lr: 5.4019e-05  eta: 4:12:59  time: 0.6595  data_time: 0.0246  memory: 5440  loss: 0.5107  decode.loss_ce: 0.5107  decode.acc_seg: 79.9935\n",
      "03/05 20:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17400/40000]  base_lr: 5.3981e-05 lr: 5.3981e-05  eta: 4:11:50  time: 0.6546  data_time: 0.0243  memory: 5440  loss: 0.2936  decode.loss_ce: 0.2936  decode.acc_seg: 85.3278\n",
      "03/05 20:43:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17500/40000]  base_lr: 5.3944e-05 lr: 5.3944e-05  eta: 4:10:42  time: 0.6491  data_time: 0.0235  memory: 5440  loss: 0.3146  decode.loss_ce: 0.3146  decode.acc_seg: 86.2113\n",
      "03/05 20:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17600/40000]  base_lr: 5.3906e-05 lr: 5.3906e-05  eta: 4:09:33  time: 0.6530  data_time: 0.0239  memory: 5440  loss: 0.3065  decode.loss_ce: 0.3065  decode.acc_seg: 90.5552\n",
      "03/05 20:45:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17700/40000]  base_lr: 5.3868e-05 lr: 5.3868e-05  eta: 4:08:25  time: 0.6554  data_time: 0.0236  memory: 5440  loss: 0.2997  decode.loss_ce: 0.2997  decode.acc_seg: 81.3160\n",
      "03/05 20:46:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17800/40000]  base_lr: 5.3830e-05 lr: 5.3830e-05  eta: 4:07:16  time: 0.6515  data_time: 0.0234  memory: 5440  loss: 0.2618  decode.loss_ce: 0.2618  decode.acc_seg: 75.0678\n",
      "03/05 20:47:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17900/40000]  base_lr: 5.3792e-05 lr: 5.3792e-05  eta: 4:06:07  time: 0.6485  data_time: 0.0226  memory: 5440  loss: 0.3629  decode.loss_ce: 0.3629  decode.acc_seg: 88.3201\n",
      "03/05 20:48:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 20:48:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18000/40000]  base_lr: 5.3754e-05 lr: 5.3754e-05  eta: 4:04:59  time: 0.6501  data_time: 0.0225  memory: 5440  loss: 0.5141  decode.loss_ce: 0.5141  decode.acc_seg: 81.3183\n",
      "03/05 20:48:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18000 iterations\n",
      "03/05 20:49:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18100/40000]  base_lr: 5.3716e-05 lr: 5.3716e-05  eta: 4:03:56  time: 0.6614  data_time: 0.0246  memory: 5440  loss: 0.2243  decode.loss_ce: 0.2243  decode.acc_seg: 97.0564\n",
      "03/05 20:51:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18200/40000]  base_lr: 5.3679e-05 lr: 5.3679e-05  eta: 4:02:47  time: 0.6625  data_time: 0.0243  memory: 5440  loss: 0.3628  decode.loss_ce: 0.3628  decode.acc_seg: 71.0493\n",
      "03/05 20:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18300/40000]  base_lr: 5.3641e-05 lr: 5.3641e-05  eta: 4:01:39  time: 0.6541  data_time: 0.0233  memory: 5440  loss: 0.3490  decode.loss_ce: 0.3490  decode.acc_seg: 88.2166\n",
      "03/05 20:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18400/40000]  base_lr: 5.3603e-05 lr: 5.3603e-05  eta: 4:00:31  time: 0.6505  data_time: 0.0230  memory: 5440  loss: 0.4618  decode.loss_ce: 0.4618  decode.acc_seg: 88.2088\n",
      "03/05 20:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18500/40000]  base_lr: 5.3565e-05 lr: 5.3565e-05  eta: 3:59:24  time: 0.6496  data_time: 0.0229  memory: 5440  loss: 0.4344  decode.loss_ce: 0.4344  decode.acc_seg: 81.4716\n",
      "03/05 20:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18600/40000]  base_lr: 5.3527e-05 lr: 5.3527e-05  eta: 3:58:17  time: 0.6522  data_time: 0.0238  memory: 5440  loss: 0.6243  decode.loss_ce: 0.6243  decode.acc_seg: 82.6741\n",
      "03/05 20:56:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18700/40000]  base_lr: 5.3489e-05 lr: 5.3489e-05  eta: 3:57:10  time: 0.6933  data_time: 0.0628  memory: 5440  loss: 0.4430  decode.loss_ce: 0.4430  decode.acc_seg: 74.2016\n",
      "03/05 20:57:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18800/40000]  base_lr: 5.3451e-05 lr: 5.3451e-05  eta: 3:56:03  time: 0.6500  data_time: 0.0228  memory: 5440  loss: 0.3466  decode.loss_ce: 0.3466  decode.acc_seg: 73.5972\n",
      "03/05 20:58:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18900/40000]  base_lr: 5.3414e-05 lr: 5.3414e-05  eta: 3:54:54  time: 0.6483  data_time: 0.0226  memory: 5440  loss: 0.3459  decode.loss_ce: 0.3459  decode.acc_seg: 78.6144\n",
      "03/05 20:59:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 20:59:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19000/40000]  base_lr: 5.3376e-05 lr: 5.3376e-05  eta: 3:53:46  time: 0.6535  data_time: 0.0234  memory: 5440  loss: 0.4628  decode.loss_ce: 0.4628  decode.acc_seg: 77.8196\n",
      "03/05 21:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19100/40000]  base_lr: 5.3338e-05 lr: 5.3338e-05  eta: 3:52:38  time: 0.6546  data_time: 0.0240  memory: 5440  loss: 0.3481  decode.loss_ce: 0.3481  decode.acc_seg: 92.6660\n",
      "03/05 21:02:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19200/40000]  base_lr: 5.3300e-05 lr: 5.3300e-05  eta: 3:51:29  time: 0.6480  data_time: 0.0226  memory: 5440  loss: 0.2468  decode.loss_ce: 0.2468  decode.acc_seg: 90.7401\n",
      "03/05 21:03:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19300/40000]  base_lr: 5.3262e-05 lr: 5.3262e-05  eta: 3:50:21  time: 0.6601  data_time: 0.0227  memory: 5440  loss: 0.3438  decode.loss_ce: 0.3438  decode.acc_seg: 85.6947\n",
      "03/05 21:04:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19400/40000]  base_lr: 5.3224e-05 lr: 5.3224e-05  eta: 3:49:13  time: 0.6690  data_time: 0.0233  memory: 5440  loss: 0.3713  decode.loss_ce: 0.3713  decode.acc_seg: 95.1360\n",
      "03/05 21:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19500/40000]  base_lr: 5.3186e-05 lr: 5.3186e-05  eta: 3:48:05  time: 0.6610  data_time: 0.0248  memory: 5440  loss: 0.3574  decode.loss_ce: 0.3574  decode.acc_seg: 87.2009\n",
      "03/05 21:06:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19600/40000]  base_lr: 5.3149e-05 lr: 5.3149e-05  eta: 3:46:57  time: 0.6506  data_time: 0.0235  memory: 5440  loss: 0.3112  decode.loss_ce: 0.3112  decode.acc_seg: 95.0680\n",
      "03/05 21:07:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19700/40000]  base_lr: 5.3111e-05 lr: 5.3111e-05  eta: 3:45:49  time: 0.6547  data_time: 0.0241  memory: 5440  loss: 0.3533  decode.loss_ce: 0.3533  decode.acc_seg: 71.9968\n",
      "03/05 21:08:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19800/40000]  base_lr: 5.3073e-05 lr: 5.3073e-05  eta: 3:44:41  time: 0.6536  data_time: 0.0239  memory: 5440  loss: 0.4759  decode.loss_ce: 0.4759  decode.acc_seg: 82.7842\n",
      "03/05 21:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19900/40000]  base_lr: 5.3035e-05 lr: 5.3035e-05  eta: 3:43:33  time: 0.6546  data_time: 0.0249  memory: 5440  loss: 0.2422  decode.loss_ce: 0.2422  decode.acc_seg: 74.5910\n",
      "03/05 21:10:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 21:10:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20000/40000]  base_lr: 5.2997e-05 lr: 5.2997e-05  eta: 3:42:25  time: 0.6489  data_time: 0.0226  memory: 5440  loss: 0.2127  decode.loss_ce: 0.2127  decode.acc_seg: 88.8091\n",
      "03/05 21:10:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20000 iterations\n",
      "03/05 21:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20100/40000]  base_lr: 5.2959e-05 lr: 5.2959e-05  eta: 3:41:22  time: 0.6550  data_time: 0.0239  memory: 5440  loss: 0.3352  decode.loss_ce: 0.3352  decode.acc_seg: 71.0193\n",
      "03/05 21:13:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20200/40000]  base_lr: 5.2921e-05 lr: 5.2921e-05  eta: 3:40:15  time: 0.6519  data_time: 0.0243  memory: 5440  loss: 0.3710  decode.loss_ce: 0.3710  decode.acc_seg: 51.0281\n",
      "03/05 21:14:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20300/40000]  base_lr: 5.2884e-05 lr: 5.2884e-05  eta: 3:39:07  time: 0.6538  data_time: 0.0242  memory: 5440  loss: 0.3025  decode.loss_ce: 0.3025  decode.acc_seg: 98.3398\n",
      "03/05 21:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20400/40000]  base_lr: 5.2846e-05 lr: 5.2846e-05  eta: 3:37:59  time: 0.6535  data_time: 0.0239  memory: 5440  loss: 0.2532  decode.loss_ce: 0.2532  decode.acc_seg: 88.7246\n",
      "03/05 21:16:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20500/40000]  base_lr: 5.2808e-05 lr: 5.2808e-05  eta: 3:36:51  time: 0.6559  data_time: 0.0238  memory: 5440  loss: 0.2870  decode.loss_ce: 0.2870  decode.acc_seg: 97.9408\n",
      "03/05 21:17:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20600/40000]  base_lr: 5.2770e-05 lr: 5.2770e-05  eta: 3:35:44  time: 0.6628  data_time: 0.0242  memory: 5440  loss: 0.4311  decode.loss_ce: 0.4311  decode.acc_seg: 88.2310\n",
      "03/05 21:18:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20700/40000]  base_lr: 5.2732e-05 lr: 5.2732e-05  eta: 3:34:36  time: 0.6657  data_time: 0.0240  memory: 5440  loss: 0.3895  decode.loss_ce: 0.3895  decode.acc_seg: 88.1044\n",
      "03/05 21:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20800/40000]  base_lr: 5.2694e-05 lr: 5.2694e-05  eta: 3:33:28  time: 0.6623  data_time: 0.0242  memory: 5440  loss: 0.4559  decode.loss_ce: 0.4559  decode.acc_seg: 82.9418\n",
      "03/05 21:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20900/40000]  base_lr: 5.2656e-05 lr: 5.2656e-05  eta: 3:32:21  time: 0.6574  data_time: 0.0250  memory: 5440  loss: 0.3886  decode.loss_ce: 0.3886  decode.acc_seg: 83.5809\n",
      "03/05 21:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 21:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21000/40000]  base_lr: 5.2619e-05 lr: 5.2619e-05  eta: 3:31:13  time: 0.6584  data_time: 0.0256  memory: 5440  loss: 0.2803  decode.loss_ce: 0.2803  decode.acc_seg: 83.0080\n",
      "03/05 21:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21100/40000]  base_lr: 5.2581e-05 lr: 5.2581e-05  eta: 3:30:05  time: 0.6516  data_time: 0.0237  memory: 5440  loss: 0.2190  decode.loss_ce: 0.2190  decode.acc_seg: 80.3477\n",
      "03/05 21:24:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21200/40000]  base_lr: 5.2543e-05 lr: 5.2543e-05  eta: 3:28:58  time: 0.6539  data_time: 0.0247  memory: 5440  loss: 0.3830  decode.loss_ce: 0.3830  decode.acc_seg: 93.9161\n",
      "03/05 21:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21300/40000]  base_lr: 5.2505e-05 lr: 5.2505e-05  eta: 3:27:50  time: 0.6514  data_time: 0.0232  memory: 5440  loss: 0.2618  decode.loss_ce: 0.2618  decode.acc_seg: 84.9672\n",
      "03/05 21:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21400/40000]  base_lr: 5.2467e-05 lr: 5.2467e-05  eta: 3:26:42  time: 0.6529  data_time: 0.0239  memory: 5440  loss: 0.4223  decode.loss_ce: 0.4223  decode.acc_seg: 73.2773\n",
      "03/05 21:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21500/40000]  base_lr: 5.2429e-05 lr: 5.2429e-05  eta: 3:25:35  time: 0.6492  data_time: 0.0226  memory: 5440  loss: 0.5616  decode.loss_ce: 0.5616  decode.acc_seg: 71.3865\n",
      "03/05 21:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21600/40000]  base_lr: 5.2391e-05 lr: 5.2391e-05  eta: 3:24:27  time: 0.6551  data_time: 0.0236  memory: 5440  loss: 0.4338  decode.loss_ce: 0.4338  decode.acc_seg: 84.7915\n",
      "03/05 21:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21700/40000]  base_lr: 5.2354e-05 lr: 5.2354e-05  eta: 3:23:20  time: 0.6543  data_time: 0.0243  memory: 5440  loss: 0.3079  decode.loss_ce: 0.3079  decode.acc_seg: 84.1543\n",
      "03/05 21:30:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21800/40000]  base_lr: 5.2316e-05 lr: 5.2316e-05  eta: 3:22:12  time: 0.6540  data_time: 0.0238  memory: 5440  loss: 0.2456  decode.loss_ce: 0.2456  decode.acc_seg: 76.9046\n",
      "03/05 21:31:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21900/40000]  base_lr: 5.2278e-05 lr: 5.2278e-05  eta: 3:21:05  time: 0.6744  data_time: 0.0431  memory: 5440  loss: 0.4677  decode.loss_ce: 0.4677  decode.acc_seg: 92.3455\n",
      "03/05 21:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 21:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22000/40000]  base_lr: 5.2240e-05 lr: 5.2240e-05  eta: 3:19:58  time: 0.6542  data_time: 0.0237  memory: 5440  loss: 0.3775  decode.loss_ce: 0.3775  decode.acc_seg: 77.0955\n",
      "03/05 21:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 22000 iterations\n",
      "03/05 21:33:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22100/40000]  base_lr: 5.2202e-05 lr: 5.2202e-05  eta: 3:18:54  time: 0.6687  data_time: 0.0267  memory: 5440  loss: 0.2643  decode.loss_ce: 0.2643  decode.acc_seg: 91.8261\n",
      "03/05 21:35:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22200/40000]  base_lr: 5.2164e-05 lr: 5.2164e-05  eta: 3:17:47  time: 0.6534  data_time: 0.0246  memory: 5440  loss: 0.3705  decode.loss_ce: 0.3705  decode.acc_seg: 92.9561\n",
      "03/05 21:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22300/40000]  base_lr: 5.2127e-05 lr: 5.2127e-05  eta: 3:16:39  time: 0.6555  data_time: 0.0243  memory: 5440  loss: 0.3671  decode.loss_ce: 0.3671  decode.acc_seg: 63.5102\n",
      "03/05 21:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22400/40000]  base_lr: 5.2089e-05 lr: 5.2089e-05  eta: 3:15:32  time: 0.6537  data_time: 0.0239  memory: 5440  loss: 0.2894  decode.loss_ce: 0.2894  decode.acc_seg: 33.8951\n",
      "03/05 21:38:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22500/40000]  base_lr: 5.2051e-05 lr: 5.2051e-05  eta: 3:14:25  time: 0.6549  data_time: 0.0234  memory: 5440  loss: 0.4615  decode.loss_ce: 0.4615  decode.acc_seg: 75.9718\n",
      "03/05 21:39:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22600/40000]  base_lr: 5.2013e-05 lr: 5.2013e-05  eta: 3:13:17  time: 0.6530  data_time: 0.0237  memory: 5440  loss: 0.4764  decode.loss_ce: 0.4764  decode.acc_seg: 77.1888\n",
      "03/05 21:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22700/40000]  base_lr: 5.1975e-05 lr: 5.1975e-05  eta: 3:12:10  time: 0.6532  data_time: 0.0233  memory: 5440  loss: 0.3096  decode.loss_ce: 0.3096  decode.acc_seg: 79.7443\n",
      "03/05 21:41:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22800/40000]  base_lr: 5.1937e-05 lr: 5.1937e-05  eta: 3:11:02  time: 0.6524  data_time: 0.0242  memory: 5440  loss: 0.2757  decode.loss_ce: 0.2757  decode.acc_seg: 91.5036\n",
      "03/05 21:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22900/40000]  base_lr: 5.1899e-05 lr: 5.1899e-05  eta: 3:09:55  time: 0.6524  data_time: 0.0237  memory: 5440  loss: 0.4874  decode.loss_ce: 0.4874  decode.acc_seg: 96.8045\n",
      "03/05 21:43:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 21:43:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23000/40000]  base_lr: 5.1862e-05 lr: 5.1862e-05  eta: 3:08:48  time: 0.6556  data_time: 0.0240  memory: 5440  loss: 0.3319  decode.loss_ce: 0.3319  decode.acc_seg: 92.8997\n",
      "03/05 21:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23100/40000]  base_lr: 5.1824e-05 lr: 5.1824e-05  eta: 3:07:41  time: 0.6555  data_time: 0.0235  memory: 5440  loss: 0.4024  decode.loss_ce: 0.4024  decode.acc_seg: 55.7966\n",
      "03/05 21:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23200/40000]  base_lr: 5.1786e-05 lr: 5.1786e-05  eta: 3:06:33  time: 0.6586  data_time: 0.0243  memory: 5440  loss: 0.3129  decode.loss_ce: 0.3129  decode.acc_seg: 78.6671\n",
      "03/05 21:47:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23300/40000]  base_lr: 5.1748e-05 lr: 5.1748e-05  eta: 3:05:26  time: 0.6630  data_time: 0.0239  memory: 5440  loss: 0.3391  decode.loss_ce: 0.3391  decode.acc_seg: 95.2753\n",
      "03/05 21:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23400/40000]  base_lr: 5.1710e-05 lr: 5.1710e-05  eta: 3:04:19  time: 0.6727  data_time: 0.0260  memory: 5440  loss: 0.4303  decode.loss_ce: 0.4303  decode.acc_seg: 52.8535\n",
      "03/05 21:49:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23500/40000]  base_lr: 5.1672e-05 lr: 5.1672e-05  eta: 3:03:11  time: 0.6586  data_time: 0.0249  memory: 5440  loss: 0.2937  decode.loss_ce: 0.2937  decode.acc_seg: 71.5441\n",
      "03/05 21:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23600/40000]  base_lr: 5.1634e-05 lr: 5.1634e-05  eta: 3:02:04  time: 0.6504  data_time: 0.0232  memory: 5440  loss: 0.2389  decode.loss_ce: 0.2389  decode.acc_seg: 79.2112\n",
      "03/05 21:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23700/40000]  base_lr: 5.1597e-05 lr: 5.1597e-05  eta: 3:00:56  time: 0.6504  data_time: 0.0233  memory: 5440  loss: 0.3174  decode.loss_ce: 0.3174  decode.acc_seg: 34.7746\n",
      "03/05 21:52:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23800/40000]  base_lr: 5.1559e-05 lr: 5.1559e-05  eta: 2:59:49  time: 0.6527  data_time: 0.0236  memory: 5440  loss: 0.4535  decode.loss_ce: 0.4535  decode.acc_seg: 91.3312\n",
      "03/05 21:53:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23900/40000]  base_lr: 5.1521e-05 lr: 5.1521e-05  eta: 2:58:41  time: 0.6489  data_time: 0.0235  memory: 5440  loss: 0.3275  decode.loss_ce: 0.3275  decode.acc_seg: 58.7599\n",
      "03/05 21:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 21:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24000/40000]  base_lr: 5.1483e-05 lr: 5.1483e-05  eta: 2:57:34  time: 0.6533  data_time: 0.0233  memory: 5440  loss: 0.2701  decode.loss_ce: 0.2701  decode.acc_seg: 95.8937\n",
      "03/05 21:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24000 iterations\n",
      "03/05 21:55:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24100/40000]  base_lr: 5.1445e-05 lr: 5.1445e-05  eta: 2:56:30  time: 0.6532  data_time: 0.0227  memory: 5440  loss: 0.5700  decode.loss_ce: 0.5700  decode.acc_seg: 37.1788\n",
      "03/05 21:57:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24200/40000]  base_lr: 5.1407e-05 lr: 5.1407e-05  eta: 2:55:23  time: 0.6563  data_time: 0.0238  memory: 5440  loss: 0.3737  decode.loss_ce: 0.3737  decode.acc_seg: 98.3269\n",
      "03/05 21:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24300/40000]  base_lr: 5.1369e-05 lr: 5.1369e-05  eta: 2:54:15  time: 0.6515  data_time: 0.0244  memory: 5440  loss: 0.3251  decode.loss_ce: 0.3251  decode.acc_seg: 69.1551\n",
      "03/05 21:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24400/40000]  base_lr: 5.1332e-05 lr: 5.1332e-05  eta: 2:53:08  time: 0.6516  data_time: 0.0229  memory: 5440  loss: 0.6671  decode.loss_ce: 0.6671  decode.acc_seg: 60.8023\n",
      "03/05 22:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24500/40000]  base_lr: 5.1294e-05 lr: 5.1294e-05  eta: 2:52:00  time: 0.6495  data_time: 0.0232  memory: 5440  loss: 0.2906  decode.loss_ce: 0.2906  decode.acc_seg: 93.3268\n",
      "03/05 22:01:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24600/40000]  base_lr: 5.1256e-05 lr: 5.1256e-05  eta: 2:50:53  time: 0.6517  data_time: 0.0231  memory: 5440  loss: 0.2450  decode.loss_ce: 0.2450  decode.acc_seg: 92.3115\n",
      "03/05 22:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24700/40000]  base_lr: 5.1218e-05 lr: 5.1218e-05  eta: 2:49:46  time: 0.6540  data_time: 0.0240  memory: 5440  loss: 0.3280  decode.loss_ce: 0.3280  decode.acc_seg: 95.3720\n",
      "03/05 22:03:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24800/40000]  base_lr: 5.1180e-05 lr: 5.1180e-05  eta: 2:48:38  time: 0.6637  data_time: 0.0246  memory: 5440  loss: 0.6707  decode.loss_ce: 0.6707  decode.acc_seg: 86.6968\n",
      "03/05 22:04:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24900/40000]  base_lr: 5.1142e-05 lr: 5.1142e-05  eta: 2:47:31  time: 0.6661  data_time: 0.0263  memory: 5440  loss: 0.3872  decode.loss_ce: 0.3872  decode.acc_seg: 90.6362\n",
      "03/05 22:05:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 22:05:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25000/40000]  base_lr: 5.1104e-05 lr: 5.1104e-05  eta: 2:46:24  time: 0.6602  data_time: 0.0246  memory: 5440  loss: 0.3579  decode.loss_ce: 0.3579  decode.acc_seg: 72.6748\n",
      "03/05 22:06:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25100/40000]  base_lr: 5.1067e-05 lr: 5.1067e-05  eta: 2:45:17  time: 0.6498  data_time: 0.0230  memory: 5440  loss: 0.3057  decode.loss_ce: 0.3057  decode.acc_seg: 82.2574\n",
      "03/05 22:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25200/40000]  base_lr: 5.1029e-05 lr: 5.1029e-05  eta: 2:44:09  time: 0.6489  data_time: 0.0229  memory: 5440  loss: 0.3929  decode.loss_ce: 0.3929  decode.acc_seg: 62.7815\n",
      "03/05 22:08:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25300/40000]  base_lr: 5.0991e-05 lr: 5.0991e-05  eta: 2:43:02  time: 0.6542  data_time: 0.0224  memory: 5440  loss: 0.2746  decode.loss_ce: 0.2746  decode.acc_seg: 88.8979\n",
      "03/05 22:10:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25400/40000]  base_lr: 5.0953e-05 lr: 5.0953e-05  eta: 2:41:55  time: 0.6508  data_time: 0.0237  memory: 5440  loss: 0.2401  decode.loss_ce: 0.2401  decode.acc_seg: 98.5592\n",
      "03/05 22:11:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25500/40000]  base_lr: 5.0915e-05 lr: 5.0915e-05  eta: 2:40:47  time: 0.6519  data_time: 0.0237  memory: 5440  loss: 0.2844  decode.loss_ce: 0.2844  decode.acc_seg: 88.9204\n",
      "03/05 22:12:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25600/40000]  base_lr: 5.0877e-05 lr: 5.0877e-05  eta: 2:39:40  time: 0.6510  data_time: 0.0242  memory: 5440  loss: 0.2805  decode.loss_ce: 0.2805  decode.acc_seg: 69.9347\n",
      "03/05 22:13:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25700/40000]  base_lr: 5.0839e-05 lr: 5.0839e-05  eta: 2:38:33  time: 0.6525  data_time: 0.0236  memory: 5440  loss: 0.3358  decode.loss_ce: 0.3358  decode.acc_seg: 97.4071\n",
      "03/05 22:14:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25800/40000]  base_lr: 5.0802e-05 lr: 5.0802e-05  eta: 2:37:26  time: 0.6542  data_time: 0.0233  memory: 5440  loss: 0.2903  decode.loss_ce: 0.2903  decode.acc_seg: 95.4228\n",
      "03/05 22:15:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25900/40000]  base_lr: 5.0764e-05 lr: 5.0764e-05  eta: 2:36:19  time: 0.6528  data_time: 0.0234  memory: 5440  loss: 0.4305  decode.loss_ce: 0.4305  decode.acc_seg: 72.7742\n",
      "03/05 22:16:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 22:16:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26000/40000]  base_lr: 5.0726e-05 lr: 5.0726e-05  eta: 2:35:12  time: 0.6499  data_time: 0.0236  memory: 5440  loss: 0.1829  decode.loss_ce: 0.1829  decode.acc_seg: 92.5788\n",
      "03/05 22:16:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 26000 iterations\n",
      "03/05 22:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26100/40000]  base_lr: 5.0688e-05 lr: 5.0688e-05  eta: 2:34:07  time: 0.6656  data_time: 0.0248  memory: 5440  loss: 0.2050  decode.loss_ce: 0.2050  decode.acc_seg: 95.3823\n",
      "03/05 22:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26200/40000]  base_lr: 5.0650e-05 lr: 5.0650e-05  eta: 2:33:00  time: 0.6592  data_time: 0.0242  memory: 5440  loss: 0.3645  decode.loss_ce: 0.3645  decode.acc_seg: 87.2955\n",
      "03/05 22:19:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26300/40000]  base_lr: 5.0612e-05 lr: 5.0612e-05  eta: 2:31:53  time: 0.6605  data_time: 0.0253  memory: 5440  loss: 0.3099  decode.loss_ce: 0.3099  decode.acc_seg: 74.9481\n",
      "03/05 22:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26400/40000]  base_lr: 5.0574e-05 lr: 5.0574e-05  eta: 2:30:46  time: 0.6532  data_time: 0.0243  memory: 5440  loss: 0.2381  decode.loss_ce: 0.2381  decode.acc_seg: 86.3485\n",
      "03/05 22:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26500/40000]  base_lr: 5.0537e-05 lr: 5.0537e-05  eta: 2:29:39  time: 0.6512  data_time: 0.0231  memory: 5440  loss: 0.3634  decode.loss_ce: 0.3634  decode.acc_seg: 92.5946\n",
      "03/05 22:23:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26600/40000]  base_lr: 5.0499e-05 lr: 5.0499e-05  eta: 2:28:32  time: 0.6511  data_time: 0.0226  memory: 5440  loss: 0.3847  decode.loss_ce: 0.3847  decode.acc_seg: 88.9278\n",
      "03/05 22:24:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26700/40000]  base_lr: 5.0461e-05 lr: 5.0461e-05  eta: 2:27:25  time: 0.6551  data_time: 0.0244  memory: 5440  loss: 0.8183  decode.loss_ce: 0.8183  decode.acc_seg: 46.3266\n",
      "03/05 22:25:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26800/40000]  base_lr: 5.0423e-05 lr: 5.0423e-05  eta: 2:26:18  time: 0.6514  data_time: 0.0233  memory: 5440  loss: 0.2899  decode.loss_ce: 0.2899  decode.acc_seg: 79.4794\n",
      "03/05 22:26:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26900/40000]  base_lr: 5.0385e-05 lr: 5.0385e-05  eta: 2:25:11  time: 0.6545  data_time: 0.0249  memory: 5440  loss: 0.2465  decode.loss_ce: 0.2465  decode.acc_seg: 99.0574\n",
      "03/05 22:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 22:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27000/40000]  base_lr: 5.0347e-05 lr: 5.0347e-05  eta: 2:24:04  time: 0.6642  data_time: 0.0248  memory: 5440  loss: 0.2917  decode.loss_ce: 0.2917  decode.acc_seg: 93.3213\n",
      "03/05 22:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27100/40000]  base_lr: 5.0309e-05 lr: 5.0309e-05  eta: 2:22:57  time: 0.6762  data_time: 0.0244  memory: 5440  loss: 0.3572  decode.loss_ce: 0.3572  decode.acc_seg: 81.6823\n",
      "03/05 22:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27200/40000]  base_lr: 5.0272e-05 lr: 5.0272e-05  eta: 2:21:51  time: 0.6585  data_time: 0.0237  memory: 5440  loss: 0.2400  decode.loss_ce: 0.2400  decode.acc_seg: 96.1696\n",
      "03/05 22:30:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27300/40000]  base_lr: 5.0234e-05 lr: 5.0234e-05  eta: 2:20:44  time: 0.6597  data_time: 0.0242  memory: 5440  loss: 0.3200  decode.loss_ce: 0.3200  decode.acc_seg: 56.9607\n",
      "03/05 22:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27400/40000]  base_lr: 5.0196e-05 lr: 5.0196e-05  eta: 2:19:37  time: 0.6574  data_time: 0.0246  memory: 5440  loss: 0.4317  decode.loss_ce: 0.4317  decode.acc_seg: 77.6261\n",
      "03/05 22:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27500/40000]  base_lr: 5.0158e-05 lr: 5.0158e-05  eta: 2:18:31  time: 0.6679  data_time: 0.0256  memory: 5440  loss: 0.3340  decode.loss_ce: 0.3340  decode.acc_seg: 79.4079\n",
      "03/05 22:34:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27600/40000]  base_lr: 5.0120e-05 lr: 5.0120e-05  eta: 2:17:24  time: 0.6667  data_time: 0.0251  memory: 5440  loss: 0.2570  decode.loss_ce: 0.2570  decode.acc_seg: 93.1712\n",
      "03/05 22:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27700/40000]  base_lr: 5.0082e-05 lr: 5.0082e-05  eta: 2:16:17  time: 0.6850  data_time: 0.0431  memory: 5440  loss: 0.3768  decode.loss_ce: 0.3768  decode.acc_seg: 88.8916\n",
      "03/05 22:36:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27800/40000]  base_lr: 5.0044e-05 lr: 5.0044e-05  eta: 2:15:11  time: 0.6636  data_time: 0.0306  memory: 5440  loss: 0.3303  decode.loss_ce: 0.3303  decode.acc_seg: 95.2225\n",
      "03/05 22:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27900/40000]  base_lr: 5.0007e-05 lr: 5.0007e-05  eta: 2:14:04  time: 0.6590  data_time: 0.0246  memory: 5440  loss: 0.3017  decode.loss_ce: 0.3017  decode.acc_seg: 93.1507\n",
      "03/05 22:38:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 22:38:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28000/40000]  base_lr: 4.9969e-05 lr: 4.9969e-05  eta: 2:12:57  time: 0.6610  data_time: 0.0254  memory: 5440  loss: 0.6261  decode.loss_ce: 0.6261  decode.acc_seg: 90.0651\n",
      "03/05 22:38:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 28000 iterations\n",
      "03/05 22:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28100/40000]  base_lr: 4.9931e-05 lr: 4.9931e-05  eta: 2:11:52  time: 0.6561  data_time: 0.0236  memory: 5440  loss: 0.2963  decode.loss_ce: 0.2963  decode.acc_seg: 87.6932\n",
      "03/05 22:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28200/40000]  base_lr: 4.9893e-05 lr: 4.9893e-05  eta: 2:10:46  time: 0.6572  data_time: 0.0237  memory: 5440  loss: 0.2401  decode.loss_ce: 0.2401  decode.acc_seg: 90.4504\n",
      "03/05 22:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28300/40000]  base_lr: 4.9855e-05 lr: 4.9855e-05  eta: 2:09:39  time: 0.6676  data_time: 0.0288  memory: 5440  loss: 0.4487  decode.loss_ce: 0.4487  decode.acc_seg: 79.7912\n",
      "03/05 22:43:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28400/40000]  base_lr: 4.9817e-05 lr: 4.9817e-05  eta: 2:08:32  time: 0.6579  data_time: 0.0254  memory: 5440  loss: 0.4197  decode.loss_ce: 0.4197  decode.acc_seg: 98.7382\n",
      "03/05 22:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28500/40000]  base_lr: 4.9779e-05 lr: 4.9779e-05  eta: 2:07:26  time: 0.6579  data_time: 0.0244  memory: 5440  loss: 0.3290  decode.loss_ce: 0.3290  decode.acc_seg: 93.2954\n",
      "03/05 22:45:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28600/40000]  base_lr: 4.9742e-05 lr: 4.9742e-05  eta: 2:06:19  time: 0.6704  data_time: 0.0268  memory: 5440  loss: 0.3174  decode.loss_ce: 0.3174  decode.acc_seg: 64.6840\n",
      "03/05 22:46:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28700/40000]  base_lr: 4.9704e-05 lr: 4.9704e-05  eta: 2:05:12  time: 0.6606  data_time: 0.0245  memory: 5440  loss: 0.3042  decode.loss_ce: 0.3042  decode.acc_seg: 81.8508\n",
      "03/05 22:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28800/40000]  base_lr: 4.9666e-05 lr: 4.9666e-05  eta: 2:04:06  time: 0.6915  data_time: 0.0534  memory: 5440  loss: 0.2000  decode.loss_ce: 0.2000  decode.acc_seg: 81.0830\n",
      "03/05 22:48:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28900/40000]  base_lr: 4.9628e-05 lr: 4.9628e-05  eta: 2:02:59  time: 0.6629  data_time: 0.0308  memory: 5440  loss: 0.2652  decode.loss_ce: 0.2652  decode.acc_seg: 97.1975\n",
      "03/05 22:49:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 22:49:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29000/40000]  base_lr: 4.9590e-05 lr: 4.9590e-05  eta: 2:01:53  time: 0.6560  data_time: 0.0238  memory: 5440  loss: 0.8186  decode.loss_ce: 0.8186  decode.acc_seg: 80.9199\n",
      "03/05 22:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29100/40000]  base_lr: 4.9552e-05 lr: 4.9552e-05  eta: 2:00:46  time: 0.6590  data_time: 0.0242  memory: 5440  loss: 0.2286  decode.loss_ce: 0.2286  decode.acc_seg: 97.6562\n",
      "03/05 22:51:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29200/40000]  base_lr: 4.9515e-05 lr: 4.9515e-05  eta: 1:59:40  time: 0.6637  data_time: 0.0283  memory: 5440  loss: 0.2245  decode.loss_ce: 0.2245  decode.acc_seg: 93.8680\n",
      "03/05 22:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29300/40000]  base_lr: 4.9477e-05 lr: 4.9477e-05  eta: 1:58:33  time: 0.6549  data_time: 0.0242  memory: 5440  loss: 0.2449  decode.loss_ce: 0.2449  decode.acc_seg: 85.7239\n",
      "03/05 22:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29400/40000]  base_lr: 4.9439e-05 lr: 4.9439e-05  eta: 1:57:27  time: 0.6679  data_time: 0.0336  memory: 5440  loss: 0.5695  decode.loss_ce: 0.5695  decode.acc_seg: 87.0359\n",
      "03/05 22:55:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29500/40000]  base_lr: 4.9401e-05 lr: 4.9401e-05  eta: 1:56:20  time: 0.6571  data_time: 0.0246  memory: 5440  loss: 0.2644  decode.loss_ce: 0.2644  decode.acc_seg: 85.6318\n",
      "03/05 22:56:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29600/40000]  base_lr: 4.9363e-05 lr: 4.9363e-05  eta: 1:55:13  time: 0.6527  data_time: 0.0232  memory: 5440  loss: 0.2532  decode.loss_ce: 0.2532  decode.acc_seg: 92.2184\n",
      "03/05 22:57:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29700/40000]  base_lr: 4.9325e-05 lr: 4.9325e-05  eta: 1:54:07  time: 0.6582  data_time: 0.0248  memory: 5440  loss: 0.2971  decode.loss_ce: 0.2971  decode.acc_seg: 90.0262\n",
      "03/05 22:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29800/40000]  base_lr: 4.9287e-05 lr: 4.9287e-05  eta: 1:53:00  time: 0.6640  data_time: 0.0259  memory: 5440  loss: 0.2501  decode.loss_ce: 0.2501  decode.acc_seg: 92.5220\n",
      "03/05 22:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29900/40000]  base_lr: 4.9250e-05 lr: 4.9250e-05  eta: 1:51:53  time: 0.6634  data_time: 0.0254  memory: 5440  loss: 0.1932  decode.loss_ce: 0.1932  decode.acc_seg: 90.1663\n",
      "03/05 23:00:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 23:00:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30000/40000]  base_lr: 4.9212e-05 lr: 4.9212e-05  eta: 1:50:46  time: 0.6643  data_time: 0.0245  memory: 5440  loss: 0.3202  decode.loss_ce: 0.3202  decode.acc_seg: 92.2701\n",
      "03/05 23:00:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30000 iterations\n",
      "03/05 23:01:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30100/40000]  base_lr: 4.9174e-05 lr: 4.9174e-05  eta: 1:49:41  time: 0.6545  data_time: 0.0231  memory: 5440  loss: 0.2532  decode.loss_ce: 0.2532  decode.acc_seg: 87.3188\n",
      "03/05 23:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30200/40000]  base_lr: 4.9136e-05 lr: 4.9136e-05  eta: 1:48:35  time: 0.6537  data_time: 0.0237  memory: 5440  loss: 0.2973  decode.loss_ce: 0.2973  decode.acc_seg: 90.4426\n",
      "03/05 23:04:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30300/40000]  base_lr: 4.9098e-05 lr: 4.9098e-05  eta: 1:47:28  time: 0.6555  data_time: 0.0236  memory: 5440  loss: 0.2746  decode.loss_ce: 0.2746  decode.acc_seg: 90.0086\n",
      "03/05 23:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30400/40000]  base_lr: 4.9060e-05 lr: 4.9060e-05  eta: 1:46:21  time: 0.6524  data_time: 0.0241  memory: 5440  loss: 0.3299  decode.loss_ce: 0.3299  decode.acc_seg: 97.0926\n",
      "03/05 23:06:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30500/40000]  base_lr: 4.9022e-05 lr: 4.9022e-05  eta: 1:45:14  time: 0.6510  data_time: 0.0235  memory: 5440  loss: 0.2529  decode.loss_ce: 0.2529  decode.acc_seg: 79.8137\n",
      "03/05 23:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30600/40000]  base_lr: 4.8985e-05 lr: 4.8985e-05  eta: 1:44:08  time: 0.6533  data_time: 0.0238  memory: 5440  loss: 0.1821  decode.loss_ce: 0.1821  decode.acc_seg: 95.5673\n",
      "03/05 23:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30700/40000]  base_lr: 4.8947e-05 lr: 4.8947e-05  eta: 1:43:01  time: 0.6550  data_time: 0.0236  memory: 5440  loss: 0.3235  decode.loss_ce: 0.3235  decode.acc_seg: 73.7196\n",
      "03/05 23:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30800/40000]  base_lr: 4.8909e-05 lr: 4.8909e-05  eta: 1:41:54  time: 0.6531  data_time: 0.0242  memory: 5440  loss: 0.2841  decode.loss_ce: 0.2841  decode.acc_seg: 87.9717\n",
      "03/05 23:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30900/40000]  base_lr: 4.8871e-05 lr: 4.8871e-05  eta: 1:40:47  time: 0.6546  data_time: 0.0245  memory: 5440  loss: 0.2906  decode.loss_ce: 0.2906  decode.acc_seg: 86.5659\n",
      "03/05 23:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 23:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31000/40000]  base_lr: 4.8833e-05 lr: 4.8833e-05  eta: 1:39:41  time: 0.6522  data_time: 0.0237  memory: 5440  loss: 0.2299  decode.loss_ce: 0.2299  decode.acc_seg: 97.0157\n",
      "03/05 23:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31100/40000]  base_lr: 4.8795e-05 lr: 4.8795e-05  eta: 1:38:34  time: 0.6608  data_time: 0.0236  memory: 5440  loss: 0.1602  decode.loss_ce: 0.1602  decode.acc_seg: 85.2436\n",
      "03/05 23:13:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31200/40000]  base_lr: 4.8757e-05 lr: 4.8757e-05  eta: 1:37:27  time: 0.6588  data_time: 0.0243  memory: 5440  loss: 0.2818  decode.loss_ce: 0.2818  decode.acc_seg: 91.8894\n",
      "03/05 23:15:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31300/40000]  base_lr: 4.8720e-05 lr: 4.8720e-05  eta: 1:36:21  time: 0.6660  data_time: 0.0254  memory: 5440  loss: 0.2213  decode.loss_ce: 0.2213  decode.acc_seg: 86.8182\n",
      "03/05 23:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31400/40000]  base_lr: 4.8682e-05 lr: 4.8682e-05  eta: 1:35:14  time: 0.6543  data_time: 0.0247  memory: 5440  loss: 0.2700  decode.loss_ce: 0.2700  decode.acc_seg: 83.1831\n",
      "03/05 23:17:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31500/40000]  base_lr: 4.8644e-05 lr: 4.8644e-05  eta: 1:34:07  time: 0.6546  data_time: 0.0243  memory: 5440  loss: 0.3626  decode.loss_ce: 0.3626  decode.acc_seg: 73.1068\n",
      "03/05 23:18:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31600/40000]  base_lr: 4.8606e-05 lr: 4.8606e-05  eta: 1:33:01  time: 0.6540  data_time: 0.0232  memory: 5440  loss: 0.3866  decode.loss_ce: 0.3866  decode.acc_seg: 71.4270\n",
      "03/05 23:19:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31700/40000]  base_lr: 4.8568e-05 lr: 4.8568e-05  eta: 1:31:54  time: 0.6697  data_time: 0.0389  memory: 5440  loss: 0.3634  decode.loss_ce: 0.3634  decode.acc_seg: 87.4346\n",
      "03/05 23:20:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31800/40000]  base_lr: 4.8530e-05 lr: 4.8530e-05  eta: 1:30:47  time: 0.6545  data_time: 0.0246  memory: 5440  loss: 0.1923  decode.loss_ce: 0.1923  decode.acc_seg: 98.5460\n",
      "03/05 23:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31900/40000]  base_lr: 4.8492e-05 lr: 4.8492e-05  eta: 1:29:41  time: 0.6602  data_time: 0.0242  memory: 5440  loss: 0.3545  decode.loss_ce: 0.3545  decode.acc_seg: 83.1109\n",
      "03/05 23:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 23:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32000/40000]  base_lr: 4.8455e-05 lr: 4.8455e-05  eta: 1:28:34  time: 0.6538  data_time: 0.0234  memory: 5440  loss: 0.1990  decode.loss_ce: 0.1990  decode.acc_seg: 88.0449\n",
      "03/05 23:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 32000 iterations\n",
      "03/05 23:23:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32100/40000]  base_lr: 4.8417e-05 lr: 4.8417e-05  eta: 1:27:29  time: 0.6557  data_time: 0.0252  memory: 5440  loss: 0.3825  decode.loss_ce: 0.3825  decode.acc_seg: 76.7948\n",
      "03/05 23:24:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32200/40000]  base_lr: 4.8379e-05 lr: 4.8379e-05  eta: 1:26:22  time: 0.6562  data_time: 0.0251  memory: 5440  loss: 0.2461  decode.loss_ce: 0.2461  decode.acc_seg: 97.8375\n",
      "03/05 23:26:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32300/40000]  base_lr: 4.8341e-05 lr: 4.8341e-05  eta: 1:25:16  time: 0.6609  data_time: 0.0251  memory: 5440  loss: 0.4524  decode.loss_ce: 0.4524  decode.acc_seg: 83.8698\n",
      "03/05 23:27:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32400/40000]  base_lr: 4.8303e-05 lr: 4.8303e-05  eta: 1:24:09  time: 0.6667  data_time: 0.0253  memory: 5440  loss: 0.3176  decode.loss_ce: 0.3176  decode.acc_seg: 81.2250\n",
      "03/05 23:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32500/40000]  base_lr: 4.8265e-05 lr: 4.8265e-05  eta: 1:23:03  time: 0.6702  data_time: 0.0254  memory: 5440  loss: 0.2549  decode.loss_ce: 0.2549  decode.acc_seg: 86.9536\n",
      "03/05 23:29:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32600/40000]  base_lr: 4.8227e-05 lr: 4.8227e-05  eta: 1:21:56  time: 0.6544  data_time: 0.0245  memory: 5440  loss: 0.3437  decode.loss_ce: 0.3437  decode.acc_seg: 96.1026\n",
      "03/05 23:30:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32700/40000]  base_lr: 4.8190e-05 lr: 4.8190e-05  eta: 1:20:50  time: 0.6607  data_time: 0.0243  memory: 5440  loss: 0.2838  decode.loss_ce: 0.2838  decode.acc_seg: 90.4921\n",
      "03/05 23:31:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32800/40000]  base_lr: 4.8152e-05 lr: 4.8152e-05  eta: 1:19:43  time: 0.6581  data_time: 0.0245  memory: 5440  loss: 0.2482  decode.loss_ce: 0.2482  decode.acc_seg: 83.1364\n",
      "03/05 23:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32900/40000]  base_lr: 4.8114e-05 lr: 4.8114e-05  eta: 1:18:36  time: 0.6563  data_time: 0.0239  memory: 5440  loss: 0.3763  decode.loss_ce: 0.3763  decode.acc_seg: 88.3825\n",
      "03/05 23:33:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 23:33:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33000/40000]  base_lr: 4.8076e-05 lr: 4.8076e-05  eta: 1:17:30  time: 0.6534  data_time: 0.0236  memory: 5440  loss: 0.2221  decode.loss_ce: 0.2221  decode.acc_seg: 94.1242\n",
      "03/05 23:34:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33100/40000]  base_lr: 4.8038e-05 lr: 4.8038e-05  eta: 1:16:23  time: 0.6540  data_time: 0.0242  memory: 5440  loss: 0.2421  decode.loss_ce: 0.2421  decode.acc_seg: 98.1185\n",
      "03/05 23:35:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33200/40000]  base_lr: 4.8000e-05 lr: 4.8000e-05  eta: 1:15:17  time: 0.6539  data_time: 0.0232  memory: 5440  loss: 0.4405  decode.loss_ce: 0.4405  decode.acc_seg: 83.2418\n",
      "03/05 23:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33300/40000]  base_lr: 4.7962e-05 lr: 4.7962e-05  eta: 1:14:10  time: 0.6520  data_time: 0.0236  memory: 5440  loss: 0.2533  decode.loss_ce: 0.2533  decode.acc_seg: 89.6483\n",
      "03/05 23:38:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33400/40000]  base_lr: 4.7925e-05 lr: 4.7925e-05  eta: 1:13:04  time: 0.6536  data_time: 0.0240  memory: 5440  loss: 0.2649  decode.loss_ce: 0.2649  decode.acc_seg: 59.5003\n",
      "03/05 23:39:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33500/40000]  base_lr: 4.7887e-05 lr: 4.7887e-05  eta: 1:11:57  time: 0.6551  data_time: 0.0242  memory: 5440  loss: 0.2937  decode.loss_ce: 0.2937  decode.acc_seg: 90.9734\n",
      "03/05 23:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33600/40000]  base_lr: 4.7849e-05 lr: 4.7849e-05  eta: 1:10:50  time: 0.6523  data_time: 0.0234  memory: 5440  loss: 0.2217  decode.loss_ce: 0.2217  decode.acc_seg: 74.8752\n",
      "03/05 23:41:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33700/40000]  base_lr: 4.7811e-05 lr: 4.7811e-05  eta: 1:09:44  time: 0.6664  data_time: 0.0263  memory: 5440  loss: 0.6480  decode.loss_ce: 0.6480  decode.acc_seg: 85.0291\n",
      "03/05 23:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33800/40000]  base_lr: 4.7773e-05 lr: 4.7773e-05  eta: 1:08:37  time: 0.6654  data_time: 0.0252  memory: 5440  loss: 0.3495  decode.loss_ce: 0.3495  decode.acc_seg: 81.9699\n",
      "03/05 23:43:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33900/40000]  base_lr: 4.7735e-05 lr: 4.7735e-05  eta: 1:07:31  time: 0.6666  data_time: 0.0254  memory: 5440  loss: 0.2323  decode.loss_ce: 0.2323  decode.acc_seg: 85.2269\n",
      "03/05 23:44:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 23:44:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34000/40000]  base_lr: 4.7697e-05 lr: 4.7697e-05  eta: 1:06:24  time: 0.6602  data_time: 0.0251  memory: 5440  loss: 0.3079  decode.loss_ce: 0.3079  decode.acc_seg: 77.3727\n",
      "03/05 23:44:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 34000 iterations\n",
      "03/05 23:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34100/40000]  base_lr: 4.7660e-05 lr: 4.7660e-05  eta: 1:05:19  time: 0.6551  data_time: 0.0241  memory: 5440  loss: 0.1412  decode.loss_ce: 0.1412  decode.acc_seg: 89.7870\n",
      "03/05 23:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34200/40000]  base_lr: 4.7622e-05 lr: 4.7622e-05  eta: 1:04:12  time: 0.6578  data_time: 0.0244  memory: 5440  loss: 0.3272  decode.loss_ce: 0.3272  decode.acc_seg: 85.7491\n",
      "03/05 23:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34300/40000]  base_lr: 4.7584e-05 lr: 4.7584e-05  eta: 1:03:06  time: 0.6544  data_time: 0.0234  memory: 5440  loss: 0.3069  decode.loss_ce: 0.3069  decode.acc_seg: 78.1335\n",
      "03/05 23:49:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34400/40000]  base_lr: 4.7546e-05 lr: 4.7546e-05  eta: 1:01:59  time: 0.6512  data_time: 0.0233  memory: 5440  loss: 0.3023  decode.loss_ce: 0.3023  decode.acc_seg: 71.9698\n",
      "03/05 23:50:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34500/40000]  base_lr: 4.7508e-05 lr: 4.7508e-05  eta: 1:00:52  time: 0.6574  data_time: 0.0241  memory: 5440  loss: 0.4344  decode.loss_ce: 0.4344  decode.acc_seg: 87.5876\n",
      "03/05 23:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34600/40000]  base_lr: 4.7470e-05 lr: 4.7470e-05  eta: 0:59:46  time: 0.6543  data_time: 0.0244  memory: 5440  loss: 0.3595  decode.loss_ce: 0.3595  decode.acc_seg: 76.6793\n",
      "03/05 23:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34700/40000]  base_lr: 4.7432e-05 lr: 4.7432e-05  eta: 0:58:39  time: 0.6556  data_time: 0.0241  memory: 5440  loss: 0.2613  decode.loss_ce: 0.2613  decode.acc_seg: 89.2823\n",
      "03/05 23:53:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34800/40000]  base_lr: 4.7395e-05 lr: 4.7395e-05  eta: 0:57:33  time: 0.6564  data_time: 0.0238  memory: 5440  loss: 0.2622  decode.loss_ce: 0.2622  decode.acc_seg: 91.3212\n",
      "03/05 23:54:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34900/40000]  base_lr: 4.7357e-05 lr: 4.7357e-05  eta: 0:56:26  time: 0.6538  data_time: 0.0242  memory: 5440  loss: 0.4208  decode.loss_ce: 0.4208  decode.acc_seg: 78.9441\n",
      "03/05 23:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/05 23:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35000/40000]  base_lr: 4.7319e-05 lr: 4.7319e-05  eta: 0:55:20  time: 0.6679  data_time: 0.0258  memory: 5440  loss: 0.2528  decode.loss_ce: 0.2528  decode.acc_seg: 88.8157\n",
      "03/05 23:56:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35100/40000]  base_lr: 4.7281e-05 lr: 4.7281e-05  eta: 0:54:13  time: 0.6726  data_time: 0.0258  memory: 5440  loss: 0.2084  decode.loss_ce: 0.2084  decode.acc_seg: 88.4187\n",
      "03/05 23:57:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35200/40000]  base_lr: 4.7243e-05 lr: 4.7243e-05  eta: 0:53:07  time: 0.6750  data_time: 0.0265  memory: 5440  loss: 0.3595  decode.loss_ce: 0.3595  decode.acc_seg: 81.4535\n",
      "03/05 23:59:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35300/40000]  base_lr: 4.7205e-05 lr: 4.7205e-05  eta: 0:52:00  time: 0.6539  data_time: 0.0238  memory: 5440  loss: 0.1181  decode.loss_ce: 0.1181  decode.acc_seg: 90.4875\n",
      "03/06 00:00:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35400/40000]  base_lr: 4.7167e-05 lr: 4.7167e-05  eta: 0:50:54  time: 0.6598  data_time: 0.0246  memory: 5440  loss: 0.3051  decode.loss_ce: 0.3051  decode.acc_seg: 85.4698\n",
      "03/06 00:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35500/40000]  base_lr: 4.7130e-05 lr: 4.7130e-05  eta: 0:49:47  time: 0.6536  data_time: 0.0233  memory: 5440  loss: 0.1811  decode.loss_ce: 0.1811  decode.acc_seg: 96.6323\n",
      "03/06 00:02:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35600/40000]  base_lr: 4.7092e-05 lr: 4.7092e-05  eta: 0:48:41  time: 0.6544  data_time: 0.0242  memory: 5440  loss: 0.6157  decode.loss_ce: 0.6157  decode.acc_seg: 71.3410\n",
      "03/06 00:03:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35700/40000]  base_lr: 4.7054e-05 lr: 4.7054e-05  eta: 0:47:34  time: 0.6540  data_time: 0.0236  memory: 5440  loss: 0.3157  decode.loss_ce: 0.3157  decode.acc_seg: 95.0624\n",
      "03/06 00:04:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35800/40000]  base_lr: 4.7016e-05 lr: 4.7016e-05  eta: 0:46:28  time: 0.6519  data_time: 0.0229  memory: 5440  loss: 0.3563  decode.loss_ce: 0.3563  decode.acc_seg: 97.5021\n",
      "03/06 00:05:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35900/40000]  base_lr: 4.6978e-05 lr: 4.6978e-05  eta: 0:45:22  time: 0.6587  data_time: 0.0242  memory: 5440  loss: 0.2748  decode.loss_ce: 0.2748  decode.acc_seg: 94.4021\n",
      "03/06 00:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/06 00:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36000/40000]  base_lr: 4.6940e-05 lr: 4.6940e-05  eta: 0:44:15  time: 0.6548  data_time: 0.0244  memory: 5440  loss: 0.3589  decode.loss_ce: 0.3589  decode.acc_seg: 95.2321\n",
      "03/06 00:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36000 iterations\n",
      "03/06 00:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36100/40000]  base_lr: 4.6903e-05 lr: 4.6903e-05  eta: 0:43:09  time: 0.6531  data_time: 0.0239  memory: 5440  loss: 0.2774  decode.loss_ce: 0.2774  decode.acc_seg: 81.2516\n",
      "03/06 00:09:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36200/40000]  base_lr: 4.6865e-05 lr: 4.6865e-05  eta: 0:42:03  time: 0.6551  data_time: 0.0237  memory: 5440  loss: 0.3744  decode.loss_ce: 0.3744  decode.acc_seg: 81.6238\n",
      "03/06 00:10:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36300/40000]  base_lr: 4.6827e-05 lr: 4.6827e-05  eta: 0:40:56  time: 0.6570  data_time: 0.0251  memory: 5440  loss: 0.2084  decode.loss_ce: 0.2084  decode.acc_seg: 97.6142\n",
      "03/06 00:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36400/40000]  base_lr: 4.6789e-05 lr: 4.6789e-05  eta: 0:39:50  time: 0.6555  data_time: 0.0242  memory: 5440  loss: 0.2764  decode.loss_ce: 0.2764  decode.acc_seg: 44.7926\n",
      "03/06 00:12:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36500/40000]  base_lr: 4.6751e-05 lr: 4.6751e-05  eta: 0:38:43  time: 0.6584  data_time: 0.0246  memory: 5440  loss: 0.3904  decode.loss_ce: 0.3904  decode.acc_seg: 85.1934\n",
      "03/06 00:13:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36600/40000]  base_lr: 4.6713e-05 lr: 4.6713e-05  eta: 0:37:37  time: 0.6525  data_time: 0.0236  memory: 5440  loss: 0.2623  decode.loss_ce: 0.2623  decode.acc_seg: 94.7032\n",
      "03/06 00:14:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36700/40000]  base_lr: 4.6675e-05 lr: 4.6675e-05  eta: 0:36:30  time: 0.6596  data_time: 0.0237  memory: 5440  loss: 0.3297  decode.loss_ce: 0.3297  decode.acc_seg: 52.2966\n",
      "03/06 00:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36800/40000]  base_lr: 4.6638e-05 lr: 4.6638e-05  eta: 0:35:24  time: 0.6531  data_time: 0.0237  memory: 5440  loss: 0.2183  decode.loss_ce: 0.2183  decode.acc_seg: 97.9048\n",
      "03/06 00:16:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36900/40000]  base_lr: 4.6600e-05 lr: 4.6600e-05  eta: 0:34:18  time: 0.6582  data_time: 0.0235  memory: 5440  loss: 0.2188  decode.loss_ce: 0.2188  decode.acc_seg: 85.5057\n",
      "03/06 00:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/06 00:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37000/40000]  base_lr: 4.6562e-05 lr: 4.6562e-05  eta: 0:33:11  time: 0.6598  data_time: 0.0240  memory: 5440  loss: 0.2301  decode.loss_ce: 0.2301  decode.acc_seg: 87.8382\n",
      "03/06 00:18:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37100/40000]  base_lr: 4.6524e-05 lr: 4.6524e-05  eta: 0:32:05  time: 0.6521  data_time: 0.0237  memory: 5440  loss: 0.3008  decode.loss_ce: 0.3008  decode.acc_seg: 86.3290\n",
      "03/06 00:19:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37200/40000]  base_lr: 4.6486e-05 lr: 4.6486e-05  eta: 0:30:58  time: 0.6512  data_time: 0.0238  memory: 5440  loss: 0.2577  decode.loss_ce: 0.2577  decode.acc_seg: 91.4024\n",
      "03/06 00:21:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37300/40000]  base_lr: 4.6448e-05 lr: 4.6448e-05  eta: 0:29:52  time: 0.6532  data_time: 0.0235  memory: 5440  loss: 0.2729  decode.loss_ce: 0.2729  decode.acc_seg: 81.5105\n",
      "03/06 00:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37400/40000]  base_lr: 4.6410e-05 lr: 4.6410e-05  eta: 0:28:45  time: 0.6532  data_time: 0.0242  memory: 5440  loss: 0.2977  decode.loss_ce: 0.2977  decode.acc_seg: 92.4436\n",
      "03/06 00:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37500/40000]  base_lr: 4.6373e-05 lr: 4.6373e-05  eta: 0:27:39  time: 0.6538  data_time: 0.0244  memory: 5440  loss: 0.1743  decode.loss_ce: 0.1743  decode.acc_seg: 95.1592\n",
      "03/06 00:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37600/40000]  base_lr: 4.6335e-05 lr: 4.6335e-05  eta: 0:26:33  time: 0.6514  data_time: 0.0236  memory: 5440  loss: 0.2392  decode.loss_ce: 0.2392  decode.acc_seg: 93.9431\n",
      "03/06 00:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37700/40000]  base_lr: 4.6297e-05 lr: 4.6297e-05  eta: 0:25:26  time: 0.6641  data_time: 0.0259  memory: 5440  loss: 0.2692  decode.loss_ce: 0.2692  decode.acc_seg: 94.3849\n",
      "03/06 00:26:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37800/40000]  base_lr: 4.6259e-05 lr: 4.6259e-05  eta: 0:24:20  time: 0.6624  data_time: 0.0241  memory: 5440  loss: 0.3034  decode.loss_ce: 0.3034  decode.acc_seg: 87.0446\n",
      "03/06 00:27:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37900/40000]  base_lr: 4.6221e-05 lr: 4.6221e-05  eta: 0:23:13  time: 0.6680  data_time: 0.0252  memory: 5440  loss: 0.2412  decode.loss_ce: 0.2412  decode.acc_seg: 92.4268\n",
      "03/06 00:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/06 00:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38000/40000]  base_lr: 4.6183e-05 lr: 4.6183e-05  eta: 0:22:07  time: 0.6544  data_time: 0.0237  memory: 5440  loss: 0.3963  decode.loss_ce: 0.3963  decode.acc_seg: 94.6633\n",
      "03/06 00:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 38000 iterations\n",
      "03/06 00:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38100/40000]  base_lr: 4.6145e-05 lr: 4.6145e-05  eta: 0:21:01  time: 0.6551  data_time: 0.0247  memory: 5440  loss: 0.2127  decode.loss_ce: 0.2127  decode.acc_seg: 82.1222\n",
      "03/06 00:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38200/40000]  base_lr: 4.6108e-05 lr: 4.6108e-05  eta: 0:19:54  time: 0.6597  data_time: 0.0250  memory: 5440  loss: 0.2474  decode.loss_ce: 0.2474  decode.acc_seg: 63.9254\n",
      "03/06 00:32:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38300/40000]  base_lr: 4.6070e-05 lr: 4.6070e-05  eta: 0:18:48  time: 0.6525  data_time: 0.0241  memory: 5440  loss: 0.2954  decode.loss_ce: 0.2954  decode.acc_seg: 81.3778\n",
      "03/06 00:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38400/40000]  base_lr: 4.6032e-05 lr: 4.6032e-05  eta: 0:17:42  time: 0.6550  data_time: 0.0239  memory: 5440  loss: 0.4378  decode.loss_ce: 0.4378  decode.acc_seg: 89.5044\n",
      "03/06 00:34:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38500/40000]  base_lr: 4.5994e-05 lr: 4.5994e-05  eta: 0:16:35  time: 0.6671  data_time: 0.0259  memory: 5440  loss: 0.3214  decode.loss_ce: 0.3214  decode.acc_seg: 90.3698\n",
      "03/06 00:35:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38600/40000]  base_lr: 4.5956e-05 lr: 4.5956e-05  eta: 0:15:29  time: 0.6553  data_time: 0.0243  memory: 5440  loss: 0.3879  decode.loss_ce: 0.3879  decode.acc_seg: 82.0495\n",
      "03/06 00:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38700/40000]  base_lr: 4.5918e-05 lr: 4.5918e-05  eta: 0:14:22  time: 0.6530  data_time: 0.0240  memory: 5440  loss: 0.2837  decode.loss_ce: 0.2837  decode.acc_seg: 75.2058\n",
      "03/06 00:37:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38800/40000]  base_lr: 4.5880e-05 lr: 4.5880e-05  eta: 0:13:16  time: 0.6667  data_time: 0.0260  memory: 5440  loss: 0.2839  decode.loss_ce: 0.2839  decode.acc_seg: 97.6845\n",
      "03/06 00:38:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38900/40000]  base_lr: 4.5843e-05 lr: 4.5843e-05  eta: 0:12:10  time: 0.6645  data_time: 0.0249  memory: 5440  loss: 0.2104  decode.loss_ce: 0.2104  decode.acc_seg: 95.9733\n",
      "03/06 00:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/06 00:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39000/40000]  base_lr: 4.5805e-05 lr: 4.5805e-05  eta: 0:11:03  time: 0.6686  data_time: 0.0247  memory: 5440  loss: 0.3395  decode.loss_ce: 0.3395  decode.acc_seg: 79.5689\n",
      "03/06 00:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39100/40000]  base_lr: 4.5767e-05 lr: 4.5767e-05  eta: 0:09:57  time: 0.6552  data_time: 0.0245  memory: 5440  loss: 0.2123  decode.loss_ce: 0.2123  decode.acc_seg: 91.1578\n",
      "03/06 00:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39200/40000]  base_lr: 4.5729e-05 lr: 4.5729e-05  eta: 0:08:50  time: 0.6536  data_time: 0.0237  memory: 5440  loss: 0.3774  decode.loss_ce: 0.3774  decode.acc_seg: 89.0493\n",
      "03/06 00:43:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39300/40000]  base_lr: 4.5691e-05 lr: 4.5691e-05  eta: 0:07:44  time: 0.6577  data_time: 0.0245  memory: 5440  loss: 0.2911  decode.loss_ce: 0.2911  decode.acc_seg: 75.2832\n",
      "03/06 00:44:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39400/40000]  base_lr: 4.5653e-05 lr: 4.5653e-05  eta: 0:06:38  time: 0.6539  data_time: 0.0237  memory: 5440  loss: 0.5505  decode.loss_ce: 0.5505  decode.acc_seg: 95.0078\n",
      "03/06 00:45:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39500/40000]  base_lr: 4.5615e-05 lr: 4.5615e-05  eta: 0:05:31  time: 0.6539  data_time: 0.0243  memory: 5440  loss: 0.1610  decode.loss_ce: 0.1610  decode.acc_seg: 86.4595\n",
      "03/06 00:46:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39600/40000]  base_lr: 4.5578e-05 lr: 4.5578e-05  eta: 0:04:25  time: 0.6572  data_time: 0.0246  memory: 5440  loss: 0.2032  decode.loss_ce: 0.2032  decode.acc_seg: 87.6160\n",
      "03/06 00:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39700/40000]  base_lr: 4.5540e-05 lr: 4.5540e-05  eta: 0:03:19  time: 0.6595  data_time: 0.0247  memory: 5440  loss: 0.4548  decode.loss_ce: 0.4548  decode.acc_seg: 60.6395\n",
      "03/06 00:48:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39800/40000]  base_lr: 4.5502e-05 lr: 4.5502e-05  eta: 0:02:12  time: 0.6572  data_time: 0.0245  memory: 5440  loss: 0.2845  decode.loss_ce: 0.2845  decode.acc_seg: 82.4687\n",
      "03/06 00:49:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39900/40000]  base_lr: 4.5464e-05 lr: 4.5464e-05  eta: 0:01:06  time: 0.6547  data_time: 0.0242  memory: 5440  loss: 0.2114  decode.loss_ce: 0.2114  decode.acc_seg: 91.8308\n",
      "03/06 00:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: segformer_mit-b5_8xb2-160k_ade20k-512x512_20240305_172749\n",
      "03/06 00:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40000/40000]  base_lr: 4.5426e-05 lr: 4.5426e-05  eta: 0:00:00  time: 0.6609  data_time: 0.0250  memory: 5440  loss: 0.2487  decode.loss_ce: 0.2487  decode.acc_seg: 91.3148\n",
      "03/06 00:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40000 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (data_preprocessor): SegDataPreProcessor()\n",
       "  (backbone): MixVisionTransformer(\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n",
       "              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (8): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (9): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (10): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (11): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (12): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (13): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (14): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (15): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (16): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (17): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (18): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (19): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (20): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (21): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (22): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (23): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (24): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (25): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (26): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (27): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (28): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (29): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (30): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (31): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (32): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (33): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (34): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (35): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (36): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (37): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (38): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (39): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): PatchEmbed(\n",
       "          (projection): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): EfficientMultiheadAttention(\n",
       "              (attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "              )\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (ffn): MixFFN(\n",
       "              (activate): GELU(approximate=none)\n",
       "              (layers): Sequential(\n",
       "                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "                (2): GELU(approximate=none)\n",
       "                (3): Dropout(p=0.0, inplace=False)\n",
       "                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (5): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b4_512x512_160k_ade20k/segformer_mit-b4_512x512_160k_ade20k_20210728_183055-7f509d7d.pth'}\n",
       "  (decode_head): SegformerHead(\n",
       "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (conv_seg): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fusion_conv): ConvModule(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f6266b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-06T00:50:51.961878Z",
     "iopub.status.busy": "2024-03-06T00:50:51.960980Z",
     "iopub.status.idle": "2024-03-06T00:54:32.685031Z",
     "shell.execute_reply": "2024-03-06T00:54:32.684086Z"
    },
    "papermill": {
     "duration": 220.930666,
     "end_time": "2024-03-06T00:54:32.687190",
     "exception": false,
     "start_time": "2024-03-06T00:50:51.756524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmseg/datasets/transforms/loading.py:83: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/06 00:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/450]    eta: 0:02:54  time: 0.4679  data_time: 0.2809  memory: 4884  \n",
      "03/06 00:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/450]    eta: 0:02:05  time: 0.5790  data_time: 0.3917  memory: 2556  \n",
      "03/06 00:53:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/450]    eta: 0:01:14  time: 0.4548  data_time: 0.2486  memory: 2547  \n",
      "03/06 00:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/450]    eta: 0:00:24  time: 0.4585  data_time: 0.2577  memory: 2380  \n",
      "03/06 00:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "03/06 00:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 22.85 | 31.62 | 37.19 | 37.19  |   45.15   | 31.62  |\n",
      "| BuildingFlooded |  72.1 | 87.91 | 83.79 | 83.79  |   80.03   | 87.91  |\n",
      "|   BNonFlooded   |  62.7 | 74.87 | 77.08 | 77.08  |   79.42   | 74.87  |\n",
      "|   RoadFlooded   | 55.14 | 72.33 | 71.09 | 71.09  |   69.89   | 72.33  |\n",
      "|   RNonFlooded   | 73.96 |  79.9 | 85.03 | 85.03  |   90.86   |  79.9  |\n",
      "|      Water      | 63.23 | 76.73 | 77.48 | 77.48  |   78.23   | 76.73  |\n",
      "|       Tree      | 75.39 | 82.63 | 85.97 | 85.97  |    89.6   | 82.63  |\n",
      "|      Vecile     | 18.94 | 27.43 | 31.85 | 31.85  |   37.98   | 27.43  |\n",
      "|       Pool      | 40.84 | 46.75 | 57.99 | 57.99  |   76.34   | 46.75  |\n",
      "|      Grass      | 84.07 | 93.92 | 91.34 | 91.34  |   88.91   | 93.92  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "03/06 00:54:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/450]    aAcc: 86.1600  mIoU: 56.9200  mAcc: 67.4100  mDice: 69.8800  mFscore: 69.8800  mPrecision: 73.6400  mRecall: 67.4100  data_time: 0.2877  time: 0.4860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aAcc': 86.16,\n",
       " 'mIoU': 56.92,\n",
       " 'mAcc': 67.41,\n",
       " 'mDice': 69.88,\n",
       " 'mFscore': 69.88,\n",
       " 'mPrecision': 73.64,\n",
       " 'mRecall': 67.41}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.test()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2963587,
     "sourceId": 5104516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27039.200341,
   "end_time": "2024-03-06T00:54:37.200603",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-05T17:23:58.000262",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
