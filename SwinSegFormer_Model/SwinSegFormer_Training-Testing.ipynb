{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb368fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:05:00.260720Z",
     "iopub.status.busy": "2024-05-09T06:05:00.260413Z",
     "iopub.status.idle": "2024-05-09T06:05:01.218849Z",
     "shell.execute_reply": "2024-05-09T06:05:01.217945Z"
    },
    "papermill": {
     "duration": 0.972555,
     "end_time": "2024-05-09T06:05:01.221114",
     "exception": false,
     "start_time": "2024-05-09T06:05:00.248559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\r\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\r\n",
      "Cuda compilation tools, release 12.1, V12.1.105\r\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9266cba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:05:01.243913Z",
     "iopub.status.busy": "2024-05-09T06:05:01.243606Z",
     "iopub.status.idle": "2024-05-09T06:05:02.225882Z",
     "shell.execute_reply": "2024-05-09T06:05:02.224793Z"
    },
    "papermill": {
     "duration": 0.996356,
     "end_time": "2024-05-09T06:05:02.228236",
     "exception": false,
     "start_time": "2024-05-09T06:05:01.231880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  9 06:05:02 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   33C    P0              25W / 250W |      0MiB / 16384MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4ad34db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:05:02.251013Z",
     "iopub.status.busy": "2024-05-09T06:05:02.250691Z",
     "iopub.status.idle": "2024-05-09T06:05:03.187828Z",
     "shell.execute_reply": "2024-05-09T06:05:03.186720Z"
    },
    "papermill": {
     "duration": 0.951354,
     "end_time": "2024-05-09T06:05:03.190328",
     "exception": false,
     "start_time": "2024-05-09T06:05:02.238974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc2ec98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:05:03.213930Z",
     "iopub.status.busy": "2024-05-09T06:05:03.213612Z",
     "iopub.status.idle": "2024-05-09T06:05:03.219456Z",
     "shell.execute_reply": "2024-05-09T06:05:03.218698Z"
    },
    "papermill": {
     "duration": 0.020413,
     "end_time": "2024-05-09T06:05:03.221534",
     "exception": false,
     "start_time": "2024-05-09T06:05:03.201121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33744d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:05:03.243999Z",
     "iopub.status.busy": "2024-05-09T06:05:03.243536Z",
     "iopub.status.idle": "2024-05-09T06:06:06.486237Z",
     "shell.execute_reply": "2024-05-09T06:06:06.485138Z"
    },
    "papermill": {
     "duration": 63.256482,
     "end_time": "2024-05-09T06:06:06.488614",
     "exception": false,
     "start_time": "2024-05-09T06:05:03.232132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.12.0\r\n",
      "  Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\r\n",
      "Collecting torchvision==0.13.0\r\n",
      "  Downloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\r\n",
      "Collecting torchaudio==0.12.0\r\n",
      "  Downloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==1.12.0) (4.9.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (1.26.4)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (2.31.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.13.0) (9.5.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.13.0) (2024.2.2)\r\n",
      "Downloading torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchvision-0.13.0-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torchaudio-0.12.0-cp310-cp310-manylinux1_x86_64.whl (3.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision, torchaudio\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 2.1.2\r\n",
      "    Uninstalling torch-2.1.2:\r\n",
      "      Successfully uninstalled torch-2.1.2\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.16.2\r\n",
      "    Uninstalling torchvision-0.16.2:\r\n",
      "      Successfully uninstalled torchvision-0.16.2\r\n",
      "  Attempting uninstall: torchaudio\r\n",
      "    Found existing installation: torchaudio 2.1.2\r\n",
      "    Uninstalling torchaudio-2.1.2:\r\n",
      "      Successfully uninstalled torchaudio-2.1.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 2.2.2 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "stable-baselines3 2.1.0 requires torch>=1.13, but you have torch 1.12.0 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.12.0 torchaudio-0.12.0 torchvision-0.13.0\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch==1.7.0 torchvision==0.8.0\n",
    "!pip install torch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef1cae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:06:06.544499Z",
     "iopub.status.busy": "2024-05-09T06:06:06.543938Z",
     "iopub.status.idle": "2024-05-09T06:07:17.595274Z",
     "shell.execute_reply": "2024-05-09T06:07:17.594342Z"
    },
    "papermill": {
     "duration": 71.081737,
     "end_time": "2024-05-09T06:07:17.597717",
     "exception": false,
     "start_time": "2024-05-09T06:06:06.515980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\r\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.10/site-packages (from openmim) (8.1.7)\r\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from openmim) (0.4.6)\r\n",
      "Collecting model-index (from openmim)\r\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting opendatalab (from openmim)\r\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from openmim) (2.1.4)\r\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.10/site-packages (from openmim) (23.3.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from openmim) (2.31.0)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from openmim) (13.7.0)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from openmim) (0.9.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (6.0.1)\r\n",
      "Requirement already satisfied: markdown in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (3.5.2)\r\n",
      "Requirement already satisfied: ordered-set in /opt/conda/lib/python3.10/site-packages (from model-index->openmim) (4.1.0)\r\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (3.20.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from opendatalab->openmim) (4.66.1)\r\n",
      "Collecting openxlab (from opendatalab->openmim)\r\n",
      "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->openmim) (2024.2.2)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->openmim) (2023.4)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->openmim) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\r\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting requests (from openmim)\r\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\r\n",
      "Collecting rich (from openmim)\r\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\r\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\r\n",
      "Collecting tqdm (from opendatalab->openmim)\r\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2~=2.17.0->openxlab->opendatalab->openmim) (1.7)\r\n",
      "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading aliyun-python-sdk-core-2.15.1.tar.gz (443 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\r\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.7)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\r\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\r\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\r\n",
      "Downloading openxlab-0.0.38-py3-none-any.whl (302 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading setuptools-60.2.0-py3-none-any.whl (953 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.3-py2.py3-none-any.whl (98 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\r\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core\r\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=6d2fca809aa9c43b83a9f2a00836b36adcb9a7e6d65abb43c07c44ceaab646b2\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\r\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.1-py3-none-any.whl size=535325 sha256=f506468a9280c873b4d223838c584357bb652de04f85cc93e46d91dbbd1d23a4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/4b/8e/0a28e00f4cf43b273c18cce083804738d41013e017da922ce4\r\n",
      "Successfully built oss2 aliyun-python-sdk-core\r\n",
      "Installing collected packages: tqdm, setuptools, requests, model-index, jmespath, rich, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.1\r\n",
      "    Uninstalling tqdm-4.66.1:\r\n",
      "      Successfully uninstalled tqdm-4.66.1\r\n",
      "  Attempting uninstall: setuptools\r\n",
      "    Found existing installation: setuptools 69.0.3\r\n",
      "    Uninstalling setuptools-69.0.3:\r\n",
      "      Successfully uninstalled setuptools-69.0.3\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.31.0\r\n",
      "    Uninstalling requests-2.31.0:\r\n",
      "      Successfully uninstalled requests-2.31.0\r\n",
      "  Attempting uninstall: jmespath\r\n",
      "    Found existing installation: jmespath 1.0.1\r\n",
      "    Uninstalling jmespath-1.0.1:\r\n",
      "      Successfully uninstalled jmespath-1.0.1\r\n",
      "  Attempting uninstall: rich\r\n",
      "    Found existing installation: rich 13.7.0\r\n",
      "    Uninstalling rich-13.7.0:\r\n",
      "      Successfully uninstalled rich-13.7.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.9.3 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.6 which is incompatible.\r\n",
      "boto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.34.69 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\r\n",
      "jupyterlab-server 2.25.2 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "pytorch-lightning 2.2.2 requires torch>=1.13.0, but you have torch 1.12.0 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\r\n",
      "torchdata 0.7.1 requires torch>=2, but you have torch 1.12.0 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.15.1 aliyun-python-sdk-kms-2.16.3 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.38 oss2-2.17.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmengine\r\n",
      "  Downloading mmengine-0.10.4-py3-none-any.whl.metadata (20 kB)\r\n",
      "Collecting addict (from mmengine)\r\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmengine) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmengine) (6.0.1)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine) (2.4.0)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmengine) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmengine) (4.9.0.80)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (21.3)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine) (2.9.0.post0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine) (2.17.2)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmengine) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\r\n",
      "Downloading mmengine-0.10.4-py3-none-any.whl (451 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
      "Installing collected packages: addict, mmengine\r\n",
      "Successfully installed addict-2.4.0 mmengine-0.10.4\r\n",
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\r\n",
      "  warnings.warn(\r\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/index.html\r\n",
      "Collecting mmcv==2.0.0rc4\r\n",
      "  Downloading https://download.openmmlab.com/mmcv/dist/cu102/torch1.12.0/mmcv-2.0.0rc4-cp310-cp310-manylinux1_x86_64.whl (36.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.0/36.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (2.4.0)\r\n",
      "Requirement already satisfied: mmengine>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (0.10.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (21.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (6.0.1)\r\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (0.40.2)\r\n",
      "Requirement already satisfied: opencv-python>=3 in /opt/conda/lib/python3.10/site-packages (from mmcv==2.0.0rc4) (4.9.0.80)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv==2.0.0rc4) (3.7.5)\r\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv==2.0.0rc4) (13.4.2)\r\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from mmengine>=0.2.0->mmcv==2.0.0rc4) (2.4.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->mmcv==2.0.0rc4) (3.1.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=6.6.0 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv==2.0.0rc4) (6.11.0)\r\n",
      "Requirement already satisfied: platformdirs>=3.5.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv==2.0.0rc4) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=2.0.1 in /opt/conda/lib/python3.10/site-packages (from yapf->mmcv==2.0.0rc4) (2.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=6.6.0->yapf->mmcv==2.0.0rc4) (3.17.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (1.4.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0rc4) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->mmengine>=0.2.0->mmcv==2.0.0rc4) (2.17.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.2.0->mmcv==2.0.0rc4) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.2.0->mmcv==2.0.0rc4) (1.16.0)\r\n",
      "Installing collected packages: mmcv\r\n",
      "Successfully installed mmcv-2.0.0rc4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openmim\n",
    "# Install mmengine\n",
    "!mim install mmengine\n",
    "# Install MMCV\n",
    "#!mim install 'mmcv >= 2.0.0rc1'\n",
    "!mim install 'mmcv==2.0.0rc4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41154748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:17.683001Z",
     "iopub.status.busy": "2024-05-09T06:07:17.682652Z",
     "iopub.status.idle": "2024-05-09T06:07:18.835993Z",
     "shell.execute_reply": "2024-05-09T06:07:18.835007Z"
    },
    "papermill": {
     "duration": 1.198997,
     "end_time": "2024-05-09T06:07:18.838791",
     "exception": false,
     "start_time": "2024-05-09T06:07:17.639794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102 True\n",
      "0.13.0+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/requests/__init__.py:109: RequestsDependencyWarning: urllib3 (2.1.0) or chardet (None)/charset_normalizer (3.3.2) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0486aabe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:18.924692Z",
     "iopub.status.busy": "2024-05-09T06:07:18.924316Z",
     "iopub.status.idle": "2024-05-09T06:07:46.640799Z",
     "shell.execute_reply": "2024-05-09T06:07:46.639671Z"
    },
    "papermill": {
     "duration": 27.761701,
     "end_time": "2024-05-09T06:07:46.642949",
     "exception": false,
     "start_time": "2024-05-09T06:07:18.881248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'mmsegmentation': No such file or directory\r\n",
      "Cloning into 'mmsegmentation'...\r\n",
      "remote: Enumerating objects: 16493, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (165/165), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (98/98), done.\u001b[K\r\n",
      "remote: Total 16493 (delta 68), reused 118 (delta 65), pack-reused 16328\u001b[K\r\n",
      "Receiving objects: 100% (16493/16493), 43.85 MiB | 37.02 MiB/s, done.\r\n",
      "Resolving deltas: 100% (11448/11448), done.\r\n",
      "/kaggle/working/mmsegmentation\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools_scm/_integration/setuptools.py:30: RuntimeWarning: \r\n",
      "ERROR: setuptools==60.2.0 is used in combination with setuptools_scm>=8.x\r\n",
      "\r\n",
      "Your build configuration is incomplete and previously worked by accident!\r\n",
      "setuptools_scm requires setuptools>=61\r\n",
      "\r\n",
      "Suggested workaround if applicable:\r\n",
      " - migrating from the deprecated setup_requires mechanism to pep517/518\r\n",
      "   and using a pyproject.toml to declare build dependencies\r\n",
      "   which are reliably pre-installed before running the build tools\r\n",
      "\r\n",
      "  warnings.warn(\r\n",
      "running build\r\n",
      "running build_py\r\n",
      "creating build\r\n",
      "creating build/lib\r\n",
      "creating build/lib/tests\r\n",
      "copying tests/test_digit_version.py -> build/lib/tests\r\n",
      "copying tests/__init__.py -> build/lib/tests\r\n",
      "copying tests/test_config.py -> build/lib/tests\r\n",
      "copying tests/test_sampler.py -> build/lib/tests\r\n",
      "creating build/lib/mmseg\r\n",
      "copying mmseg/__init__.py -> build/lib/mmseg\r\n",
      "copying mmseg/version.py -> build/lib/mmseg\r\n",
      "creating build/lib/tests/test_models\r\n",
      "copying tests/test_models/__init__.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_data_preprocessor.py -> build/lib/tests/test_models\r\n",
      "copying tests/test_models/test_forward.py -> build/lib/tests/test_models\r\n",
      "creating build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/utils.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_cascade_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_seg_tta_model.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_multimodal_encoder_decoder.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/__init__.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "copying tests/test_models/test_segmentors/test_depth_estimator.py -> build/lib/tests/test_models/test_segmentors\r\n",
      "creating build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/utils.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_san_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ocr_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_lraspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ema_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_cc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segmenter_mask_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dm_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/__init__.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_vpd_depth_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ann_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_up_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dnl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_gc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_apc_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_uper_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_segformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_dpt_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_pidnet_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_isa_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_nl_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_psp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_setr_mla_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_fcn_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_decode_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_aspp_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_ham_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_maskformer_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "copying tests/test_models/test_heads/test_mask2former_head.py -> build/lib/tests/test_models/test_heads\r\n",
      "creating build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/__init__.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_shape_convert.py -> build/lib/tests/test_models/test_utils\r\n",
      "copying tests/test_models/test_utils/test_embed.py -> build/lib/tests/test_models/test_utils\r\n",
      "creating build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/utils.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_stdc.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mscan.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_swin.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/__init__.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_unet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv1.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_erfnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_icnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_blocks.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mobilenet_v3.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_twins.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnest.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_timm_backbone.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_clip_text_encoder.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_beit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_hrnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_resnext.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_bisenetv2.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_cgnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_pidnet.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_vpd.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mit.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_fast_scnn.py -> build/lib/tests/test_models/test_backbones\r\n",
      "copying tests/test_models/test_backbones/test_mae.py -> build/lib/tests/test_models/test_backbones\r\n",
      "creating build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_mla_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_multilevel_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/__init__.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_jpu.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_feature2pyramid.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_fpn.py -> build/lib/tests/test_models/test_necks\r\n",
      "copying tests/test_models/test_necks/test_ic_neck.py -> build/lib/tests/test_models/test_necks\r\n",
      "creating build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/local_visualizer.py -> build/lib/mmseg/visualization\r\n",
      "copying mmseg/visualization/__init__.py -> build/lib/mmseg/visualization\r\n",
      "creating build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/__init__.py -> build/lib/mmseg/structures\r\n",
      "copying mmseg/structures/seg_data_sample.py -> build/lib/mmseg/structures\r\n",
      "creating build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/class_names.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/io.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/tokenizer.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/__init__.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/collect_env.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/get_templates.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/typing_utils.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/mask_classification.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/misc.py -> build/lib/mmseg/utils\r\n",
      "copying mmseg/utils/set_env.py -> build/lib/mmseg/utils\r\n",
      "creating build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dsdl.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/synapse.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isaid.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/basesegdataset.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/isprs.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/stare.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/levir.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/coco_stuff.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dark_zurich.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/__init__.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/pascal_context.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/lip.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/decathlon.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/chase_db1.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hsi_drive.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/cityscapes.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/dataset_wrappers.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/hrf.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/voc.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/ade.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/mapillary.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/potsdam.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/bdd100k.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/loveda.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/refuge.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/night_driving.py -> build/lib/mmseg/datasets\r\n",
      "copying mmseg/datasets/nyu.py -> build/lib/mmseg/datasets\r\n",
      "creating build/lib/mmseg/engine\r\n",
      "copying mmseg/engine/__init__.py -> build/lib/mmseg/engine\r\n",
      "creating build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/__init__.py -> build/lib/mmseg/registry\r\n",
      "copying mmseg/registry/registry.py -> build/lib/mmseg/registry\r\n",
      "creating build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/utils.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/__init__.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/mmseg_inferencer.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/remote_sense_inferencer.py -> build/lib/mmseg/apis\r\n",
      "copying mmseg/apis/inference.py -> build/lib/mmseg/apis\r\n",
      "creating build/lib/mmseg/evaluation\r\n",
      "copying mmseg/evaluation/__init__.py -> build/lib/mmseg/evaluation\r\n",
      "creating build/lib/mmseg/models\r\n",
      "copying mmseg/models/builder.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/__init__.py -> build/lib/mmseg/models\r\n",
      "copying mmseg/models/data_preprocessor.py -> build/lib/mmseg/models\r\n",
      "creating build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/builder.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/__init__.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/ohem_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "copying mmseg/structures/sampler/base_pixel_sampler.py -> build/lib/mmseg/structures/sampler\r\n",
      "creating build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/formatting.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/transforms.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/loading.py -> build/lib/mmseg/datasets/transforms\r\n",
      "copying mmseg/datasets/transforms/__init__.py -> build/lib/mmseg/datasets/transforms\r\n",
      "creating build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/__init__.py -> build/lib/mmseg/engine/schedulers\r\n",
      "copying mmseg/engine/schedulers/poly_ratio_scheduler.py -> build/lib/mmseg/engine/schedulers\r\n",
      "creating build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/visualization_hook.py -> build/lib/mmseg/engine/hooks\r\n",
      "copying mmseg/engine/hooks/__init__.py -> build/lib/mmseg/engine/hooks\r\n",
      "creating build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/force_default_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/__init__.py -> build/lib/mmseg/engine/optimizers\r\n",
      "copying mmseg/engine/optimizers/layer_decay_optimizer_constructor.py -> build/lib/mmseg/engine/optimizers\r\n",
      "creating build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/__init__.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/iou_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/citys_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "copying mmseg/evaluation/metrics/depth_metric.py -> build/lib/mmseg/evaluation/metrics\r\n",
      "creating build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/featurepyramid.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/ic_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/__init__.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/fpn.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/mla_neck.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/jpu.py -> build/lib/mmseg/models/necks\r\n",
      "copying mmseg/models/necks/multilevel_neck.py -> build/lib/mmseg/models/necks\r\n",
      "creating build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnest.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mscan.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/twins.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/beit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/fast_scnn.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vit.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/__init__.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/resnext.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/bisenetv1.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/vpd.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/swin.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/timm_backbone.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/stdc.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/erfnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/cgnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/hrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v3.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mobilenet_v2.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/pidnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/icnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/ddrnet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/unet.py -> build/lib/mmseg/models/backbones\r\n",
      "copying mmseg/models/backbones/mae.py -> build/lib/mmseg/models/backbones\r\n",
      "creating build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/__init__.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/hungarian_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/base_assigner.py -> build/lib/mmseg/models/assigners\r\n",
      "copying mmseg/models/assigners/match_cost.py -> build/lib/mmseg/models/assigners\r\n",
      "creating build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/res_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/__init__.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/point_sample.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/se_layer.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/ppm.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/inverted_residual.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/basic_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/wrappers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/make_divisible.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/up_conv_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/san_layers.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/self_attention_block.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/shape_convert.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/embed.py -> build/lib/mmseg/models/utils\r\n",
      "copying mmseg/models/utils/encoding.py -> build/lib/mmseg/models/utils\r\n",
      "creating build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/__init__.py -> build/lib/mmseg/models/text_encoder\r\n",
      "copying mmseg/models/text_encoder/clip_text_encoder.py -> build/lib/mmseg/models/text_encoder\r\n",
      "creating build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/depth_estimator.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/__init__.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/cascade_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/multimodal_encoder_decoder.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/seg_tta.py -> build/lib/mmseg/models/segmentors\r\n",
      "copying mmseg/models/segmentors/base.py -> build/lib/mmseg/models/segmentors\r\n",
      "creating build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/point_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cascade_decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fpn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/mask2former_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/enc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dm_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_up_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/__init__.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/isa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ocr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/decode_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/gc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/cc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dpt_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/stdc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/setr_mla_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ann_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/nl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/pid_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/vpd_depth_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/lraspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/apc_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/knet_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/uper_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ddr_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/dnl_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ham_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/da_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/ema_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/san_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/psa_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_fcn_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/segmenter_mask_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/sep_aspp_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "copying mmseg/models/decode_heads/maskformer_head.py -> build/lib/mmseg/models/decode_heads\r\n",
      "creating build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/utils.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/tversky_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/focal_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/ohem_cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/dice_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/boundary_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/accuracy.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/kldiv_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/__init__.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/huasdorff_distance_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/silog_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/cross_entropy_loss.py -> build/lib/mmseg/models/losses\r\n",
      "copying mmseg/models/losses/lovasz_loss.py -> build/lib/mmseg/models/losses\r\n",
      "running egg_info\r\n",
      "creating mmsegmentation.egg-info\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "warning: no files found matching 'mmseg/.mim/model-index.yml'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.yaml' under directory 'mmseg/.mim/configs'\r\n",
      "warning: no files found matching '*.py' under directory 'mmseg/.mim/tools'\r\n",
      "warning: no files found matching '*.sh' under directory 'mmseg/.mim/tools'\r\n",
      "writing manifest file 'mmsegmentation.egg-info/SOURCES.txt'\r\n",
      "creating build/lib/tests/data\r\n",
      "copying tests/data/biomedical.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.npy -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical.pkl -> build/lib/tests/data\r\n",
      "copying tests/data/biomedical_ann.nii.gz -> build/lib/tests/data\r\n",
      "copying tests/data/color.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/dataset.json -> build/lib/tests/data\r\n",
      "copying tests/data/gray.jpg -> build/lib/tests/data\r\n",
      "copying tests/data/seg.png -> build/lib/tests/data\r\n",
      "creating build/lib/tests/data/dsdl_seg\r\n",
      "copying tests/data/dsdl_seg/config.py -> build/lib/tests/data/dsdl_seg\r\n",
      "creating build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/class-dom.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "copying tests/data/dsdl_seg/defs/segmentation-def.yaml -> build/lib/tests/data/dsdl_seg/defs\r\n",
      "creating build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train.yaml -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "copying tests/data/dsdl_seg/set-train/train_samples.json -> build/lib/tests/data/dsdl_seg/set-train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/0004a4c0-d4dff0ad.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00054602-3bf57337.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/train/00067cfb-e535423e.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d06fefd-f7be05a6.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d128593-0ccfea4c.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/images/10k/val/7d15b18b-1e0d6e3f.jpg -> build/lib/tests/data/pseudo_bdd100k_dataset/images/10k/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val/7d2f7975-e0c1c5a7.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/colormaps/val\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/0004a4c0-d4dff0ad.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00054602-3bf57337.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train/00067cfb-e535423e.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/train\r\n",
      "creating build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d06fefd-f7be05a6.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d128593-0ccfea4c.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "copying tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val/7d15b18b-1e0d6e3f.png -> build/lib/tests/data/pseudo_bdd100k_dataset/labels/sem_seg/masks/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_instanceIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt/frankfurt_000000_000294_gtFine_labelTrainIds.png -> build/lib/tests/data/pseudo_cityscapes_dataset/gtFine/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val\r\n",
      "creating build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "copying tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt/frankfurt_000000_000294_leftImg8bit.png -> build/lib/tests/data/pseudo_cityscapes_dataset/leftImg8bit/val/frankfurt\r\n",
      "creating build/lib/tests/data/pseudo_dataset\r\n",
      "creating build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00000_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00001_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00002_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00003_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "copying tests/data/pseudo_dataset/gts/00004_gt.png -> build/lib/tests/data/pseudo_dataset/gts\r\n",
      "creating build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00000_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00001_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00002_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00003_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "copying tests/data/pseudo_dataset/imgs/00004_img.jpg -> build/lib/tests/data/pseudo_dataset/imgs\r\n",
      "creating build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/train.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "copying tests/data/pseudo_dataset/splits/val.txt -> build/lib/tests/data/pseudo_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/annotations\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1111_577_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1112_569_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/annotations/test/nf1113_557_TC.png -> build/lib/tests/data/pseudo_hsidrive20_dataset/annotations/test\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1111_577_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1112_569_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "copying tests/data/pseudo_hsidrive20_dataset/images/test/nf1113_557_TC.npy -> build/lib/tests/data/pseudo_hsidrive20_dataset/images/test\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1024_1920_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/ann_dir/P0000_0_896_1536_2432_instance_color_RGB.png -> build/lib/tests/data/pseudo_isaid_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1024_1920.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "copying tests/data/pseudo_isaid_dataset/img_dir/P0000_0_896_1536_2432.png -> build/lib/tests/data/pseudo_isaid_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/train.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "copying tests/data/pseudo_isaid_dataset/splits/val.txt -> build/lib/tests/data/pseudo_isaid_dataset/splits\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "copying tests/data/pseudo_lip_dataset/train_images/684_2150041.jpg -> build/lib/tests/data/pseudo_lip_dataset/train_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/train_segmentations/684_2150041.png -> build/lib/tests/data/pseudo_lip_dataset/train_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "copying tests/data/pseudo_lip_dataset/val_images/86_185913.jpg -> build/lib/tests/data/pseudo_lip_dataset/val_images\r\n",
      "creating build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "copying tests/data/pseudo_lip_dataset/val_segmentations/86_185913.png -> build/lib/tests/data/pseudo_lip_dataset/val_segmentations\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/ann_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/0.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/1.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "copying tests/data/pseudo_loveda_dataset/img_dir/2.png -> build/lib/tests/data/pseudo_loveda_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "copying tests/data/pseudo_mapillary_dataset/images/__CRyFzoDOXn6unQ6a3DnQ.jpg -> build/lib/tests/data/pseudo_mapillary_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v1.2/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v1.2\r\n",
      "creating build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "copying tests/data/pseudo_mapillary_dataset/v2.0/__CRyFzoDOXn6unQ6a3DnQ.png -> build/lib/tests/data/pseudo_mapillary_dataset/v2.0\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "copying tests/data/pseudo_nyu_dataset/annotations/bookstore_0001d_00001.png -> build/lib/tests/data/pseudo_nyu_dataset/annotations\r\n",
      "creating build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "copying tests/data/pseudo_nyu_dataset/images/bookstore_0001d_00001.jpg -> build/lib/tests/data/pseudo_nyu_dataset/images\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/ann_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "copying tests/data/pseudo_potsdam_dataset/img_dir/2_10_0_0_512_512.png -> build/lib/tests/data/pseudo_potsdam_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/ann_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "copying tests/data/pseudo_refuge_dataset/img_dir/pseudo_g0001.png -> build/lib/tests/data/pseudo_refuge_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice000.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/ann_dir/case0005_slice001.png -> build/lib/tests/data/pseudo_synapse_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice000.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "copying tests/data/pseudo_synapse_dataset/img_dir/case0005_slice001.jpg -> build/lib/tests/data/pseudo_synapse_dataset/img_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/ann_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/ann_dir\r\n",
      "creating build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "copying tests/data/pseudo_vaihingen_dataset/img_dir/area1_0_0_512_512.png -> build/lib/tests/data/pseudo_vaihingen_dataset/img_dir\r\n",
      "creating build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/test_rs_inferencer.py -> build/lib/tests/test_apis\r\n",
      "copying tests/test_apis/utils.py -> build/lib/tests/test_apis\r\n",
      "creating build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_dataset_builder.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_formatting.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_loading.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_transform.py -> build/lib/tests/test_datasets\r\n",
      "copying tests/test_datasets/test_tta.py -> build/lib/tests/test_datasets\r\n",
      "creating build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_layer_decay_optimizer_constructor.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_optimizer.py -> build/lib/tests/test_engine\r\n",
      "copying tests/test_engine/test_visualization_hook.py -> build/lib/tests/test_engine\r\n",
      "creating build/lib/tests/test_evaluation\r\n",
      "creating build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_citys_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_depth_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "copying tests/test_evaluation/test_metrics/test_iou_metric.py -> build/lib/tests/test_evaluation/test_metrics\r\n",
      "creating build/lib/tests/test_structures\r\n",
      "copying tests/test_structures/test_seg_data_sample.py -> build/lib/tests/test_structures\r\n",
      "creating build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_io.py -> build/lib/tests/test_utils\r\n",
      "copying tests/test_utils/test_set_env.py -> build/lib/tests/test_utils\r\n",
      "creating build/lib/tests/test_visualization\r\n",
      "copying tests/test_visualization/test_local_visualizer.py -> build/lib/tests/test_visualization\r\n",
      "creating build/lib/mmseg/configs\r\n",
      "creating build/lib/mmseg/configs/_base_\r\n",
      "copying mmseg/configs/_base_/default_runtime.py -> build/lib/mmseg/configs/_base_\r\n",
      "creating build/lib/mmseg/configs/_base_/datasets\r\n",
      "copying mmseg/configs/_base_/datasets/loveda.py -> build/lib/mmseg/configs/_base_/datasets\r\n",
      "copying mmseg/configs/_base_/datasets/potsdam.py -> build/lib/mmseg/configs/_base_/datasets\r\n",
      "creating build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_160k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_20k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_240k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_25k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_320k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_40k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "copying mmseg/configs/_base_/schedules/schedule_80k.py -> build/lib/mmseg/configs/_base_/schedules\r\n",
      "creating build/lib/tests/test_models/test_assigners\r\n",
      "copying tests/test_models/test_assigners/test_hungarian_assigner.py -> build/lib/tests/test_models/test_assigners\r\n",
      "creating build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_cross_entropy_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_dice_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_huasdorff_distance_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_kldiv_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_silog_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying tests/test_models/test_losses/test_tversky_loss.py -> build/lib/tests/test_models/test_losses\r\n",
      "copying mmseg/utils/bpe_simple_vocab_16e6.txt.gz -> build/lib/mmseg/utils\r\n",
      "Processing /kaggle/working/mmsegmentation\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.7.5)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (21.3)\r\n",
      "Requirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (3.9.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from mmsegmentation==1.2.2) (1.11.4)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (1.4.5)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (9.5.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mmsegmentation==1.2.2) (2.9.0.post0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->mmsegmentation==1.2.2) (0.2.13)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mmsegmentation==1.2.2) (1.16.0)\r\n",
      "Building wheels for collected packages: mmsegmentation\r\n",
      "  Building wheel for mmsegmentation (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for mmsegmentation: filename=mmsegmentation-1.2.2-py3-none-any.whl size=31510284 sha256=362eefc1fe69bff833eb31026cae8d5b5d33abc95e76d90bb7f0243fa3292bf6\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qs_y3_hy/wheels/43/47/68/4f234c90f5372e6bde61cb1d00ac67ba84723d1e9801de501d\r\n",
      "Successfully built mmsegmentation\r\n",
      "Installing collected packages: mmsegmentation\r\n",
      "Successfully installed mmsegmentation-1.2.2\r\n",
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "!rm -r mmsegmentation\n",
    "#!git clone https://github.com/alirafiqmalik/mmsegmentation.git \n",
    "!git clone -b main https://github.com/open-mmlab/mmsegmentation.git \n",
    "%cd mmsegmentation\n",
    "# !pip install -v -e .\n",
    "!python setup.py build\n",
    "!pip install .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e894539a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:46.742218Z",
     "iopub.status.busy": "2024-05-09T06:07:46.741476Z",
     "iopub.status.idle": "2024-05-09T06:07:47.694786Z",
     "shell.execute_reply": "2024-05-09T06:07:47.693511Z"
    },
    "papermill": {
     "duration": 1.005787,
     "end_time": "2024-05-09T06:07:47.698050",
     "exception": false,
     "start_time": "2024-05-09T06:07:46.692263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmsegmentation\n",
      "/kaggle/working/mmsegmentation\r\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/mmsegmentation\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "970db008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:47.816958Z",
     "iopub.status.busy": "2024-05-09T06:07:47.816578Z",
     "iopub.status.idle": "2024-05-09T06:07:48.614477Z",
     "shell.execute_reply": "2024-05-09T06:07:48.613248Z"
    },
    "papermill": {
     "duration": 0.860839,
     "end_time": "2024-05-09T06:07:48.617475",
     "exception": false,
     "start_time": "2024-05-09T06:07:47.756636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2 2.0.0rc4 0.10.4\n"
     ]
    }
   ],
   "source": [
    "# Check MMSegmentation installation\n",
    "import mmseg,mmcv,mmengine\n",
    "print(mmseg.__version__,mmcv.__version__,mmengine.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c892fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:48.714660Z",
     "iopub.status.busy": "2024-05-09T06:07:48.714299Z",
     "iopub.status.idle": "2024-05-09T06:07:48.718786Z",
     "shell.execute_reply": "2024-05-09T06:07:48.717939Z"
    },
    "papermill": {
     "duration": 0.054469,
     "end_time": "2024-05-09T06:07:48.720775",
     "exception": false,
     "start_time": "2024-05-09T06:07:48.666306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import mmseg\n",
    "print(mmseg.__version__)\n",
    "# Example output: 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c8fde42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:48.858029Z",
     "iopub.status.busy": "2024-05-09T06:07:48.857675Z",
     "iopub.status.idle": "2024-05-09T06:07:49.829265Z",
     "shell.execute_reply": "2024-05-09T06:07:49.828252Z"
    },
    "papermill": {
     "duration": 1.062679,
     "end_time": "2024-05-09T06:07:49.831543",
     "exception": false,
     "start_time": "2024-05-09T06:07:48.768864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmsegmentation\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a47ca61",
   "metadata": {
    "papermill": {
     "duration": 0.048551,
     "end_time": "2024-05-09T06:07:49.930301",
     "exception": false,
     "start_time": "2024-05-09T06:07:49.881750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **TRAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dba1a42e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:50.028884Z",
     "iopub.status.busy": "2024-05-09T06:07:50.028485Z",
     "iopub.status.idle": "2024-05-09T06:07:50.033524Z",
     "shell.execute_reply": "2024-05-09T06:07:50.032619Z"
    },
    "papermill": {
     "duration": 0.057709,
     "end_time": "2024-05-09T06:07:50.035742",
     "exception": false,
     "start_time": "2024-05-09T06:07:49.978033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the dataset\n",
    "import mmcv\n",
    "import mmengine\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba3afdcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:50.135326Z",
     "iopub.status.busy": "2024-05-09T06:07:50.135002Z",
     "iopub.status.idle": "2024-05-09T06:07:50.139666Z",
     "shell.execute_reply": "2024-05-09T06:07:50.138800Z"
    },
    "papermill": {
     "duration": 0.056135,
     "end_time": "2024-05-09T06:07:50.141768",
     "exception": false,
     "start_time": "2024-05-09T06:07:50.085633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define dataset root and directory for images and annotations\n",
    "#data_root = '/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
    "data_root = '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c07174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:50.240951Z",
     "iopub.status.busy": "2024-05-09T06:07:50.240325Z",
     "iopub.status.idle": "2024-05-09T06:07:50.596865Z",
     "shell.execute_reply": "2024-05-09T06:07:50.595769Z"
    },
    "papermill": {
     "duration": 0.408028,
     "end_time": "2024-05-09T06:07:50.599483",
     "exception": false,
     "start_time": "2024-05-09T06:07:50.191455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes:  10\n",
      "\n",
      "classes names:\n",
      " 0         Background\n",
      "1    BuildingFlooded\n",
      "2        BNonFlooded\n",
      "3        RoadFlooded\n",
      "4        RNonFlooded\n",
      "5              Water\n",
      "6               Tree\n",
      "7             Vecile\n",
      "8               Pool\n",
      "9              Grass\n",
      "Name: name, dtype: object\n",
      "\n",
      "palette for each class:\n",
      " [[  0   0   0]\n",
      " [255   0   0]\n",
      " [181  72  72]\n",
      " [150 150   0]\n",
      " [135 135 135]\n",
      " [  0 224 224]\n",
      " [  0   0 225]\n",
      " [204   0 204]\n",
      " [237 237   0]\n",
      " [  0 225   0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# define class and palette for better visualization\n",
    "#df=pd.read_csv('/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/Now_class_dict_seg_10clss.csv')\n",
    "df=pd.read_csv('/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/Now_class_dict_seg_10clss.csv')\n",
    "classes = df['name']\n",
    "palette = df[[' r', ' g', ' b']].values\n",
    "id2label = classes.to_dict()\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(\"Total classes: \", len(id2label))\n",
    "print(\"\\nclasses names:\\n\", classes)\n",
    "print(\"\\npalette for each class:\\n\", palette)\n",
    "\n",
    "classes=list(classes)\n",
    "palette=list(palette)\n",
    "num_classes=len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca6bf51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:50.713340Z",
     "iopub.status.busy": "2024-05-09T06:07:50.712957Z",
     "iopub.status.idle": "2024-05-09T06:07:52.663491Z",
     "shell.execute_reply": "2024-05-09T06:07:52.662546Z"
    },
    "papermill": {
     "duration": 2.008278,
     "end_time": "2024-05-09T06:07:52.665639",
     "exception": false,
     "start_time": "2024-05-09T06:07:50.657361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAH/CAYAAAAVCPOeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABq9ElEQVR4nO3deVwW5f7/8fcNCDeogMomCYqYuOWSpuGSorigZlYnj0sFHk0zLU1za3EpT7iVmpkdTyVWWif7qWnlvqahbZJpxVFzKY+oaIAbCtzz+yOYr7eAgiI3wuv5eNyPvGeumfnM1X0rb66ZayyGYRgCAAAAAJR5To4uAAAAAABQMhAQAQAAAACSCIgAAAAAgGwERAAAAACAJAIiAAAAACAbAREAAAAAIImACAAAAADIRkAEAAAAAEgiIAIAAAAAshEQAQAAAACSSnhAnDdvnmrUqCGr1aoWLVrom2++cXRJAAAAAFBqldiA+J///EcjR47UxIkT9cMPP6hRo0bq3LmzTp486ejSAAAAAKBUshiGYTi6iLy0aNFC99xzj958801Jks1mU1BQkJ5++mmNGzfOwdUBAAAAQOnj4ugC8nL58mV9//33Gj9+vLnMyclJkZGRio+Pz3ObS5cu6dKlS+Z7m82mM2fOqEqVKrJYLLe8ZgAAAFybYRg6e/asAgMD5eTkuAvZsrKylJGR4bDjA8XJ2dlZ5cqVK3D7EhkQk5OTlZWVJX9/f7vl/v7++vXXX/PcJjY2VpMnTy6O8gAAAHATfv/9d1WrVq3Yj2sYhpKSkpSamqoSehEdcEu4ubnJx8dHnp6e121bIgPijRg/frxGjhxpvk9NTVVwcLDc3NwYQQTKMMMwZLPZ+EEAAEqIzMxMVaxY0SHHTk1NVUpKinx9fVW+fHl+RkSpZxiGMjIylJqaqmPHjknSdUNiiQyIPj4+cnZ21okTJ+yWnzhxQgEBAXlu4+bmJjc3t1zLLRYLX36gjHNycpLNZnN0GQCAbI742cwwDJ08eVKenp7y8fEp9uMDjuLu7q6KFSvqjz/+UHJy8nUDYomcxdTV1VVNmzbVxo0bzWU2m00bN25UeHi4AysDcLvhF0QAAOmv+w6zsrIKdIkdUNpYLBZ5eXnp0qVL173/tkSOIErSyJEjFR0drWbNmql58+aaPXu2zp8/r/79+zu6NAC3mZwrCbjMFADKrszMTEmSi0uJ/fEXuKVyJqrJysq65qQ1JfYb8ve//12nTp3ShAkTlJSUpMaNG2vNmjW5Jq4BgOshIAIAcnBlCcqqgn72S2xAlKRhw4Zp2LBhji4DAAAAAMqEEnkPIgAUNSasAgCg6NWoUUPdu3d3dBkOY7FYNGnSJEeXUaRK9AgiABQVi8UiJycnZWVlOboUAEAJc/ToUSUnJzu6DPn4+Cg4OPiGto2Li8s1V4evr6/q16+vMWPGKCoqqihKRBlAQARQpjg7OxMSAQCmo0ePKiwsTOnp6Y4uRVarVYmJiTccEiXp5ZdfVkhIiAzD0IkTJxQXF6euXbtq1apVZXqkDwVHQARQZuRMVENIBADkSE5OLhHhUJLS09OVnJx8UwExKipKzZo1M98PGDBA/v7++uijj27bgHj+/HmVL1/e0WWUGdyDCKBMybkP0dnZ2cGVAABw63l7e8vd3d3u8R4zZ85Uy5YtVaVKFbm7u6tp06b69NNP89z+ww8/VPPmzeXh4aFKlSrpvvvu07p16655zEWLFsnFxUWjR482l50+fVqPPfaYPD095e3trejoaP3444+yWCyKi4sz28XExKhChQo6ePCgunbtqooVK6pfv36S/gqKo0aNUlBQkNzc3BQWFqaZM2fazVJ++PDhXPvMcfX9gpMmTZLFYtGBAwcUExMjb29veXl5qX///rpw4YLdtpcuXdKzzz4rX19fVaxYUT169NAff/xxzX64XTGCCKDMYSQRAFBapaamKjk5WYZh6OTJk5o7d67OnTunRx991GwzZ84c9ejRQ/369dPly5f18ccf65FHHtHnn3+ubt26me0mT56sSZMmqWXLlnr55Zfl6uqqXbt2adOmTerUqVOex1+wYIGefPJJPf/885oyZYokyWaz6f7779c333yjIUOGqE6dOvrss88UHR2d5z4yMzPVuXNntW7dWjNnzpSHh4cMw1CPHj20efNmDRgwQI0bN9batWs1evRoHTt2TLNmzbrhPuvVq5dCQkIUGxurH374Qe+88478/Pw0bdo0s83AgQP14Ycfqm/fvmrZsqU2bdpk11elCQERQJlESAQAlEaRkZF2793c3PTee++pY8eO5rL//ve/cnd3N98PGzZMd999t15//XUz9Bw4cEAvv/yyHnzwQX366adycvq/Cw/ze67wG2+8oREjRujll1/Wiy++aC5fsWKF4uPjNXv2bA0fPlySNGTIELuarnTp0iU98sgjio2NNZd99tln2rRpk6ZMmaIXXnhBkjR06FA98sgjmjNnjoYNG6bQ0NAC9dHVmjRponfffdd8f/r0ab377rtmQPzxxx/14Ycf6qmnntK8efPMY/fr10979uy5oWOWZFxiCqDM4nJTAEBpM2/ePK1fv17r16/Xhx9+qIiICA0cOFDLli0z21wZDv/880+lpqaqTZs2+uGHH8zlK1askM1m04QJE+zCoZT3A9enT5+u4cOHa9q0aXbhUJLWrFmjcuXK6YknnjCXOTk5aejQofmex5AhQ+zef/nll3J2dtYzzzxjt3zUqFEyDEOrV6/Od1/X8+STT9q9b9OmjU6fPq20tDTz2JJyHXvEiBE3fMySjBFEAGVazkiik5OTbDabo8sBAOCmNG/e3G6Smj59+qhJkyYaNmyYunfvLldXV33++eeaMmWKEhISdOnSJbPtlcHv4MGDcnJyUr169a57zK1bt+qLL77Q2LFj7e47zHHkyBFVrVpVHh4edstr1aqV5/5cXFxUrVq1XPsIDAxUxYoV7ZbXrVvXXH+jrp4UqFKlSpL+Cs+enp46cuSInJycco1QhoWF3fAxSzJGEAFAIhwCAEolJycnRURE6Pjx49q/f7+++uor9ejRQ1arVW+99Za+/PJLrV+/Xn379s330tHrqV+/vsLCwvTBBx/o0KFDN12zm5tbrlHLgsprdFPSNW8nye9Kohvtj9sdAREAAAAoxTIzMyVJ586d0//7f/9PVqtVa9eu1T/+8Q9FRUXlum9RkkJDQ2Wz2fTzzz9fd/8+Pj7asGGDypUrpw4dOuh///uf3frq1avr+PHjuWYGPXDgQIHPoXr16vrf//6ns2fP2i3/9ddfzfXS/43+paSk2LW7mRHG6tWry2az6eDBg3bLExMTb3ifJRkBEUCJZxiG+bLZbMrKyrJ7Xbk+r1dB9gkAQGmUkZGhdevWydXVVXXr1pWzs7MsFovdiNrhw4e1YsUKu+169uwpJycnvfzyy7n+nczr39Zq1appw4YNunjxojp27KjTp0+b6zp37qyMjAz9+9//NpfZbDZzwpeC6Nq1q7KysvTmm2/aLZ81a5YsFouioqIkSZ6envLx8dG2bdvs2r311lsFPtbVcvb9xhtv2C2fPXv2De+zJOMeRAAlVs4/QFcGvbz+UcrKysrzkhKLxWLeY5jf/q8VIgEAuN2sXr3aHFU7efKklixZov3792vcuHHy9PRUt27d9Prrr6tLly7q27evTp48qXnz5qlWrVp2M3LWqlVLL7zwgl555RW1adNGDz30kNzc3PTtt98qMDDQbobRK7dZt26d2rVrp86dO2vTpk3y9PRUz5491bx5c40aNUoHDhxQnTp1tHLlSp05c0ZS/peFXun+++9XRESEXnjhBR0+fFiNGjXSunXr9Nlnn2nEiBF29wcOHDhQU6dO1cCBA9WsWTNt27ZN//3vf2+4Txs3bqw+ffrorbfeUmpqqlq2bKmNGzcWagT0dkJABFDiXBnYbDZbgQJcXm0Mw7jmPzoEQwBAaTNhwgTzz1arVXXq1NH8+fM1ePBgSVL79u317rvvaurUqRoxYoRCQkI0bdo0HT58ONcjG15++WWFhIRo7ty5euGFF+Th4aGGDRvqsccey/f4d911l1avXq3IyEjdf//9WrNmjdzd3fXFF19o+PDhWrRokZycnPTggw9q4sSJatWqlaxW63XPy8nJSStXrtSECRP0n//8RwsXLlSNGjU0Y8YMjRo1KlcfnDp1Sp9++qk++eQTRUVFafXq1fLz8ytMV9p577335Ovrq8WLF2vFihVq3769vvjiCwUFBd3wPksqi1FKf0JKS0uTl5eXrFZrgX4rAaBkyPkrqaDBEABwe8nIyFBqaqo8PT2L9bjp6ek6dOiQQkJC7ALJ0aNHFRYWpvT09GKtJy9Wq1WJiYm5ZtUsrVasWKEHH3xQ27dvV6tWrRxdTqmX33fgaowgAihxeHA9AKC4BAcHKzExUcnJyY4uRT4+PqU2HF68eNHu+YtZWVmaO3euPD09dffddzuwMlyNgAgAAIAyLTg4uNQGs5Li6aef1sWLFxUeHq5Lly5p2bJl+vrrr/Xqq6/aBUc4HgERQInBhDEAAJRO7du312uvvabPP/9c6enpqlWrlubOnathw4Y5ujRchYAIoEThkRMAAJQ+ffv2Vd++fR1dBgqA5yACAAAAACQREAEAAAAA2QiIAAAAAABJBEQAAAAAQDYCIgAAAABAEgERAAAAAJCNgAgAAAAAkERABAAAAJCHSZMmyWKx2C2rUaOGYmJirrttXFycLBaLDh8+bC5r166d2rVrV7RF3qCYmBjVqFHDIccuaB8W1OHDh2WxWBQXF1ck+yMgAgAAALe5nEB25cvPz08RERFavXq1o8srNjlhKa/Xvffe6+jybgsuji4AAAAAcKijR6XkZEdXIfn4SMHBN7WLl19+WSEhITIMQydOnFBcXJy6du2qVatWqXv37oXa14svvqhx48bdVD1XWrduXZHt63r69Omjrl272i3z9fUttuPfzgiIAAAAKLuOHpXCwqT0dEdXIlmtUmLiTYXEqKgoNWvWzHw/YMAA+fv766OPPip0QHRxcZGLS9HFBVdX1yLb1/XcfffdevTRR4vteKUJl5gCAACg7EpOLhnhUPqrjiIeyfT29pa7u7sZ9LZs2SKLxaItW7bYtcvrPra87kHMy759+9S+fXu5u7urWrVqmjJlimw2W652V9+DmFPLJ598on/+85+qVq2arFarOnTooAMHDuTaft68eapZs6bc3d3VvHlzffXVV0V6X+P58+c1atQoBQUFyc3NTWFhYZo5c6YMw7Brl5mZqVdeeUWhoaFyc3NTjRo19Pzzz+vSpUt27QzD0JQpU1StWjV5eHgoIiJC+/bty/PYKSkpGjFihHnsWrVqadq0abn6MSUlRTExMfLy8pK3t7eio6OVkpJSJOefgxFEAAAAoJRITU1VcnKyDMPQyZMnNXfuXJ07d+6WjaYlJSUpIiJCmZmZGjdunMqXL68FCxbI3d29wPuYOnWqnJyc9Nxzzyk1NVXTp09Xv379tGvXLrPN/PnzNWzYMLVp00bPPvusDh8+rJ49e6pSpUqqVq1arn1euHBByVeFbS8vL5UrVy7PGgzDUI8ePbR582YNGDBAjRs31tq1azV69GgdO3ZMs2bNMtsOHDhQixYt0t/+9jeNGjVKu3btUmxsrH755RctX77cbDdhwgRNmTJFXbt2VdeuXfXDDz+oU6dOunz5cq5a27Ztq2PHjmnw4MEKDg7W119/rfHjx+v48eOaPXu2WeMDDzyg7du368knn1TdunW1fPlyRUdHF7ivC4KACAAAAJQSkZGRdu/d3Nz03nvvqWPHjrfkeNOmTdOpU6e0a9cuNW/eXJIUHR2tO++8s8D7SE9PV0JCgnkJaqVKlTR8+HDt3btXDRo00OXLl/XSSy/pnnvu0aZNm8zR0IYNGyomJibPgDhx4kRNnDjRbtnmzZvzHW1cuXKlNm3apClTpuiFF16QJA0dOlSPPPKI5syZo2HDhik0NFQ//vijFi1apIEDB+rf//63JOmpp56Sn5+fZs6cqc2bNysiIkKnTp3S9OnT1a1bN61atcociX3hhRf06quv2h379ddf18GDB7V7926z3wYPHqzAwEDNmDHDHNVcuXKltm3bpunTp2v06NGSpCFDhigiIqLAfV0QXGIKoES4+vINAABQePPmzdP69eu1fv16ffjhh4qIiNDAgQO1bNmyW3K8L7/8Uvfee68ZDqW/JoPp169fgffRv39/u/sT27RpI0n67bffJEnfffedTp8+rSeeeMLunsh+/fqpUqVKee5z0KBBZj/kvBo1anTN83B2dtYzzzxjt3zUqFEyDMOcCfbLL7+UJI0cOTJXO0n64osvJEkbNmzQ5cuX9fTTT9tdpjtixIhcx166dKnatGmjSpUqKTk52XxFRkYqKytL27ZtM4/t4uKiIUOGmNs6Ozvr6aefzve8bgQjiABKjLzuVwAAAAXXvHlzu0lq+vTpoyZNmmjYsGGFnqSmII4cOaIWLVrkWh4WFlbgfQRfNSlPTuj7888/zWNIUq1atezaubi45PsswzvvvDPXaOq1HDlyRIGBgapYsaLd8rp169rVcOTIETk5OeWqJSAgQN7e3nbtcuq4kq+vb65Qu3//fu3ZsyffWVZPnjxp7rNq1aqqUKGC3frC9HVBEBABlBiMIgIAULScnJwUERGhOXPmaP/+/flOOpOVlVXMlf0fZ2fnPJeX5J8LCjJ5T0HZbDZ17NhRY8aMyXN97dq1i+xYBUFABAAAAEqxzMxMSdK5c+fM0aurZ77MGfEqrOrVq2v//v25licmJt7Q/vI7hiQdOHDA7n67zMxMHT58WA0bNiySY2zYsEFnz561G0X89ddf7WqoXr26bDab9u/fb44uStKJEyeUkpJi1076a3SwZs2aZrtTp06ZI6M5QkNDde7cueuOeFavXl0bN27UuXPn7EYRi7KvJe5BBAAAAEqtjIwMrVu3Tq6urqpbt66qV68uZ2dn8762HG+99dYN7b9r167auXOnvvnmG3PZqVOntHjx4puq+0rNmjVTlSpV9O9//9sMu5K0ePHiXGHrRnXt2lVZWVl688037ZbPmjVLFotFUVFRZjtJ5syiOV5//XVJUrdu3ST9NVlQuXLlNHfuXLuR0Ku3k6RevXopPj5ea9euzbUuJSXFPOeuXbsqMzNT8+fPN9dnZWVp7ty5hTzba2MEEQAAACglVq9ebY56nTx5UkuWLNH+/fs1btw4eXp6SpIeeeQRzZ07VxaLRaGhofr888/N+9wKa8yYMfrggw/UpUsXDR8+3HzMRfXq1bVnz54iOSdXV1dNmjRJTz/9tNq3b69evXrp8OHDiouLU2hoaJFc7nn//fcrIiJCL7zwgg4fPqxGjRpp3bp1+uyzzzRixAiFhoZKkho1aqTo6GgtWLBAKSkpatu2rb755hstWrRIPXv2NEc4fX199dxzzyk2Nlbdu3dX165dtXv3bq1evVo+Pj52xx49erRWrlyp7t27KyYmRk2bNtX58+f1008/6dNPP9Xhw4fl4+Oj+++/X61atdK4ceN0+PBh1atXT8uWLVNqaupNn/+VCIgAAABAKTFhwgTzz1arVXXq1NH8+fM1ePBgc/ncuXOVkZGht99+W25uburVq5dmzJihBg0aFPp4VatW1ebNm/X0009r6tSpqlKlip588kkFBgZqwIABRXJOkjRs2DAZhqHXXntNzz33nBo1aqSVK1fqmWeekdVqven9Ozk5aeXKlZowYYL+85//aOHChapRo4b5mIkrvfPOO6pZs6bi4uK0fPlyBQQEaPz48bkeqzFlyhRZrVa9/fbb2rx5s1q0aKF169aZo4w5PDw8tHXrVr366qtaunSp3n//fXl6eqp27dqaPHmyvLy87GocMWKEPvzwQ1ksFvXo0UOvvfaamjRpctN9kMNilOS7P29CWlqavLy8ZLVai/QmUgC3hmEYDr1BHgBQPDIyMpSammqOZhWX9PR0HTp0SCEhIfaB4uhRKSxMSk8v1nryZLVKiYnSVbN6Im82m02+vr566KGHzGcSIn/5fgeuwggiAAAAyq7g4L9CWXKyoyuRfHwIh/lIT0+Xm5ub3cDP+++/rzNnzqhdu3aOK6wUIiACAACgbAsOJpiVcDt37tSzzz6rRx55RFWqVNEPP/ygd999Vw0aNNAjjzzi6PJKFQIiAAAAgBKtRo0aCgoK0htvvKEzZ86ocuXKevzxxzV16lS5uro6urxShYAIAAAAoESrUaOGVq5c6egyygSegwgAAAAAkERABAAAAABkIyACAAAAACQREAEAAAAA2QiIAAAAAABJBEQAAAAAQDYCIgAAAABAEgERQAlgGIajSwAAAIAIiABKCJvN5ugSAABACRIXFyeLxaLDhw8X+7FjYmJUo0aNIt1njRo1FBMTU6T7vBVcHF0AAEiMIgIAHOfiyZO6nJbm6DLk6ukpdz+/G9o2Li5O/fv3t1vm6+ur+vXra8yYMYqKijKXWywWSdLMmTM1atSoPPfz7bffqlmzZjdUS0HUqFFDR44cyXPdxYsXZbVab9mxcW0ERAAAAJRZF0+e1NaBA2XLyHB0KXIqV05t33nnhkOiJL388ssKCQmRYRg6ceKE4uLi1LVrV61atUrdu3e3aztjxgwNGTJEHh4eN1v6DWncuHGugCpJrq6uDqgGOQiIAAAAKLMup6WViHAoSbaMDF1OS7upgBgVFWU38jdgwAD5+/vro48+sguIjRs3VkJCgt5++22NHDnypuq+UXfccYceffRRhxwb+eMeRAAAAKCU8vb2lru7u1xc7MeFWrVqpfbt22v69Om6ePHidfezadMmtWnTRuXLl5e3t7ceeOAB/fLLL3ZtJk2aJIvFogMHDigmJkbe3t7y8vJS//79deHChSI7p7feekv169eXm5ubAgMDNXToUKWkpORqt3TpUjVt2lTu7u7y8fHRo48+qmPHjuVqt2LFCjVo0EBWq1UNGjTQ8uXL8zyuzWbT7NmzVb9+fVmtVvn7+2vw4MH6888/7doZhqEpU6aoWrVq8vDwUEREhPbt21ck514cCIgAAABAKZGamqrk5GSdOnVK+/bt05AhQ3Tu3Lk8R+omTZqkEydOaP78+dfc54YNG9S5c2edPHlSkyZN0siRI/X111+rVatWeU4g06tXL509e1axsbHq1auX4uLiNHny5FztMjIylJycbPe6XpCcNGmShg4dqsDAQL322mt6+OGH9a9//UudOnVSxhUjwXFxcerVq5ecnZ0VGxurJ554QsuWLVPr1q3twuS6dev08MMPy2KxKDY2Vj179lT//v313Xff5Tr24MGDNXr0aLVq1Upz5sxR//79tXjxYnXu3Nnu2BMmTNBLL72kRo0aacaMGapZs6Y6deqk8+fPX/PcSgouMQUAAABKicjISLv3bm5ueu+999SxY8dcbdu0aaOIiAjzXkR3d/c89zl69GhVrlxZ8fHxqly5siSpZ8+eatKkiSZOnKhFixbZtW/SpIneffdd8/3p06f17rvvatq0aXbt1q1bJ19fX7tlEydO1KRJk/Ks49SpU4qNjVWnTp20evVqOTn9NdZVp04dDRs2TB9++KH69++vjIwMjR07Vg0aNNC2bdvMCW9at26t7t27a9asWWZgHTt2rPz9/bV9+3Z5eXlJktq2batOnTqpevXq5rG3b9+ud955R4sXL1bfvn3N5REREerSpYuWLl2qvn376tSpU5o+fbq6deumVatWmRMCvfDCC3r11VfzPK+ShhFEAAAAoJSYN2+e1q9fr/Xr1+vDDz9URESEBg4cqGXLluXZftKkSUpKStLbb7+d5/rjx48rISFBMTExZjiUpIYNG6pjx4768ssvc23z5JNP2r1v06aNTp8+rbSrZopt0aKFWWvO6/HHH8/33DZs2KDLly9rxIgRZjiUpCeeeEKenp764osvJEnfffedTp48qaeeespuNtRu3bqpTp06Zrucc4uOjjbDoSR17NhR9erVszv20qVL5eXlpY4dO9qNeDZt2lQVKlTQ5s2b7Wp8+umnzXAoSSNGjMj3vEoaRhABAACAUqJ58+Z2k9T06dNHTZo00bBhw9S9e/dcM4Ted999ioiI0PTp03MFO0nmoyjCwsJyratbt67Wrl2r8+fPq3z58uby4OBgu3aVKlWSJP3555/y9PQ0l/v4+OQa8byW/GpxdXVVzZo1zfXXqrlOnTravn27Xbs777wzV7uwsDD98MMP5vv9+/crNTVVfvlMIHTy5Mlr7tPX19fsh5KOgAjA4Ww2m6NLAACgVHJyclJERITmzJmj/fv3q379+rnaTJw4Ue3atdO//vUveXt73/QxnZ2d81x+Oz/z2Gazyc/PT4sXL85z/dWXyt7OCIgAAABAKZaZmSlJOnfuXJ7r27Ztq3bt2mnatGmaMGGC3bqc+/ASExNzbffrr7/Kx8fHbvTwVrqylpo1a5rLL1++rEOHDpmjkVe2a9++vd0+EhMTzfU5/92/f3+uY119vqGhodqwYYNatWqV772aV+/zyhpPnTqVa7bTkop7EAEAAIBSKiMjQ+vWrZOrq6vq1q2bb7ucexEXLFhgt7xq1apq3LixFi1aZDf75969e7Vu3Tp17dr1VpWeS2RkpFxdXfXGG2/YjUa+++67Sk1NVbdu3SRJzZo1k5+fn95++21dunTJbLd69Wr98ssvZrsrzy01NdVst379ev388892x+7Vq5eysrL0yiuv5KorMzPT7JvIyEiVK1dOc+fOtatx9uzZN33+xYURRAAAAKCUWL16tX799VdJf90Xt2TJEu3fv1/jxo2zu//vam3btlXbtm21devWXOtmzJihqKgohYeHa8CAAbp48aLmzp0rLy+vfGccvRV8fX01fvx4TZ48WV26dFGPHj2UmJiot956S/fcc4/5KI9y5cpp2rRp6t+/v9q2bas+ffroxIkTmjNnjmrUqKFnn33W3GdsbKy6deum1q1b6x//+IfOnDmjuXPnqn79+nYjrm3bttXgwYMVGxurhIQEderUSeXKldP+/fu1dOlSzZkzR3/729/k6+ur5557TrGxserevbu6du2q3bt3a/Xq1fLx8Sm2vroZRT6CmPOAzCtfderUMdenp6dr6NChqlKliipUqKCHH35YJ06csNvH0aNH1a1bN3l4eMjPz0+jR482h8YBAAAA5G3ChAl67LHH9Nhjj+mFF15QVlaW5s+fX6BHLOQX9iIjI7VmzRpVqVJFEyZM0MyZM3Xvvfdqx44dCgkJKeIzuH6Nb775po4ePapnn31Wn3zyiQYNGqR169apXLlyZruYmBj95z//0eXLlzV27Fj961//0oMPPqjt27fb3WeZ84iKrKwsjR8/XsuWLdPChQvtJvrJ8fbbb2vBggU6efKknn/+eY0fP16bNm3So48+qlatWpntpkyZosmTJ2v37t0aPXq0Dh48qHXr1hXbpbg3y2IU8d2ikyZN0qeffqoNGzaYy1xcXMzEPGTIEH3xxReKi4uTl5eXhg0bJicnJ+3YsUOSlJWVpcaNGysgIEAzZszQ8ePH9fjjj+uJJ54o1LND0tLS5OXlJavVajfFLICSJysr67a+cR0AUHAZGRlKTU295mjWrZCenq5Dhw4pJCTE7tEHF0+e1NaBA2W74kHnjuJUrpzavvOO3POZKRO4Gfl9B652Sy4xdXFxUUBAQK7lqampevfdd7VkyRLzhtGFCxeqbt262rlzp+69916tW7dOP//8szZs2CB/f381btxYr7zyisaOHatJkyblmpoXAAAAuFHufn5q+847unzVM/ocwdXTk3AIh7slAXH//v0KDAyU1WpVeHi4YmNjFRwcrO+//14ZGRl2zzupU6eOgoODFR8fr3vvvVfx8fG666675O/vb7bp3LmzhgwZon379qlJkyZ5HvPSpUt2N6Fe/SBOAAAAIC/ufn4EMyBbkd+D2KJFC8XFxWnNmjWaP3++Dh06pDZt2ujs2bNKSkqSq6trruer+Pv7KykpSZKUlJRkFw5z1uesy09sbKy8vLzMV1BQUNGeGAAAAACUckU+ghgVFWX+uWHDhmrRooWqV6+uTz755JrPDLlZ48eP18iRI833aWlphEQAAAAAKIRb/hxEb29v1a5dWwcOHFBAQIAuX75s9wwVSTpx4oR5z2JAQECuWU1z3ud1X2MONzc3eXp62r0AAAAAAAV3ywPiuXPndPDgQVWtWlVNmzZVuXLltHHjRnN9YmKijh49qvDwcElSeHi4fvrpJ508edJss379enl6eqpevXq3ulwAAAAAKLOK/BLT5557Tvfff7+qV6+u//3vf5o4caKcnZ3Vp08feXl5acCAARo5cqQqV64sT09PPf300woPD9e9994rSerUqZPq1aunxx57TNOnT1dSUpJefPFFDR06VG5ubkVdLgAAAAAgW5EHxD/++EN9+vTR6dOn5evrq9atW2vnzp3y9fWVJM2aNUtOTk56+OGHdenSJXXu3FlvvfWWub2zs7M+//xzDRkyROHh4Spfvryio6P18ssvF3WpAAAAAIArWIxS+nTqtLQ0eXl5yWq1ymKxOLocANeQlZWlUvpXEQDgKhkZGUpNTS32+SIK+pBwoLQq6Hfglt+DCAAAAAC4PRAQAQAAAACSCIgAAAAAilhcXJwsFosOHz5cqO22bNkii8WiLVu23JK6rmXSpElFfmtau3bt1K5duyLd561W5JPUAAAAALeTs2ePKj092dFlyGr1UcWKwTe0bVxcnPr372++d3Z2lr+/vzp27Kh//vOfuuOOO4qqzBvWrl07bd26Nc91v/zyi+rUqVPMFSEvBEQAAACUWWfPHtVHH4UpKyvd0aXI2dmqPn0SbzgkStLLL7+skJAQpaena+fOnYqLi9P27du1d+/eEjE5T7Vq1RQbG5treWBgoAOqQV4IiAAAACiz0tOTS0Q4lKSsrHSlpyffVECMiopSs2bNJEkDBw6Uj4+Ppk2bppUrV6pXr15FVeoN8/Ly0qOPPuroMnAN3IMIAAAAlFJt2rSRJB08eNBctmnTJrVp00bly5eXt7e3HnjgAf3yyy922x05ckRPPfWUwsLC5O7uripVquiRRx7J857Cffv2qX379nJ3d1e1atU0ZcoU2Wy2Ij2PpUuXqmnTpnJ3d5ePj48effRRHTt2LFe7gpybJG3fvl333HOPrFarQkND9a9//SvfY3/44YfmsStXrqzevXvr999/z9VuwYIFCg0Nlbu7u5o3b66vvvrq5k7aQRhBBAAAAEqpnEBXqVIlSdKGDRsUFRWlmjVratKkSbp48aLmzp2rVq1a6YcfflCNGjUkSd9++62+/vpr9e7dW9WqVdPhw4c1f/58tWvXTj///LM8PDwkSUlJSYqIiFBmZqbGjRun8uXLa8GCBXJ3d8+znqysLCUn29/vabVaVaFChXzPIef+ynvuuUexsbE6ceKE5syZox07dmj37t3y9vYu1Ln99NNP6tSpk3x9fTVp0iRlZmZq4sSJ8vf3z3Xsf/7zn3rppZfUq1cvDRw4UKdOndLcuXN133332R373Xff1eDBg9WyZUuNGDFCv/32m3r06KHKlSsrKCioIP+rSgwCIgAAAFBKpKamKjk5Wenp6dq1a5cmT54sNzc3de/eXZI0evRoVa5cWfHx8apcubIkqWfPnmrSpIkmTpyoRYsWSZK6deumv/3tb3b7vv/++xUeHq7/9//+nx577DFJ0rRp03Tq1Cnt2rVLzZs3lyRFR0frzjvvzLO+X3/9Vb6+vnbLoqOjFRcXl2f7jIwMjR07Vg0aNNC2bdvM+yhbt26t7t27a9asWZo8eXKhzm3ChAkyDENfffWVgoP/upz34Ycf1l133WV37CNHjmjixImaMmWKnn/+eXP5Qw89pCZNmuitt97S888/r4yMDD3//PNq3LixNm/eLFdXV0lSvXr1NGjQoNsuIHKJKQCHMgzD0SUAAFBqREZGytfXV0FBQfrb3/6m8uXLa+XKlapWrZqOHz+uhIQExcTEmAFKkho2bKiOHTvqyy+/NJddOQKYkZGh06dPq1atWvL29tYPP/xgrvvyyy917733muFQknx9fdWvX78866tRo4bWr19v9xozZky+5/Pdd9/p5MmTeuqpp+wm2enWrZvq1KmjL774QpIKfG5ZWVlau3atevbsaYZDSapbt646d+5sd+xly5bJZrOpV69eSk5ONl8BAQG68847tXnzZrsan3zySTMcSlJMTIy8vLzyPbeSihFEAA5lGAYhEQCAIjJv3jzVrl1bqampeu+997Rt2za5ublJ+mtETJLCwsJybVe3bl2tXbtW58+fV/ny5XXx4kXFxsZq4cKFOnbsmN2/1ampqeafjxw5ohYtWuTaX17HkKTy5csrMjKywOdzrZrr1Kmj7du3F+rczp49q4sXL+Y5whkWFmYXkvfv3y/DMPIdDS1Xrpzdsa9uV65cOdWsWfO651jSEBABAACAUqJ58+bmLKY9e/ZU69at1bdvXyUmJhZqP08//bQWLlyoESNGKDw8XF5eXrJYLOrdu3eRT0BTUtlsNlksFq1evVrOzs651l/rvsnbGQERAAAAKIWcnZ0VGxuriIgIvfnmm4qOjpakPMPir7/+Kh8fH5UvX16S9Omnnyo6Olqvvfaa2SY9PV0pKSl221WvXl379+/Ptb/CBtL8VK9e3dxf+/btcx0jZ/2V7a525blZrVa5u7sXqObQ0FAZhqGQkBDVrl37ujXu37/frsaMjAwdOnRIjRo1KsiplhjcgwgAAACUUu3atVPz5s01e/ZsVapUSY0bN9aiRYvsgt7evXu1bt06de3a1Vzm7Oyc6xaQuXPnKisry25Z165dtXPnTn3zzTfmslOnTmnx4sVFUn+zZs3k5+ent99+W5cuXTKXr169Wr/88ou6desmSapatWqBzs3Z2VmdO3fWihUrdPToUbPdL7/8orVr19od+6GHHpKzs7MmT56cqy8Mw9Dp06fNGn19ffX222/r8uXLZpu4uLhcgfp2wAgiAAAAUIqNHj1ajzzyiOLi4jRjxgxFRUUpPDxcAwYMMB8F4eXlpUmTJpnbdO/eXR988IG8vLxUr149xcfHa8OGDapSpYrdvseMGaMPPvhAXbp00fDhw83HXFSvXl179uy56drLlSunadOmqX///mrbtq369OljPuaiRo0aevbZZ822BT23yZMna82aNWrTpo2eeuopZWZmau7cuapfv75dzaGhoZoyZYrGjx+vw4cPq2fPnqpYsaIOHTqk5cuXa9CgQXruuedUrlw5TZkyRYMHD1b79u3197//XYcOHdLChQu5BxEACoPJaQAAuPUeeughhYaGaubMmUpMTNSaNWs0ceJETZgwQeXKlVPbtm01bdo0hYSEmNvMmTNHzs7OWrx4sdLT09WqVStt2LAh10yfVatW1ebNm/X0009r6tSpqlKlip588kkFBgZqwIABRVJ/TEyMPDw8NHXqVI0dO1bly5fXgw8+qGnTppnPIZT+msG1IOfWsGFDrV27ViNHjtSECRNUrVo1TZ48WcePH88VaseNG6fatWvbPU4jKChInTp1Uo8ePcx2gwYNUlZWlmbMmKHRo0frrrvu0sqVK/XSSy8VSR8UJ4tRSn9CS0tLk5eXl6xWqywWi6PLAZAHwzByXaoCACjdMjIylJqaKk9Pz2I9bnp6ug4dOqSQkBC7xyWcPXtUH30Upqys9GKtJy/Ozlb16ZOoihWDr98YKKT8vgNXYwQRgMOU0t9PAQBuIxUrBqtPn0Slpyc7uhRZrT6EQzgcAREAAABlWsWKwQQzIBuzmAIAAAAAJBEQAQAAAADZCIgAAAAAAEkERAAAAABANgIiAAAAAEASAREAAAAAkI2ACAAAAACQREAEAAAAAGQjIAIAAAAAJBEQAQAAAJRAhw8flsViUVxcXLEfOy4uThaLRYcPHy6yfcbExKhGjRpFtr9bhYAIAAAA3OZyAk3Oy8XFRXfccYdiYmJ07Ngxu7bt2rWTxWLR/fffn2s/OaFs5syZt7TemJgYu3qvfK1Zs+aWHhvX5uLoAgAAAABHSk1N1cWLFx1dhtzd3eXl5XVT+3j55ZcVEhKi9PR07dy5U3Fxcdq+fbv27t0rq9Vq1/bzzz/X999/r6ZNm97UMW+Um5ub3nnnnVzLGzVq5IBqkIOACAAAgDIrNTVVCxYsUFZWlqNLkbOzswYNGnRTITEqKkrNmjWTJA0cOFA+Pj6aNm2aVq5cqV69epntgoODdfbsWU2ePFkrV6686dpvhIuLix599FGHHBv54xJTAAAAlFkXL14sEeFQkrKysop8JLNNmzaSpIMHD9otr1ixop599lmtWrVKP/zww3X389tvv+mRRx5R5cqV5eHhoXvvvVdffPGFXZstW7bIYrHok08+0T//+U9Vq1ZNVqtVHTp00IEDB4rsnDZt2qQ2bdqofPny8vb21gMPPKBffvklV7vdu3crKipKnp6eqlChgjp06KCdO3fmardv3z61b99e7u7uqlatmqZMmSKbzZbnsVevXm0eu2LFiurWrZv27duXq92KFSvUoEEDWa1WNWjQQMuXL7/5Ey8mjCACAAAApVTOJCuVKlXKtW748OGaNWuWJk2adM1RxBMnTqhly5a6cOGCnnnmGVWpUkWLFi1Sjx499Omnn+rBBx+0az916lQ5OTnpueeeU2pqqqZPn65+/fpp165dufadnJxs975cuXLXHEHdsGGDoqKiVLNmTU2aNEkXL17U3Llz1apVK/3www/mJDD79u1TmzZt5OnpqTFjxqhcuXL617/+pXbt2mnr1q1q0aKFJCkpKUkRERHKzMzUuHHjVL58eS1YsEDu7u65jv3BBx8oOjpanTt31rRp03ThwgXNnz9frVu31u7du81jr1u3Tg8//LDq1aun2NhYnT59Wv3791e1atXyPa+ShIAIAAAAlBKpqalKTk5Wenq6du3apcmTJ8vNzU3du3fP1dbT01MjRozQxIkT9cMPP+juu+/Oc59Tp07ViRMn9NVXX6l169aSpCeeeEINGzbUyJEj9cADD8jJ6f8uTExPT1dCQoJcXV0l/RVOhw8frr1796pBgwZmu/Pnz8vX19fuWG3bttWWLVvyPb/Ro0ercuXKio+PV+XKlSVJPXv2VJMmTTRx4kQtWrRIkvTiiy8qIyND27dvV82aNSVJjz/+uMLCwjRmzBht3bpVkjRt2jSdOnVKu3btUvPmzSVJ0dHRuvPOO+2Oe+7cOT3zzDMaOHCgFixYYC6Pjo5WWFiYXn31VXP52LFj5e/vr+3bt5tht23bturUqZOqV6+e77mVFFxiCgAAAJQSkZGR8vX1VVBQkP72t7+pfPnyWrlyZb6jV8OHD1elSpU0efLkfPf55Zdfqnnz5mY4lKQKFSpo0KBBOnz4sH7++We79v379zfDofR/l7n+9ttvdu2sVqvWr19v93rttdfyreP48eNKSEhQTEyMGQ4lqWHDhurYsaO+/PJLSX9dqrtu3Tr17NnTDIeSVLVqVfXt21fbt29XWlqaeW733nuvGQ4lydfXV/369bM79vr165WSkqI+ffooOTnZfDk7O6tFixbavHmzXY3R0dF2I6EdO3ZUvXr18j23koQRRAAOYRiGo0sAAKDUmTdvnmrXrq3U1FS999572rZtm9zc3PJt7+XlZY4i7t69O89LUY8cOWJeknmlunXrmuuvHBkMDg62a5ezzz///NNuubOzsyIjIwt8bkeOHJEkhYWF5VnL2rVrdf78eZ09e1YXLlzIt53NZtPvv/+u+vXr53tuV2+7f/9+SVL79u3zrM3T09OuxqtHIHP2WZD7PR2NgAjAIQzDyPcGcAAAcGOaN29uzmLas2dPtW7dWn379lViYqIqVKiQ5zY59yJOnjxZs2fPvukanJ2d81x+O/9yOOdnlg8++EABAQG51ru4lJ5YVXrOBAAAAIDJ2dlZsbGxioiI0Jtvvqlx48bl2S5nFHHSpEmKjo7Otb569epKTEzMtfzXX3811xeHnOPkV4uPj4/Kly8vq9UqDw+PfNs5OTkpKCjI3GfO6OCVrt42NDRUkuTn53fNUc+cGguyz5KKexABAACAUqpdu3Zq3ry5Zs+erfT09HzbjRgxQt7e3nr55Zdzrevatau++eYbxcfHm8vOnz+vBQsWqEaNGsV2b13VqlXVuHFjLVq0SCkpKebyvXv3at26derataukv4Jxp06d9Nlnn5mzuEp/zca6ZMkStW7d2rwktGvXrtq5c6e++eYbs92pU6e0ePFiu2N37txZnp6eevXVV5WRkZGrtlOnTuWqMTU11Vy/fv36XPdqllQERAAAAKAUGz16tE6cOKG4uLh823h5eWn48OFKSEjItW7cuHHy9/dXVFSUJkyYoNmzZ6t169Y6dOiQXn/9dbsZTG+1GTNm6PTp0woPD9fMmTP1yiuvqH379vLy8tKkSZPMdlOmTJGLi4tat26tV199VdOnT1fLli116dIlTZ8+3Ww3ZswYValSRV26dNHkyZM1c+ZMtWrVKteoqKenp+bPn6+vvvpKd999t/75z39qwYIFevHFF9WkSRO7SX5iY2N14sQJtW7dWrNmzdJLL72kRx55RPXr17/l/VMUCIgAAABAKfbQQw8pNDRUM2fOVFZWVr7tRowYkeczCP39/fX111+rY8eOmjt3rsaPHy9XV1etWrUq1zMQb7XIyEitWbNGVapU0YQJEzRz5kzde++92rFjh0JCQsx29evX11dffaUGDRooNjZWkydPVvXq1bV582a7SWmqVq2qzZs3q2HDhpo6dapmz56txx9/XMOHD8917L59+2rjxo264447NGPGDA0fPlwff/yxGjdurP79+5vtunTpoqVLlyorK0vjx4/XsmXLtHDhQvPe0JLOYtzOd4teQ1pamry8vGS1WmWxWBxdDoCr2Gw2JqkBgDIoIyNDqamp5iV+xSU9PV2HDh1SSEiIrFaruTw1NVULFiy4ZnAqLs7Ozho0aNA1HxQP3Kj8vgNXY5IaAA5hsVhksVhu6xnNAAC3Py8vLw0aNEgXL150dClyd3cnHMLhCIgAHIKACAAoKby8vAhmQDbuQQQAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAAAAAIAkAiIAAAAAIBsBEQAAAAAgiYAIAAAAAMhGQAQAAAAASCIgAnAQwzAcXQIAAACuQkAE4BCGYchmszm6DAAAAFzBxdEFAAAAAI50NDNTyVlZji5DPs7OCnYp/I/nn3zyif7+979r2bJlevDBB+3WNWrUSHv27NGmTZsUERFhty44OFjVqlXT119/XaDjvPXWW/Lw8FBMTEyha8Ttg4AIAACAMutoZqbCjh1TuqMLkWSVlHjHHYUOia1bt5Ykbd++3S4gpqWlae/evXJxcdGOHTvsAuLvv/+u33//Xb179y7wcd566y35+PgQEEs5LjEFAABAmZWclVUiwqEkpUs3NJIZGBiokJAQbd++3W55fHy8DMPQI488kmtdzvuccOkomZmZunz5skNrgD0CIgAAAHCba926tXbv3q2LFy+ay3bs2KH69esrKipKO3futLv3f8eOHbJYLGrVqpUWLlyo9u3by8/PT25ubqpXr57mz59vt/8aNWpo37592rp1qywWiywWi9q1a2euT0lJ0YgRIxQUFCQ3NzfVqlVL06ZNszvm4cOHZbFYNHPmTM2ePVuhoaFyc3PTzz//fOs6BoXGJaYAAADAba5169b64IMPtGvXLjO47dixQy1btlTLli2VmpqqvXv3qmHDhua6OnXqqEqVKpo/f77q16+vHj16yMXFRatWrdJTTz0lm82moUOHSpJmz56tp59+WhUqVNALL7wgSfL395ckXbhwQW3bttWxY8c0ePBgBQcH6+uvv9b48eN1/PhxzZ49267WhQsXKj09XYMGDZKbm5sqV65cPJ2EAiEgAgAAALe5K+9DbNeunTIzM7Vr1y5FR0crNDRU/v7+2r59uxo2bKizZ8/qp59+0j/+8Q9J0tatW+Xu7m7ua9iwYerSpYtef/11MyD27NlTL774onx8fPToo4/aHfv111/XwYMHtXv3bt15552SpMGDByswMFAzZszQqFGjFBQUZLb/448/dODAAfn6+t7SPsGN4RJTAAAA4DZXt25dValSxby38Mcff9T58+fVsmVLSVLLli21Y8cOSX/dm5iVlWWGyivDYWpqqpKTk9W2bVv99ttvSk1Nve6xly5dqjZt2qhSpUpKTk42X5GRkcrKytK2bdvs2j/88MOEwxKMEUQAAADgNmexWNSyZUtt27ZNNptNO3bskJ+fn2rVqiXpr4D45ptvSpIZFHMC4o4dOzRx4kTFx8frwoULdvtNTU2Vl5fXNY+9f/9+7dmzJ9/Qd/LkSbv3ISEhhT9BFBsCIgAAAFAKtG7dWqtWrdJPP/1k3n+Yo2XLlho9erSOHTum7du3KzAwUDVr1tTBgwfVoUMH1alTR6+//rqCgoLk6uqqL7/8UrNmzbKbZCY/NptNHTt21JgxY/JcX7t2bbv3V45YouQhIAIAAAClwJX3Ie7YsUMjRoww1zVt2lRubm7asmWLdu3apa5du0qSVq1apUuXLmnlypUKDg4222/evDnX/i0WS57HDQ0N1blz5xQZGVmEZwNHKfQ9iNu2bdP999+vwMBAWSwWrVixwm69YRiaMGGCqlatKnd3d0VGRmr//v12bc6cOaN+/frJ09NT3t7eGjBggM6dO2fXZs+ePWrTpo2sVquCgoI0ffr0wp8dAAAAUEY0a9ZMVqtVixcv1rFjx+xGEN3c3HT33Xdr3rx5On/+vBkmnZ2dJf31M3yO1NRULVy4MNf+y5cvr5SUlFzLe/Xqpfj4eK1duzbXupSUFGVmZt7sqaEYFTognj9/Xo0aNdK8efPyXD99+nS98cYbevvtt7Vr1y6VL19enTt3Vnr6/z2CtF+/ftq3b5/Wr1+vzz//XNu2bdOgQYPM9WlpaerUqZOqV6+u77//XjNmzNCkSZO0YMGCGzhFAAAAoPRzdXXVPffco/j4eLm5ualp06Z261u2bKn4+HhJ/zfa2KlTJ7m6uur+++/XvHnzNG3aNDVt2lR+fn659t+0aVPt2bNHU6ZM0ccff6xNmzZJkkaPHq27775b3bt31xNPPKG3335br732mmJiYlStWrU8QyVKrkJfYhoVFaWoqKg81xmGodmzZ+vFF1/UAw88IEl6//335e/vrxUrVqh379765ZdftGbNGn377bdq1qyZJGnu3Lnq2rWrZs6cqcDAQC1evFiXL1/We++9J1dXV9WvX18JCQl6/fXX7YIkAAAAgP/TunVrffXVV+YlpVdq1aqVXnvtNVWsWFGNGjWSJIWFhenTTz/Viy++qOeee04BAQEaMmSIfH19zcdg5JgwYYKOHDmi6dOn6+zZs2rbtq3at28vDw8Pbd26Va+++qqWLl2q999/X56enqpdu7YmT5583UluULJYjCvHkwu7scWi5cuXq2fPnpKk3377TaGhodq9e7caN25stmvbtq0aN26sOXPm6L333tOoUaP0559/muszMzNltVq1dOlSPfjgg3r88ceVlpZmd/nq5s2b1b59e505c0aVKlXKVculS5d06dIl831aWpqCgoJktVrzvV4agOPYbLYC3fgOAChdMjIylJqaKk9Pz2I9bnp6ug4dOqSQkBBZrVZz+dHMTIUdO6b0a2xbXKySEu+4Q8EuTBOCopffd+BqRfrpS0pKkiT5+/vbLff39zfXJSUl5RqydnFxUeXKle3aXD39bc4+k5KS8gyIsbGxmjx5ctGcCAAAAMqEYBcXJd5xh5KzshxdinycnQmHcLhS8wkcP368Ro4cab7PGUEEAAAAriXYxYVgBmQr9CQ11xIQECBJOnHihN3yEydOmOsCAgJyPSwzMzNTZ86csWuT1z6uPMbV3Nzc5OnpafcCAAAAABRckQbEkJAQBQQEaOPGjeaytLQ07dq1S+Hh4ZKk8PBwpaSk6PvvvzfbbNq0STabTS1atDDbbNu2TRkZGWab9evXKywsLM/LSwEAAAAAN6/QAfHcuXNKSEhQQkKCJOnQoUNKSEjQ0aNHZbFYNGLECE2ZMkUrV67UTz/9pMcff1yBgYHmRDZ169ZVly5d9MQTT+ibb77Rjh07NGzYMPXu3VuBgYGSpL59+8rV1VUDBgzQvn379J///Edz5syxu4QUAAAAAFC0Cn2x9XfffaeIiAjzfU5oi46OVlxcnMaMGaPz589r0KBBSklJUevWrbVmzRq7mXIWL16sYcOGqUOHDnJyctLDDz+sN954w1zv5eWldevWaejQoWratKl8fHw0YcIEHnEBAAAAALfQTT3moiRLS0uTl5cXj7kASigecwEAZVNJe8wFUFYU9DtQpPcgAkBBWSwWfnkDAABQwhAQATgEAREAAKDkISACAAAAACQREAEAAAAA2QiIAAAAAABJN/CYCwAAAKA0OXo0U8nJjp9Z28fHScHBhfvxvKD382/evFnt2rW7gapQ1hAQAQAAUGYdPZqpsLD/KT3d0ZVIVquUmBhYqJD4wQcf2L1///33tX79+lzL69atWyQ1ovQjIAIAAKDMSk62lYhwKEnp6X/VExxc8G0effRRu/c7d+7U+vXrcy2/2oULF+Th4XEjZaKU4x5EAAAAoBRr166dGjRooO+//1733XefPDw89Pzzz0uSLl26pIkTJ6pWrVpyc3NTUFCQxowZo0uXLuXaz4cffqimTZvK3d1dlStXVu/evfX7778X9+ngFmMEEQAAACjlTp8+raioKPXu3VuPPvqo/P39ZbPZ1KNHD23fvl2DBg1S3bp19dNPP2nWrFn673//qxUrVpjb//Of/9RLL72kXr16aeDAgTp16pTmzp2r++67T7t375a3t7fDzg1Fi4AIAAAAlHJJSUl6++23NXjwYHPZhx9+qA0bNmjr1q1q3bq1ubxBgwZ68skn9fXXX6tly5Y6cuSIJk6cqClTppgjj5L00EMPqUmTJnrrrbfsluP2xiWmAAAAQCnn5uam/v372y1bunSp6tatqzp16ig5Odl8tW/fXtJfM59K0rJly2Sz2dSrVy+7dgEBAbrzzjvNdigdGEEEAAAASrk77rhDrq6udsv279+vX375Rb6+vnluc/LkSbOdYRi6884782xXrly5oi0WDkVABAAAAEo5d3f3XMtsNpvuuusuvf7663luExQUZLazWCxavXq1nJ2dc7WrUKFC0RYLhyIgAgAAAGVQaGiofvzxR3Xo0EEWi+Wa7QzDUEhIiGrXrl2MFcIRuAcRAAAAKIN69eqlY8eO6d///neudRcvXtT58+cl/TUZjbOzsyZPnizDMOzaGYah06dPF0u9KB6MIAIAAABl0GOPPaZPPvlETz75pDZv3qxWrVopKytLv/76qz755BOtXbtWzZo1U2hoqKZMmaLx48fr8OHD6tmzpypWrKhDhw5p+fLlGjRokJ577jlHnw6KCAERAAAAKIOcnJy0YsUKzZo1S++//76WL18uDw8P1axZU8OHD7e7nHTcuHGqXbu2Zs2apcmTJ0v66x7FTp06qUePHo46BdwCFuPqceJSIi0tTV5eXrJarde8phqAYxiGIZvNlutSFQBA6ZaRkaHU1FR5enoW63HT09N16NAhhYSEyGq1msuPHs1UWNj/lJ5erOXkyWqVEhMDFRzMGA6KXn7fgavx6QPgEIZhEA4BAA4XHOyixMRAJSfbHF2KfHycCIdwOD6BAAAAKNOCg10UHOzoKoCSgVlMAQAAAACSCIgAAAAAgGwERAAAAACAJAIiAAAAACAbAREAAAAAIImACAAAAADIRkAEAAAAAEgiIAIAAAAAshEQAQAAAACSCIgAAAAACqlGjRqKiYkx32/ZskUWi0VbtmxxWE0oGgREAAAA4DbVo0cPeXh46OzZs/m26devn1xdXXX69OlirAy3KxdHFwAAAAA40uWjl5WZnOnoMuTi4yLXYNdCbdOvXz+tWrVKy5cv1+OPP55r/YULF/TZZ5+pS5cuqlKlSlGVqsTERDk5MdZUGhEQAQAAUGZdPnpZe8P2ykg3HF2KLFaLGiQ2KFRI7NGjhypWrKglS5bkGRA/++wznT9/Xv369SvKUuXm5lak+0PJQewHAABAmZWZnFkiwqEkGelGoUcy3d3d9dBDD2njxo06efJkrvVLlixRxYoV1aNHD6WkpGjEiBEKCgqSm5ubatWqpWnTpslms9ltY7PZNGfOHN11112yWq3y9fVVly5d9N1335ltrr4HMT+7du1Sly5d5OXlJQ8PD7Vt21Y7duwo1DmieBEQATiExWJxdAkAAJQK/fr1U2Zmpj755BO75WfOnNHatWv14IMPyjAMtW3bVh9++KEef/xxvfHGG2rVqpXGjx+vkSNH2m03YMAAM0hOmzZN48aNk9Vq1c6dOwtV16ZNm3TfffcpLS1NEydO1KuvvqqUlBS1b99e33zzzU2fN24NLjEF4DBOTk65fmsJAAAKp3379qpataqWLFmiYcOGmcuXLl2qjIwM9evXT6+//roOHjyo3bt3684775QkDR48WIGBgZoxY4ZGjRqloKAgbd68WXFxcXrmmWc0Z84cc1+jRo2SYRR8pNUwDD355JOKiIjQ6tWrzV8MDx48WPXr19eLL76odevWFVEPoCgxggjAIRhBBACgaDg7O6t3796Kj4/X4cOHzeVLliyRv7+/OnTooKVLl6pNmzaqVKmSkpOTzVdkZKSysrK0bds2SdL/+3//TxaLRRMnTsx1nML8252QkKD9+/erb9++On36tHm88+fPq0OHDtq2bRu/JC6hGEEEAAAAbnP9+vXTrFmztGTJEj3//PP6448/9NVXX+mZZ56Rs7Oz9u/frz179sjX1zfP7XPuXzx48KACAwNVuXLlm6pn//79kqTo6Oh826SmpqpSpUo3dRwUPQIiAAAAcJtr2rSp6tSpo48++kjPP/+8PvroIxmGYc5earPZ1LFjR40ZMybP7WvXrl2k9eSMDs6YMUONGzfOs02FChWK9JgoGgREAAAAoBTo16+fXnrpJe3Zs0dLlizRnXfeqXvuuUeSFBoaqnPnzikyMvKa+wgNDdXatWt15syZmxpFDA0NlSR5enpe95goWbgHEQAAACgFckYLJ0yYoISEBLtnH/bq1Uvx8fFau3Ztru1SUlKUmfnX4zUefvhhGYahyZMn52pXmElqmjZtqtDQUM2cOVPnzp3Ltf7UqVMF3heKFyOIAAAAQCkQEhKili1b6rPPPpMku4A4evRorVy5Ut27d1dMTIyaNm2q8+fP66efftKnn36qw4cPy8fHRxEREXrsscf0xhtvaP/+/erSpYtsNpu++uorRURE2M2Sei1OTk565513FBUVpfr166t///664447dOzYMW3evFmenp5atWrVLekH3BwCIgAAAFBK9OvXT19//bWaN2+uWrVqmcs9PDy0detWvfrqq1q6dKnef/99eXp6qnbt2po8ebK8vLzMtgsXLlTDhg317rvvavTo0fLy8lKzZs3UsmXLQtXSrl07xcfH65VXXtGbb76pc+fOKSAgQC1atNDgwYOL7JxRtCxGYcaKbyNpaWny8vKS1WplOn2ghLLZbExxDQBlTEZGhlJTU+Xp6Vmsx01PT9ehQ4cUEhIiq9VqLr989LL2hu2Vke74H4ktVosaJDaQa7Cro0tBKZTfd+BqjCACAACgzHINdlWDxAbKTM50dCly8XEhHMLhCIgAAAAo01yDXQlmQDZmMQUAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAAAAAIAkAiIAAADKkFL6CHDgugr62ScgAgAAoNQrV66cJOnChQsOrgRwjPPnz8tisZjfhfzwHEQAAACUes7OzvL29tbJkyclSR4eHrJYLA6uCri1DMNQZmam0tLSlJaWJm9vbzk7O19zGwIiAAAAyoSAgABJMkMiUFY4OzuratWq8vLyum5bAiIAAADKBIvFoqpVq8rPz08ZGRmOLgcoFi4uLnJ2di7wiDkBEQAAAGWKs7PzdS+zA8oqJqkB4BDMIgcAAFDyEBABOIRhGLLZbI4uAwAAAFcgIAIAAAAAJBEQAQAAAADZCIgAAAAAAEkERAAAAABANgIiAAAAAEASAREAAAAAkK3QAXHbtm26//77FRgYKIvFohUrVtitj4mJkcVisXt16dLFrs2ZM2fUr18/eXp6ytvbWwMGDNC5c+fs2uzZs0dt2rSR1WpVUFCQpk+fXvizAwAAAAAUWKED4vnz59WoUSPNmzcv3zZdunTR8ePHzddHH31kt75fv37at2+f1q9fr88//1zbtm3ToEGDzPVpaWnq1KmTqlevru+//14zZszQpEmTtGDBgsKWC6CEslgscnLiIgYAAICSxKWwG0RFRSkqKuqabdzc3BQQEJDnul9++UVr1qzRt99+q2bNmkmS5s6dq65du2rmzJkKDAzU4sWLdfnyZb333ntydXVV/fr1lZCQoNdff90uSAK4fVksFhmG4egyAAAAcIVb8uv7LVu2yM/PT2FhYRoyZIhOnz5trouPj5e3t7cZDiUpMjJSTk5O2rVrl9nmvvvuk6urq9mmc+fOSkxM1J9//pnnMS9duqS0tDS7FwAAAACg4Io8IHbp0kXvv/++Nm7cqGnTpmnr1q2KiopSVlaWJCkpKUl+fn5227i4uKhy5cpKSkoy2/j7+9u1yXmf0+ZqsbGx8vLyMl9BQUFFfWoAAAAAUKoV+hLT6+ndu7f557vuuksNGzZUaGiotmzZog4dOhT14Uzjx4/XyJEjzfdpaWmERAAAAAAohFs+Q0TNmjXl4+OjAwcOSJICAgJ08uRJuzaZmZk6c+aMed9iQECATpw4Ydcm531+9za6ubnJ09PT7gUAAAAAKLhbHhD/+OMPnT59WlWrVpUkhYeHKyUlRd9//73ZZtOmTbLZbGrRooXZZtu2bcrIyDDbrF+/XmFhYapUqdKtLhkAAAAAyqRCB8Rz584pISFBCQkJkqRDhw4pISFBR48e1blz5zR69Gjt3LlThw8f1saNG/XAAw+oVq1a6ty5sySpbt266tKli5544gl988032rFjh4YNG6bevXsrMDBQktS3b1+5urpqwIAB2rdvn/7zn/9ozpw5dpeQAgAAAACKlsUo5DzzW7ZsUURERK7l0dHRmj9/vnr27Kndu3crJSVFgYGB6tSpk1555RW7SWfOnDmjYcOGadWqVXJyctLDDz+sN954QxUqVDDb7NmzR0OHDtW3334rHx8fPf300xo7dmyB60xLS5OXl5esVqssFkthThFAMbHZbLLZbI4uAwBQjDIyMpSamsrtQEAJVeiAeLsgIAIlm2EYMgyDgAgAZQwBESjZbvk9iACQH8IhAABAyUJABOAQpfTiBQAAgNsaAREAAAAAIImACAAAAADIRkAEAAAAAEgiIAIAAAAAshEQAQAAAACSCIgAHIAZTAEAAEomAiIAh+AZiAAAACUPARFAsWMEEQAAoGQiIAIAAAAAJBEQAQAAAADZCIgAAAAAAEkERAAAAABANgIiAAAAAEASAREAAAAAkI2ACAAAAACQREAEAAAAAGQjIAIAAAAAJBEQAQAAAADZCIgAipVhGI4uAQAAAPkgIAIodjabzdElAAAAIA8ERAAAAACAJAIiAAAAACAbAREAAAAAIImACAAAAADIRkAEAAAAAEgiIAIAAAAAshEQAQAAAACSCIgAAAAAgGwERAAAAACAJAIiAAAAACAbAREAAAAAIImACAAAAADIRkAEAAAAAEgiIAIAAAAAshEQARQbwzAcXQIAAACugYAIoFhlZWU5ugQAAADkg4AIAAAAAJBEQAQAAAAAZCMgAgAAAAAkERABAAAAANkIiAAAAAAASQREAAAAAEA2AiIAAAAAQBIBEQAAAACQjYAIAAAAAJBEQAQAAAAAZCMgAgAAAAAkERABAAAAANkIiAAAAAAASQREAAAAAEA2AiKAYmEYhqNLAAAAwHUQEAEUG5vN5ugSAAAAcA0ERADFhlFEAACAko2ACAAAAACQREAEAAAAAGQjIAIAAAAAJBEQAQAAAADZCIgAAAAAAEkERAAAAABANgIiAAAAAEASAREAAAAAkI2ACAAAAACQREAEAAAAAGQjIAIAAAAAJBUyIMbGxuqee+5RxYoV5efnp549eyoxMdGuTXp6uoYOHaoqVaqoQoUKevjhh3XixAm7NkePHlW3bt3k4eEhPz8/jR49WpmZmXZttmzZorvvvltubm6qVauW4uLibuwMAQAAAAAFUqiAuHXrVg0dOlQ7d+7U+vXrlZGRoU6dOun8+fNmm2effVarVq3S0qVLtXXrVv3vf//TQw89ZK7PyspSt27ddPnyZX399ddatGiR4uLiNGHCBLPNoUOH1K1bN0VERCghIUEjRozQwIEDtXbt2iI4ZQAAAABAXiyGYRg3uvGpU6fk5+enrVu36r777lNqaqp8fX21ZMkS/e1vf5Mk/frrr6pbt67i4+N17733avXq1erevbv+97//yd/fX5L09ttva+zYsTp16pRcXV01duxYffHFF9q7d695rN69eyslJUVr1qwpUG1paWny8vKS1WqVxWK50VMEUEQMw1BWVpajywAAOFhGRoZSU1Pl6enp6FIA5OGm7kFMTU2VJFWuXFmS9P333ysjI0ORkZFmmzp16ig4OFjx8fGSpPj4eN11111mOJSkzp07Ky0tTfv27TPbXLmPnDY5+8jLpUuXlJaWZvcCAAAAABTcDQdEm82mESNGqFWrVmrQoIEkKSkpSa6urvL29rZr6+/vr6SkJLPNleEwZ33Oumu1SUtL08WLF/OsJzY2Vl5eXuYrKCjoRk8NQBG7iQsVAAAAUIxuOCAOHTpUe/fu1ccff1yU9dyw8ePHKzU11Xz9/vvvji4JwBUIiQAAACWfy41sNGzYMH3++efatm2bqlWrZi4PCAjQ5cuXlZKSYjeKeOLECQUEBJhtvvnmG7v95cxyemWbq2c+PXHihDw9PeXu7p5nTW5ubnJzc7uR0wFQDGw2m6NLAAAAwHUUagTRMAwNGzZMy5cv16ZNmxQSEmK3vmnTpipXrpw2btxoLktMTNTRo0cVHh4uSQoPD9dPP/2kkydPmm3Wr18vT09P1atXz2xz5T5y2uTsA8Dth8miAAAASr5CzWL61FNPacmSJfrss88UFhZmLvfy8jJH9oYMGaIvv/xScXFx8vT01NNPPy1J+vrrryX99ZiLxo0bKzAwUNOnT1dSUpIee+wxDRw4UK+++qqkvx5z0aBBAw0dOlT/+Mc/tGnTJj3zzDP64osv1Llz5wLVyiymQMmR89cMs5gCAJjFFCjZChUQ8wtaCxcuVExMjCQpPT1do0aN0kcffaRLly6pc+fOeuutt8zLRyXpyJEjGjJkiLZs2aLy5csrOjpaU6dOlYvL/13xumXLFj377LP6+eefVa1aNb300kvmMQqCgAiULDzmAgAgERCBku6mnoNYkhEQgZKFgAgAkAiIQEl3U89BBAAAAACUHgREAAAAAIAkAiIAAAAAIBsBEQAAAAAgiYAIAAAAAMhGQAQAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAAAAAIAkAiIAAAAAIBsBEQAAAAAgiYAIAAAAAMhGQAQAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAAAAAIAkAiIAAAAAIBsBEQAAAAAgiYAIAAAAAMhGQAQAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAAAAAIAkAiIAAAAAIBsBEQAAAAAgiYAIAAAAAMhGQAQAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAAAAAIAkAiIAAAAAIBsBEQAAAAAgiYAIAAAAAMhGQAQAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAMXG2dnZ0SUAAADgGgiIAIqFxWJxdAkAAAC4DgIiAAAAAEASAREAAAAAkI2ACAAAAACQREAEAAAAAGQjIAIAAAAAJBEQAQAAAADZCIgAAAAAAEkERAAAAABANgIiAAAAAEASARFAMTEMw9ElAAAA4DoIiACKTVZWlqNLAAAAwDUQEAEAAAAAkgiIAAAAAIBsBEQAAAAAgCQCIgAAAAAgGwERAAAAACCJgAgAAAAAyEZABFBsLBaLo0sAAADANRAQARQbJyf+ygEAACjJ+GkNQLFg9BAAAKDkIyACAAAAACQREAEAAAAA2QiIAAAAAABJhQyIsbGxuueee1SxYkX5+fmpZ8+eSkxMtGvTrl07WSwWu9eTTz5p1+bo0aPq1q2bPDw85Ofnp9GjRyszM9OuzZYtW3T33XfLzc1NtWrVUlxc3I2dIQAAAACgQAoVELdu3aqhQ4dq586dWr9+vTIyMtSpUyedP3/ert0TTzyh48ePm6/p06eb67KystStWzddvnxZX3/9tRYtWqS4uDhNmDDBbHPo0CF169ZNERERSkhI0IgRIzRw4ECtXbv2Jk8XAAAAAJAfi2EYxo1ufOrUKfn5+Wnr1q267777JP01gti4cWPNnj07z21Wr16t7t2763//+5/8/f0lSW+//bbGjh2rU6dOydXVVWPHjtUXX3yhvXv3mtv17t1bKSkpWrNmTYFqS0tLk5eXl6xWK7MnAiWEYRjKyspydBkAAAfKyMhQamqqPD09HV0KgDzc1D2IqampkqTKlSvbLV+8eLF8fHzUoEEDjR8/XhcuXDDXxcfH66677jLDoSR17txZaWlp2rdvn9kmMjLSbp+dO3dWfHx8vrVcunRJaWlpdi8AAAAAQMG53OiGNptNI0aMUKtWrdSgQQNzed++fVW9enUFBgZqz549Gjt2rBITE7Vs2TJJUlJSkl04lGS+T0pKumabtLQ0Xbx4Ue7u7rnqiY2N1eTJk2/0dAAAAACgzLvhgDh06FDt3btX27dvt1s+aNAg88933XWXqlatqg4dOujgwYMKDQ298UqvY/z48Ro5cqT5Pi0tTUFBQbfseAAAAABQ2tzQJabDhg3T559/rs2bN6tatWrXbNuiRQtJ0oEDByRJAQEBOnHihF2bnPcBAQHXbOPp6Znn6KEkubm5ydPT0+4FAAAAACi4QgVEwzA0bNgwLV++XJs2bVJISMh1t0lISJAkVa1aVZIUHh6un376SSdPnjTbrF+/Xp6enqpXr57ZZuPGjXb7Wb9+vcLDwwtTLgAAAACgEAo1i+lTTz2lJUuW6LPPPlNYWJi53MvLS+7u7jp48KCWLFmirl27qkqVKtqzZ4+effZZVatWTVu3bpX012MuGjdurMDAQE2fPl1JSUl67LHHNHDgQL366quS/nrMRYMGDTR06FD94x//0KZNm/TMM8/oiy++UOfOnQtUK7OYAiUPs5gCAJjFFCjZChUQ8wtaCxcuVExMjH7//Xc9+uij2rt3r86fP6+goCA9+OCDevHFF+3+Ejhy5IiGDBmiLVu2qHz58oqOjtbUqVPl4vJ/t0Ru2bJFzz77rH7++WdVq1ZNL730kmJiYgp8YgREoOQhIAIACIhAyXZTz0EsyQiIQMlDQAQAEBCBku2mnoMIAAAAACg9CIgAipWzs7OjSwAAAEA+CIgAig2XewMAAJRsBEQAAAAAgCQCIgAAAAAgGwERAAAAACCJgAgAAAAAyEZABAAAAABIIiACAAAAALIREAEAAAAAkgiIAIqRYRgyDMPRZQAAACAfBEQAxcpmszm6BAAAAOSDgAigWDB6CAAAUPIREAEUG0YPAQAASjYCIgAAAABAEgERQDHg8lIAAIDbAwERwC2VEwy5vBQAAKDkIyACuOUIhwAAALcHAiIAAAAAQBIBEQAAAACQjYAI4JbJuf+QCWoAAABuDwREALcU9x8CAADcPgiIAAAAAABJBEQAAAAAQDYCIgAAAABAEgERwC1kGAYT1AAAANxGCIgAbhnCIQAAwO2FgAgAAAAAkERABAAAAABkIyACuCW4vBQAAOD2Q0AEcEswQQ0AAMDth4AIAAAAAJBEQAQAAAAAZCMgAgAAAAAkERABAAAAANkIiAAAAAAASQREAAAAAEA2AiIAAAAAQBIBEQAAAACQjYAIAAAAAJBEQAQAAAAAZCMgAgAAAAAkERABAAAAANkIiAAAAAAASQREAAAAAEA2AiIAAAAAQBIBEQAAAACQjYAIAAAAAJBEQAQAAAAAZCMgAgAAAAAkERABAAAAANkIiAAAAAAASQREAAAAAEA2AiIAAAAAQBIBEcAtYBiGDMNwdBkAAAAoJAIigFuCgAgAAHD7ISACKHKEQwAAgNsTAREAAAAAIImACAAAAADIRkAEUKSYoAYAAOD2RUAEUOQIiAAAALcnAiIAAAAAQBIBEQAAAACQjYAIAAAAAJBEQAQAAAAAZCMgAgAAAAAkERABAAAAANkIiAAAAAAASQREALeAxWJxdAkAAAC4AS6OLuBWyXlQNw/sBopfTkDk+wcAyAv/PgAlV6kNiKdPn5YkXbp0ycGVAAAA4Epnz56Vl5eXo8sAkIdSGxArV64sSTp69Ch/ARVQWlqagoKC9Pvvv8vT09PR5dwW6LPCo88Kjz4rPPqs8OizwqPPCs8wDJ09e1aBgYGOLgVAPkptQHRy+uv2Si8vL/7SLiRPT0/6rJDos8KjzwqPPis8+qzw6LPCo88Kh1/cAyUbk9QAAAAAACQREAEAAAAA2UptQHRzc9PEiRPl5ubm6FJuG/RZ4dFnhUefFR59Vnj0WeHRZ4VHnwEojSwG8wwDAAAAAFSKRxABAAAAAIVDQAQAAAAASCIgAgAAAACyERABAAAAAJJKaUCcN2+eatSoIavVqhYtWuibb75xdEkOM2nSJFksFrtXnTp1zPXp6ekaOnSoqlSpogoVKujhhx/WiRMn7PZx9OhRdevWTR4eHvLz89Po0aOVmZlZ3Kdyy2zbtk3333+/AgMDZbFYtGLFCrv1hmFowoQJqlq1qtzd3RUZGan9+/fbtTlz5oz69esnT09PeXt7a8CAATp37pxdmz179qhNmzayWq0KCgrS9OnTb/Wp3TLX67OYmJhcn7suXbrYtSlLfRYbG6t77rlHFStWlJ+fn3r27KnExES7NkX1XdyyZYvuvvtuubm5qVatWoqLi7vVp3dLFKTP2rVrl+tz9uSTT9q1KUt9Nn/+fDVs2NB8aHt4eLhWr15truczltv1+ozPGIAyyShlPv74Y8PV1dV47733jH379hlPPPGE4e3tbZw4ccLRpTnExIkTjfr16xvHjx83X6dOnTLXP/nkk0ZQUJCxceNG47vvvjPuvfdeo2XLlub6zMxMo0GDBkZkZKSxe/du48svvzR8fHyM8ePHO+J0bokvv/zSeOGFF4xly5YZkozly5fbrZ86darh5eVlrFixwvjxxx+NHj16GCEhIcbFixfNNl26dDEaNWpk7Ny50/jqq6+MWrVqGX369DHXp6amGv7+/ka/fv2MvXv3Gh999JHh7u5u/Otf/yqu0yxS1+uz6Ohoo0uXLnafuzNnzti1KUt91rlzZ2PhwoXG3r17jYSEBKNr165GcHCwce7cObNNUXwXf/vtN8PDw8MYOXKk8fPPPxtz5841nJ2djTVr1hTr+RaFgvRZ27ZtjSeeeMLuc5aammquL2t9tnLlSuOLL74w/vvf/xqJiYnG888/b5QrV87Yu3evYRh8xvJyvT7jMwagLCp1AbF58+bG0KFDzfdZWVlGYGCgERsb68CqHGfixIlGo0aN8lyXkpJilCtXzli6dKm57JdffjEkGfHx8YZh/BUEnJycjKSkJLPN/PnzDU9PT+PSpUu3tHZHuDrs2Gw2IyAgwJgxY4a5LCUlxXBzczM++ugjwzAM4+effzYkGd9++63ZZvXq1YbFYjGOHTtmGIZhvPXWW0alSpXs+mzs2LFGWFjYLT6jWy+/gPjAAw/ku01Z77OTJ08akoytW7cahlF038UxY8YY9evXtzvW3//+d6Nz5863+pRuuav7zDD++uF9+PDh+W5T1vvMMAyjUqVKxjvvvMNnrBBy+sww+IwBKJtK1SWmly9f1vfff6/IyEhzmZOTkyIjIxUfH+/Ayhxr//79CgwMVM2aNdWvXz8dPXpUkvT9998rIyPDrr/q1Kmj4OBgs7/i4+N11113yd/f32zTuXNnpaWlad++fcV7Ig5w6NAhJSUl2fWRl5eXWrRoYddH3t7eatasmdkmMjJSTk5O2rVrl9nmvvvuk6urq9mmc+fOSkxM1J9//llMZ1O8tmzZIj8/P4WFhWnIkCE6ffq0ua6s91lqaqokqXLlypKK7rsYHx9vt4+cNqXh77+r+yzH4sWL5ePjowYNGmj8+PG6cOGCua4s91lWVpY+/vhjnT9/XuHh4XzGCuDqPsvBZwxAWePi6AKKUnJysrKysuz+opYkf39//frrrw6qyrFatGihuLg4hYWF6fjx45o8ebLatGmjvXv3KikpSa6urvL29rbbxt/fX0lJSZKkpKSkPPszZ11pl3OOefXBlX3k5+dnt97FxUWVK1e2axMSEpJrHznrKlWqdEvqd5QuXbrooYceUkhIiA4ePKjnn39eUVFRio+Pl7Ozc5nuM5vNphEjRqhVq1Zq0KCBJBXZdzG/Nmlpabp48aLc3d1vxSndcnn1mST17dtX1atXV2BgoPbs2aOxY8cqMTFRy5Ytk1Q2++ynn35SeHi40tPTVaFCBS1fvlz16tVTQkICn7F85NdnEp8xAGVTqQqIyC0qKsr8c8OGDdWiRQtVr15dn3zyCf8o4Zbp3bu3+ee77rpLDRs2VGhoqLZs2aIOHTo4sDLHGzp0qPbu3avt27c7upTbRn59NmjQIPPPd911l6pWraoOHTro4MGDCg0NLe4yS4SwsDAlJCQoNTVVn376qaKjo7V161ZHl1Wi5ddn9erV4zMGoEwqVZeY+vj4yNnZOdesbCdOnFBAQICDqipZvL29Vbt2bR04cEABAQG6fPmyUlJS7Npc2V8BAQF59mfOutIu5xyv9ZkKCAjQyZMn7dZnZmbqzJkz9GO2mjVrysfHRwcOHJBUdvts2LBh+vzzz7V582ZVq1bNXF5U38X82nh6et62vxDKr8/y0qJFC0my+5yVtT5zdXVVrVq11LRpU8XGxqpRo0aaM2cOn7FryK/P8sJnDEBZUKoCoqurq5o2baqNGzeay2w2mzZu3Gh3P0FZdu7cOR08eFBVq1ZV06ZNVa5cObv+SkxM1NGjR83+Cg8P108//WT3w/z69evl6elpXoJTmoWEhCggIMCuj9LS0rRr1y67PkpJSdH3339vttm0aZNsNpv5w0R4eLi2bdumjIwMs8369esVFhZ2214qWRh//PGHTp8+rapVq0oqe31mGIaGDRum5cuXa9OmTbkunS2q72J4eLjdPnLa3I5//12vz/KSkJAgSXafs7LUZ3mx2Wy6dOkSn7FCyOmzvPAZA1AmOHqWnKL28ccfG25ubkZcXJzx888/G4MGDTK8vb3tZhgrS0aNGmVs2bLFOHTokLFjxw4jMjLS8PHxMU6ePGkYxl/TngcHBxubNm0yvvvuOyM8PNwIDw83t8+ZwrtTp05GQkKCsWbNGsPX17dUPebi7Nmzxu7du43du3cbkozXX3/d2L17t3HkyBHDMP56zIW3t7fx2WefGXv27DEeeOCBPB9z0aRJE2PXrl3G9u3bjTvvvNPukQ0pKSmGv7+/8dhjjxl79+41Pv74Y8PDw+O2fGSDYVy7z86ePWs899xzRnx8vHHo0CFjw4YNxt13323ceeedRnp6urmPstRnQ4YMMby8vIwtW7bYTZd/4cIFs01RfBdzptMfPXq08csvvxjz5s27bafTv16fHThwwHj55ZeN7777zjh06JDx2WefGTVr1jTuu+8+cx9lrc/GjRtnbN261Th06JCxZ88eY9y4cYbFYjHWrVtnGAafsbxcq8/4jAEoq0pdQDQMw5g7d64RHBxsuLq6Gs2bNzd27tzp6JIc5u9//7tRtWpVw9XV1bjjjjuMv//978aBAwfM9RcvXjSeeuopo1KlSoaHh4fx4IMPGsePH7fbx+HDh42oqCjD3d3d8PHxMUaNGmVkZGQU96ncMps3bzYk5XpFR0cbhvHXoy5eeuklw9/f33BzczM6dOhgJCYm2u3j9OnTRp8+fYwKFSoYnp6eRv/+/Y2zZ8/atfnxxx+N1q1bG25ubsYdd9xhTJ06tbhOschdq88uXLhgdOrUyfD19TXKlStnVK9e3XjiiSdy/ZKmLPVZXn0lyVi4cKHZpqi+i5s3bzYaN25suLq6GjVr1rQ7xu3ken129OhR47777jMqV65suLm5GbVq1TJGjx5t94w6wyhbffaPf/zDqF69uuHq6mr4+voaHTp0MMOhYfAZy8u1+ozPGICyymIYhlF845UAAAAAgJKqVN2DCAAAAAC4cQREAAAAAIAkAiIAAAAAIBsBEQAAAAAgiYAIAAAAAMhGQAQAAAAASCIgAgAAAACyERABAAAAAJIIiAAAAACAbAREAAAAAIAkAiIAAAAAIBsBEQAAAAAgSfr/SalHfNrXVzoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look at the segmentation map we got\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#img = Image.open('/kaggle/input/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/annotations/training/10166_lab.png')\n",
    "img = Image.open('/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData/annotations/testing/10163_lab.png')\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(np.array(img.convert('RGB')))\n",
    "\n",
    "# create a patch (proxy artist) for every color \n",
    "patches = [mpatches.Patch(color=np.array(palette[i])/255., \n",
    "                          label=classes[i]) for i in range(8)]\n",
    "# put those patched as legend-handles into the legend\n",
    "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., \n",
    "           fontsize='large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d356570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:52.764562Z",
     "iopub.status.busy": "2024-05-09T06:07:52.763930Z",
     "iopub.status.idle": "2024-05-09T06:07:52.770199Z",
     "shell.execute_reply": "2024-05-09T06:07:52.769242Z"
    },
    "papermill": {
     "duration": 0.057234,
     "end_time": "2024-05-09T06:07:52.772210",
     "exception": false,
     "start_time": "2024-05-09T06:07:52.714976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Background',\n",
       " 'BuildingFlooded',\n",
       " 'BNonFlooded',\n",
       " 'RoadFlooded',\n",
       " 'RNonFlooded',\n",
       " 'Water',\n",
       " 'Tree',\n",
       " 'Vecile',\n",
       " 'Pool',\n",
       " 'Grass']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82848d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:52.869691Z",
     "iopub.status.busy": "2024-05-09T06:07:52.868978Z",
     "iopub.status.idle": "2024-05-09T06:07:52.875460Z",
     "shell.execute_reply": "2024-05-09T06:07:52.874591Z"
    },
    "papermill": {
     "duration": 0.057153,
     "end_time": "2024-05-09T06:07:52.877383",
     "exception": false,
     "start_time": "2024-05-09T06:07:52.820230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0]),\n",
       " array([255,   0,   0]),\n",
       " array([181,  72,  72]),\n",
       " array([150, 150,   0]),\n",
       " array([135, 135, 135]),\n",
       " array([  0, 224, 224]),\n",
       " array([  0,   0, 225]),\n",
       " array([204,   0, 204]),\n",
       " array([237, 237,   0]),\n",
       " array([  0, 225,   0])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6382e765",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:07:52.990935Z",
     "iopub.status.busy": "2024-05-09T06:07:52.990296Z",
     "iopub.status.idle": "2024-05-09T06:08:05.719071Z",
     "shell.execute_reply": "2024-05-09T06:08:05.717958Z"
    },
    "papermill": {
     "duration": 12.791652,
     "end_time": "2024-05-09T06:08:05.721654",
     "exception": false,
     "start_time": "2024-05-09T06:07:52.930002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\r\n",
      "  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy) (0.2.13)\r\n",
      "Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ftfy\r\n",
      "Successfully installed ftfy-6.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65dbb79c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:05.822805Z",
     "iopub.status.busy": "2024-05-09T06:08:05.822430Z",
     "iopub.status.idle": "2024-05-09T06:08:09.182045Z",
     "shell.execute_reply": "2024-05-09T06:08:09.181005Z"
    },
    "papermill": {
     "duration": 3.413417,
     "end_time": "2024-05-09T06:08:09.184353",
     "exception": false,
     "start_time": "2024-05-09T06:08:05.770936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmseg.registry import DATASETS\n",
    "from mmseg.datasets import BaseSegDataset\n",
    "\n",
    "## should be run only once\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ImageSegmentationDataset(BaseSegDataset):\n",
    "    METAINFO = dict(classes = classes, palette = palette)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(img_suffix='.jpg', seg_map_suffix=\"_lab.png\", **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd4199d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:09.285557Z",
     "iopub.status.busy": "2024-05-09T06:08:09.284496Z",
     "iopub.status.idle": "2024-05-09T06:08:09.291030Z",
     "shell.execute_reply": "2024-05-09T06:08:09.289896Z"
    },
    "papermill": {
     "duration": 0.057873,
     "end_time": "2024-05-09T06:08:09.292928",
     "exception": false,
     "start_time": "2024-05-09T06:08:09.235055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0fdef62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:09.390326Z",
     "iopub.status.busy": "2024-05-09T06:08:09.390033Z",
     "iopub.status.idle": "2024-05-09T06:08:11.315057Z",
     "shell.execute_reply": "2024-05-09T06:08:11.313696Z"
    },
    "papermill": {
     "duration": 1.97665,
     "end_time": "2024-05-09T06:08:11.317708",
     "exception": false,
     "start_time": "2024-05-09T06:08:09.341058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'checkpoint': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r checkpoint\n",
    "!mkdir checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87cf271c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:11.419314Z",
     "iopub.status.busy": "2024-05-09T06:08:11.418565Z",
     "iopub.status.idle": "2024-05-09T06:08:12.533954Z",
     "shell.execute_reply": "2024-05-09T06:08:12.533032Z"
    },
    "papermill": {
     "duration": 1.169,
     "end_time": "2024-05-09T06:08:12.537230",
     "exception": false,
     "start_time": "2024-05-09T06:08:11.368230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "backbone_norm_cfg = dict(requires_grad=True, type='LN')\n",
      "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/ade/ADEChallengeData2016'\n",
      "dataset_type = 'ADE20KDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),\n",
      "    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=256,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=512,\n",
      "        in_index=2,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=150,\n",
      "        num_convs=1,\n",
      "        type='FCNHead'),\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        attn_drop_rate=0.0,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            18,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.3,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=128,\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratio=4,\n",
      "        norm_cfg=dict(requires_grad=True, type='LN'),\n",
      "        num_heads=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        patch_size=4,\n",
      "        pretrain_img_size=384,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        strides=(\n",
      "            4,\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        type='SwinTransformer',\n",
      "        use_abs_pos_embed=False,\n",
      "        window_size=12),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            128,\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='SyncBN'),\n",
      "        num_classes=150,\n",
      "        pool_scales=(\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "            6,\n",
      "        ),\n",
      "        type='UPerHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='SyncBN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root='data/ade/ADEChallengeData2016',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=True, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ADE20KDataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('/kaggle/working/mmsegmentation/configs/swin/swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83476a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:12.639429Z",
     "iopub.status.busy": "2024-05-09T06:08:12.639059Z",
     "iopub.status.idle": "2024-05-09T06:08:12.645943Z",
     "shell.execute_reply": "2024-05-09T06:08:12.645065Z"
    },
    "papermill": {
     "duration": 0.059025,
     "end_time": "2024-05-09T06:08:12.647951",
     "exception": false,
     "start_time": "2024-05-09T06:08:12.588926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'UPerHead',\n",
       " 'in_channels': [128, 256, 512, 1024],\n",
       " 'in_index': [0, 1, 2, 3],\n",
       " 'pool_scales': (1, 2, 3, 6),\n",
       " 'channels': 512,\n",
       " 'dropout_ratio': 0.1,\n",
       " 'num_classes': 150,\n",
       " 'norm_cfg': {'type': 'SyncBN', 'requires_grad': True},\n",
       " 'align_corners': False,\n",
       " 'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "  'use_sigmoid': False,\n",
       "  'loss_weight': 1.0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.decode_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c5e0429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:12.749042Z",
     "iopub.status.busy": "2024-05-09T06:08:12.748739Z",
     "iopub.status.idle": "2024-05-09T06:08:12.762919Z",
     "shell.execute_reply": "2024-05-09T06:08:12.762165Z"
    },
    "papermill": {
     "duration": 0.066955,
     "end_time": "2024-05-09T06:08:12.764655",
     "exception": false,
     "start_time": "2024-05-09T06:08:12.697700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 10\n",
    "# cfg.model.auxiliary_head.num_classes = 10\n",
    "\n",
    "cfg.model.pretrained='https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K_20210531_132020-05b22ea4.pth'\n",
    "\n",
    "\n",
    "cfg.val_evaluator = dict(type='IoUMetric',\n",
    "                         iou_metrics=['mIoU', 'mDice', 'mFscore'],\n",
    "#                          format_only=True,\n",
    "#                          output_dir='/kaggle/working/results'\n",
    "                        )\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# # Modify dataset type and path\n",
    "cfg.dataset_type = 'ImageSegmentationDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "\n",
    "cfg.train_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.val_dataloader.dataset.type=cfg.dataset_type\n",
    "cfg.test_dataloader.dataset.type=cfg.dataset_type\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n",
    "    # add loading annotation after ``Resize`` because ground truth\n",
    "    # does not need to do resize data transform\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(type='PackSegInputs')\n",
    "]\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
    "    dict(\n",
    "        type='RandomResize',\n",
    "        scale=(\n",
    "            512,\n",
    "            512,\n",
    "        ),\n",
    "        ratio_range=(\n",
    "            0.5,\n",
    "            2.0,\n",
    "        ),\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomCrop', crop_size=(\n",
    "        512,\n",
    "        512,\n",
    "    ), cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', prob=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='PackSegInputs'),\n",
    "]\n",
    "\n",
    "cfg.train_dataloader.dataset.pipeline = cfg.train_pipeline\n",
    "\n",
    "cfg.test_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "cfg.val_dataloader.dataset.pipeline = cfg.test_pipeline\n",
    "\n",
    "cfg.train_dataloader.num_workers=1\n",
    "cfg.train_dataloader.batch_size = 2\n",
    "cfg.train_dataloader.persistent_workers=False\n",
    "\n",
    "\n",
    "cfg.val_dataloader.batch_size = 1\n",
    "cfg.val_dataloader.num_workers=1\n",
    "cfg.val_dataloader.persistent_workers=False\n",
    "\n",
    "cfg.test_dataloader.batch_size = 1\n",
    "cfg.test_dataloader.num_workers=1\n",
    "cfg.test_dataloader.persistent_workers=False\n",
    "\n",
    "cfg.work_dir = '/kaggle/working/checkpoint'\n",
    "\n",
    "cfg.train_cfg.max_iters = 57000\n",
    "cfg.train_cfg.val_interval = 3000\n",
    "cfg.default_hooks.logger.interval = 100\n",
    "#cfg.default_hooks.checkpoint.interval = 55000\n",
    "cfg.default_hooks.checkpoint.save_best='mIoU'\n",
    "\n",
    "# Set seed to facilitate reproducing the result\n",
    "cfg['randomness'] = dict(seed=0)\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "# print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a4a61e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:12.864905Z",
     "iopub.status.busy": "2024-05-09T06:08:12.864616Z",
     "iopub.status.idle": "2024-05-09T06:08:12.871041Z",
     "shell.execute_reply": "2024-05-09T06:08:12.870226Z"
    },
    "papermill": {
     "duration": 0.05796,
     "end_time": "2024-05-09T06:08:12.873007",
     "exception": false,
     "start_time": "2024-05-09T06:08:12.815047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'UPerHead',\n",
       " 'in_channels': [128, 256, 512, 1024],\n",
       " 'in_index': [0, 1, 2, 3],\n",
       " 'pool_scales': (1, 2, 3, 6),\n",
       " 'channels': 512,\n",
       " 'dropout_ratio': 0.1,\n",
       " 'num_classes': 10,\n",
       " 'norm_cfg': {'type': 'SyncBN', 'requires_grad': True},\n",
       " 'align_corners': False,\n",
       " 'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "  'use_sigmoid': False,\n",
       "  'loss_weight': 1.0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.decode_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c68324cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:12.973303Z",
     "iopub.status.busy": "2024-05-09T06:08:12.972984Z",
     "iopub.status.idle": "2024-05-09T06:08:12.978919Z",
     "shell.execute_reply": "2024-05-09T06:08:12.978098Z"
    },
    "papermill": {
     "duration": 0.058911,
     "end_time": "2024-05-09T06:08:12.980700",
     "exception": false,
     "start_time": "2024-05-09T06:08:12.921789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.model.decode_head=dict(\n",
    "    type='SegformerHead',\n",
    "    in_channels=[128,256,512,1024,],\n",
    "    in_index=[0, 1, 2, 3],\n",
    "    channels=512,\n",
    "    dropout_ratio=0.1,\n",
    "    num_classes=10,\n",
    "    norm_cfg=cfg.norm_cfg,\n",
    "    align_corners=False,\n",
    "    loss_decode=dict(\n",
    "        type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
    "    init_cfg=dict(\n",
    "        type='Pretrained',\n",
    "        checkpoint='https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'\n",
    "    ))\n",
    "cfg.model.auxiliary_head=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cddc3c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:13.081000Z",
     "iopub.status.busy": "2024-05-09T06:08:13.080713Z",
     "iopub.status.idle": "2024-05-09T06:08:13.087303Z",
     "shell.execute_reply": "2024-05-09T06:08:13.086365Z"
    },
    "papermill": {
     "duration": 0.058935,
     "end_time": "2024-05-09T06:08:13.089361",
     "exception": false,
     "start_time": "2024-05-09T06:08:13.030426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'SegformerHead',\n",
       " 'in_channels': [128, 256, 512, 1024],\n",
       " 'in_index': [0, 1, 2, 3],\n",
       " 'channels': 512,\n",
       " 'dropout_ratio': 0.1,\n",
       " 'num_classes': 10,\n",
       " 'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       " 'align_corners': False,\n",
       " 'loss_decode': {'type': 'CrossEntropyLoss',\n",
       "  'use_sigmoid': False,\n",
       "  'loss_weight': 1.0},\n",
       " 'init_cfg': {'type': 'Pretrained',\n",
       "  'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model.decode_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b9828a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:13.189458Z",
     "iopub.status.busy": "2024-05-09T06:08:13.189156Z",
     "iopub.status.idle": "2024-05-09T06:08:14.533233Z",
     "shell.execute_reply": "2024-05-09T06:08:14.532451Z"
    },
    "papermill": {
     "duration": 1.397216,
     "end_time": "2024-05-09T06:08:14.535633",
     "exception": false,
     "start_time": "2024-05-09T06:08:13.138417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.dump('/kaggle/working/my_config_file.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c955dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:14.639392Z",
     "iopub.status.busy": "2024-05-09T06:08:14.638692Z",
     "iopub.status.idle": "2024-05-09T06:08:14.644967Z",
     "shell.execute_reply": "2024-05-09T06:08:14.644078Z"
    },
    "papermill": {
     "duration": 0.060005,
     "end_time": "2024-05-09T06:08:14.646869",
     "exception": false,
     "start_time": "2024-05-09T06:08:14.586864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Pretrained',\n",
       " 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model['backbone'].pop('init_cfg', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3eca5456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:14.749159Z",
     "iopub.status.busy": "2024-05-09T06:08:14.748879Z",
     "iopub.status.idle": "2024-05-09T06:08:14.754379Z",
     "shell.execute_reply": "2024-05-09T06:08:14.753539Z"
    },
    "papermill": {
     "duration": 0.059461,
     "end_time": "2024-05-09T06:08:14.756280",
     "exception": false,
     "start_time": "2024-05-09T06:08:14.696819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ade/ADEChallengeData2016'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train_dataloader['dataset']['data_root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7a7540d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:14.859952Z",
     "iopub.status.busy": "2024-05-09T06:08:14.859215Z",
     "iopub.status.idle": "2024-05-09T06:08:14.865994Z",
     "shell.execute_reply": "2024-05-09T06:08:14.865165Z"
    },
    "papermill": {
     "duration": 0.059495,
     "end_time": "2024-05-09T06:08:14.868044",
     "exception": false,
     "start_time": "2024-05-09T06:08:14.808549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_path= '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
    "cfg.train_dataloader['dataset']['data_root'] = new_path\n",
    "cfg.test_dataloader['dataset']['data_root'] = new_path\n",
    "cfg.val_dataloader['dataset']['data_root'] = new_path\n",
    "\n",
    "\n",
    "cfg.train_dataloader['dataset']['data_root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9aad01a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:14.968981Z",
     "iopub.status.busy": "2024-05-09T06:08:14.968311Z",
     "iopub.status.idle": "2024-05-09T06:08:14.974299Z",
     "shell.execute_reply": "2024-05-09T06:08:14.973439Z"
    },
    "papermill": {
     "duration": 0.058238,
     "end_time": "2024-05-09T06:08:14.976168",
     "exception": false,
     "start_time": "2024-05-09T06:08:14.917930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78f38b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:15.200961Z",
     "iopub.status.busy": "2024-05-09T06:08:15.200477Z",
     "iopub.status.idle": "2024-05-09T06:08:25.239913Z",
     "shell.execute_reply": "2024-05-09T06:08:25.239014Z"
    },
    "papermill": {
     "duration": 10.106152,
     "end_time": "2024-05-09T06:08:25.242513",
     "exception": false,
     "start_time": "2024-05-09T06:08:15.136361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 06:08:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 0\n",
      "    GPU 0: Tesla P100-PCIE-16GB\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "    GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "    PyTorch: 1.12.0+cu102\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.2\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.5\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.2, CUDNN_VERSION=7.6.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.13.0+cu102\n",
      "    OpenCV: 4.9.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 0\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/09 06:08:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "backbone_norm_cfg = dict(requires_grad=True, type='LN')\n",
      "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData'\n",
      "dataset_type = 'ImageSegmentationDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=16000,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=None,\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        attn_drop_rate=0.0,\n",
      "        depths=[\n",
      "            2,\n",
      "            2,\n",
      "            18,\n",
      "            2,\n",
      "        ],\n",
      "        drop_path_rate=0.3,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=128,\n",
      "        mlp_ratio=4,\n",
      "        norm_cfg=dict(requires_grad=True, type='LN'),\n",
      "        num_heads=[\n",
      "            4,\n",
      "            8,\n",
      "            16,\n",
      "            32,\n",
      "        ],\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ),\n",
      "        patch_norm=True,\n",
      "        patch_size=4,\n",
      "        pretrain_img_size=384,\n",
      "        qk_scale=None,\n",
      "        qkv_bias=True,\n",
      "        strides=(\n",
      "            4,\n",
      "            2,\n",
      "            2,\n",
      "            2,\n",
      "        ),\n",
      "        type='SwinTransformer',\n",
      "        use_abs_pos_embed=False,\n",
      "        window_size=12),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        in_channels=[\n",
      "            128,\n",
      "            256,\n",
      "            512,\n",
      "            1024,\n",
      "        ],\n",
      "        in_index=[\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth',\n",
      "            type='Pretrained'),\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=10,\n",
      "        type='SegformerHead'),\n",
      "    pretrained=\n",
      "    'https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K_20210531_132020-05b22ea4.pth',\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=57000, type='IterBasedTrainLoop', val_interval=3000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/training', seg_map_path='annotations/training'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/validation',\n",
      "            seg_map_path='annotations/validation'),\n",
      "        data_root=\n",
      "        '/kaggle/input/samplezip/content/drive/MyDrive/Thesis_Code_msee/FloodNet_myData',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                512,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='ImageSegmentationDataset'),\n",
      "    num_workers=1,\n",
      "    persistent_workers=False,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/kaggle/working/checkpoint'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmsegmentation/mmseg/models/backbones/swin.py:556: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n",
      "/kaggle/working/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 06:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "05/09 06:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import Runner\n",
    "runner = Runner.from_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bee4046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T06:08:25.361723Z",
     "iopub.status.busy": "2024-05-09T06:08:25.361103Z",
     "iopub.status.idle": "2024-05-09T16:19:39.401635Z",
     "shell.execute_reply": "2024-05-09T16:19:39.400584Z"
    },
    "papermill": {
     "duration": 36674.1014,
     "end_time": "2024-05-09T16:19:39.403953",
     "exception": false,
     "start_time": "2024-05-09T06:08:25.302553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmsegmentation/mmseg/datasets/transforms/loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm0.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm1.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm2.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.weight:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.weight:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.weight:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.bias:lr=6e-05\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.bias:weight_decay=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.norm3.bias:decay_mult=0.0\n",
      "05/09 06:08:27 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K_20210531_132020-05b22ea4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K_20210531_132020-05b22ea4.pth\" to /root/.cache/torch/hub/checkpoints/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K_20210531_132020-05b22ea4.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 06:09:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n",
      "05/09 06:09:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\" to /root/.cache/torch/hub/checkpoints/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 06:10:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.layers.0.0.projection.weight, backbone.layers.0.0.projection.bias, backbone.layers.0.0.norm.weight, backbone.layers.0.0.norm.bias, backbone.layers.0.1.0.norm1.weight, backbone.layers.0.1.0.norm1.bias, backbone.layers.0.1.0.attn.attn.in_proj_weight, backbone.layers.0.1.0.attn.attn.in_proj_bias, backbone.layers.0.1.0.attn.attn.out_proj.weight, backbone.layers.0.1.0.attn.attn.out_proj.bias, backbone.layers.0.1.0.attn.sr.weight, backbone.layers.0.1.0.attn.sr.bias, backbone.layers.0.1.0.attn.norm.weight, backbone.layers.0.1.0.attn.norm.bias, backbone.layers.0.1.0.norm2.weight, backbone.layers.0.1.0.norm2.bias, backbone.layers.0.1.0.ffn.layers.0.weight, backbone.layers.0.1.0.ffn.layers.0.bias, backbone.layers.0.1.0.ffn.layers.1.weight, backbone.layers.0.1.0.ffn.layers.1.bias, backbone.layers.0.1.0.ffn.layers.4.weight, backbone.layers.0.1.0.ffn.layers.4.bias, backbone.layers.0.1.1.norm1.weight, backbone.layers.0.1.1.norm1.bias, backbone.layers.0.1.1.attn.attn.in_proj_weight, backbone.layers.0.1.1.attn.attn.in_proj_bias, backbone.layers.0.1.1.attn.attn.out_proj.weight, backbone.layers.0.1.1.attn.attn.out_proj.bias, backbone.layers.0.1.1.attn.sr.weight, backbone.layers.0.1.1.attn.sr.bias, backbone.layers.0.1.1.attn.norm.weight, backbone.layers.0.1.1.attn.norm.bias, backbone.layers.0.1.1.norm2.weight, backbone.layers.0.1.1.norm2.bias, backbone.layers.0.1.1.ffn.layers.0.weight, backbone.layers.0.1.1.ffn.layers.0.bias, backbone.layers.0.1.1.ffn.layers.1.weight, backbone.layers.0.1.1.ffn.layers.1.bias, backbone.layers.0.1.1.ffn.layers.4.weight, backbone.layers.0.1.1.ffn.layers.4.bias, backbone.layers.0.1.2.norm1.weight, backbone.layers.0.1.2.norm1.bias, backbone.layers.0.1.2.attn.attn.in_proj_weight, backbone.layers.0.1.2.attn.attn.in_proj_bias, backbone.layers.0.1.2.attn.attn.out_proj.weight, backbone.layers.0.1.2.attn.attn.out_proj.bias, backbone.layers.0.1.2.attn.sr.weight, backbone.layers.0.1.2.attn.sr.bias, backbone.layers.0.1.2.attn.norm.weight, backbone.layers.0.1.2.attn.norm.bias, backbone.layers.0.1.2.norm2.weight, backbone.layers.0.1.2.norm2.bias, backbone.layers.0.1.2.ffn.layers.0.weight, backbone.layers.0.1.2.ffn.layers.0.bias, backbone.layers.0.1.2.ffn.layers.1.weight, backbone.layers.0.1.2.ffn.layers.1.bias, backbone.layers.0.1.2.ffn.layers.4.weight, backbone.layers.0.1.2.ffn.layers.4.bias, backbone.layers.0.2.weight, backbone.layers.0.2.bias, backbone.layers.1.0.projection.weight, backbone.layers.1.0.projection.bias, backbone.layers.1.0.norm.weight, backbone.layers.1.0.norm.bias, backbone.layers.1.1.0.norm1.weight, backbone.layers.1.1.0.norm1.bias, backbone.layers.1.1.0.attn.attn.in_proj_weight, backbone.layers.1.1.0.attn.attn.in_proj_bias, backbone.layers.1.1.0.attn.attn.out_proj.weight, backbone.layers.1.1.0.attn.attn.out_proj.bias, backbone.layers.1.1.0.attn.sr.weight, backbone.layers.1.1.0.attn.sr.bias, backbone.layers.1.1.0.attn.norm.weight, backbone.layers.1.1.0.attn.norm.bias, backbone.layers.1.1.0.norm2.weight, backbone.layers.1.1.0.norm2.bias, backbone.layers.1.1.0.ffn.layers.0.weight, backbone.layers.1.1.0.ffn.layers.0.bias, backbone.layers.1.1.0.ffn.layers.1.weight, backbone.layers.1.1.0.ffn.layers.1.bias, backbone.layers.1.1.0.ffn.layers.4.weight, backbone.layers.1.1.0.ffn.layers.4.bias, backbone.layers.1.1.1.norm1.weight, backbone.layers.1.1.1.norm1.bias, backbone.layers.1.1.1.attn.attn.in_proj_weight, backbone.layers.1.1.1.attn.attn.in_proj_bias, backbone.layers.1.1.1.attn.attn.out_proj.weight, backbone.layers.1.1.1.attn.attn.out_proj.bias, backbone.layers.1.1.1.attn.sr.weight, backbone.layers.1.1.1.attn.sr.bias, backbone.layers.1.1.1.attn.norm.weight, backbone.layers.1.1.1.attn.norm.bias, backbone.layers.1.1.1.norm2.weight, backbone.layers.1.1.1.norm2.bias, backbone.layers.1.1.1.ffn.layers.0.weight, backbone.layers.1.1.1.ffn.layers.0.bias, backbone.layers.1.1.1.ffn.layers.1.weight, backbone.layers.1.1.1.ffn.layers.1.bias, backbone.layers.1.1.1.ffn.layers.4.weight, backbone.layers.1.1.1.ffn.layers.4.bias, backbone.layers.1.1.2.norm1.weight, backbone.layers.1.1.2.norm1.bias, backbone.layers.1.1.2.attn.attn.in_proj_weight, backbone.layers.1.1.2.attn.attn.in_proj_bias, backbone.layers.1.1.2.attn.attn.out_proj.weight, backbone.layers.1.1.2.attn.attn.out_proj.bias, backbone.layers.1.1.2.attn.sr.weight, backbone.layers.1.1.2.attn.sr.bias, backbone.layers.1.1.2.attn.norm.weight, backbone.layers.1.1.2.attn.norm.bias, backbone.layers.1.1.2.norm2.weight, backbone.layers.1.1.2.norm2.bias, backbone.layers.1.1.2.ffn.layers.0.weight, backbone.layers.1.1.2.ffn.layers.0.bias, backbone.layers.1.1.2.ffn.layers.1.weight, backbone.layers.1.1.2.ffn.layers.1.bias, backbone.layers.1.1.2.ffn.layers.4.weight, backbone.layers.1.1.2.ffn.layers.4.bias, backbone.layers.1.1.3.norm1.weight, backbone.layers.1.1.3.norm1.bias, backbone.layers.1.1.3.attn.attn.in_proj_weight, backbone.layers.1.1.3.attn.attn.in_proj_bias, backbone.layers.1.1.3.attn.attn.out_proj.weight, backbone.layers.1.1.3.attn.attn.out_proj.bias, backbone.layers.1.1.3.attn.sr.weight, backbone.layers.1.1.3.attn.sr.bias, backbone.layers.1.1.3.attn.norm.weight, backbone.layers.1.1.3.attn.norm.bias, backbone.layers.1.1.3.norm2.weight, backbone.layers.1.1.3.norm2.bias, backbone.layers.1.1.3.ffn.layers.0.weight, backbone.layers.1.1.3.ffn.layers.0.bias, backbone.layers.1.1.3.ffn.layers.1.weight, backbone.layers.1.1.3.ffn.layers.1.bias, backbone.layers.1.1.3.ffn.layers.4.weight, backbone.layers.1.1.3.ffn.layers.4.bias, backbone.layers.1.1.4.norm1.weight, backbone.layers.1.1.4.norm1.bias, backbone.layers.1.1.4.attn.attn.in_proj_weight, backbone.layers.1.1.4.attn.attn.in_proj_bias, backbone.layers.1.1.4.attn.attn.out_proj.weight, backbone.layers.1.1.4.attn.attn.out_proj.bias, backbone.layers.1.1.4.attn.sr.weight, backbone.layers.1.1.4.attn.sr.bias, backbone.layers.1.1.4.attn.norm.weight, backbone.layers.1.1.4.attn.norm.bias, backbone.layers.1.1.4.norm2.weight, backbone.layers.1.1.4.norm2.bias, backbone.layers.1.1.4.ffn.layers.0.weight, backbone.layers.1.1.4.ffn.layers.0.bias, backbone.layers.1.1.4.ffn.layers.1.weight, backbone.layers.1.1.4.ffn.layers.1.bias, backbone.layers.1.1.4.ffn.layers.4.weight, backbone.layers.1.1.4.ffn.layers.4.bias, backbone.layers.1.1.5.norm1.weight, backbone.layers.1.1.5.norm1.bias, backbone.layers.1.1.5.attn.attn.in_proj_weight, backbone.layers.1.1.5.attn.attn.in_proj_bias, backbone.layers.1.1.5.attn.attn.out_proj.weight, backbone.layers.1.1.5.attn.attn.out_proj.bias, backbone.layers.1.1.5.attn.sr.weight, backbone.layers.1.1.5.attn.sr.bias, backbone.layers.1.1.5.attn.norm.weight, backbone.layers.1.1.5.attn.norm.bias, backbone.layers.1.1.5.norm2.weight, backbone.layers.1.1.5.norm2.bias, backbone.layers.1.1.5.ffn.layers.0.weight, backbone.layers.1.1.5.ffn.layers.0.bias, backbone.layers.1.1.5.ffn.layers.1.weight, backbone.layers.1.1.5.ffn.layers.1.bias, backbone.layers.1.1.5.ffn.layers.4.weight, backbone.layers.1.1.5.ffn.layers.4.bias, backbone.layers.1.2.weight, backbone.layers.1.2.bias, backbone.layers.2.0.projection.weight, backbone.layers.2.0.projection.bias, backbone.layers.2.0.norm.weight, backbone.layers.2.0.norm.bias, backbone.layers.2.1.0.norm1.weight, backbone.layers.2.1.0.norm1.bias, backbone.layers.2.1.0.attn.attn.in_proj_weight, backbone.layers.2.1.0.attn.attn.in_proj_bias, backbone.layers.2.1.0.attn.attn.out_proj.weight, backbone.layers.2.1.0.attn.attn.out_proj.bias, backbone.layers.2.1.0.attn.sr.weight, backbone.layers.2.1.0.attn.sr.bias, backbone.layers.2.1.0.attn.norm.weight, backbone.layers.2.1.0.attn.norm.bias, backbone.layers.2.1.0.norm2.weight, backbone.layers.2.1.0.norm2.bias, backbone.layers.2.1.0.ffn.layers.0.weight, backbone.layers.2.1.0.ffn.layers.0.bias, backbone.layers.2.1.0.ffn.layers.1.weight, backbone.layers.2.1.0.ffn.layers.1.bias, backbone.layers.2.1.0.ffn.layers.4.weight, backbone.layers.2.1.0.ffn.layers.4.bias, backbone.layers.2.1.1.norm1.weight, backbone.layers.2.1.1.norm1.bias, backbone.layers.2.1.1.attn.attn.in_proj_weight, backbone.layers.2.1.1.attn.attn.in_proj_bias, backbone.layers.2.1.1.attn.attn.out_proj.weight, backbone.layers.2.1.1.attn.attn.out_proj.bias, backbone.layers.2.1.1.attn.sr.weight, backbone.layers.2.1.1.attn.sr.bias, backbone.layers.2.1.1.attn.norm.weight, backbone.layers.2.1.1.attn.norm.bias, backbone.layers.2.1.1.norm2.weight, backbone.layers.2.1.1.norm2.bias, backbone.layers.2.1.1.ffn.layers.0.weight, backbone.layers.2.1.1.ffn.layers.0.bias, backbone.layers.2.1.1.ffn.layers.1.weight, backbone.layers.2.1.1.ffn.layers.1.bias, backbone.layers.2.1.1.ffn.layers.4.weight, backbone.layers.2.1.1.ffn.layers.4.bias, backbone.layers.2.1.2.norm1.weight, backbone.layers.2.1.2.norm1.bias, backbone.layers.2.1.2.attn.attn.in_proj_weight, backbone.layers.2.1.2.attn.attn.in_proj_bias, backbone.layers.2.1.2.attn.attn.out_proj.weight, backbone.layers.2.1.2.attn.attn.out_proj.bias, backbone.layers.2.1.2.attn.sr.weight, backbone.layers.2.1.2.attn.sr.bias, backbone.layers.2.1.2.attn.norm.weight, backbone.layers.2.1.2.attn.norm.bias, backbone.layers.2.1.2.norm2.weight, backbone.layers.2.1.2.norm2.bias, backbone.layers.2.1.2.ffn.layers.0.weight, backbone.layers.2.1.2.ffn.layers.0.bias, backbone.layers.2.1.2.ffn.layers.1.weight, backbone.layers.2.1.2.ffn.layers.1.bias, backbone.layers.2.1.2.ffn.layers.4.weight, backbone.layers.2.1.2.ffn.layers.4.bias, backbone.layers.2.1.3.norm1.weight, backbone.layers.2.1.3.norm1.bias, backbone.layers.2.1.3.attn.attn.in_proj_weight, backbone.layers.2.1.3.attn.attn.in_proj_bias, backbone.layers.2.1.3.attn.attn.out_proj.weight, backbone.layers.2.1.3.attn.attn.out_proj.bias, backbone.layers.2.1.3.attn.sr.weight, backbone.layers.2.1.3.attn.sr.bias, backbone.layers.2.1.3.attn.norm.weight, backbone.layers.2.1.3.attn.norm.bias, backbone.layers.2.1.3.norm2.weight, backbone.layers.2.1.3.norm2.bias, backbone.layers.2.1.3.ffn.layers.0.weight, backbone.layers.2.1.3.ffn.layers.0.bias, backbone.layers.2.1.3.ffn.layers.1.weight, backbone.layers.2.1.3.ffn.layers.1.bias, backbone.layers.2.1.3.ffn.layers.4.weight, backbone.layers.2.1.3.ffn.layers.4.bias, backbone.layers.2.1.4.norm1.weight, backbone.layers.2.1.4.norm1.bias, backbone.layers.2.1.4.attn.attn.in_proj_weight, backbone.layers.2.1.4.attn.attn.in_proj_bias, backbone.layers.2.1.4.attn.attn.out_proj.weight, backbone.layers.2.1.4.attn.attn.out_proj.bias, backbone.layers.2.1.4.attn.sr.weight, backbone.layers.2.1.4.attn.sr.bias, backbone.layers.2.1.4.attn.norm.weight, backbone.layers.2.1.4.attn.norm.bias, backbone.layers.2.1.4.norm2.weight, backbone.layers.2.1.4.norm2.bias, backbone.layers.2.1.4.ffn.layers.0.weight, backbone.layers.2.1.4.ffn.layers.0.bias, backbone.layers.2.1.4.ffn.layers.1.weight, backbone.layers.2.1.4.ffn.layers.1.bias, backbone.layers.2.1.4.ffn.layers.4.weight, backbone.layers.2.1.4.ffn.layers.4.bias, backbone.layers.2.1.5.norm1.weight, backbone.layers.2.1.5.norm1.bias, backbone.layers.2.1.5.attn.attn.in_proj_weight, backbone.layers.2.1.5.attn.attn.in_proj_bias, backbone.layers.2.1.5.attn.attn.out_proj.weight, backbone.layers.2.1.5.attn.attn.out_proj.bias, backbone.layers.2.1.5.attn.sr.weight, backbone.layers.2.1.5.attn.sr.bias, backbone.layers.2.1.5.attn.norm.weight, backbone.layers.2.1.5.attn.norm.bias, backbone.layers.2.1.5.norm2.weight, backbone.layers.2.1.5.norm2.bias, backbone.layers.2.1.5.ffn.layers.0.weight, backbone.layers.2.1.5.ffn.layers.0.bias, backbone.layers.2.1.5.ffn.layers.1.weight, backbone.layers.2.1.5.ffn.layers.1.bias, backbone.layers.2.1.5.ffn.layers.4.weight, backbone.layers.2.1.5.ffn.layers.4.bias, backbone.layers.2.1.6.norm1.weight, backbone.layers.2.1.6.norm1.bias, backbone.layers.2.1.6.attn.attn.in_proj_weight, backbone.layers.2.1.6.attn.attn.in_proj_bias, backbone.layers.2.1.6.attn.attn.out_proj.weight, backbone.layers.2.1.6.attn.attn.out_proj.bias, backbone.layers.2.1.6.attn.sr.weight, backbone.layers.2.1.6.attn.sr.bias, backbone.layers.2.1.6.attn.norm.weight, backbone.layers.2.1.6.attn.norm.bias, backbone.layers.2.1.6.norm2.weight, backbone.layers.2.1.6.norm2.bias, backbone.layers.2.1.6.ffn.layers.0.weight, backbone.layers.2.1.6.ffn.layers.0.bias, backbone.layers.2.1.6.ffn.layers.1.weight, backbone.layers.2.1.6.ffn.layers.1.bias, backbone.layers.2.1.6.ffn.layers.4.weight, backbone.layers.2.1.6.ffn.layers.4.bias, backbone.layers.2.1.7.norm1.weight, backbone.layers.2.1.7.norm1.bias, backbone.layers.2.1.7.attn.attn.in_proj_weight, backbone.layers.2.1.7.attn.attn.in_proj_bias, backbone.layers.2.1.7.attn.attn.out_proj.weight, backbone.layers.2.1.7.attn.attn.out_proj.bias, backbone.layers.2.1.7.attn.sr.weight, backbone.layers.2.1.7.attn.sr.bias, backbone.layers.2.1.7.attn.norm.weight, backbone.layers.2.1.7.attn.norm.bias, backbone.layers.2.1.7.norm2.weight, backbone.layers.2.1.7.norm2.bias, backbone.layers.2.1.7.ffn.layers.0.weight, backbone.layers.2.1.7.ffn.layers.0.bias, backbone.layers.2.1.7.ffn.layers.1.weight, backbone.layers.2.1.7.ffn.layers.1.bias, backbone.layers.2.1.7.ffn.layers.4.weight, backbone.layers.2.1.7.ffn.layers.4.bias, backbone.layers.2.1.8.norm1.weight, backbone.layers.2.1.8.norm1.bias, backbone.layers.2.1.8.attn.attn.in_proj_weight, backbone.layers.2.1.8.attn.attn.in_proj_bias, backbone.layers.2.1.8.attn.attn.out_proj.weight, backbone.layers.2.1.8.attn.attn.out_proj.bias, backbone.layers.2.1.8.attn.sr.weight, backbone.layers.2.1.8.attn.sr.bias, backbone.layers.2.1.8.attn.norm.weight, backbone.layers.2.1.8.attn.norm.bias, backbone.layers.2.1.8.norm2.weight, backbone.layers.2.1.8.norm2.bias, backbone.layers.2.1.8.ffn.layers.0.weight, backbone.layers.2.1.8.ffn.layers.0.bias, backbone.layers.2.1.8.ffn.layers.1.weight, backbone.layers.2.1.8.ffn.layers.1.bias, backbone.layers.2.1.8.ffn.layers.4.weight, backbone.layers.2.1.8.ffn.layers.4.bias, backbone.layers.2.1.9.norm1.weight, backbone.layers.2.1.9.norm1.bias, backbone.layers.2.1.9.attn.attn.in_proj_weight, backbone.layers.2.1.9.attn.attn.in_proj_bias, backbone.layers.2.1.9.attn.attn.out_proj.weight, backbone.layers.2.1.9.attn.attn.out_proj.bias, backbone.layers.2.1.9.attn.sr.weight, backbone.layers.2.1.9.attn.sr.bias, backbone.layers.2.1.9.attn.norm.weight, backbone.layers.2.1.9.attn.norm.bias, backbone.layers.2.1.9.norm2.weight, backbone.layers.2.1.9.norm2.bias, backbone.layers.2.1.9.ffn.layers.0.weight, backbone.layers.2.1.9.ffn.layers.0.bias, backbone.layers.2.1.9.ffn.layers.1.weight, backbone.layers.2.1.9.ffn.layers.1.bias, backbone.layers.2.1.9.ffn.layers.4.weight, backbone.layers.2.1.9.ffn.layers.4.bias, backbone.layers.2.1.10.norm1.weight, backbone.layers.2.1.10.norm1.bias, backbone.layers.2.1.10.attn.attn.in_proj_weight, backbone.layers.2.1.10.attn.attn.in_proj_bias, backbone.layers.2.1.10.attn.attn.out_proj.weight, backbone.layers.2.1.10.attn.attn.out_proj.bias, backbone.layers.2.1.10.attn.sr.weight, backbone.layers.2.1.10.attn.sr.bias, backbone.layers.2.1.10.attn.norm.weight, backbone.layers.2.1.10.attn.norm.bias, backbone.layers.2.1.10.norm2.weight, backbone.layers.2.1.10.norm2.bias, backbone.layers.2.1.10.ffn.layers.0.weight, backbone.layers.2.1.10.ffn.layers.0.bias, backbone.layers.2.1.10.ffn.layers.1.weight, backbone.layers.2.1.10.ffn.layers.1.bias, backbone.layers.2.1.10.ffn.layers.4.weight, backbone.layers.2.1.10.ffn.layers.4.bias, backbone.layers.2.1.11.norm1.weight, backbone.layers.2.1.11.norm1.bias, backbone.layers.2.1.11.attn.attn.in_proj_weight, backbone.layers.2.1.11.attn.attn.in_proj_bias, backbone.layers.2.1.11.attn.attn.out_proj.weight, backbone.layers.2.1.11.attn.attn.out_proj.bias, backbone.layers.2.1.11.attn.sr.weight, backbone.layers.2.1.11.attn.sr.bias, backbone.layers.2.1.11.attn.norm.weight, backbone.layers.2.1.11.attn.norm.bias, backbone.layers.2.1.11.norm2.weight, backbone.layers.2.1.11.norm2.bias, backbone.layers.2.1.11.ffn.layers.0.weight, backbone.layers.2.1.11.ffn.layers.0.bias, backbone.layers.2.1.11.ffn.layers.1.weight, backbone.layers.2.1.11.ffn.layers.1.bias, backbone.layers.2.1.11.ffn.layers.4.weight, backbone.layers.2.1.11.ffn.layers.4.bias, backbone.layers.2.1.12.norm1.weight, backbone.layers.2.1.12.norm1.bias, backbone.layers.2.1.12.attn.attn.in_proj_weight, backbone.layers.2.1.12.attn.attn.in_proj_bias, backbone.layers.2.1.12.attn.attn.out_proj.weight, backbone.layers.2.1.12.attn.attn.out_proj.bias, backbone.layers.2.1.12.attn.sr.weight, backbone.layers.2.1.12.attn.sr.bias, backbone.layers.2.1.12.attn.norm.weight, backbone.layers.2.1.12.attn.norm.bias, backbone.layers.2.1.12.norm2.weight, backbone.layers.2.1.12.norm2.bias, backbone.layers.2.1.12.ffn.layers.0.weight, backbone.layers.2.1.12.ffn.layers.0.bias, backbone.layers.2.1.12.ffn.layers.1.weight, backbone.layers.2.1.12.ffn.layers.1.bias, backbone.layers.2.1.12.ffn.layers.4.weight, backbone.layers.2.1.12.ffn.layers.4.bias, backbone.layers.2.1.13.norm1.weight, backbone.layers.2.1.13.norm1.bias, backbone.layers.2.1.13.attn.attn.in_proj_weight, backbone.layers.2.1.13.attn.attn.in_proj_bias, backbone.layers.2.1.13.attn.attn.out_proj.weight, backbone.layers.2.1.13.attn.attn.out_proj.bias, backbone.layers.2.1.13.attn.sr.weight, backbone.layers.2.1.13.attn.sr.bias, backbone.layers.2.1.13.attn.norm.weight, backbone.layers.2.1.13.attn.norm.bias, backbone.layers.2.1.13.norm2.weight, backbone.layers.2.1.13.norm2.bias, backbone.layers.2.1.13.ffn.layers.0.weight, backbone.layers.2.1.13.ffn.layers.0.bias, backbone.layers.2.1.13.ffn.layers.1.weight, backbone.layers.2.1.13.ffn.layers.1.bias, backbone.layers.2.1.13.ffn.layers.4.weight, backbone.layers.2.1.13.ffn.layers.4.bias, backbone.layers.2.1.14.norm1.weight, backbone.layers.2.1.14.norm1.bias, backbone.layers.2.1.14.attn.attn.in_proj_weight, backbone.layers.2.1.14.attn.attn.in_proj_bias, backbone.layers.2.1.14.attn.attn.out_proj.weight, backbone.layers.2.1.14.attn.attn.out_proj.bias, backbone.layers.2.1.14.attn.sr.weight, backbone.layers.2.1.14.attn.sr.bias, backbone.layers.2.1.14.attn.norm.weight, backbone.layers.2.1.14.attn.norm.bias, backbone.layers.2.1.14.norm2.weight, backbone.layers.2.1.14.norm2.bias, backbone.layers.2.1.14.ffn.layers.0.weight, backbone.layers.2.1.14.ffn.layers.0.bias, backbone.layers.2.1.14.ffn.layers.1.weight, backbone.layers.2.1.14.ffn.layers.1.bias, backbone.layers.2.1.14.ffn.layers.4.weight, backbone.layers.2.1.14.ffn.layers.4.bias, backbone.layers.2.1.15.norm1.weight, backbone.layers.2.1.15.norm1.bias, backbone.layers.2.1.15.attn.attn.in_proj_weight, backbone.layers.2.1.15.attn.attn.in_proj_bias, backbone.layers.2.1.15.attn.attn.out_proj.weight, backbone.layers.2.1.15.attn.attn.out_proj.bias, backbone.layers.2.1.15.attn.sr.weight, backbone.layers.2.1.15.attn.sr.bias, backbone.layers.2.1.15.attn.norm.weight, backbone.layers.2.1.15.attn.norm.bias, backbone.layers.2.1.15.norm2.weight, backbone.layers.2.1.15.norm2.bias, backbone.layers.2.1.15.ffn.layers.0.weight, backbone.layers.2.1.15.ffn.layers.0.bias, backbone.layers.2.1.15.ffn.layers.1.weight, backbone.layers.2.1.15.ffn.layers.1.bias, backbone.layers.2.1.15.ffn.layers.4.weight, backbone.layers.2.1.15.ffn.layers.4.bias, backbone.layers.2.1.16.norm1.weight, backbone.layers.2.1.16.norm1.bias, backbone.layers.2.1.16.attn.attn.in_proj_weight, backbone.layers.2.1.16.attn.attn.in_proj_bias, backbone.layers.2.1.16.attn.attn.out_proj.weight, backbone.layers.2.1.16.attn.attn.out_proj.bias, backbone.layers.2.1.16.attn.sr.weight, backbone.layers.2.1.16.attn.sr.bias, backbone.layers.2.1.16.attn.norm.weight, backbone.layers.2.1.16.attn.norm.bias, backbone.layers.2.1.16.norm2.weight, backbone.layers.2.1.16.norm2.bias, backbone.layers.2.1.16.ffn.layers.0.weight, backbone.layers.2.1.16.ffn.layers.0.bias, backbone.layers.2.1.16.ffn.layers.1.weight, backbone.layers.2.1.16.ffn.layers.1.bias, backbone.layers.2.1.16.ffn.layers.4.weight, backbone.layers.2.1.16.ffn.layers.4.bias, backbone.layers.2.1.17.norm1.weight, backbone.layers.2.1.17.norm1.bias, backbone.layers.2.1.17.attn.attn.in_proj_weight, backbone.layers.2.1.17.attn.attn.in_proj_bias, backbone.layers.2.1.17.attn.attn.out_proj.weight, backbone.layers.2.1.17.attn.attn.out_proj.bias, backbone.layers.2.1.17.attn.sr.weight, backbone.layers.2.1.17.attn.sr.bias, backbone.layers.2.1.17.attn.norm.weight, backbone.layers.2.1.17.attn.norm.bias, backbone.layers.2.1.17.norm2.weight, backbone.layers.2.1.17.norm2.bias, backbone.layers.2.1.17.ffn.layers.0.weight, backbone.layers.2.1.17.ffn.layers.0.bias, backbone.layers.2.1.17.ffn.layers.1.weight, backbone.layers.2.1.17.ffn.layers.1.bias, backbone.layers.2.1.17.ffn.layers.4.weight, backbone.layers.2.1.17.ffn.layers.4.bias, backbone.layers.2.1.18.norm1.weight, backbone.layers.2.1.18.norm1.bias, backbone.layers.2.1.18.attn.attn.in_proj_weight, backbone.layers.2.1.18.attn.attn.in_proj_bias, backbone.layers.2.1.18.attn.attn.out_proj.weight, backbone.layers.2.1.18.attn.attn.out_proj.bias, backbone.layers.2.1.18.attn.sr.weight, backbone.layers.2.1.18.attn.sr.bias, backbone.layers.2.1.18.attn.norm.weight, backbone.layers.2.1.18.attn.norm.bias, backbone.layers.2.1.18.norm2.weight, backbone.layers.2.1.18.norm2.bias, backbone.layers.2.1.18.ffn.layers.0.weight, backbone.layers.2.1.18.ffn.layers.0.bias, backbone.layers.2.1.18.ffn.layers.1.weight, backbone.layers.2.1.18.ffn.layers.1.bias, backbone.layers.2.1.18.ffn.layers.4.weight, backbone.layers.2.1.18.ffn.layers.4.bias, backbone.layers.2.1.19.norm1.weight, backbone.layers.2.1.19.norm1.bias, backbone.layers.2.1.19.attn.attn.in_proj_weight, backbone.layers.2.1.19.attn.attn.in_proj_bias, backbone.layers.2.1.19.attn.attn.out_proj.weight, backbone.layers.2.1.19.attn.attn.out_proj.bias, backbone.layers.2.1.19.attn.sr.weight, backbone.layers.2.1.19.attn.sr.bias, backbone.layers.2.1.19.attn.norm.weight, backbone.layers.2.1.19.attn.norm.bias, backbone.layers.2.1.19.norm2.weight, backbone.layers.2.1.19.norm2.bias, backbone.layers.2.1.19.ffn.layers.0.weight, backbone.layers.2.1.19.ffn.layers.0.bias, backbone.layers.2.1.19.ffn.layers.1.weight, backbone.layers.2.1.19.ffn.layers.1.bias, backbone.layers.2.1.19.ffn.layers.4.weight, backbone.layers.2.1.19.ffn.layers.4.bias, backbone.layers.2.1.20.norm1.weight, backbone.layers.2.1.20.norm1.bias, backbone.layers.2.1.20.attn.attn.in_proj_weight, backbone.layers.2.1.20.attn.attn.in_proj_bias, backbone.layers.2.1.20.attn.attn.out_proj.weight, backbone.layers.2.1.20.attn.attn.out_proj.bias, backbone.layers.2.1.20.attn.sr.weight, backbone.layers.2.1.20.attn.sr.bias, backbone.layers.2.1.20.attn.norm.weight, backbone.layers.2.1.20.attn.norm.bias, backbone.layers.2.1.20.norm2.weight, backbone.layers.2.1.20.norm2.bias, backbone.layers.2.1.20.ffn.layers.0.weight, backbone.layers.2.1.20.ffn.layers.0.bias, backbone.layers.2.1.20.ffn.layers.1.weight, backbone.layers.2.1.20.ffn.layers.1.bias, backbone.layers.2.1.20.ffn.layers.4.weight, backbone.layers.2.1.20.ffn.layers.4.bias, backbone.layers.2.1.21.norm1.weight, backbone.layers.2.1.21.norm1.bias, backbone.layers.2.1.21.attn.attn.in_proj_weight, backbone.layers.2.1.21.attn.attn.in_proj_bias, backbone.layers.2.1.21.attn.attn.out_proj.weight, backbone.layers.2.1.21.attn.attn.out_proj.bias, backbone.layers.2.1.21.attn.sr.weight, backbone.layers.2.1.21.attn.sr.bias, backbone.layers.2.1.21.attn.norm.weight, backbone.layers.2.1.21.attn.norm.bias, backbone.layers.2.1.21.norm2.weight, backbone.layers.2.1.21.norm2.bias, backbone.layers.2.1.21.ffn.layers.0.weight, backbone.layers.2.1.21.ffn.layers.0.bias, backbone.layers.2.1.21.ffn.layers.1.weight, backbone.layers.2.1.21.ffn.layers.1.bias, backbone.layers.2.1.21.ffn.layers.4.weight, backbone.layers.2.1.21.ffn.layers.4.bias, backbone.layers.2.1.22.norm1.weight, backbone.layers.2.1.22.norm1.bias, backbone.layers.2.1.22.attn.attn.in_proj_weight, backbone.layers.2.1.22.attn.attn.in_proj_bias, backbone.layers.2.1.22.attn.attn.out_proj.weight, backbone.layers.2.1.22.attn.attn.out_proj.bias, backbone.layers.2.1.22.attn.sr.weight, backbone.layers.2.1.22.attn.sr.bias, backbone.layers.2.1.22.attn.norm.weight, backbone.layers.2.1.22.attn.norm.bias, backbone.layers.2.1.22.norm2.weight, backbone.layers.2.1.22.norm2.bias, backbone.layers.2.1.22.ffn.layers.0.weight, backbone.layers.2.1.22.ffn.layers.0.bias, backbone.layers.2.1.22.ffn.layers.1.weight, backbone.layers.2.1.22.ffn.layers.1.bias, backbone.layers.2.1.22.ffn.layers.4.weight, backbone.layers.2.1.22.ffn.layers.4.bias, backbone.layers.2.1.23.norm1.weight, backbone.layers.2.1.23.norm1.bias, backbone.layers.2.1.23.attn.attn.in_proj_weight, backbone.layers.2.1.23.attn.attn.in_proj_bias, backbone.layers.2.1.23.attn.attn.out_proj.weight, backbone.layers.2.1.23.attn.attn.out_proj.bias, backbone.layers.2.1.23.attn.sr.weight, backbone.layers.2.1.23.attn.sr.bias, backbone.layers.2.1.23.attn.norm.weight, backbone.layers.2.1.23.attn.norm.bias, backbone.layers.2.1.23.norm2.weight, backbone.layers.2.1.23.norm2.bias, backbone.layers.2.1.23.ffn.layers.0.weight, backbone.layers.2.1.23.ffn.layers.0.bias, backbone.layers.2.1.23.ffn.layers.1.weight, backbone.layers.2.1.23.ffn.layers.1.bias, backbone.layers.2.1.23.ffn.layers.4.weight, backbone.layers.2.1.23.ffn.layers.4.bias, backbone.layers.2.1.24.norm1.weight, backbone.layers.2.1.24.norm1.bias, backbone.layers.2.1.24.attn.attn.in_proj_weight, backbone.layers.2.1.24.attn.attn.in_proj_bias, backbone.layers.2.1.24.attn.attn.out_proj.weight, backbone.layers.2.1.24.attn.attn.out_proj.bias, backbone.layers.2.1.24.attn.sr.weight, backbone.layers.2.1.24.attn.sr.bias, backbone.layers.2.1.24.attn.norm.weight, backbone.layers.2.1.24.attn.norm.bias, backbone.layers.2.1.24.norm2.weight, backbone.layers.2.1.24.norm2.bias, backbone.layers.2.1.24.ffn.layers.0.weight, backbone.layers.2.1.24.ffn.layers.0.bias, backbone.layers.2.1.24.ffn.layers.1.weight, backbone.layers.2.1.24.ffn.layers.1.bias, backbone.layers.2.1.24.ffn.layers.4.weight, backbone.layers.2.1.24.ffn.layers.4.bias, backbone.layers.2.1.25.norm1.weight, backbone.layers.2.1.25.norm1.bias, backbone.layers.2.1.25.attn.attn.in_proj_weight, backbone.layers.2.1.25.attn.attn.in_proj_bias, backbone.layers.2.1.25.attn.attn.out_proj.weight, backbone.layers.2.1.25.attn.attn.out_proj.bias, backbone.layers.2.1.25.attn.sr.weight, backbone.layers.2.1.25.attn.sr.bias, backbone.layers.2.1.25.attn.norm.weight, backbone.layers.2.1.25.attn.norm.bias, backbone.layers.2.1.25.norm2.weight, backbone.layers.2.1.25.norm2.bias, backbone.layers.2.1.25.ffn.layers.0.weight, backbone.layers.2.1.25.ffn.layers.0.bias, backbone.layers.2.1.25.ffn.layers.1.weight, backbone.layers.2.1.25.ffn.layers.1.bias, backbone.layers.2.1.25.ffn.layers.4.weight, backbone.layers.2.1.25.ffn.layers.4.bias, backbone.layers.2.1.26.norm1.weight, backbone.layers.2.1.26.norm1.bias, backbone.layers.2.1.26.attn.attn.in_proj_weight, backbone.layers.2.1.26.attn.attn.in_proj_bias, backbone.layers.2.1.26.attn.attn.out_proj.weight, backbone.layers.2.1.26.attn.attn.out_proj.bias, backbone.layers.2.1.26.attn.sr.weight, backbone.layers.2.1.26.attn.sr.bias, backbone.layers.2.1.26.attn.norm.weight, backbone.layers.2.1.26.attn.norm.bias, backbone.layers.2.1.26.norm2.weight, backbone.layers.2.1.26.norm2.bias, backbone.layers.2.1.26.ffn.layers.0.weight, backbone.layers.2.1.26.ffn.layers.0.bias, backbone.layers.2.1.26.ffn.layers.1.weight, backbone.layers.2.1.26.ffn.layers.1.bias, backbone.layers.2.1.26.ffn.layers.4.weight, backbone.layers.2.1.26.ffn.layers.4.bias, backbone.layers.2.1.27.norm1.weight, backbone.layers.2.1.27.norm1.bias, backbone.layers.2.1.27.attn.attn.in_proj_weight, backbone.layers.2.1.27.attn.attn.in_proj_bias, backbone.layers.2.1.27.attn.attn.out_proj.weight, backbone.layers.2.1.27.attn.attn.out_proj.bias, backbone.layers.2.1.27.attn.sr.weight, backbone.layers.2.1.27.attn.sr.bias, backbone.layers.2.1.27.attn.norm.weight, backbone.layers.2.1.27.attn.norm.bias, backbone.layers.2.1.27.norm2.weight, backbone.layers.2.1.27.norm2.bias, backbone.layers.2.1.27.ffn.layers.0.weight, backbone.layers.2.1.27.ffn.layers.0.bias, backbone.layers.2.1.27.ffn.layers.1.weight, backbone.layers.2.1.27.ffn.layers.1.bias, backbone.layers.2.1.27.ffn.layers.4.weight, backbone.layers.2.1.27.ffn.layers.4.bias, backbone.layers.2.1.28.norm1.weight, backbone.layers.2.1.28.norm1.bias, backbone.layers.2.1.28.attn.attn.in_proj_weight, backbone.layers.2.1.28.attn.attn.in_proj_bias, backbone.layers.2.1.28.attn.attn.out_proj.weight, backbone.layers.2.1.28.attn.attn.out_proj.bias, backbone.layers.2.1.28.attn.sr.weight, backbone.layers.2.1.28.attn.sr.bias, backbone.layers.2.1.28.attn.norm.weight, backbone.layers.2.1.28.attn.norm.bias, backbone.layers.2.1.28.norm2.weight, backbone.layers.2.1.28.norm2.bias, backbone.layers.2.1.28.ffn.layers.0.weight, backbone.layers.2.1.28.ffn.layers.0.bias, backbone.layers.2.1.28.ffn.layers.1.weight, backbone.layers.2.1.28.ffn.layers.1.bias, backbone.layers.2.1.28.ffn.layers.4.weight, backbone.layers.2.1.28.ffn.layers.4.bias, backbone.layers.2.1.29.norm1.weight, backbone.layers.2.1.29.norm1.bias, backbone.layers.2.1.29.attn.attn.in_proj_weight, backbone.layers.2.1.29.attn.attn.in_proj_bias, backbone.layers.2.1.29.attn.attn.out_proj.weight, backbone.layers.2.1.29.attn.attn.out_proj.bias, backbone.layers.2.1.29.attn.sr.weight, backbone.layers.2.1.29.attn.sr.bias, backbone.layers.2.1.29.attn.norm.weight, backbone.layers.2.1.29.attn.norm.bias, backbone.layers.2.1.29.norm2.weight, backbone.layers.2.1.29.norm2.bias, backbone.layers.2.1.29.ffn.layers.0.weight, backbone.layers.2.1.29.ffn.layers.0.bias, backbone.layers.2.1.29.ffn.layers.1.weight, backbone.layers.2.1.29.ffn.layers.1.bias, backbone.layers.2.1.29.ffn.layers.4.weight, backbone.layers.2.1.29.ffn.layers.4.bias, backbone.layers.2.1.30.norm1.weight, backbone.layers.2.1.30.norm1.bias, backbone.layers.2.1.30.attn.attn.in_proj_weight, backbone.layers.2.1.30.attn.attn.in_proj_bias, backbone.layers.2.1.30.attn.attn.out_proj.weight, backbone.layers.2.1.30.attn.attn.out_proj.bias, backbone.layers.2.1.30.attn.sr.weight, backbone.layers.2.1.30.attn.sr.bias, backbone.layers.2.1.30.attn.norm.weight, backbone.layers.2.1.30.attn.norm.bias, backbone.layers.2.1.30.norm2.weight, backbone.layers.2.1.30.norm2.bias, backbone.layers.2.1.30.ffn.layers.0.weight, backbone.layers.2.1.30.ffn.layers.0.bias, backbone.layers.2.1.30.ffn.layers.1.weight, backbone.layers.2.1.30.ffn.layers.1.bias, backbone.layers.2.1.30.ffn.layers.4.weight, backbone.layers.2.1.30.ffn.layers.4.bias, backbone.layers.2.1.31.norm1.weight, backbone.layers.2.1.31.norm1.bias, backbone.layers.2.1.31.attn.attn.in_proj_weight, backbone.layers.2.1.31.attn.attn.in_proj_bias, backbone.layers.2.1.31.attn.attn.out_proj.weight, backbone.layers.2.1.31.attn.attn.out_proj.bias, backbone.layers.2.1.31.attn.sr.weight, backbone.layers.2.1.31.attn.sr.bias, backbone.layers.2.1.31.attn.norm.weight, backbone.layers.2.1.31.attn.norm.bias, backbone.layers.2.1.31.norm2.weight, backbone.layers.2.1.31.norm2.bias, backbone.layers.2.1.31.ffn.layers.0.weight, backbone.layers.2.1.31.ffn.layers.0.bias, backbone.layers.2.1.31.ffn.layers.1.weight, backbone.layers.2.1.31.ffn.layers.1.bias, backbone.layers.2.1.31.ffn.layers.4.weight, backbone.layers.2.1.31.ffn.layers.4.bias, backbone.layers.2.1.32.norm1.weight, backbone.layers.2.1.32.norm1.bias, backbone.layers.2.1.32.attn.attn.in_proj_weight, backbone.layers.2.1.32.attn.attn.in_proj_bias, backbone.layers.2.1.32.attn.attn.out_proj.weight, backbone.layers.2.1.32.attn.attn.out_proj.bias, backbone.layers.2.1.32.attn.sr.weight, backbone.layers.2.1.32.attn.sr.bias, backbone.layers.2.1.32.attn.norm.weight, backbone.layers.2.1.32.attn.norm.bias, backbone.layers.2.1.32.norm2.weight, backbone.layers.2.1.32.norm2.bias, backbone.layers.2.1.32.ffn.layers.0.weight, backbone.layers.2.1.32.ffn.layers.0.bias, backbone.layers.2.1.32.ffn.layers.1.weight, backbone.layers.2.1.32.ffn.layers.1.bias, backbone.layers.2.1.32.ffn.layers.4.weight, backbone.layers.2.1.32.ffn.layers.4.bias, backbone.layers.2.1.33.norm1.weight, backbone.layers.2.1.33.norm1.bias, backbone.layers.2.1.33.attn.attn.in_proj_weight, backbone.layers.2.1.33.attn.attn.in_proj_bias, backbone.layers.2.1.33.attn.attn.out_proj.weight, backbone.layers.2.1.33.attn.attn.out_proj.bias, backbone.layers.2.1.33.attn.sr.weight, backbone.layers.2.1.33.attn.sr.bias, backbone.layers.2.1.33.attn.norm.weight, backbone.layers.2.1.33.attn.norm.bias, backbone.layers.2.1.33.norm2.weight, backbone.layers.2.1.33.norm2.bias, backbone.layers.2.1.33.ffn.layers.0.weight, backbone.layers.2.1.33.ffn.layers.0.bias, backbone.layers.2.1.33.ffn.layers.1.weight, backbone.layers.2.1.33.ffn.layers.1.bias, backbone.layers.2.1.33.ffn.layers.4.weight, backbone.layers.2.1.33.ffn.layers.4.bias, backbone.layers.2.1.34.norm1.weight, backbone.layers.2.1.34.norm1.bias, backbone.layers.2.1.34.attn.attn.in_proj_weight, backbone.layers.2.1.34.attn.attn.in_proj_bias, backbone.layers.2.1.34.attn.attn.out_proj.weight, backbone.layers.2.1.34.attn.attn.out_proj.bias, backbone.layers.2.1.34.attn.sr.weight, backbone.layers.2.1.34.attn.sr.bias, backbone.layers.2.1.34.attn.norm.weight, backbone.layers.2.1.34.attn.norm.bias, backbone.layers.2.1.34.norm2.weight, backbone.layers.2.1.34.norm2.bias, backbone.layers.2.1.34.ffn.layers.0.weight, backbone.layers.2.1.34.ffn.layers.0.bias, backbone.layers.2.1.34.ffn.layers.1.weight, backbone.layers.2.1.34.ffn.layers.1.bias, backbone.layers.2.1.34.ffn.layers.4.weight, backbone.layers.2.1.34.ffn.layers.4.bias, backbone.layers.2.1.35.norm1.weight, backbone.layers.2.1.35.norm1.bias, backbone.layers.2.1.35.attn.attn.in_proj_weight, backbone.layers.2.1.35.attn.attn.in_proj_bias, backbone.layers.2.1.35.attn.attn.out_proj.weight, backbone.layers.2.1.35.attn.attn.out_proj.bias, backbone.layers.2.1.35.attn.sr.weight, backbone.layers.2.1.35.attn.sr.bias, backbone.layers.2.1.35.attn.norm.weight, backbone.layers.2.1.35.attn.norm.bias, backbone.layers.2.1.35.norm2.weight, backbone.layers.2.1.35.norm2.bias, backbone.layers.2.1.35.ffn.layers.0.weight, backbone.layers.2.1.35.ffn.layers.0.bias, backbone.layers.2.1.35.ffn.layers.1.weight, backbone.layers.2.1.35.ffn.layers.1.bias, backbone.layers.2.1.35.ffn.layers.4.weight, backbone.layers.2.1.35.ffn.layers.4.bias, backbone.layers.2.1.36.norm1.weight, backbone.layers.2.1.36.norm1.bias, backbone.layers.2.1.36.attn.attn.in_proj_weight, backbone.layers.2.1.36.attn.attn.in_proj_bias, backbone.layers.2.1.36.attn.attn.out_proj.weight, backbone.layers.2.1.36.attn.attn.out_proj.bias, backbone.layers.2.1.36.attn.sr.weight, backbone.layers.2.1.36.attn.sr.bias, backbone.layers.2.1.36.attn.norm.weight, backbone.layers.2.1.36.attn.norm.bias, backbone.layers.2.1.36.norm2.weight, backbone.layers.2.1.36.norm2.bias, backbone.layers.2.1.36.ffn.layers.0.weight, backbone.layers.2.1.36.ffn.layers.0.bias, backbone.layers.2.1.36.ffn.layers.1.weight, backbone.layers.2.1.36.ffn.layers.1.bias, backbone.layers.2.1.36.ffn.layers.4.weight, backbone.layers.2.1.36.ffn.layers.4.bias, backbone.layers.2.1.37.norm1.weight, backbone.layers.2.1.37.norm1.bias, backbone.layers.2.1.37.attn.attn.in_proj_weight, backbone.layers.2.1.37.attn.attn.in_proj_bias, backbone.layers.2.1.37.attn.attn.out_proj.weight, backbone.layers.2.1.37.attn.attn.out_proj.bias, backbone.layers.2.1.37.attn.sr.weight, backbone.layers.2.1.37.attn.sr.bias, backbone.layers.2.1.37.attn.norm.weight, backbone.layers.2.1.37.attn.norm.bias, backbone.layers.2.1.37.norm2.weight, backbone.layers.2.1.37.norm2.bias, backbone.layers.2.1.37.ffn.layers.0.weight, backbone.layers.2.1.37.ffn.layers.0.bias, backbone.layers.2.1.37.ffn.layers.1.weight, backbone.layers.2.1.37.ffn.layers.1.bias, backbone.layers.2.1.37.ffn.layers.4.weight, backbone.layers.2.1.37.ffn.layers.4.bias, backbone.layers.2.1.38.norm1.weight, backbone.layers.2.1.38.norm1.bias, backbone.layers.2.1.38.attn.attn.in_proj_weight, backbone.layers.2.1.38.attn.attn.in_proj_bias, backbone.layers.2.1.38.attn.attn.out_proj.weight, backbone.layers.2.1.38.attn.attn.out_proj.bias, backbone.layers.2.1.38.attn.sr.weight, backbone.layers.2.1.38.attn.sr.bias, backbone.layers.2.1.38.attn.norm.weight, backbone.layers.2.1.38.attn.norm.bias, backbone.layers.2.1.38.norm2.weight, backbone.layers.2.1.38.norm2.bias, backbone.layers.2.1.38.ffn.layers.0.weight, backbone.layers.2.1.38.ffn.layers.0.bias, backbone.layers.2.1.38.ffn.layers.1.weight, backbone.layers.2.1.38.ffn.layers.1.bias, backbone.layers.2.1.38.ffn.layers.4.weight, backbone.layers.2.1.38.ffn.layers.4.bias, backbone.layers.2.1.39.norm1.weight, backbone.layers.2.1.39.norm1.bias, backbone.layers.2.1.39.attn.attn.in_proj_weight, backbone.layers.2.1.39.attn.attn.in_proj_bias, backbone.layers.2.1.39.attn.attn.out_proj.weight, backbone.layers.2.1.39.attn.attn.out_proj.bias, backbone.layers.2.1.39.attn.sr.weight, backbone.layers.2.1.39.attn.sr.bias, backbone.layers.2.1.39.attn.norm.weight, backbone.layers.2.1.39.attn.norm.bias, backbone.layers.2.1.39.norm2.weight, backbone.layers.2.1.39.norm2.bias, backbone.layers.2.1.39.ffn.layers.0.weight, backbone.layers.2.1.39.ffn.layers.0.bias, backbone.layers.2.1.39.ffn.layers.1.weight, backbone.layers.2.1.39.ffn.layers.1.bias, backbone.layers.2.1.39.ffn.layers.4.weight, backbone.layers.2.1.39.ffn.layers.4.bias, backbone.layers.2.2.weight, backbone.layers.2.2.bias, backbone.layers.3.0.projection.weight, backbone.layers.3.0.projection.bias, backbone.layers.3.0.norm.weight, backbone.layers.3.0.norm.bias, backbone.layers.3.1.0.norm1.weight, backbone.layers.3.1.0.norm1.bias, backbone.layers.3.1.0.attn.attn.in_proj_weight, backbone.layers.3.1.0.attn.attn.in_proj_bias, backbone.layers.3.1.0.attn.attn.out_proj.weight, backbone.layers.3.1.0.attn.attn.out_proj.bias, backbone.layers.3.1.0.norm2.weight, backbone.layers.3.1.0.norm2.bias, backbone.layers.3.1.0.ffn.layers.0.weight, backbone.layers.3.1.0.ffn.layers.0.bias, backbone.layers.3.1.0.ffn.layers.1.weight, backbone.layers.3.1.0.ffn.layers.1.bias, backbone.layers.3.1.0.ffn.layers.4.weight, backbone.layers.3.1.0.ffn.layers.4.bias, backbone.layers.3.1.1.norm1.weight, backbone.layers.3.1.1.norm1.bias, backbone.layers.3.1.1.attn.attn.in_proj_weight, backbone.layers.3.1.1.attn.attn.in_proj_bias, backbone.layers.3.1.1.attn.attn.out_proj.weight, backbone.layers.3.1.1.attn.attn.out_proj.bias, backbone.layers.3.1.1.norm2.weight, backbone.layers.3.1.1.norm2.bias, backbone.layers.3.1.1.ffn.layers.0.weight, backbone.layers.3.1.1.ffn.layers.0.bias, backbone.layers.3.1.1.ffn.layers.1.weight, backbone.layers.3.1.1.ffn.layers.1.bias, backbone.layers.3.1.1.ffn.layers.4.weight, backbone.layers.3.1.1.ffn.layers.4.bias, backbone.layers.3.1.2.norm1.weight, backbone.layers.3.1.2.norm1.bias, backbone.layers.3.1.2.attn.attn.in_proj_weight, backbone.layers.3.1.2.attn.attn.in_proj_bias, backbone.layers.3.1.2.attn.attn.out_proj.weight, backbone.layers.3.1.2.attn.attn.out_proj.bias, backbone.layers.3.1.2.norm2.weight, backbone.layers.3.1.2.norm2.bias, backbone.layers.3.1.2.ffn.layers.0.weight, backbone.layers.3.1.2.ffn.layers.0.bias, backbone.layers.3.1.2.ffn.layers.1.weight, backbone.layers.3.1.2.ffn.layers.1.bias, backbone.layers.3.1.2.ffn.layers.4.weight, backbone.layers.3.1.2.ffn.layers.4.bias, backbone.layers.3.2.weight, backbone.layers.3.2.bias, decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.convs.0.conv.weight, decode_head.convs.0.bn.weight, decode_head.convs.0.bn.bias, decode_head.convs.0.bn.running_mean, decode_head.convs.0.bn.running_var, decode_head.convs.0.bn.num_batches_tracked, decode_head.convs.1.conv.weight, decode_head.convs.1.bn.weight, decode_head.convs.1.bn.bias, decode_head.convs.1.bn.running_mean, decode_head.convs.1.bn.running_var, decode_head.convs.1.bn.num_batches_tracked, decode_head.convs.2.conv.weight, decode_head.convs.2.bn.weight, decode_head.convs.2.bn.bias, decode_head.convs.2.bn.running_mean, decode_head.convs.2.bn.running_var, decode_head.convs.2.bn.num_batches_tracked, decode_head.convs.3.conv.weight, decode_head.convs.3.bn.weight, decode_head.convs.3.bn.bias, decode_head.convs.3.bn.running_mean, decode_head.convs.3.bn.running_var, decode_head.convs.3.bn.num_batches_tracked, decode_head.fusion_conv.conv.weight, decode_head.fusion_conv.bn.weight, decode_head.fusion_conv.bn.bias, decode_head.fusion_conv.bn.running_mean, decode_head.fusion_conv.bn.running_var, decode_head.fusion_conv.bn.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: conv_seg.weight, conv_seg.bias, convs.0.conv.weight, convs.0.bn.weight, convs.0.bn.bias, convs.0.bn.running_mean, convs.0.bn.running_var, convs.1.conv.weight, convs.1.bn.weight, convs.1.bn.bias, convs.1.bn.running_mean, convs.1.bn.running_var, convs.2.conv.weight, convs.2.bn.weight, convs.2.bn.bias, convs.2.bn.running_mean, convs.2.bn.running_var, convs.3.conv.weight, convs.3.bn.weight, convs.3.bn.bias, convs.3.bn.running_mean, convs.3.bn.running_var, fusion_conv.conv.weight, fusion_conv.bn.weight, fusion_conv.bn.bias, fusion_conv.bn.running_mean, fusion_conv.bn.running_var\n",
      "\n",
      "05/09 06:10:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "05/09 06:10:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
      "05/09 06:10:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /kaggle/working/checkpoint.\n",
      "05/09 06:11:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  100/57000]  base_lr: 3.9627e-06 lr: 3.9627e-06  eta: 11:07:06  time: 0.6970  data_time: 0.2925  memory: 11769  loss: 1.5621  decode.loss_ce: 1.5621  decode.acc_seg: 28.1519\n",
      "05/09 06:12:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  200/57000]  base_lr: 7.9654e-06 lr: 7.9654e-06  eta: 11:05:25  time: 0.7081  data_time: 0.3010  memory: 5259  loss: 1.1760  decode.loss_ce: 1.1760  decode.acc_seg: 62.8898\n",
      "05/09 06:14:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  300/57000]  base_lr: 1.1968e-05 lr: 1.1968e-05  eta: 11:06:05  time: 0.7244  data_time: 0.3169  memory: 5259  loss: 1.0408  decode.loss_ce: 1.0408  decode.acc_seg: 35.6487\n",
      "05/09 06:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  400/57000]  base_lr: 1.5971e-05 lr: 1.5971e-05  eta: 11:04:15  time: 0.7261  data_time: 0.3193  memory: 5259  loss: 0.8486  decode.loss_ce: 0.8486  decode.acc_seg: 80.1264\n",
      "05/09 06:16:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  500/57000]  base_lr: 1.9973e-05 lr: 1.9973e-05  eta: 11:05:06  time: 0.7340  data_time: 0.3269  memory: 5259  loss: 0.6739  decode.loss_ce: 0.6739  decode.acc_seg: 68.5428\n",
      "05/09 06:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  600/57000]  base_lr: 2.3976e-05 lr: 2.3976e-05  eta: 11:04:01  time: 0.6932  data_time: 0.2876  memory: 5259  loss: 0.7255  decode.loss_ce: 0.7255  decode.acc_seg: 88.3204\n",
      "05/09 06:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  700/57000]  base_lr: 2.7979e-05 lr: 2.7979e-05  eta: 11:02:27  time: 0.7352  data_time: 0.3298  memory: 5259  loss: 0.6718  decode.loss_ce: 0.6718  decode.acc_seg: 76.1591\n",
      "05/09 06:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 06:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  800/57000]  base_lr: 3.1981e-05 lr: 3.1981e-05  eta: 10:49:22  time: 0.5429  data_time: 0.1404  memory: 5259  loss: 0.3173  decode.loss_ce: 0.3173  decode.acc_seg: 93.0731\n",
      "05/09 06:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [  900/57000]  base_lr: 3.5984e-05 lr: 3.5984e-05  eta: 10:35:31  time: 0.5532  data_time: 0.1507  memory: 5259  loss: 0.3791  decode.loss_ce: 0.3791  decode.acc_seg: 57.7145\n",
      "05/09 06:21:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 06:21:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1000/57000]  base_lr: 3.9987e-05 lr: 3.9987e-05  eta: 10:25:18  time: 0.5937  data_time: 0.1883  memory: 5259  loss: 0.4821  decode.loss_ce: 0.4821  decode.acc_seg: 84.3559\n",
      "05/09 06:22:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1100/57000]  base_lr: 4.3989e-05 lr: 4.3989e-05  eta: 10:16:40  time: 0.5667  data_time: 0.1637  memory: 5259  loss: 0.3354  decode.loss_ce: 0.3354  decode.acc_seg: 82.4170\n",
      "05/09 06:23:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1200/57000]  base_lr: 4.7992e-05 lr: 4.7992e-05  eta: 10:09:00  time: 0.5775  data_time: 0.1754  memory: 5259  loss: 0.4302  decode.loss_ce: 0.4302  decode.acc_seg: 86.3543\n",
      "05/09 06:24:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1300/57000]  base_lr: 5.1995e-05 lr: 5.1995e-05  eta: 10:02:20  time: 0.5938  data_time: 0.1850  memory: 5259  loss: 0.2718  decode.loss_ce: 0.2718  decode.acc_seg: 92.8629\n",
      "05/09 06:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1400/57000]  base_lr: 5.5997e-05 lr: 5.5997e-05  eta: 9:56:19  time: 0.5701  data_time: 0.1679  memory: 5259  loss: 0.4240  decode.loss_ce: 0.4240  decode.acc_seg: 92.5150\n",
      "05/09 06:26:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1500/57000]  base_lr: 6.0000e-05 lr: 6.0000e-05  eta: 9:51:25  time: 0.5599  data_time: 0.1583  memory: 5259  loss: 0.3244  decode.loss_ce: 0.3244  decode.acc_seg: 81.3067\n",
      "05/09 06:27:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1600/57000]  base_lr: 5.9963e-05 lr: 5.9963e-05  eta: 9:46:31  time: 0.5786  data_time: 0.1760  memory: 5259  loss: 0.5986  decode.loss_ce: 0.5986  decode.acc_seg: 58.5474\n",
      "05/09 06:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1700/57000]  base_lr: 5.9925e-05 lr: 5.9925e-05  eta: 9:42:10  time: 0.5811  data_time: 0.1749  memory: 5259  loss: 0.4351  decode.loss_ce: 0.4351  decode.acc_seg: 92.2755\n",
      "05/09 06:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1800/57000]  base_lr: 5.9887e-05 lr: 5.9887e-05  eta: 9:38:07  time: 0.5791  data_time: 0.1719  memory: 5259  loss: 0.2927  decode.loss_ce: 0.2927  decode.acc_seg: 94.6352\n",
      "05/09 06:30:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 1900/57000]  base_lr: 5.9849e-05 lr: 5.9849e-05  eta: 9:34:34  time: 0.5970  data_time: 0.1905  memory: 5259  loss: 0.3277  decode.loss_ce: 0.3277  decode.acc_seg: 91.2387\n",
      "05/09 06:31:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 06:31:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2000/57000]  base_lr: 5.9811e-05 lr: 5.9811e-05  eta: 9:31:02  time: 0.5824  data_time: 0.1798  memory: 5259  loss: 0.3023  decode.loss_ce: 0.3023  decode.acc_seg: 86.9298\n",
      "05/09 06:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2100/57000]  base_lr: 5.9773e-05 lr: 5.9773e-05  eta: 9:28:05  time: 0.5614  data_time: 0.1597  memory: 5259  loss: 0.2872  decode.loss_ce: 0.2872  decode.acc_seg: 96.2341\n",
      "05/09 06:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2200/57000]  base_lr: 5.9735e-05 lr: 5.9735e-05  eta: 9:25:05  time: 0.5610  data_time: 0.1589  memory: 5259  loss: 0.3579  decode.loss_ce: 0.3579  decode.acc_seg: 93.4595\n",
      "05/09 06:34:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2300/57000]  base_lr: 5.9698e-05 lr: 5.9698e-05  eta: 9:22:31  time: 0.5591  data_time: 0.1551  memory: 5259  loss: 0.3077  decode.loss_ce: 0.3077  decode.acc_seg: 92.8781\n",
      "05/09 06:35:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2400/57000]  base_lr: 5.9660e-05 lr: 5.9660e-05  eta: 9:20:05  time: 0.5815  data_time: 0.1796  memory: 5259  loss: 0.4403  decode.loss_ce: 0.4403  decode.acc_seg: 87.6245\n",
      "05/09 06:36:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2500/57000]  base_lr: 5.9622e-05 lr: 5.9622e-05  eta: 9:17:35  time: 0.6101  data_time: 0.1998  memory: 5259  loss: 0.2054  decode.loss_ce: 0.2054  decode.acc_seg: 95.4678\n",
      "05/09 06:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2600/57000]  base_lr: 5.9584e-05 lr: 5.9584e-05  eta: 9:15:42  time: 0.5770  data_time: 0.1690  memory: 5259  loss: 0.3346  decode.loss_ce: 0.3346  decode.acc_seg: 93.7196\n",
      "05/09 06:38:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2700/57000]  base_lr: 5.9546e-05 lr: 5.9546e-05  eta: 9:13:50  time: 0.5792  data_time: 0.1763  memory: 5259  loss: 0.1814  decode.loss_ce: 0.1814  decode.acc_seg: 93.9437\n",
      "05/09 06:39:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2800/57000]  base_lr: 5.9508e-05 lr: 5.9508e-05  eta: 9:11:41  time: 0.5776  data_time: 0.1750  memory: 5259  loss: 0.3231  decode.loss_ce: 0.3231  decode.acc_seg: 94.4799\n",
      "05/09 06:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 2900/57000]  base_lr: 5.9470e-05 lr: 5.9470e-05  eta: 9:09:38  time: 0.5689  data_time: 0.1660  memory: 5259  loss: 0.1703  decode.loss_ce: 0.1703  decode.acc_seg: 94.7992\n",
      "05/09 06:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 06:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3000/57000]  base_lr: 5.9433e-05 lr: 5.9433e-05  eta: 9:07:32  time: 0.5669  data_time: 0.1642  memory: 5259  loss: 0.2033  decode.loss_ce: 0.2033  decode.acc_seg: 93.7216\n",
      "05/09 06:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:40  time: 0.4271  data_time: 0.2528  memory: 9859  \n",
      "05/09 06:42:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:55  time: 0.5390  data_time: 0.3674  memory: 2585  \n",
      "05/09 06:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:01:08  time: 0.4226  data_time: 0.2304  memory: 2577  \n",
      "05/09 06:43:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:22  time: 0.4241  data_time: 0.2398  memory: 2410  \n",
      "05/09 06:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 06:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 46.97 | 66.36 | 63.92 | 63.92  |   61.65   | 66.36  |\n",
      "| BuildingFlooded | 64.21 | 97.05 |  78.2 |  78.2  |   65.49   | 97.05  |\n",
      "|   BNonFlooded   | 76.07 | 84.77 | 86.41 | 86.41  |   88.11   | 84.77  |\n",
      "|   RoadFlooded   | 60.41 | 87.54 | 75.32 | 75.32  |    66.1   | 87.54  |\n",
      "|   RNonFlooded   | 80.43 | 88.04 | 89.16 | 89.16  |    90.3   | 88.04  |\n",
      "|      Water      | 66.64 | 81.82 | 79.98 | 79.98  |   78.23   | 81.82  |\n",
      "|       Tree      | 80.33 | 87.18 | 89.09 | 89.09  |    91.1   | 87.18  |\n",
      "|      Vecile     | 26.15 | 29.54 | 41.46 | 41.46  |   69.52   | 29.54  |\n",
      "|       Pool      | 46.26 | 55.28 | 63.25 | 63.25  |   73.92   | 55.28  |\n",
      "|      Grass      | 86.73 | 91.71 | 92.89 | 92.89  |    94.1   | 91.71  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 06:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 88.5700  mIoU: 63.4200  mAcc: 76.9300  mDice: 75.9700  mFscore: 75.9700  mPrecision: 77.8500  mRecall: 76.9300  data_time: 0.2662  time: 0.4488\n",
      "05/09 06:44:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 63.4200 mIoU at 3000 iter is saved to best_mIoU_iter_3000.pth.\n",
      "05/09 06:45:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3100/57000]  base_lr: 5.9395e-05 lr: 5.9395e-05  eta: 9:06:28  time: 0.5690  data_time: 0.1645  memory: 5238  loss: 0.2362  decode.loss_ce: 0.2362  decode.acc_seg: 82.4824\n",
      "05/09 06:46:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3200/57000]  base_lr: 5.9357e-05 lr: 5.9357e-05  eta: 9:04:52  time: 0.5976  data_time: 0.1946  memory: 5238  loss: 0.3878  decode.loss_ce: 0.3878  decode.acc_seg: 82.3261\n",
      "05/09 06:47:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3300/57000]  base_lr: 5.9319e-05 lr: 5.9319e-05  eta: 9:02:50  time: 0.5634  data_time: 0.1613  memory: 5238  loss: 0.2644  decode.loss_ce: 0.2644  decode.acc_seg: 98.4703\n",
      "05/09 06:48:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3400/57000]  base_lr: 5.9281e-05 lr: 5.9281e-05  eta: 9:01:04  time: 0.5755  data_time: 0.1724  memory: 5238  loss: 0.1936  decode.loss_ce: 0.1936  decode.acc_seg: 87.0155\n",
      "05/09 06:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3500/57000]  base_lr: 5.9243e-05 lr: 5.9243e-05  eta: 8:59:22  time: 0.5788  data_time: 0.1754  memory: 5238  loss: 0.3471  decode.loss_ce: 0.3471  decode.acc_seg: 96.5333\n",
      "05/09 06:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3600/57000]  base_lr: 5.9205e-05 lr: 5.9205e-05  eta: 8:57:43  time: 0.5982  data_time: 0.1885  memory: 5238  loss: 0.2506  decode.loss_ce: 0.2506  decode.acc_seg: 86.5820\n",
      "05/09 06:51:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3700/57000]  base_lr: 5.9168e-05 lr: 5.9168e-05  eta: 8:56:05  time: 0.5843  data_time: 0.1790  memory: 5238  loss: 0.2824  decode.loss_ce: 0.2824  decode.acc_seg: 86.7903\n",
      "05/09 06:52:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3800/57000]  base_lr: 5.9130e-05 lr: 5.9130e-05  eta: 8:54:26  time: 0.5836  data_time: 0.1809  memory: 5238  loss: 0.6962  decode.loss_ce: 0.6962  decode.acc_seg: 81.6168\n",
      "05/09 06:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 3900/57000]  base_lr: 5.9092e-05 lr: 5.9092e-05  eta: 8:52:48  time: 0.5881  data_time: 0.1835  memory: 5238  loss: 0.1960  decode.loss_ce: 0.1960  decode.acc_seg: 85.7821\n",
      "05/09 06:54:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 06:54:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4000/57000]  base_lr: 5.9054e-05 lr: 5.9054e-05  eta: 8:51:19  time: 0.5740  data_time: 0.1706  memory: 5238  loss: 0.3265  decode.loss_ce: 0.3265  decode.acc_seg: 89.2153\n",
      "05/09 06:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4100/57000]  base_lr: 5.9016e-05 lr: 5.9016e-05  eta: 8:49:57  time: 0.6037  data_time: 0.1998  memory: 5238  loss: 0.2434  decode.loss_ce: 0.2434  decode.acc_seg: 93.7671\n",
      "05/09 06:55:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4200/57000]  base_lr: 5.8978e-05 lr: 5.8978e-05  eta: 8:48:43  time: 0.5648  data_time: 0.1615  memory: 5238  loss: 0.1890  decode.loss_ce: 0.1890  decode.acc_seg: 97.5575\n",
      "05/09 06:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4300/57000]  base_lr: 5.8940e-05 lr: 5.8940e-05  eta: 8:47:23  time: 0.5786  data_time: 0.1709  memory: 5238  loss: 0.2348  decode.loss_ce: 0.2348  decode.acc_seg: 86.5503\n",
      "05/09 06:57:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4400/57000]  base_lr: 5.8903e-05 lr: 5.8903e-05  eta: 8:45:58  time: 0.5769  data_time: 0.1720  memory: 5238  loss: 0.1939  decode.loss_ce: 0.1939  decode.acc_seg: 90.5827\n",
      "05/09 06:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4500/57000]  base_lr: 5.8865e-05 lr: 5.8865e-05  eta: 8:44:42  time: 0.5922  data_time: 0.1884  memory: 5238  loss: 0.4154  decode.loss_ce: 0.4154  decode.acc_seg: 57.2981\n",
      "05/09 06:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4600/57000]  base_lr: 5.8827e-05 lr: 5.8827e-05  eta: 8:43:14  time: 0.5805  data_time: 0.1775  memory: 5238  loss: 0.3596  decode.loss_ce: 0.3596  decode.acc_seg: 90.1793\n",
      "05/09 07:00:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4700/57000]  base_lr: 5.8789e-05 lr: 5.8789e-05  eta: 8:41:57  time: 0.5956  data_time: 0.1912  memory: 5238  loss: 0.3941  decode.loss_ce: 0.3941  decode.acc_seg: 76.8058\n",
      "05/09 07:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4800/57000]  base_lr: 5.8751e-05 lr: 5.8751e-05  eta: 8:40:38  time: 0.5645  data_time: 0.1599  memory: 5238  loss: 0.2225  decode.loss_ce: 0.2225  decode.acc_seg: 99.2321\n",
      "05/09 07:02:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 4900/57000]  base_lr: 5.8713e-05 lr: 5.8713e-05  eta: 8:39:20  time: 0.5684  data_time: 0.1624  memory: 5238  loss: 0.1782  decode.loss_ce: 0.1782  decode.acc_seg: 95.1709\n",
      "05/09 07:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 07:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5000/57000]  base_lr: 5.8675e-05 lr: 5.8675e-05  eta: 8:38:03  time: 0.5816  data_time: 0.1742  memory: 5238  loss: 0.1796  decode.loss_ce: 0.1796  decode.acc_seg: 82.5237\n",
      "05/09 07:04:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5100/57000]  base_lr: 5.8638e-05 lr: 5.8638e-05  eta: 8:36:57  time: 0.5968  data_time: 0.1925  memory: 5238  loss: 0.1413  decode.loss_ce: 0.1413  decode.acc_seg: 96.3314\n",
      "05/09 07:05:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5200/57000]  base_lr: 5.8600e-05 lr: 5.8600e-05  eta: 8:35:51  time: 0.5809  data_time: 0.1748  memory: 5238  loss: 0.2082  decode.loss_ce: 0.2082  decode.acc_seg: 95.5881\n",
      "05/09 07:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5300/57000]  base_lr: 5.8562e-05 lr: 5.8562e-05  eta: 8:34:38  time: 0.5720  data_time: 0.1669  memory: 5238  loss: 0.1409  decode.loss_ce: 0.1409  decode.acc_seg: 95.9388\n",
      "05/09 07:07:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5400/57000]  base_lr: 5.8524e-05 lr: 5.8524e-05  eta: 8:33:28  time: 0.5872  data_time: 0.1824  memory: 5238  loss: 0.1719  decode.loss_ce: 0.1719  decode.acc_seg: 91.5452\n",
      "05/09 07:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5500/57000]  base_lr: 5.8486e-05 lr: 5.8486e-05  eta: 8:32:17  time: 0.5825  data_time: 0.1781  memory: 5238  loss: 0.2159  decode.loss_ce: 0.2159  decode.acc_seg: 93.2159\n",
      "05/09 07:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5600/57000]  base_lr: 5.8448e-05 lr: 5.8448e-05  eta: 8:31:05  time: 0.5692  data_time: 0.1644  memory: 5238  loss: 0.1816  decode.loss_ce: 0.1816  decode.acc_seg: 95.5256\n",
      "05/09 07:10:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5700/57000]  base_lr: 5.8410e-05 lr: 5.8410e-05  eta: 8:29:55  time: 0.5866  data_time: 0.1817  memory: 5238  loss: 0.1395  decode.loss_ce: 0.1395  decode.acc_seg: 97.8704\n",
      "05/09 07:11:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5800/57000]  base_lr: 5.8373e-05 lr: 5.8373e-05  eta: 8:28:43  time: 0.5882  data_time: 0.1824  memory: 5238  loss: 0.2765  decode.loss_ce: 0.2765  decode.acc_seg: 93.5595\n",
      "05/09 07:12:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 5900/57000]  base_lr: 5.8335e-05 lr: 5.8335e-05  eta: 8:27:29  time: 0.5540  data_time: 0.1503  memory: 5238  loss: 0.1747  decode.loss_ce: 0.1747  decode.acc_seg: 94.0510\n",
      "05/09 07:13:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 07:13:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6000/57000]  base_lr: 5.8297e-05 lr: 5.8297e-05  eta: 8:26:22  time: 0.5793  data_time: 0.1739  memory: 5238  loss: 0.3574  decode.loss_ce: 0.3574  decode.acc_seg: 94.1308\n",
      "05/09 07:14:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:17  time: 0.3877  data_time: 0.2143  memory: 2589  \n",
      "05/09 07:14:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:39  time: 0.4497  data_time: 0.2805  memory: 2580  \n",
      "05/09 07:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:59  time: 0.3679  data_time: 0.1769  memory: 2577  \n",
      "05/09 07:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3697  data_time: 0.1850  memory: 2410  \n",
      "05/09 07:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 07:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 39.81 | 52.31 | 56.95 | 56.95  |   62.48   | 52.31  |\n",
      "| BuildingFlooded | 70.53 |  96.6 | 82.72 | 82.72  |   72.32   |  96.6  |\n",
      "|   BNonFlooded   | 77.85 | 84.02 | 87.54 | 87.54  |   91.37   | 84.02  |\n",
      "|   RoadFlooded   |  52.4 | 89.14 | 68.77 | 68.77  |   55.97   | 89.14  |\n",
      "|   RNonFlooded   | 77.85 | 89.66 | 87.55 | 87.55  |   85.53   | 89.66  |\n",
      "|      Water      | 63.91 | 71.55 | 77.98 | 77.98  |   85.69   | 71.55  |\n",
      "|       Tree      | 81.27 | 89.17 | 89.67 | 89.67  |   90.17   | 89.17  |\n",
      "|      Vecile     | 32.24 | 37.66 | 48.76 | 48.76  |   69.13   | 37.66  |\n",
      "|       Pool      | 54.03 | 70.82 | 70.15 | 70.15  |   69.49   | 70.82  |\n",
      "|      Grass      | 87.38 | 93.37 | 93.27 | 93.27  |   93.16   | 93.37  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 07:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 88.5000  mIoU: 63.7300  mAcc: 77.4300  mDice: 76.3300  mFscore: 76.3300  mPrecision: 77.5300  mRecall: 77.4300  data_time: 0.2078  time: 0.3878\n",
      "05/09 07:16:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_3000.pth is removed\n",
      "05/09 07:16:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 63.7300 mIoU at 6000 iter is saved to best_mIoU_iter_6000.pth.\n",
      "05/09 07:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6100/57000]  base_lr: 5.8259e-05 lr: 5.8259e-05  eta: 8:25:29  time: 0.5827  data_time: 0.1747  memory: 5238  loss: 0.2034  decode.loss_ce: 0.2034  decode.acc_seg: 93.1063\n",
      "05/09 07:18:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6200/57000]  base_lr: 5.8221e-05 lr: 5.8221e-05  eta: 8:24:17  time: 0.5950  data_time: 0.1911  memory: 5238  loss: 0.1180  decode.loss_ce: 0.1180  decode.acc_seg: 98.1688\n",
      "05/09 07:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6300/57000]  base_lr: 5.8183e-05 lr: 5.8183e-05  eta: 8:23:06  time: 0.5830  data_time: 0.1720  memory: 5238  loss: 0.1669  decode.loss_ce: 0.1669  decode.acc_seg: 82.2513\n",
      "05/09 07:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6400/57000]  base_lr: 5.8145e-05 lr: 5.8145e-05  eta: 8:21:56  time: 0.5789  data_time: 0.1752  memory: 5238  loss: 0.1449  decode.loss_ce: 0.1449  decode.acc_seg: 93.1532\n",
      "05/09 07:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6500/57000]  base_lr: 5.8108e-05 lr: 5.8108e-05  eta: 8:20:51  time: 0.5910  data_time: 0.1861  memory: 5238  loss: 0.3520  decode.loss_ce: 0.3520  decode.acc_seg: 67.6378\n",
      "05/09 07:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6600/57000]  base_lr: 5.8070e-05 lr: 5.8070e-05  eta: 8:19:43  time: 0.5701  data_time: 0.1652  memory: 5238  loss: 0.4211  decode.loss_ce: 0.4211  decode.acc_seg: 96.6683\n",
      "05/09 07:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6700/57000]  base_lr: 5.8032e-05 lr: 5.8032e-05  eta: 8:18:34  time: 0.5738  data_time: 0.1685  memory: 5238  loss: 0.3044  decode.loss_ce: 0.3044  decode.acc_seg: 98.8157\n",
      "05/09 07:24:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6800/57000]  base_lr: 5.7994e-05 lr: 5.7994e-05  eta: 8:17:26  time: 0.5718  data_time: 0.1653  memory: 5238  loss: 0.4072  decode.loss_ce: 0.4072  decode.acc_seg: 92.4094\n",
      "05/09 07:25:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 6900/57000]  base_lr: 5.7956e-05 lr: 5.7956e-05  eta: 8:16:22  time: 0.5767  data_time: 0.1725  memory: 5238  loss: 0.1689  decode.loss_ce: 0.1689  decode.acc_seg: 87.8141\n",
      "05/09 07:26:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 07:26:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7000/57000]  base_lr: 5.7918e-05 lr: 5.7918e-05  eta: 8:15:20  time: 0.6048  data_time: 0.1969  memory: 5238  loss: 0.2144  decode.loss_ce: 0.2144  decode.acc_seg: 97.4433\n",
      "05/09 07:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7100/57000]  base_lr: 5.7880e-05 lr: 5.7880e-05  eta: 8:14:17  time: 0.6090  data_time: 0.2002  memory: 5238  loss: 0.2323  decode.loss_ce: 0.2323  decode.acc_seg: 91.2476\n",
      "05/09 07:28:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7200/57000]  base_lr: 5.7843e-05 lr: 5.7843e-05  eta: 8:13:15  time: 0.6039  data_time: 0.1994  memory: 5238  loss: 0.2732  decode.loss_ce: 0.2732  decode.acc_seg: 99.5247\n",
      "05/09 07:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7300/57000]  base_lr: 5.7805e-05 lr: 5.7805e-05  eta: 8:12:11  time: 0.5871  data_time: 0.1815  memory: 5238  loss: 0.1568  decode.loss_ce: 0.1568  decode.acc_seg: 84.4705\n",
      "05/09 07:30:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7400/57000]  base_lr: 5.7767e-05 lr: 5.7767e-05  eta: 8:11:07  time: 0.5778  data_time: 0.1725  memory: 5238  loss: 0.1945  decode.loss_ce: 0.1945  decode.acc_seg: 96.9805\n",
      "05/09 07:31:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7500/57000]  base_lr: 5.7729e-05 lr: 5.7729e-05  eta: 8:10:04  time: 0.5900  data_time: 0.1858  memory: 5238  loss: 0.3697  decode.loss_ce: 0.3697  decode.acc_seg: 64.3269\n",
      "05/09 07:32:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7600/57000]  base_lr: 5.7691e-05 lr: 5.7691e-05  eta: 8:08:54  time: 0.5567  data_time: 0.1519  memory: 5238  loss: 0.1406  decode.loss_ce: 0.1406  decode.acc_seg: 96.1305\n",
      "05/09 07:33:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7700/57000]  base_lr: 5.7653e-05 lr: 5.7653e-05  eta: 8:07:50  time: 0.5805  data_time: 0.1751  memory: 5238  loss: 0.3273  decode.loss_ce: 0.3273  decode.acc_seg: 93.9934\n",
      "05/09 07:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7800/57000]  base_lr: 5.7616e-05 lr: 5.7616e-05  eta: 8:06:48  time: 0.5878  data_time: 0.1822  memory: 5238  loss: 0.1258  decode.loss_ce: 0.1258  decode.acc_seg: 96.3706\n",
      "05/09 07:34:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 7900/57000]  base_lr: 5.7578e-05 lr: 5.7578e-05  eta: 8:05:40  time: 0.5874  data_time: 0.1811  memory: 5238  loss: 0.1239  decode.loss_ce: 0.1239  decode.acc_seg: 97.1413\n",
      "05/09 07:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 07:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8000/57000]  base_lr: 5.7540e-05 lr: 5.7540e-05  eta: 8:04:34  time: 0.5750  data_time: 0.1702  memory: 5238  loss: 0.1753  decode.loss_ce: 0.1753  decode.acc_seg: 92.9338\n",
      "05/09 07:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8100/57000]  base_lr: 5.7502e-05 lr: 5.7502e-05  eta: 8:03:27  time: 0.5999  data_time: 0.1924  memory: 5238  loss: 0.2576  decode.loss_ce: 0.2576  decode.acc_seg: 97.5887\n",
      "05/09 07:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8200/57000]  base_lr: 5.7464e-05 lr: 5.7464e-05  eta: 8:02:26  time: 0.5893  data_time: 0.1836  memory: 5238  loss: 0.2208  decode.loss_ce: 0.2208  decode.acc_seg: 86.8220\n",
      "05/09 07:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8300/57000]  base_lr: 5.7426e-05 lr: 5.7426e-05  eta: 8:01:28  time: 0.6039  data_time: 0.1975  memory: 5238  loss: 0.2359  decode.loss_ce: 0.2359  decode.acc_seg: 95.4069\n",
      "05/09 07:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8400/57000]  base_lr: 5.7388e-05 lr: 5.7388e-05  eta: 8:00:34  time: 0.6099  data_time: 0.2048  memory: 5238  loss: 0.1709  decode.loss_ce: 0.1709  decode.acc_seg: 98.8764\n",
      "05/09 07:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8500/57000]  base_lr: 5.7351e-05 lr: 5.7351e-05  eta: 7:59:30  time: 0.5701  data_time: 0.1660  memory: 5238  loss: 0.0982  decode.loss_ce: 0.0982  decode.acc_seg: 95.8868\n",
      "05/09 07:41:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8600/57000]  base_lr: 5.7313e-05 lr: 5.7313e-05  eta: 7:58:27  time: 0.6087  data_time: 0.1993  memory: 5238  loss: 0.2005  decode.loss_ce: 0.2005  decode.acc_seg: 94.5869\n",
      "05/09 07:42:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8700/57000]  base_lr: 5.7275e-05 lr: 5.7275e-05  eta: 7:57:24  time: 0.5857  data_time: 0.1774  memory: 5238  loss: 0.2401  decode.loss_ce: 0.2401  decode.acc_seg: 93.7561\n",
      "05/09 07:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8800/57000]  base_lr: 5.7237e-05 lr: 5.7237e-05  eta: 7:56:15  time: 0.5811  data_time: 0.1768  memory: 5238  loss: 0.1659  decode.loss_ce: 0.1659  decode.acc_seg: 90.0002\n",
      "05/09 07:44:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 8900/57000]  base_lr: 5.7199e-05 lr: 5.7199e-05  eta: 7:55:10  time: 0.5851  data_time: 0.1813  memory: 5238  loss: 0.1591  decode.loss_ce: 0.1591  decode.acc_seg: 93.2554\n",
      "05/09 07:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 07:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9000/57000]  base_lr: 5.7161e-05 lr: 5.7161e-05  eta: 7:54:05  time: 0.5744  data_time: 0.1666  memory: 5238  loss: 0.1943  decode.loss_ce: 0.1943  decode.acc_seg: 74.2220\n",
      "05/09 07:46:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:17  time: 0.3768  data_time: 0.2049  memory: 2589  \n",
      "05/09 07:47:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:38  time: 0.4623  data_time: 0.2906  memory: 2589  \n",
      "05/09 07:47:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:59  time: 0.3687  data_time: 0.1777  memory: 2577  \n",
      "05/09 07:48:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3667  data_time: 0.1811  memory: 2410  \n",
      "05/09 07:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 07:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 25.74 | 34.13 | 40.94 | 40.94  |   51.13   | 34.13  |\n",
      "| BuildingFlooded | 74.03 | 90.59 | 85.08 | 85.08  |    80.2   | 90.59  |\n",
      "|   BNonFlooded   | 76.96 |  84.5 | 86.98 | 86.98  |   89.61   |  84.5  |\n",
      "|   RoadFlooded   | 60.98 | 83.03 | 75.76 | 75.76  |   69.66   | 83.03  |\n",
      "|   RNonFlooded   | 76.52 | 81.31 |  86.7 |  86.7  |   92.85   | 81.31  |\n",
      "|      Water      | 70.09 | 84.12 | 82.42 | 82.42  |   80.79   | 84.12  |\n",
      "|       Tree      | 83.09 | 90.65 | 90.77 | 90.77  |   90.89   | 90.65  |\n",
      "|      Vecile     | 40.32 | 53.33 | 57.47 | 57.47  |    62.3   | 53.33  |\n",
      "|       Pool      | 49.71 | 77.34 | 66.41 | 66.41  |   58.18   | 77.34  |\n",
      "|      Grass      | 88.41 | 94.18 | 93.85 | 93.85  |   93.52   | 94.18  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 07:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 89.5000  mIoU: 64.5900  mAcc: 77.3200  mDice: 76.6400  mFscore: 76.6400  mPrecision: 76.9100  mRecall: 77.3200  data_time: 0.2070  time: 0.3873\n",
      "05/09 07:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_6000.pth is removed\n",
      "05/09 07:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 64.5900 mIoU at 9000 iter is saved to best_mIoU_iter_9000.pth.\n",
      "05/09 07:49:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9100/57000]  base_lr: 5.7123e-05 lr: 5.7123e-05  eta: 7:53:15  time: 0.6205  data_time: 0.2147  memory: 5238  loss: 0.2113  decode.loss_ce: 0.2113  decode.acc_seg: 87.5874\n",
      "05/09 07:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9200/57000]  base_lr: 5.7086e-05 lr: 5.7086e-05  eta: 7:52:10  time: 0.5816  data_time: 0.1769  memory: 5238  loss: 0.2311  decode.loss_ce: 0.2311  decode.acc_seg: 95.0921\n",
      "05/09 07:51:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9300/57000]  base_lr: 5.7048e-05 lr: 5.7048e-05  eta: 7:51:07  time: 0.5850  data_time: 0.1802  memory: 5238  loss: 0.1600  decode.loss_ce: 0.1600  decode.acc_seg: 97.9020\n",
      "05/09 07:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9400/57000]  base_lr: 5.7010e-05 lr: 5.7010e-05  eta: 7:50:01  time: 0.5709  data_time: 0.1677  memory: 5238  loss: 0.1594  decode.loss_ce: 0.1594  decode.acc_seg: 94.6034\n",
      "05/09 07:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9500/57000]  base_lr: 5.6972e-05 lr: 5.6972e-05  eta: 7:48:54  time: 0.5741  data_time: 0.1700  memory: 5238  loss: 0.1775  decode.loss_ce: 0.1775  decode.acc_seg: 95.7664\n",
      "05/09 07:54:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9600/57000]  base_lr: 5.6934e-05 lr: 5.6934e-05  eta: 7:47:49  time: 0.5711  data_time: 0.1676  memory: 5238  loss: 0.1717  decode.loss_ce: 0.1717  decode.acc_seg: 89.8099\n",
      "05/09 07:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9700/57000]  base_lr: 5.6896e-05 lr: 5.6896e-05  eta: 7:46:41  time: 0.5575  data_time: 0.1544  memory: 5238  loss: 0.2143  decode.loss_ce: 0.2143  decode.acc_seg: 93.5247\n",
      "05/09 07:56:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9800/57000]  base_lr: 5.6858e-05 lr: 5.6858e-05  eta: 7:45:35  time: 0.5853  data_time: 0.1776  memory: 5238  loss: 0.1541  decode.loss_ce: 0.1541  decode.acc_seg: 92.4500\n",
      "05/09 07:57:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [ 9900/57000]  base_lr: 5.6821e-05 lr: 5.6821e-05  eta: 7:44:31  time: 0.5832  data_time: 0.1786  memory: 5238  loss: 0.2550  decode.loss_ce: 0.2550  decode.acc_seg: 93.9541\n",
      "05/09 07:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 07:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10000/57000]  base_lr: 5.6783e-05 lr: 5.6783e-05  eta: 7:43:28  time: 0.5814  data_time: 0.1768  memory: 5238  loss: 0.3211  decode.loss_ce: 0.3211  decode.acc_seg: 98.0429\n",
      "05/09 07:59:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10100/57000]  base_lr: 5.6745e-05 lr: 5.6745e-05  eta: 7:42:23  time: 0.5746  data_time: 0.1715  memory: 5238  loss: 0.3177  decode.loss_ce: 0.3177  decode.acc_seg: 96.6141\n",
      "05/09 08:00:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10200/57000]  base_lr: 5.6707e-05 lr: 5.6707e-05  eta: 7:41:15  time: 0.5922  data_time: 0.1887  memory: 5238  loss: 0.1106  decode.loss_ce: 0.1106  decode.acc_seg: 99.4078\n",
      "05/09 08:01:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10300/57000]  base_lr: 5.6669e-05 lr: 5.6669e-05  eta: 7:40:09  time: 0.5685  data_time: 0.1636  memory: 5238  loss: 0.1767  decode.loss_ce: 0.1767  decode.acc_seg: 89.7436\n",
      "05/09 08:02:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10400/57000]  base_lr: 5.6631e-05 lr: 5.6631e-05  eta: 7:39:08  time: 0.5837  data_time: 0.1779  memory: 5238  loss: 0.2639  decode.loss_ce: 0.2639  decode.acc_seg: 97.1691\n",
      "05/09 08:03:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10500/57000]  base_lr: 5.6593e-05 lr: 5.6593e-05  eta: 7:38:06  time: 0.5967  data_time: 0.1897  memory: 5238  loss: 0.0846  decode.loss_ce: 0.0846  decode.acc_seg: 94.0459\n",
      "05/09 08:04:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10600/57000]  base_lr: 5.6556e-05 lr: 5.6556e-05  eta: 7:37:01  time: 0.5900  data_time: 0.1850  memory: 5238  loss: 0.3289  decode.loss_ce: 0.3289  decode.acc_seg: 73.0555\n",
      "05/09 08:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10700/57000]  base_lr: 5.6518e-05 lr: 5.6518e-05  eta: 7:35:59  time: 0.5922  data_time: 0.1866  memory: 5238  loss: 0.2865  decode.loss_ce: 0.2865  decode.acc_seg: 94.1410\n",
      "05/09 08:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10800/57000]  base_lr: 5.6480e-05 lr: 5.6480e-05  eta: 7:34:57  time: 0.5834  data_time: 0.1773  memory: 5238  loss: 0.2261  decode.loss_ce: 0.2261  decode.acc_seg: 95.0928\n",
      "05/09 08:07:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [10900/57000]  base_lr: 5.6442e-05 lr: 5.6442e-05  eta: 7:33:57  time: 0.5710  data_time: 0.1645  memory: 5238  loss: 0.2077  decode.loss_ce: 0.2077  decode.acc_seg: 90.8800\n",
      "05/09 08:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 08:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11000/57000]  base_lr: 5.6404e-05 lr: 5.6404e-05  eta: 7:32:51  time: 0.5546  data_time: 0.1506  memory: 5238  loss: 0.1213  decode.loss_ce: 0.1213  decode.acc_seg: 84.6685\n",
      "05/09 08:09:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11100/57000]  base_lr: 5.6366e-05 lr: 5.6366e-05  eta: 7:31:48  time: 0.5664  data_time: 0.1615  memory: 5238  loss: 0.1525  decode.loss_ce: 0.1525  decode.acc_seg: 90.5779\n",
      "05/09 08:09:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11200/57000]  base_lr: 5.6328e-05 lr: 5.6328e-05  eta: 7:30:43  time: 0.5868  data_time: 0.1775  memory: 5238  loss: 0.2444  decode.loss_ce: 0.2444  decode.acc_seg: 94.5385\n",
      "05/09 08:10:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11300/57000]  base_lr: 5.6291e-05 lr: 5.6291e-05  eta: 7:29:37  time: 0.5691  data_time: 0.1661  memory: 5238  loss: 0.1501  decode.loss_ce: 0.1501  decode.acc_seg: 94.7677\n",
      "05/09 08:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11400/57000]  base_lr: 5.6253e-05 lr: 5.6253e-05  eta: 7:28:35  time: 0.5673  data_time: 0.1635  memory: 5238  loss: 0.1768  decode.loss_ce: 0.1768  decode.acc_seg: 98.5218\n",
      "05/09 08:12:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11500/57000]  base_lr: 5.6215e-05 lr: 5.6215e-05  eta: 7:27:33  time: 0.5634  data_time: 0.1601  memory: 5238  loss: 0.3230  decode.loss_ce: 0.3230  decode.acc_seg: 95.4916\n",
      "05/09 08:13:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11600/57000]  base_lr: 5.6177e-05 lr: 5.6177e-05  eta: 7:26:30  time: 0.5670  data_time: 0.1632  memory: 5238  loss: 0.1616  decode.loss_ce: 0.1616  decode.acc_seg: 93.2889\n",
      "05/09 08:14:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11700/57000]  base_lr: 5.6139e-05 lr: 5.6139e-05  eta: 7:25:28  time: 0.5742  data_time: 0.1689  memory: 5238  loss: 0.1294  decode.loss_ce: 0.1294  decode.acc_seg: 97.5628\n",
      "05/09 08:15:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11800/57000]  base_lr: 5.6101e-05 lr: 5.6101e-05  eta: 7:24:26  time: 0.5889  data_time: 0.1811  memory: 5238  loss: 0.1439  decode.loss_ce: 0.1439  decode.acc_seg: 90.2544\n",
      "05/09 08:16:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [11900/57000]  base_lr: 5.6063e-05 lr: 5.6063e-05  eta: 7:23:21  time: 0.5789  data_time: 0.1715  memory: 5238  loss: 0.2209  decode.loss_ce: 0.2209  decode.acc_seg: 99.2127\n",
      "05/09 08:17:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 08:17:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12000/57000]  base_lr: 5.6026e-05 lr: 5.6026e-05  eta: 7:22:19  time: 0.5684  data_time: 0.1650  memory: 5238  loss: 0.1345  decode.loss_ce: 0.1345  decode.acc_seg: 91.6352\n",
      "05/09 08:18:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:18  time: 0.3983  data_time: 0.2252  memory: 2589  \n",
      "05/09 08:19:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:39  time: 0.4428  data_time: 0.2702  memory: 2589  \n",
      "05/09 08:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3656  data_time: 0.1749  memory: 2577  \n",
      "05/09 08:20:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3680  data_time: 0.1833  memory: 2410  \n",
      "05/09 08:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 08:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 26.54 |  30.4 | 41.95 | 41.95  |   67.65   |  30.4  |\n",
      "| BuildingFlooded | 72.42 | 96.88 |  84.0 |  84.0  |   74.15   | 96.88  |\n",
      "|   BNonFlooded   | 77.63 | 87.88 |  87.4 |  87.4  |   86.93   | 87.88  |\n",
      "|   RoadFlooded   | 61.79 | 77.15 | 76.39 | 76.39  |   75.63   | 77.15  |\n",
      "|   RNonFlooded   | 81.22 | 90.68 | 89.64 | 89.64  |   88.62   | 90.68  |\n",
      "|      Water      | 70.31 | 87.34 | 82.57 | 82.57  |   78.29   | 87.34  |\n",
      "|       Tree      | 82.88 | 91.06 | 90.64 | 90.64  |   90.22   | 91.06  |\n",
      "|      Vecile     | 42.49 | 60.06 | 59.64 | 59.64  |   59.23   | 60.06  |\n",
      "|       Pool      | 54.55 | 81.82 | 70.59 | 70.59  |   62.07   | 81.82  |\n",
      "|      Grass      |  88.7 | 93.04 | 94.01 | 94.01  |   95.01   | 93.04  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 08:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 89.8600  mIoU: 65.8500  mAcc: 79.6300  mDice: 77.6800  mFscore: 77.6800  mPrecision: 77.7800  mRecall: 79.6300  data_time: 0.2059  time: 0.3861\n",
      "05/09 08:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_9000.pth is removed\n",
      "05/09 08:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 65.8500 mIoU at 12000 iter is saved to best_mIoU_iter_12000.pth.\n",
      "05/09 08:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12100/57000]  base_lr: 5.5988e-05 lr: 5.5988e-05  eta: 7:21:23  time: 0.5513  data_time: 0.1474  memory: 5238  loss: 0.3382  decode.loss_ce: 0.3382  decode.acc_seg: 94.3136\n",
      "05/09 08:22:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12200/57000]  base_lr: 5.5950e-05 lr: 5.5950e-05  eta: 7:20:23  time: 0.5750  data_time: 0.1707  memory: 5238  loss: 0.1685  decode.loss_ce: 0.1685  decode.acc_seg: 86.0112\n",
      "05/09 08:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12300/57000]  base_lr: 5.5912e-05 lr: 5.5912e-05  eta: 7:19:22  time: 0.6168  data_time: 0.2096  memory: 5238  loss: 0.1808  decode.loss_ce: 0.1808  decode.acc_seg: 94.7727\n",
      "05/09 08:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12400/57000]  base_lr: 5.5874e-05 lr: 5.5874e-05  eta: 7:18:19  time: 0.5905  data_time: 0.1862  memory: 5238  loss: 0.2128  decode.loss_ce: 0.2128  decode.acc_seg: 81.5864\n",
      "05/09 08:25:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12500/57000]  base_lr: 5.5836e-05 lr: 5.5836e-05  eta: 7:17:16  time: 0.5678  data_time: 0.1633  memory: 5238  loss: 0.1675  decode.loss_ce: 0.1675  decode.acc_seg: 96.2986\n",
      "05/09 08:26:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12600/57000]  base_lr: 5.5798e-05 lr: 5.5798e-05  eta: 7:16:16  time: 0.5907  data_time: 0.1858  memory: 5238  loss: 0.1886  decode.loss_ce: 0.1886  decode.acc_seg: 97.7301\n",
      "05/09 08:27:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12700/57000]  base_lr: 5.5761e-05 lr: 5.5761e-05  eta: 7:15:14  time: 0.5681  data_time: 0.1646  memory: 5238  loss: 0.1168  decode.loss_ce: 0.1168  decode.acc_seg: 94.3672\n",
      "05/09 08:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12800/57000]  base_lr: 5.5723e-05 lr: 5.5723e-05  eta: 7:14:10  time: 0.5529  data_time: 0.1493  memory: 5238  loss: 0.1171  decode.loss_ce: 0.1171  decode.acc_seg: 90.5096\n",
      "05/09 08:29:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [12900/57000]  base_lr: 5.5685e-05 lr: 5.5685e-05  eta: 7:13:07  time: 0.5888  data_time: 0.1824  memory: 5238  loss: 0.1259  decode.loss_ce: 0.1259  decode.acc_seg: 97.4183\n",
      "05/09 08:30:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 08:30:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13000/57000]  base_lr: 5.5647e-05 lr: 5.5647e-05  eta: 7:12:02  time: 0.5759  data_time: 0.1712  memory: 5238  loss: 0.1151  decode.loss_ce: 0.1151  decode.acc_seg: 98.7535\n",
      "05/09 08:31:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13100/57000]  base_lr: 5.5609e-05 lr: 5.5609e-05  eta: 7:10:59  time: 0.5638  data_time: 0.1588  memory: 5238  loss: 0.1238  decode.loss_ce: 0.1238  decode.acc_seg: 96.5736\n",
      "05/09 08:32:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13200/57000]  base_lr: 5.5571e-05 lr: 5.5571e-05  eta: 7:09:58  time: 0.5602  data_time: 0.1545  memory: 5238  loss: 0.1735  decode.loss_ce: 0.1735  decode.acc_seg: 96.2482\n",
      "05/09 08:33:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13300/57000]  base_lr: 5.5533e-05 lr: 5.5533e-05  eta: 7:09:00  time: 0.5767  data_time: 0.1728  memory: 5238  loss: 0.1392  decode.loss_ce: 0.1392  decode.acc_seg: 93.7760\n",
      "05/09 08:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13400/57000]  base_lr: 5.5496e-05 lr: 5.5496e-05  eta: 7:08:01  time: 0.5793  data_time: 0.1749  memory: 5238  loss: 0.2730  decode.loss_ce: 0.2730  decode.acc_seg: 91.0160\n",
      "05/09 08:35:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13500/57000]  base_lr: 5.5458e-05 lr: 5.5458e-05  eta: 7:06:58  time: 0.5711  data_time: 0.1636  memory: 5238  loss: 0.2873  decode.loss_ce: 0.2873  decode.acc_seg: 94.1083\n",
      "05/09 08:36:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13600/57000]  base_lr: 5.5420e-05 lr: 5.5420e-05  eta: 7:05:57  time: 0.6193  data_time: 0.2138  memory: 5238  loss: 0.2567  decode.loss_ce: 0.2567  decode.acc_seg: 98.5507\n",
      "05/09 08:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13700/57000]  base_lr: 5.5382e-05 lr: 5.5382e-05  eta: 7:04:58  time: 0.5945  data_time: 0.1885  memory: 5238  loss: 0.1399  decode.loss_ce: 0.1399  decode.acc_seg: 91.8716\n",
      "05/09 08:38:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13800/57000]  base_lr: 5.5344e-05 lr: 5.5344e-05  eta: 7:03:56  time: 0.5872  data_time: 0.1809  memory: 5238  loss: 0.1247  decode.loss_ce: 0.1247  decode.acc_seg: 97.3385\n",
      "05/09 08:39:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [13900/57000]  base_lr: 5.5306e-05 lr: 5.5306e-05  eta: 7:02:56  time: 0.5746  data_time: 0.1709  memory: 5238  loss: 0.2769  decode.loss_ce: 0.2769  decode.acc_seg: 86.4993\n",
      "05/09 08:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 08:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14000/57000]  base_lr: 5.5268e-05 lr: 5.5268e-05  eta: 7:01:55  time: 0.5731  data_time: 0.1688  memory: 5238  loss: 0.1901  decode.loss_ce: 0.1901  decode.acc_seg: 94.7483\n",
      "05/09 08:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14100/57000]  base_lr: 5.5231e-05 lr: 5.5231e-05  eta: 7:00:54  time: 0.5812  data_time: 0.1772  memory: 5238  loss: 0.2134  decode.loss_ce: 0.2134  decode.acc_seg: 88.1817\n",
      "05/09 08:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14200/57000]  base_lr: 5.5193e-05 lr: 5.5193e-05  eta: 6:59:55  time: 0.5724  data_time: 0.1670  memory: 5238  loss: 0.1479  decode.loss_ce: 0.1479  decode.acc_seg: 96.5068\n",
      "05/09 08:42:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14300/57000]  base_lr: 5.5155e-05 lr: 5.5155e-05  eta: 6:58:57  time: 0.6098  data_time: 0.2036  memory: 5238  loss: 0.1613  decode.loss_ce: 0.1613  decode.acc_seg: 92.9369\n",
      "05/09 08:43:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14400/57000]  base_lr: 5.5117e-05 lr: 5.5117e-05  eta: 6:57:57  time: 0.6057  data_time: 0.1968  memory: 5238  loss: 0.1015  decode.loss_ce: 0.1015  decode.acc_seg: 96.9229\n",
      "05/09 08:44:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14500/57000]  base_lr: 5.5079e-05 lr: 5.5079e-05  eta: 6:56:55  time: 0.5569  data_time: 0.1536  memory: 5238  loss: 0.1710  decode.loss_ce: 0.1710  decode.acc_seg: 95.5463\n",
      "05/09 08:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14600/57000]  base_lr: 5.5041e-05 lr: 5.5041e-05  eta: 6:55:55  time: 0.5608  data_time: 0.1575  memory: 5238  loss: 0.1963  decode.loss_ce: 0.1963  decode.acc_seg: 96.3382\n",
      "05/09 08:46:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14700/57000]  base_lr: 5.5004e-05 lr: 5.5004e-05  eta: 6:54:52  time: 0.5633  data_time: 0.1594  memory: 5238  loss: 0.0886  decode.loss_ce: 0.0886  decode.acc_seg: 95.7433\n",
      "05/09 08:47:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14800/57000]  base_lr: 5.4966e-05 lr: 5.4966e-05  eta: 6:53:50  time: 0.5704  data_time: 0.1645  memory: 5238  loss: 0.2336  decode.loss_ce: 0.2336  decode.acc_seg: 93.0318\n",
      "05/09 08:48:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [14900/57000]  base_lr: 5.4928e-05 lr: 5.4928e-05  eta: 6:52:56  time: 0.5734  data_time: 0.1674  memory: 5238  loss: 0.1391  decode.loss_ce: 0.1391  decode.acc_seg: 94.6872\n",
      "05/09 08:49:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 08:49:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15000/57000]  base_lr: 5.4890e-05 lr: 5.4890e-05  eta: 6:51:54  time: 0.5906  data_time: 0.1872  memory: 5238  loss: 0.1679  decode.loss_ce: 0.1679  decode.acc_seg: 96.4999\n",
      "05/09 08:50:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:16  time: 0.3710  data_time: 0.1988  memory: 2587  \n",
      "05/09 08:51:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:38  time: 0.4477  data_time: 0.2762  memory: 2589  \n",
      "05/09 08:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3883  data_time: 0.1966  memory: 2577  \n",
      "05/09 08:52:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3634  data_time: 0.1791  memory: 2410  \n",
      "05/09 08:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 08:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   |  49.5 | 57.76 | 66.22 | 66.22  |   77.59   | 57.76  |\n",
      "| BuildingFlooded | 75.08 | 90.61 | 85.77 | 85.77  |   81.42   | 90.61  |\n",
      "|   BNonFlooded   | 78.02 | 88.75 | 87.65 | 87.65  |   86.58   | 88.75  |\n",
      "|   RoadFlooded   | 60.64 | 81.76 |  75.5 |  75.5  |   70.13   | 81.76  |\n",
      "|   RNonFlooded   | 81.32 | 88.21 |  89.7 |  89.7  |   91.24   | 88.21  |\n",
      "|      Water      | 71.65 | 83.74 | 83.49 | 83.49  |   83.23   | 83.74  |\n",
      "|       Tree      |  83.0 | 92.76 | 90.71 | 90.71  |   88.74   | 92.76  |\n",
      "|      Vecile     | 44.43 | 61.97 | 61.52 | 61.52  |   61.08   | 61.97  |\n",
      "|       Pool      | 54.99 |  79.0 | 70.96 | 70.96  |   64.41   |  79.0  |\n",
      "|      Grass      | 88.09 | 92.84 | 93.67 | 93.67  |   94.51   | 92.84  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 08:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.1700  mIoU: 68.6700  mAcc: 81.7400  mDice: 80.5200  mFscore: 80.5200  mPrecision: 79.8900  mRecall: 81.7400  data_time: 0.2050  time: 0.3852\n",
      "05/09 08:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_12000.pth is removed\n",
      "05/09 08:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 68.6700 mIoU at 15000 iter is saved to best_mIoU_iter_15000.pth.\n",
      "05/09 08:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15100/57000]  base_lr: 5.4852e-05 lr: 5.4852e-05  eta: 6:51:01  time: 0.5814  data_time: 0.1778  memory: 5238  loss: 0.2446  decode.loss_ce: 0.2446  decode.acc_seg: 87.7905\n",
      "05/09 08:54:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15200/57000]  base_lr: 5.4814e-05 lr: 5.4814e-05  eta: 6:49:59  time: 0.5842  data_time: 0.1796  memory: 5238  loss: 0.1686  decode.loss_ce: 0.1686  decode.acc_seg: 78.6829\n",
      "05/09 08:55:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15300/57000]  base_lr: 5.4776e-05 lr: 5.4776e-05  eta: 6:48:59  time: 0.5567  data_time: 0.1534  memory: 5238  loss: 0.1402  decode.loss_ce: 0.1402  decode.acc_seg: 95.7538\n",
      "05/09 08:56:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15400/57000]  base_lr: 5.4739e-05 lr: 5.4739e-05  eta: 6:47:59  time: 0.5724  data_time: 0.1682  memory: 5238  loss: 0.2074  decode.loss_ce: 0.2074  decode.acc_seg: 96.6290\n",
      "05/09 08:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15500/57000]  base_lr: 5.4701e-05 lr: 5.4701e-05  eta: 6:46:58  time: 0.5835  data_time: 0.1788  memory: 5238  loss: 0.1493  decode.loss_ce: 0.1493  decode.acc_seg: 96.5258\n",
      "05/09 08:58:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15600/57000]  base_lr: 5.4663e-05 lr: 5.4663e-05  eta: 6:45:58  time: 0.5911  data_time: 0.1843  memory: 5238  loss: 0.1483  decode.loss_ce: 0.1483  decode.acc_seg: 97.0351\n",
      "05/09 08:59:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15700/57000]  base_lr: 5.4625e-05 lr: 5.4625e-05  eta: 6:44:55  time: 0.5858  data_time: 0.1789  memory: 5238  loss: 0.1898  decode.loss_ce: 0.1898  decode.acc_seg: 72.7234\n",
      "05/09 09:00:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15800/57000]  base_lr: 5.4587e-05 lr: 5.4587e-05  eta: 6:43:55  time: 0.5656  data_time: 0.1590  memory: 5238  loss: 0.1767  decode.loss_ce: 0.1767  decode.acc_seg: 75.0633\n",
      "05/09 09:01:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [15900/57000]  base_lr: 5.4549e-05 lr: 5.4549e-05  eta: 6:42:54  time: 0.5792  data_time: 0.1754  memory: 5238  loss: 0.1305  decode.loss_ce: 0.1305  decode.acc_seg: 97.5484\n",
      "05/09 09:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 09:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16000/57000]  base_lr: 5.4511e-05 lr: 5.4511e-05  eta: 6:41:54  time: 0.5997  data_time: 0.1951  memory: 5238  loss: 0.3528  decode.loss_ce: 0.3528  decode.acc_seg: 86.6171\n",
      "05/09 09:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16000 iterations\n",
      "05/09 09:03:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16100/57000]  base_lr: 5.4474e-05 lr: 5.4474e-05  eta: 6:41:08  time: 0.6266  data_time: 0.2165  memory: 5238  loss: 0.2812  decode.loss_ce: 0.2812  decode.acc_seg: 96.0709\n",
      "05/09 09:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16200/57000]  base_lr: 5.4436e-05 lr: 5.4436e-05  eta: 6:40:12  time: 0.5985  data_time: 0.1905  memory: 5238  loss: 0.0863  decode.loss_ce: 0.0863  decode.acc_seg: 96.8614\n",
      "05/09 09:05:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16300/57000]  base_lr: 5.4398e-05 lr: 5.4398e-05  eta: 6:39:14  time: 0.5911  data_time: 0.1851  memory: 5238  loss: 0.4226  decode.loss_ce: 0.4226  decode.acc_seg: 97.0238\n",
      "05/09 09:06:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16400/57000]  base_lr: 5.4360e-05 lr: 5.4360e-05  eta: 6:38:12  time: 0.5903  data_time: 0.1822  memory: 5238  loss: 0.2045  decode.loss_ce: 0.2045  decode.acc_seg: 98.2593\n",
      "05/09 09:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16500/57000]  base_lr: 5.4322e-05 lr: 5.4322e-05  eta: 6:37:12  time: 0.5969  data_time: 0.1904  memory: 5238  loss: 0.1664  decode.loss_ce: 0.1664  decode.acc_seg: 87.0255\n",
      "05/09 09:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16600/57000]  base_lr: 5.4284e-05 lr: 5.4284e-05  eta: 6:36:12  time: 0.5878  data_time: 0.1823  memory: 5238  loss: 0.1903  decode.loss_ce: 0.1903  decode.acc_seg: 91.0496\n",
      "05/09 09:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16700/57000]  base_lr: 5.4246e-05 lr: 5.4246e-05  eta: 6:35:15  time: 0.5883  data_time: 0.1831  memory: 5238  loss: 0.1845  decode.loss_ce: 0.1845  decode.acc_seg: 85.4882\n",
      "05/09 09:10:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16800/57000]  base_lr: 5.4209e-05 lr: 5.4209e-05  eta: 6:34:16  time: 0.5737  data_time: 0.1664  memory: 5238  loss: 0.2003  decode.loss_ce: 0.2003  decode.acc_seg: 93.6543\n",
      "05/09 09:11:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [16900/57000]  base_lr: 5.4171e-05 lr: 5.4171e-05  eta: 6:33:15  time: 0.5865  data_time: 0.1820  memory: 5238  loss: 0.1294  decode.loss_ce: 0.1294  decode.acc_seg: 90.3819\n",
      "05/09 09:12:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 09:12:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17000/57000]  base_lr: 5.4133e-05 lr: 5.4133e-05  eta: 6:32:14  time: 0.5763  data_time: 0.1715  memory: 5238  loss: 0.1569  decode.loss_ce: 0.1569  decode.acc_seg: 70.6682\n",
      "05/09 09:13:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17100/57000]  base_lr: 5.4095e-05 lr: 5.4095e-05  eta: 6:31:16  time: 0.5837  data_time: 0.1797  memory: 5238  loss: 0.1747  decode.loss_ce: 0.1747  decode.acc_seg: 88.8428\n",
      "05/09 09:14:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17200/57000]  base_lr: 5.4057e-05 lr: 5.4057e-05  eta: 6:30:16  time: 0.6009  data_time: 0.1875  memory: 5238  loss: 0.1642  decode.loss_ce: 0.1642  decode.acc_seg: 92.4059\n",
      "05/09 09:15:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17300/57000]  base_lr: 5.4019e-05 lr: 5.4019e-05  eta: 6:29:18  time: 0.6101  data_time: 0.1996  memory: 5238  loss: 0.1944  decode.loss_ce: 0.1944  decode.acc_seg: 98.8598\n",
      "05/09 09:16:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17400/57000]  base_lr: 5.3981e-05 lr: 5.3981e-05  eta: 6:28:17  time: 0.5668  data_time: 0.1619  memory: 5238  loss: 0.1147  decode.loss_ce: 0.1147  decode.acc_seg: 92.2587\n",
      "05/09 09:17:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17500/57000]  base_lr: 5.3944e-05 lr: 5.3944e-05  eta: 6:27:19  time: 0.6095  data_time: 0.2022  memory: 5238  loss: 0.1719  decode.loss_ce: 0.1719  decode.acc_seg: 95.4157\n",
      "05/09 09:18:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17600/57000]  base_lr: 5.3906e-05 lr: 5.3906e-05  eta: 6:26:20  time: 0.5645  data_time: 0.1598  memory: 5238  loss: 0.1005  decode.loss_ce: 0.1005  decode.acc_seg: 94.7503\n",
      "05/09 09:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17700/57000]  base_lr: 5.3868e-05 lr: 5.3868e-05  eta: 6:25:19  time: 0.5635  data_time: 0.1583  memory: 5238  loss: 0.1069  decode.loss_ce: 0.1069  decode.acc_seg: 93.7234\n",
      "05/09 09:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17800/57000]  base_lr: 5.3830e-05 lr: 5.3830e-05  eta: 6:24:21  time: 0.5824  data_time: 0.1777  memory: 5238  loss: 0.1456  decode.loss_ce: 0.1456  decode.acc_seg: 95.4540\n",
      "05/09 09:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [17900/57000]  base_lr: 5.3792e-05 lr: 5.3792e-05  eta: 6:23:23  time: 0.5821  data_time: 0.1755  memory: 5238  loss: 0.1684  decode.loss_ce: 0.1684  decode.acc_seg: 91.2473\n",
      "05/09 09:22:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 09:22:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18000/57000]  base_lr: 5.3754e-05 lr: 5.3754e-05  eta: 6:22:26  time: 0.6228  data_time: 0.2163  memory: 5238  loss: 0.2617  decode.loss_ce: 0.2617  decode.acc_seg: 83.9930\n",
      "05/09 09:22:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:19  time: 0.3802  data_time: 0.2072  memory: 2586  \n",
      "05/09 09:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:40  time: 0.4487  data_time: 0.2787  memory: 2589  \n",
      "05/09 09:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:59  time: 0.3780  data_time: 0.1864  memory: 2578  \n",
      "05/09 09:24:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3736  data_time: 0.1889  memory: 2410  \n",
      "05/09 09:24:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 09:24:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 33.53 |  58.9 | 50.22 | 50.22  |   43.77   |  58.9  |\n",
      "| BuildingFlooded | 75.08 | 91.46 | 85.77 | 85.77  |   80.74   | 91.46  |\n",
      "|   BNonFlooded   | 77.96 | 88.53 | 87.62 | 87.62  |   86.73   | 88.53  |\n",
      "|   RoadFlooded   | 59.79 | 79.42 | 74.84 | 74.84  |   70.75   | 79.42  |\n",
      "|   RNonFlooded   | 80.44 | 89.73 | 89.16 | 89.16  |    88.6   | 89.73  |\n",
      "|      Water      | 71.89 | 80.68 | 83.65 | 83.65  |   86.84   | 80.68  |\n",
      "|       Tree      | 84.52 | 92.32 | 91.61 | 91.61  |   90.91   | 92.32  |\n",
      "|      Vecile     | 45.75 | 62.39 | 62.78 | 62.78  |   63.17   | 62.39  |\n",
      "|       Pool      |  57.8 | 72.79 | 73.26 | 73.26  |   73.73   | 72.79  |\n",
      "|      Grass      | 87.93 |  92.7 | 93.58 | 93.58  |   94.48   |  92.7  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 09:24:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 89.7100  mIoU: 67.4700  mAcc: 80.8900  mDice: 79.2500  mFscore: 79.2500  mPrecision: 77.9700  mRecall: 80.8900  data_time: 0.2109  time: 0.3912\n",
      "05/09 09:25:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18100/57000]  base_lr: 5.3716e-05 lr: 5.3716e-05  eta: 6:21:26  time: 0.5769  data_time: 0.1694  memory: 5238  loss: 0.1346  decode.loss_ce: 0.1346  decode.acc_seg: 96.6467\n",
      "05/09 09:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18200/57000]  base_lr: 5.3679e-05 lr: 5.3679e-05  eta: 6:20:31  time: 0.6183  data_time: 0.2083  memory: 5238  loss: 0.1177  decode.loss_ce: 0.1177  decode.acc_seg: 93.2058\n",
      "05/09 09:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18300/57000]  base_lr: 5.3641e-05 lr: 5.3641e-05  eta: 6:19:36  time: 0.5916  data_time: 0.1808  memory: 5238  loss: 0.1323  decode.loss_ce: 0.1323  decode.acc_seg: 94.0729\n",
      "05/09 09:28:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18400/57000]  base_lr: 5.3603e-05 lr: 5.3603e-05  eta: 6:18:38  time: 0.5974  data_time: 0.1920  memory: 5238  loss: 0.3272  decode.loss_ce: 0.3272  decode.acc_seg: 92.0828\n",
      "05/09 09:29:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18500/57000]  base_lr: 5.3565e-05 lr: 5.3565e-05  eta: 6:17:42  time: 0.6148  data_time: 0.2083  memory: 5238  loss: 0.1811  decode.loss_ce: 0.1811  decode.acc_seg: 94.4875\n",
      "05/09 09:30:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18600/57000]  base_lr: 5.3527e-05 lr: 5.3527e-05  eta: 6:16:47  time: 0.6014  data_time: 0.1961  memory: 5238  loss: 0.4520  decode.loss_ce: 0.4520  decode.acc_seg: 85.8958\n",
      "05/09 09:31:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18700/57000]  base_lr: 5.3489e-05 lr: 5.3489e-05  eta: 6:15:51  time: 0.6410  data_time: 0.2338  memory: 5238  loss: 0.1706  decode.loss_ce: 0.1706  decode.acc_seg: 82.4471\n",
      "05/09 09:32:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18800/57000]  base_lr: 5.3451e-05 lr: 5.3451e-05  eta: 6:14:54  time: 0.6101  data_time: 0.1983  memory: 5238  loss: 0.1152  decode.loss_ce: 0.1152  decode.acc_seg: 87.9650\n",
      "05/09 09:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [18900/57000]  base_lr: 5.3414e-05 lr: 5.3414e-05  eta: 6:13:55  time: 0.5831  data_time: 0.1784  memory: 5238  loss: 0.2092  decode.loss_ce: 0.2092  decode.acc_seg: 89.4477\n",
      "05/09 09:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 09:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19000/57000]  base_lr: 5.3376e-05 lr: 5.3376e-05  eta: 6:12:57  time: 0.5920  data_time: 0.1861  memory: 5238  loss: 0.2536  decode.loss_ce: 0.2536  decode.acc_seg: 82.2266\n",
      "05/09 09:35:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19100/57000]  base_lr: 5.3338e-05 lr: 5.3338e-05  eta: 6:11:57  time: 0.5871  data_time: 0.1820  memory: 5238  loss: 0.1861  decode.loss_ce: 0.1861  decode.acc_seg: 95.3219\n",
      "05/09 09:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19200/57000]  base_lr: 5.3300e-05 lr: 5.3300e-05  eta: 6:10:59  time: 0.5715  data_time: 0.1660  memory: 5238  loss: 0.0997  decode.loss_ce: 0.0997  decode.acc_seg: 95.4911\n",
      "05/09 09:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19300/57000]  base_lr: 5.3262e-05 lr: 5.3262e-05  eta: 6:10:01  time: 0.5699  data_time: 0.1658  memory: 5238  loss: 0.1830  decode.loss_ce: 0.1830  decode.acc_seg: 90.8344\n",
      "05/09 09:38:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19400/57000]  base_lr: 5.3224e-05 lr: 5.3224e-05  eta: 6:09:01  time: 0.5787  data_time: 0.1717  memory: 5238  loss: 0.1268  decode.loss_ce: 0.1268  decode.acc_seg: 96.9138\n",
      "05/09 09:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19500/57000]  base_lr: 5.3186e-05 lr: 5.3186e-05  eta: 6:08:02  time: 0.5768  data_time: 0.1719  memory: 5238  loss: 0.1434  decode.loss_ce: 0.1434  decode.acc_seg: 91.8046\n",
      "05/09 09:40:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19600/57000]  base_lr: 5.3149e-05 lr: 5.3149e-05  eta: 6:07:03  time: 0.5905  data_time: 0.1812  memory: 5238  loss: 0.1319  decode.loss_ce: 0.1319  decode.acc_seg: 98.6341\n",
      "05/09 09:41:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19700/57000]  base_lr: 5.3111e-05 lr: 5.3111e-05  eta: 6:06:04  time: 0.5761  data_time: 0.1658  memory: 5238  loss: 0.2044  decode.loss_ce: 0.2044  decode.acc_seg: 72.0345\n",
      "05/09 09:42:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19800/57000]  base_lr: 5.3073e-05 lr: 5.3073e-05  eta: 6:05:06  time: 0.5897  data_time: 0.1834  memory: 5238  loss: 0.2012  decode.loss_ce: 0.2012  decode.acc_seg: 96.1126\n",
      "05/09 09:43:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [19900/57000]  base_lr: 5.3035e-05 lr: 5.3035e-05  eta: 6:04:08  time: 0.5954  data_time: 0.1906  memory: 5238  loss: 0.1348  decode.loss_ce: 0.1348  decode.acc_seg: 85.3034\n",
      "05/09 09:44:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 09:44:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20000/57000]  base_lr: 5.2997e-05 lr: 5.2997e-05  eta: 6:03:09  time: 0.5788  data_time: 0.1728  memory: 5238  loss: 0.0888  decode.loss_ce: 0.0888  decode.acc_seg: 95.3866\n",
      "05/09 09:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20100/57000]  base_lr: 5.2959e-05 lr: 5.2959e-05  eta: 6:02:10  time: 0.6212  data_time: 0.2144  memory: 5238  loss: 0.1293  decode.loss_ce: 0.1293  decode.acc_seg: 85.7979\n",
      "05/09 09:46:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20200/57000]  base_lr: 5.2921e-05 lr: 5.2921e-05  eta: 6:01:13  time: 0.5945  data_time: 0.1893  memory: 5238  loss: 0.1821  decode.loss_ce: 0.1821  decode.acc_seg: 79.9934\n",
      "05/09 09:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20300/57000]  base_lr: 5.2884e-05 lr: 5.2884e-05  eta: 6:00:14  time: 0.5827  data_time: 0.1772  memory: 5238  loss: 0.1266  decode.loss_ce: 0.1266  decode.acc_seg: 99.1899\n",
      "05/09 09:48:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20400/57000]  base_lr: 5.2846e-05 lr: 5.2846e-05  eta: 5:59:15  time: 0.6065  data_time: 0.1997  memory: 5238  loss: 0.1311  decode.loss_ce: 0.1311  decode.acc_seg: 96.4879\n",
      "05/09 09:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20500/57000]  base_lr: 5.2808e-05 lr: 5.2808e-05  eta: 5:58:15  time: 0.5754  data_time: 0.1657  memory: 5238  loss: 0.1539  decode.loss_ce: 0.1539  decode.acc_seg: 98.4528\n",
      "05/09 09:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20600/57000]  base_lr: 5.2770e-05 lr: 5.2770e-05  eta: 5:57:17  time: 0.5968  data_time: 0.1913  memory: 5238  loss: 0.1829  decode.loss_ce: 0.1829  decode.acc_seg: 89.7241\n",
      "05/09 09:51:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20700/57000]  base_lr: 5.2732e-05 lr: 5.2732e-05  eta: 5:56:18  time: 0.5635  data_time: 0.1583  memory: 5238  loss: 0.1318  decode.loss_ce: 0.1318  decode.acc_seg: 93.8235\n",
      "05/09 09:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20800/57000]  base_lr: 5.2694e-05 lr: 5.2694e-05  eta: 5:55:18  time: 0.5763  data_time: 0.1718  memory: 5238  loss: 0.1939  decode.loss_ce: 0.1939  decode.acc_seg: 95.6925\n",
      "05/09 09:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [20900/57000]  base_lr: 5.2656e-05 lr: 5.2656e-05  eta: 5:54:18  time: 0.5880  data_time: 0.1804  memory: 5238  loss: 0.2008  decode.loss_ce: 0.2008  decode.acc_seg: 91.1137\n",
      "05/09 09:54:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 09:54:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21000/57000]  base_lr: 5.2619e-05 lr: 5.2619e-05  eta: 5:53:17  time: 0.5842  data_time: 0.1790  memory: 5238  loss: 0.1296  decode.loss_ce: 0.1296  decode.acc_seg: 96.2557\n",
      "05/09 09:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:17  time: 0.3744  data_time: 0.2009  memory: 2587  \n",
      "05/09 09:55:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:39  time: 0.4559  data_time: 0.2859  memory: 2589  \n",
      "05/09 09:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:59  time: 0.3791  data_time: 0.1876  memory: 2578  \n",
      "05/09 09:57:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3734  data_time: 0.1882  memory: 2410  \n",
      "05/09 09:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 09:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 48.46 | 58.13 | 65.28 | 65.28  |   74.44   | 58.13  |\n",
      "| BuildingFlooded | 73.88 | 89.04 | 84.98 | 84.98  |   81.28   | 89.04  |\n",
      "|   BNonFlooded   |  77.4 | 87.26 | 87.26 | 87.26  |   87.25   | 87.26  |\n",
      "|   RoadFlooded   | 56.29 |  77.0 | 72.03 | 72.03  |   67.66   |  77.0  |\n",
      "|   RNonFlooded   |  81.8 | 90.72 | 89.99 | 89.99  |   89.28   | 90.72  |\n",
      "|      Water      | 67.24 | 85.54 | 80.41 | 80.41  |   75.86   | 85.54  |\n",
      "|       Tree      | 83.63 | 92.71 | 91.08 | 91.08  |   89.51   | 92.71  |\n",
      "|      Vecile     | 46.13 | 59.17 | 63.14 | 63.14  |   67.67   | 59.17  |\n",
      "|       Pool      | 61.23 | 70.72 | 75.95 | 75.95  |   82.03   | 70.72  |\n",
      "|      Grass      | 88.25 | 91.81 | 93.76 | 93.76  |   95.78   | 91.81  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 09:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 89.7400  mIoU: 68.4300  mAcc: 80.2100  mDice: 80.3900  mFscore: 80.3900  mPrecision: 81.0800  mRecall: 80.2100  data_time: 0.2106  time: 0.3911\n",
      "05/09 09:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21100/57000]  base_lr: 5.2581e-05 lr: 5.2581e-05  eta: 5:52:16  time: 0.5880  data_time: 0.1812  memory: 5238  loss: 0.0987  decode.loss_ce: 0.0987  decode.acc_seg: 92.9476\n",
      "05/09 09:59:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21200/57000]  base_lr: 5.2543e-05 lr: 5.2543e-05  eta: 5:51:17  time: 0.5782  data_time: 0.1733  memory: 5238  loss: 0.1265  decode.loss_ce: 0.1265  decode.acc_seg: 95.1062\n",
      "05/09 10:00:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21300/57000]  base_lr: 5.2505e-05 lr: 5.2505e-05  eta: 5:50:18  time: 0.5687  data_time: 0.1636  memory: 5238  loss: 0.1359  decode.loss_ce: 0.1359  decode.acc_seg: 96.2635\n",
      "05/09 10:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21400/57000]  base_lr: 5.2467e-05 lr: 5.2467e-05  eta: 5:49:17  time: 0.5701  data_time: 0.1660  memory: 5238  loss: 0.1563  decode.loss_ce: 0.1563  decode.acc_seg: 94.7443\n",
      "05/09 10:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21500/57000]  base_lr: 5.2429e-05 lr: 5.2429e-05  eta: 5:48:19  time: 0.5795  data_time: 0.1752  memory: 5238  loss: 0.2119  decode.loss_ce: 0.2119  decode.acc_seg: 95.4127\n",
      "05/09 10:03:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21600/57000]  base_lr: 5.2391e-05 lr: 5.2391e-05  eta: 5:47:20  time: 0.5563  data_time: 0.1516  memory: 5238  loss: 0.1038  decode.loss_ce: 0.1038  decode.acc_seg: 91.8084\n",
      "05/09 10:04:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21700/57000]  base_lr: 5.2354e-05 lr: 5.2354e-05  eta: 5:46:21  time: 0.5866  data_time: 0.1766  memory: 5238  loss: 0.1185  decode.loss_ce: 0.1185  decode.acc_seg: 94.4259\n",
      "05/09 10:05:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21800/57000]  base_lr: 5.2316e-05 lr: 5.2316e-05  eta: 5:45:21  time: 0.5749  data_time: 0.1701  memory: 5238  loss: 0.1174  decode.loss_ce: 0.1174  decode.acc_seg: 91.0850\n",
      "05/09 10:06:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [21900/57000]  base_lr: 5.2278e-05 lr: 5.2278e-05  eta: 5:44:25  time: 0.6087  data_time: 0.2025  memory: 5238  loss: 0.2202  decode.loss_ce: 0.2202  decode.acc_seg: 95.8864\n",
      "05/09 10:07:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 10:07:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22000/57000]  base_lr: 5.2240e-05 lr: 5.2240e-05  eta: 5:43:27  time: 0.5827  data_time: 0.1755  memory: 5238  loss: 0.1552  decode.loss_ce: 0.1552  decode.acc_seg: 78.5788\n",
      "05/09 10:08:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22100/57000]  base_lr: 5.2202e-05 lr: 5.2202e-05  eta: 5:42:28  time: 0.5843  data_time: 0.1791  memory: 5238  loss: 0.0939  decode.loss_ce: 0.0939  decode.acc_seg: 89.7255\n",
      "05/09 10:09:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22200/57000]  base_lr: 5.2164e-05 lr: 5.2164e-05  eta: 5:41:29  time: 0.5977  data_time: 0.1919  memory: 5238  loss: 0.1299  decode.loss_ce: 0.1299  decode.acc_seg: 95.9362\n",
      "05/09 10:10:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22300/57000]  base_lr: 5.2127e-05 lr: 5.2127e-05  eta: 5:40:30  time: 0.5866  data_time: 0.1808  memory: 5238  loss: 0.2736  decode.loss_ce: 0.2736  decode.acc_seg: 70.6544\n",
      "05/09 10:11:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22400/57000]  base_lr: 5.2089e-05 lr: 5.2089e-05  eta: 5:39:30  time: 0.5622  data_time: 0.1576  memory: 5238  loss: 0.1053  decode.loss_ce: 0.1053  decode.acc_seg: 93.6850\n",
      "05/09 10:12:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22500/57000]  base_lr: 5.2051e-05 lr: 5.2051e-05  eta: 5:38:30  time: 0.5777  data_time: 0.1701  memory: 5238  loss: 0.1270  decode.loss_ce: 0.1270  decode.acc_seg: 94.6984\n",
      "05/09 10:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22600/57000]  base_lr: 5.2013e-05 lr: 5.2013e-05  eta: 5:37:29  time: 0.5898  data_time: 0.1831  memory: 5238  loss: 0.2555  decode.loss_ce: 0.2555  decode.acc_seg: 91.0455\n",
      "05/09 10:14:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22700/57000]  base_lr: 5.1975e-05 lr: 5.1975e-05  eta: 5:36:28  time: 0.5769  data_time: 0.1733  memory: 5238  loss: 0.1316  decode.loss_ce: 0.1316  decode.acc_seg: 94.2008\n",
      "05/09 10:15:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22800/57000]  base_lr: 5.1937e-05 lr: 5.1937e-05  eta: 5:35:27  time: 0.5764  data_time: 0.1696  memory: 5238  loss: 0.1598  decode.loss_ce: 0.1598  decode.acc_seg: 94.2228\n",
      "05/09 10:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [22900/57000]  base_lr: 5.1899e-05 lr: 5.1899e-05  eta: 5:34:28  time: 0.5985  data_time: 0.1923  memory: 5238  loss: 0.2388  decode.loss_ce: 0.2388  decode.acc_seg: 97.6505\n",
      "05/09 10:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 10:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23000/57000]  base_lr: 5.1862e-05 lr: 5.1862e-05  eta: 5:33:29  time: 0.5907  data_time: 0.1851  memory: 5238  loss: 0.1310  decode.loss_ce: 0.1310  decode.acc_seg: 96.1851\n",
      "05/09 10:17:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23100/57000]  base_lr: 5.1824e-05 lr: 5.1824e-05  eta: 5:32:28  time: 0.5643  data_time: 0.1609  memory: 5238  loss: 0.1285  decode.loss_ce: 0.1285  decode.acc_seg: 93.9412\n",
      "05/09 10:18:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23200/57000]  base_lr: 5.1786e-05 lr: 5.1786e-05  eta: 5:31:29  time: 0.5946  data_time: 0.1866  memory: 5238  loss: 0.1630  decode.loss_ce: 0.1630  decode.acc_seg: 84.8029\n",
      "05/09 10:19:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23300/57000]  base_lr: 5.1748e-05 lr: 5.1748e-05  eta: 5:30:28  time: 0.5721  data_time: 0.1686  memory: 5238  loss: 0.1384  decode.loss_ce: 0.1384  decode.acc_seg: 96.9731\n",
      "05/09 10:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23400/57000]  base_lr: 5.1710e-05 lr: 5.1710e-05  eta: 5:29:27  time: 0.5672  data_time: 0.1653  memory: 5238  loss: 0.1202  decode.loss_ce: 0.1202  decode.acc_seg: 93.3623\n",
      "05/09 10:21:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23500/57000]  base_lr: 5.1672e-05 lr: 5.1672e-05  eta: 5:28:25  time: 0.5648  data_time: 0.1614  memory: 5238  loss: 0.1028  decode.loss_ce: 0.1028  decode.acc_seg: 98.3288\n",
      "05/09 10:22:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23600/57000]  base_lr: 5.1634e-05 lr: 5.1634e-05  eta: 5:27:24  time: 0.5560  data_time: 0.1521  memory: 5238  loss: 0.1397  decode.loss_ce: 0.1397  decode.acc_seg: 96.9547\n",
      "05/09 10:23:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23700/57000]  base_lr: 5.1597e-05 lr: 5.1597e-05  eta: 5:26:23  time: 0.5685  data_time: 0.1663  memory: 5238  loss: 0.0789  decode.loss_ce: 0.0789  decode.acc_seg: 97.7419\n",
      "05/09 10:24:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23800/57000]  base_lr: 5.1559e-05 lr: 5.1559e-05  eta: 5:25:22  time: 0.5800  data_time: 0.1715  memory: 5238  loss: 0.1318  decode.loss_ce: 0.1318  decode.acc_seg: 97.0556\n",
      "05/09 10:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [23900/57000]  base_lr: 5.1521e-05 lr: 5.1521e-05  eta: 5:24:22  time: 0.5963  data_time: 0.1931  memory: 5238  loss: 0.1089  decode.loss_ce: 0.1089  decode.acc_seg: 94.5921\n",
      "05/09 10:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 10:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24000/57000]  base_lr: 5.1483e-05 lr: 5.1483e-05  eta: 5:23:21  time: 0.5627  data_time: 0.1598  memory: 5238  loss: 0.1386  decode.loss_ce: 0.1386  decode.acc_seg: 97.3173\n",
      "05/09 10:27:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:15  time: 0.3724  data_time: 0.1994  memory: 2588  \n",
      "05/09 10:27:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4365  data_time: 0.2655  memory: 2590  \n",
      "05/09 10:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3663  data_time: 0.1759  memory: 2578  \n",
      "05/09 10:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3669  data_time: 0.1824  memory: 2410  \n",
      "05/09 10:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 10:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   |  47.3 | 62.56 | 64.23 | 64.23  |   65.99   | 62.56  |\n",
      "| BuildingFlooded | 74.62 | 85.56 | 85.47 | 85.47  |   85.38   | 85.56  |\n",
      "|   BNonFlooded   | 77.89 | 89.65 | 87.57 | 87.57  |   85.59   | 89.65  |\n",
      "|   RoadFlooded   | 61.56 | 82.55 | 76.21 | 76.21  |   70.77   | 82.55  |\n",
      "|   RNonFlooded   |  82.3 | 90.62 | 90.29 | 90.29  |   89.97   | 90.62  |\n",
      "|      Water      | 74.72 | 84.06 | 85.53 | 85.53  |   87.06   | 84.06  |\n",
      "|       Tree      |  84.3 | 91.45 | 91.48 | 91.48  |   91.51   | 91.45  |\n",
      "|      Vecile     | 46.71 | 60.88 | 63.67 | 63.67  |   66.74   | 60.88  |\n",
      "|       Pool      | 61.73 | 74.62 | 76.34 | 76.34  |   78.14   | 74.62  |\n",
      "|      Grass      | 89.27 | 94.24 | 94.33 | 94.33  |   94.43   | 94.24  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 10:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.9000  mIoU: 70.0400  mAcc: 81.6200  mDice: 81.5100  mFscore: 81.5100  mPrecision: 81.5600  mRecall: 81.6200  data_time: 0.2005  time: 0.3806\n",
      "05/09 10:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_15000.pth is removed\n",
      "05/09 10:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 70.0400 mIoU at 24000 iter is saved to best_mIoU_iter_24000.pth.\n",
      "05/09 10:30:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24100/57000]  base_lr: 5.1445e-05 lr: 5.1445e-05  eta: 5:22:29  time: 0.5622  data_time: 0.1596  memory: 5238  loss: 0.3817  decode.loss_ce: 0.3817  decode.acc_seg: 41.4302\n",
      "05/09 10:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24200/57000]  base_lr: 5.1407e-05 lr: 5.1407e-05  eta: 5:21:28  time: 0.5885  data_time: 0.1803  memory: 5238  loss: 0.1157  decode.loss_ce: 0.1157  decode.acc_seg: 99.0871\n",
      "05/09 10:32:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24300/57000]  base_lr: 5.1369e-05 lr: 5.1369e-05  eta: 5:20:28  time: 0.5745  data_time: 0.1710  memory: 5238  loss: 0.1452  decode.loss_ce: 0.1452  decode.acc_seg: 82.8847\n",
      "05/09 10:33:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24400/57000]  base_lr: 5.1332e-05 lr: 5.1332e-05  eta: 5:19:27  time: 0.5661  data_time: 0.1638  memory: 5238  loss: 0.3195  decode.loss_ce: 0.3195  decode.acc_seg: 65.3941\n",
      "05/09 10:34:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24500/57000]  base_lr: 5.1294e-05 lr: 5.1294e-05  eta: 5:18:26  time: 0.5529  data_time: 0.1499  memory: 5238  loss: 0.1143  decode.loss_ce: 0.1143  decode.acc_seg: 96.0518\n",
      "05/09 10:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24600/57000]  base_lr: 5.1256e-05 lr: 5.1256e-05  eta: 5:17:24  time: 0.5541  data_time: 0.1516  memory: 5238  loss: 0.0822  decode.loss_ce: 0.0822  decode.acc_seg: 93.5680\n",
      "05/09 10:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24700/57000]  base_lr: 5.1218e-05 lr: 5.1218e-05  eta: 5:16:23  time: 0.5958  data_time: 0.1896  memory: 5238  loss: 0.1064  decode.loss_ce: 0.1064  decode.acc_seg: 94.9790\n",
      "05/09 10:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24800/57000]  base_lr: 5.1180e-05 lr: 5.1180e-05  eta: 5:15:22  time: 0.5977  data_time: 0.1912  memory: 5238  loss: 0.0906  decode.loss_ce: 0.0906  decode.acc_seg: 96.1872\n",
      "05/09 10:38:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [24900/57000]  base_lr: 5.1142e-05 lr: 5.1142e-05  eta: 5:14:22  time: 0.5840  data_time: 0.1793  memory: 5238  loss: 0.2169  decode.loss_ce: 0.2169  decode.acc_seg: 95.6333\n",
      "05/09 10:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 10:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25000/57000]  base_lr: 5.1104e-05 lr: 5.1104e-05  eta: 5:13:21  time: 0.5502  data_time: 0.1479  memory: 5238  loss: 0.1447  decode.loss_ce: 0.1447  decode.acc_seg: 79.6513\n",
      "05/09 10:40:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25100/57000]  base_lr: 5.1067e-05 lr: 5.1067e-05  eta: 5:12:20  time: 0.5662  data_time: 0.1642  memory: 5238  loss: 0.0999  decode.loss_ce: 0.0999  decode.acc_seg: 93.5540\n",
      "05/09 10:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25200/57000]  base_lr: 5.1029e-05 lr: 5.1029e-05  eta: 5:11:19  time: 0.5925  data_time: 0.1872  memory: 5238  loss: 0.1963  decode.loss_ce: 0.1963  decode.acc_seg: 85.4143\n",
      "05/09 10:41:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25300/57000]  base_lr: 5.0991e-05 lr: 5.0991e-05  eta: 5:10:19  time: 0.5762  data_time: 0.1701  memory: 5238  loss: 0.1411  decode.loss_ce: 0.1411  decode.acc_seg: 92.9853\n",
      "05/09 10:42:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25400/57000]  base_lr: 5.0953e-05 lr: 5.0953e-05  eta: 5:09:19  time: 0.5967  data_time: 0.1910  memory: 5238  loss: 0.1154  decode.loss_ce: 0.1154  decode.acc_seg: 99.0448\n",
      "05/09 10:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25500/57000]  base_lr: 5.0915e-05 lr: 5.0915e-05  eta: 5:08:18  time: 0.5796  data_time: 0.1777  memory: 5238  loss: 0.1103  decode.loss_ce: 0.1103  decode.acc_seg: 95.9887\n",
      "05/09 10:44:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25600/57000]  base_lr: 5.0877e-05 lr: 5.0877e-05  eta: 5:07:18  time: 0.5630  data_time: 0.1599  memory: 5238  loss: 0.1569  decode.loss_ce: 0.1569  decode.acc_seg: 91.0810\n",
      "05/09 10:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25700/57000]  base_lr: 5.0839e-05 lr: 5.0839e-05  eta: 5:06:18  time: 0.5787  data_time: 0.1730  memory: 5238  loss: 0.1370  decode.loss_ce: 0.1370  decode.acc_seg: 98.3481\n",
      "05/09 10:46:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25800/57000]  base_lr: 5.0802e-05 lr: 5.0802e-05  eta: 5:05:17  time: 0.5596  data_time: 0.1568  memory: 5238  loss: 0.1499  decode.loss_ce: 0.1499  decode.acc_seg: 96.3731\n",
      "05/09 10:47:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [25900/57000]  base_lr: 5.0764e-05 lr: 5.0764e-05  eta: 5:04:17  time: 0.6059  data_time: 0.1989  memory: 5238  loss: 0.2338  decode.loss_ce: 0.2338  decode.acc_seg: 89.0762\n",
      "05/09 10:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 10:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26000/57000]  base_lr: 5.0726e-05 lr: 5.0726e-05  eta: 5:03:16  time: 0.5886  data_time: 0.1813  memory: 5238  loss: 0.1858  decode.loss_ce: 0.1858  decode.acc_seg: 94.5531\n",
      "05/09 10:49:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26100/57000]  base_lr: 5.0688e-05 lr: 5.0688e-05  eta: 5:02:16  time: 0.5803  data_time: 0.1753  memory: 5238  loss: 0.0861  decode.loss_ce: 0.0861  decode.acc_seg: 97.3899\n",
      "05/09 10:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26200/57000]  base_lr: 5.0650e-05 lr: 5.0650e-05  eta: 5:01:15  time: 0.5586  data_time: 0.1567  memory: 5238  loss: 0.1512  decode.loss_ce: 0.1512  decode.acc_seg: 94.8090\n",
      "05/09 10:51:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26300/57000]  base_lr: 5.0612e-05 lr: 5.0612e-05  eta: 5:00:15  time: 0.5668  data_time: 0.1635  memory: 5238  loss: 0.1352  decode.loss_ce: 0.1352  decode.acc_seg: 87.2909\n",
      "05/09 10:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26400/57000]  base_lr: 5.0574e-05 lr: 5.0574e-05  eta: 4:59:14  time: 0.5700  data_time: 0.1652  memory: 5238  loss: 0.0897  decode.loss_ce: 0.0897  decode.acc_seg: 93.9653\n",
      "05/09 10:53:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26500/57000]  base_lr: 5.0537e-05 lr: 5.0537e-05  eta: 4:58:14  time: 0.5952  data_time: 0.1885  memory: 5238  loss: 0.1312  decode.loss_ce: 0.1312  decode.acc_seg: 95.8619\n",
      "05/09 10:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26600/57000]  base_lr: 5.0499e-05 lr: 5.0499e-05  eta: 4:57:14  time: 0.5804  data_time: 0.1744  memory: 5238  loss: 0.1540  decode.loss_ce: 0.1540  decode.acc_seg: 95.9503\n",
      "05/09 10:55:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26700/57000]  base_lr: 5.0461e-05 lr: 5.0461e-05  eta: 4:56:15  time: 0.6031  data_time: 0.1996  memory: 5238  loss: 0.5299  decode.loss_ce: 0.5299  decode.acc_seg: 84.4283\n",
      "05/09 10:56:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26800/57000]  base_lr: 5.0423e-05 lr: 5.0423e-05  eta: 4:55:14  time: 0.5674  data_time: 0.1642  memory: 5238  loss: 0.1272  decode.loss_ce: 0.1272  decode.acc_seg: 92.6889\n",
      "05/09 10:57:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [26900/57000]  base_lr: 5.0385e-05 lr: 5.0385e-05  eta: 4:54:14  time: 0.5716  data_time: 0.1668  memory: 5238  loss: 0.1053  decode.loss_ce: 0.1053  decode.acc_seg: 99.5972\n",
      "05/09 10:58:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 10:58:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27000/57000]  base_lr: 5.0347e-05 lr: 5.0347e-05  eta: 4:53:14  time: 0.5743  data_time: 0.1712  memory: 5238  loss: 0.0958  decode.loss_ce: 0.0958  decode.acc_seg: 97.6601\n",
      "05/09 10:58:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:16  time: 0.3682  data_time: 0.1950  memory: 2587  \n",
      "05/09 10:59:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4440  data_time: 0.2723  memory: 2589  \n",
      "05/09 11:00:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3813  data_time: 0.1897  memory: 2579  \n",
      "05/09 11:00:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3667  data_time: 0.1822  memory: 2410  \n",
      "05/09 11:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 11:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 50.25 | 64.99 | 66.89 | 66.89  |   68.89   | 64.99  |\n",
      "| BuildingFlooded | 76.17 | 92.33 | 86.48 | 86.48  |   81.32   | 92.33  |\n",
      "|   BNonFlooded   | 79.62 | 87.78 | 88.65 | 88.65  |   89.55   | 87.78  |\n",
      "|   RoadFlooded   |  60.0 | 82.42 |  75.0 |  75.0  |    68.8   | 82.42  |\n",
      "|   RNonFlooded   |  82.7 | 90.58 | 90.53 | 90.53  |   90.48   | 90.58  |\n",
      "|      Water      | 72.69 | 87.45 | 84.19 | 84.19  |   81.16   | 87.45  |\n",
      "|       Tree      | 83.34 | 91.04 | 90.91 | 90.91  |   90.78   | 91.04  |\n",
      "|      Vecile     | 51.06 | 68.55 |  67.6 |  67.6  |   66.68   | 68.55  |\n",
      "|       Pool      | 61.31 | 76.81 | 76.02 | 76.02  |   75.25   | 76.81  |\n",
      "|      Grass      | 88.11 |  92.3 | 93.68 | 93.68  |   95.11   |  92.3  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 11:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.3100  mIoU: 70.5300  mAcc: 83.4200  mDice: 81.9900  mFscore: 81.9900  mPrecision: 80.8000  mRecall: 83.4200  data_time: 0.2041  time: 0.3843\n",
      "05/09 11:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_24000.pth is removed\n",
      "05/09 11:01:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 70.5300 mIoU at 27000 iter is saved to best_mIoU_iter_27000.pth.\n",
      "05/09 11:02:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27100/57000]  base_lr: 5.0309e-05 lr: 5.0309e-05  eta: 4:52:23  time: 0.5962  data_time: 0.1912  memory: 5238  loss: 0.1642  decode.loss_ce: 0.1642  decode.acc_seg: 97.2132\n",
      "05/09 11:03:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27200/57000]  base_lr: 5.0272e-05 lr: 5.0272e-05  eta: 4:51:24  time: 0.5667  data_time: 0.1625  memory: 5238  loss: 0.1374  decode.loss_ce: 0.1374  decode.acc_seg: 97.0754\n",
      "05/09 11:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27300/57000]  base_lr: 5.0234e-05 lr: 5.0234e-05  eta: 4:50:25  time: 0.5823  data_time: 0.1780  memory: 5238  loss: 0.1288  decode.loss_ce: 0.1288  decode.acc_seg: 94.3995\n",
      "05/09 11:05:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27400/57000]  base_lr: 5.0196e-05 lr: 5.0196e-05  eta: 4:49:26  time: 0.5867  data_time: 0.1788  memory: 5238  loss: 0.1797  decode.loss_ce: 0.1797  decode.acc_seg: 85.7711\n",
      "05/09 11:06:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27500/57000]  base_lr: 5.0158e-05 lr: 5.0158e-05  eta: 4:48:27  time: 0.5846  data_time: 0.1793  memory: 5238  loss: 0.1597  decode.loss_ce: 0.1597  decode.acc_seg: 86.3460\n",
      "05/09 11:07:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27600/57000]  base_lr: 5.0120e-05 lr: 5.0120e-05  eta: 4:47:28  time: 0.5720  data_time: 0.1673  memory: 5238  loss: 0.1504  decode.loss_ce: 0.1504  decode.acc_seg: 96.0469\n",
      "05/09 11:08:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27700/57000]  base_lr: 5.0082e-05 lr: 5.0082e-05  eta: 4:46:29  time: 0.5937  data_time: 0.1837  memory: 5238  loss: 0.1366  decode.loss_ce: 0.1366  decode.acc_seg: 93.4124\n",
      "05/09 11:08:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27800/57000]  base_lr: 5.0044e-05 lr: 5.0044e-05  eta: 4:45:30  time: 0.5774  data_time: 0.1710  memory: 5238  loss: 0.1685  decode.loss_ce: 0.1685  decode.acc_seg: 98.7654\n",
      "05/09 11:09:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [27900/57000]  base_lr: 5.0007e-05 lr: 5.0007e-05  eta: 4:44:31  time: 0.5695  data_time: 0.1641  memory: 5238  loss: 0.1482  decode.loss_ce: 0.1482  decode.acc_seg: 95.5686\n",
      "05/09 11:10:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 11:10:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28000/57000]  base_lr: 4.9969e-05 lr: 4.9969e-05  eta: 4:43:31  time: 0.5613  data_time: 0.1545  memory: 5238  loss: 0.4450  decode.loss_ce: 0.4450  decode.acc_seg: 96.3608\n",
      "05/09 11:11:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28100/57000]  base_lr: 4.9931e-05 lr: 4.9931e-05  eta: 4:42:32  time: 0.5422  data_time: 0.1389  memory: 5238  loss: 0.0807  decode.loss_ce: 0.0807  decode.acc_seg: 90.5361\n",
      "05/09 11:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28200/57000]  base_lr: 4.9893e-05 lr: 4.9893e-05  eta: 4:41:31  time: 0.5591  data_time: 0.1531  memory: 5238  loss: 0.1098  decode.loss_ce: 0.1098  decode.acc_seg: 95.8957\n",
      "05/09 11:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28300/57000]  base_lr: 4.9855e-05 lr: 4.9855e-05  eta: 4:40:33  time: 0.5839  data_time: 0.1792  memory: 5238  loss: 0.1794  decode.loss_ce: 0.1794  decode.acc_seg: 82.9325\n",
      "05/09 11:14:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28400/57000]  base_lr: 4.9817e-05 lr: 4.9817e-05  eta: 4:39:33  time: 0.5888  data_time: 0.1786  memory: 5238  loss: 0.1356  decode.loss_ce: 0.1356  decode.acc_seg: 98.7815\n",
      "05/09 11:15:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28500/57000]  base_lr: 4.9779e-05 lr: 4.9779e-05  eta: 4:38:35  time: 0.5865  data_time: 0.1806  memory: 5238  loss: 0.2730  decode.loss_ce: 0.2730  decode.acc_seg: 96.7575\n",
      "05/09 11:16:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28600/57000]  base_lr: 4.9742e-05 lr: 4.9742e-05  eta: 4:37:38  time: 0.5757  data_time: 0.1720  memory: 5238  loss: 0.1189  decode.loss_ce: 0.1189  decode.acc_seg: 96.0126\n",
      "05/09 11:17:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28700/57000]  base_lr: 4.9704e-05 lr: 4.9704e-05  eta: 4:36:38  time: 0.5631  data_time: 0.1599  memory: 5238  loss: 0.1316  decode.loss_ce: 0.1316  decode.acc_seg: 89.5927\n",
      "05/09 11:18:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28800/57000]  base_lr: 4.9666e-05 lr: 4.9666e-05  eta: 4:35:39  time: 0.5566  data_time: 0.1530  memory: 5238  loss: 0.0980  decode.loss_ce: 0.0980  decode.acc_seg: 95.1409\n",
      "05/09 11:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [28900/57000]  base_lr: 4.9628e-05 lr: 4.9628e-05  eta: 4:34:40  time: 0.5829  data_time: 0.1764  memory: 5238  loss: 0.1218  decode.loss_ce: 0.1218  decode.acc_seg: 97.2134\n",
      "05/09 11:20:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 11:20:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29000/57000]  base_lr: 4.9590e-05 lr: 4.9590e-05  eta: 4:33:41  time: 0.6022  data_time: 0.1972  memory: 5238  loss: 0.4136  decode.loss_ce: 0.4136  decode.acc_seg: 96.2842\n",
      "05/09 11:21:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29100/57000]  base_lr: 4.9552e-05 lr: 4.9552e-05  eta: 4:32:41  time: 0.5953  data_time: 0.1901  memory: 5238  loss: 0.1284  decode.loss_ce: 0.1284  decode.acc_seg: 98.4241\n",
      "05/09 11:22:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29200/57000]  base_lr: 4.9515e-05 lr: 4.9515e-05  eta: 4:31:42  time: 0.5692  data_time: 0.1633  memory: 5238  loss: 0.0960  decode.loss_ce: 0.0960  decode.acc_seg: 95.7363\n",
      "05/09 11:23:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29300/57000]  base_lr: 4.9477e-05 lr: 4.9477e-05  eta: 4:30:42  time: 0.5782  data_time: 0.1731  memory: 5238  loss: 0.0957  decode.loss_ce: 0.0957  decode.acc_seg: 90.5696\n",
      "05/09 11:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29400/57000]  base_lr: 4.9439e-05 lr: 4.9439e-05  eta: 4:29:42  time: 0.5849  data_time: 0.1819  memory: 5238  loss: 0.6433  decode.loss_ce: 0.6433  decode.acc_seg: 93.8268\n",
      "05/09 11:25:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29500/57000]  base_lr: 4.9401e-05 lr: 4.9401e-05  eta: 4:28:41  time: 0.5437  data_time: 0.1407  memory: 5238  loss: 0.1133  decode.loss_ce: 0.1133  decode.acc_seg: 96.0020\n",
      "05/09 11:26:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29600/57000]  base_lr: 4.9363e-05 lr: 4.9363e-05  eta: 4:27:41  time: 0.5841  data_time: 0.1810  memory: 5238  loss: 0.1149  decode.loss_ce: 0.1149  decode.acc_seg: 97.3885\n",
      "05/09 11:27:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29700/57000]  base_lr: 4.9325e-05 lr: 4.9325e-05  eta: 4:26:43  time: 0.5815  data_time: 0.1729  memory: 5238  loss: 0.0841  decode.loss_ce: 0.0841  decode.acc_seg: 97.9773\n",
      "05/09 11:28:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29800/57000]  base_lr: 4.9287e-05 lr: 4.9287e-05  eta: 4:25:44  time: 0.5923  data_time: 0.1822  memory: 5238  loss: 0.1253  decode.loss_ce: 0.1253  decode.acc_seg: 95.7153\n",
      "05/09 11:29:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [29900/57000]  base_lr: 4.9250e-05 lr: 4.9250e-05  eta: 4:24:44  time: 0.5756  data_time: 0.1675  memory: 5238  loss: 0.1761  decode.loss_ce: 0.1761  decode.acc_seg: 95.1681\n",
      "05/09 11:30:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 11:30:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30000/57000]  base_lr: 4.9212e-05 lr: 4.9212e-05  eta: 4:23:45  time: 0.5832  data_time: 0.1790  memory: 5238  loss: 0.1201  decode.loss_ce: 0.1201  decode.acc_seg: 95.6086\n",
      "05/09 11:30:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:15  time: 0.3710  data_time: 0.1979  memory: 2585  \n",
      "05/09 11:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4421  data_time: 0.2700  memory: 2589  \n",
      "05/09 11:32:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3620  data_time: 0.1707  memory: 2578  \n",
      "05/09 11:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3656  data_time: 0.1812  memory: 2410  \n",
      "05/09 11:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 11:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 41.71 | 72.53 | 58.87 | 58.87  |   49.53   | 72.53  |\n",
      "| BuildingFlooded |  75.2 | 88.13 | 85.85 | 85.85  |   83.68   | 88.13  |\n",
      "|   BNonFlooded   | 78.33 | 86.14 | 87.85 | 87.85  |   89.62   | 86.14  |\n",
      "|   RoadFlooded   | 57.96 | 69.47 | 73.39 | 73.39  |   77.78   | 69.47  |\n",
      "|   RNonFlooded   | 81.49 | 87.99 |  89.8 |  89.8  |   91.69   | 87.99  |\n",
      "|      Water      | 72.59 | 84.19 | 84.12 | 84.12  |   84.04   | 84.19  |\n",
      "|       Tree      | 83.97 | 90.28 | 91.29 | 91.29  |   92.31   | 90.28  |\n",
      "|      Vecile     | 51.13 | 65.53 | 67.66 | 67.66  |   69.93   | 65.53  |\n",
      "|       Pool      | 61.35 | 70.71 | 76.05 | 76.05  |   82.25   | 70.71  |\n",
      "|      Grass      | 87.76 |  93.4 | 93.48 | 93.48  |   93.56   |  93.4  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 11:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 89.9100  mIoU: 69.1500  mAcc: 80.8400  mDice: 80.8300  mFscore: 80.8300  mPrecision: 81.4400  mRecall: 80.8400  data_time: 0.2015  time: 0.3814\n",
      "05/09 11:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30100/57000]  base_lr: 4.9174e-05 lr: 4.9174e-05  eta: 4:22:45  time: 0.5754  data_time: 0.1693  memory: 5238  loss: 0.1079  decode.loss_ce: 0.1079  decode.acc_seg: 96.3438\n",
      "05/09 11:35:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30200/57000]  base_lr: 4.9136e-05 lr: 4.9136e-05  eta: 4:21:45  time: 0.5660  data_time: 0.1633  memory: 5238  loss: 0.0990  decode.loss_ce: 0.0990  decode.acc_seg: 93.0039\n",
      "05/09 11:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30300/57000]  base_lr: 4.9098e-05 lr: 4.9098e-05  eta: 4:20:45  time: 0.5721  data_time: 0.1682  memory: 5238  loss: 0.1142  decode.loss_ce: 0.1142  decode.acc_seg: 92.8491\n",
      "05/09 11:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30400/57000]  base_lr: 4.9060e-05 lr: 4.9060e-05  eta: 4:19:46  time: 0.5771  data_time: 0.1734  memory: 5238  loss: 0.1848  decode.loss_ce: 0.1848  decode.acc_seg: 97.8609\n",
      "05/09 11:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30500/57000]  base_lr: 4.9022e-05 lr: 4.9022e-05  eta: 4:18:47  time: 0.5708  data_time: 0.1657  memory: 5238  loss: 0.1453  decode.loss_ce: 0.1453  decode.acc_seg: 92.1206\n",
      "05/09 11:38:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30600/57000]  base_lr: 4.8985e-05 lr: 4.8985e-05  eta: 4:17:48  time: 0.5677  data_time: 0.1641  memory: 5238  loss: 0.1016  decode.loss_ce: 0.1016  decode.acc_seg: 96.6782\n",
      "05/09 11:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30700/57000]  base_lr: 4.8947e-05 lr: 4.8947e-05  eta: 4:16:49  time: 0.5830  data_time: 0.1761  memory: 5238  loss: 0.1396  decode.loss_ce: 0.1396  decode.acc_seg: 84.1346\n",
      "05/09 11:40:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30800/57000]  base_lr: 4.8909e-05 lr: 4.8909e-05  eta: 4:15:49  time: 0.5994  data_time: 0.1931  memory: 5238  loss: 0.1172  decode.loss_ce: 0.1172  decode.acc_seg: 93.7845\n",
      "05/09 11:41:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [30900/57000]  base_lr: 4.8871e-05 lr: 4.8871e-05  eta: 4:14:50  time: 0.5777  data_time: 0.1746  memory: 5238  loss: 0.2486  decode.loss_ce: 0.2486  decode.acc_seg: 92.1726\n",
      "05/09 11:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 11:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31000/57000]  base_lr: 4.8833e-05 lr: 4.8833e-05  eta: 4:13:51  time: 0.5689  data_time: 0.1644  memory: 5238  loss: 0.0827  decode.loss_ce: 0.0827  decode.acc_seg: 98.4006\n",
      "05/09 11:43:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31100/57000]  base_lr: 4.8795e-05 lr: 4.8795e-05  eta: 4:12:53  time: 0.5633  data_time: 0.1560  memory: 5238  loss: 0.0741  decode.loss_ce: 0.0741  decode.acc_seg: 91.9447\n",
      "05/09 11:44:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31200/57000]  base_lr: 4.8757e-05 lr: 4.8757e-05  eta: 4:11:53  time: 0.5809  data_time: 0.1777  memory: 5238  loss: 0.1300  decode.loss_ce: 0.1300  decode.acc_seg: 96.1310\n",
      "05/09 11:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31300/57000]  base_lr: 4.8720e-05 lr: 4.8720e-05  eta: 4:10:53  time: 0.6162  data_time: 0.2080  memory: 5238  loss: 0.0932  decode.loss_ce: 0.0932  decode.acc_seg: 97.6982\n",
      "05/09 11:46:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31400/57000]  base_lr: 4.8682e-05 lr: 4.8682e-05  eta: 4:09:53  time: 0.5741  data_time: 0.1709  memory: 5238  loss: 0.1405  decode.loss_ce: 0.1405  decode.acc_seg: 86.5261\n",
      "05/09 11:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31500/57000]  base_lr: 4.8644e-05 lr: 4.8644e-05  eta: 4:08:54  time: 0.5666  data_time: 0.1628  memory: 5238  loss: 0.1585  decode.loss_ce: 0.1585  decode.acc_seg: 87.1864\n",
      "05/09 11:48:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31600/57000]  base_lr: 4.8606e-05 lr: 4.8606e-05  eta: 4:07:54  time: 0.5737  data_time: 0.1709  memory: 5238  loss: 0.1494  decode.loss_ce: 0.1494  decode.acc_seg: 90.8704\n",
      "05/09 11:49:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31700/57000]  base_lr: 4.8568e-05 lr: 4.8568e-05  eta: 4:06:54  time: 0.5745  data_time: 0.1722  memory: 5238  loss: 0.1775  decode.loss_ce: 0.1775  decode.acc_seg: 93.5154\n",
      "05/09 11:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31800/57000]  base_lr: 4.8530e-05 lr: 4.8530e-05  eta: 4:05:55  time: 0.5583  data_time: 0.1547  memory: 5238  loss: 0.1014  decode.loss_ce: 0.1014  decode.acc_seg: 98.9733\n",
      "05/09 11:51:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [31900/57000]  base_lr: 4.8492e-05 lr: 4.8492e-05  eta: 4:04:55  time: 0.5864  data_time: 0.1793  memory: 5238  loss: 0.1191  decode.loss_ce: 0.1191  decode.acc_seg: 95.5544\n",
      "05/09 11:52:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 11:52:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32000/57000]  base_lr: 4.8455e-05 lr: 4.8455e-05  eta: 4:03:56  time: 0.5613  data_time: 0.1571  memory: 5238  loss: 0.0767  decode.loss_ce: 0.0767  decode.acc_seg: 91.7400\n",
      "05/09 11:52:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 32000 iterations\n",
      "05/09 11:53:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32100/57000]  base_lr: 4.8417e-05 lr: 4.8417e-05  eta: 4:02:59  time: 0.5640  data_time: 0.1595  memory: 5238  loss: 0.1420  decode.loss_ce: 0.1420  decode.acc_seg: 90.6887\n",
      "05/09 11:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32200/57000]  base_lr: 4.8379e-05 lr: 4.8379e-05  eta: 4:02:00  time: 0.5596  data_time: 0.1557  memory: 5238  loss: 0.1136  decode.loss_ce: 0.1136  decode.acc_seg: 99.5726\n",
      "05/09 11:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32300/57000]  base_lr: 4.8341e-05 lr: 4.8341e-05  eta: 4:01:01  time: 0.5862  data_time: 0.1819  memory: 5238  loss: 0.1837  decode.loss_ce: 0.1837  decode.acc_seg: 90.5480\n",
      "05/09 11:56:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32400/57000]  base_lr: 4.8303e-05 lr: 4.8303e-05  eta: 4:00:02  time: 0.5772  data_time: 0.1718  memory: 5238  loss: 0.1984  decode.loss_ce: 0.1984  decode.acc_seg: 92.8064\n",
      "05/09 11:57:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32500/57000]  base_lr: 4.8265e-05 lr: 4.8265e-05  eta: 3:59:02  time: 0.5727  data_time: 0.1691  memory: 5238  loss: 0.0910  decode.loss_ce: 0.0910  decode.acc_seg: 94.3226\n",
      "05/09 11:58:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32600/57000]  base_lr: 4.8227e-05 lr: 4.8227e-05  eta: 3:58:03  time: 0.5954  data_time: 0.1876  memory: 5238  loss: 0.1844  decode.loss_ce: 0.1844  decode.acc_seg: 97.2335\n",
      "05/09 11:59:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32700/57000]  base_lr: 4.8190e-05 lr: 4.8190e-05  eta: 3:57:03  time: 0.5538  data_time: 0.1513  memory: 5238  loss: 0.1650  decode.loss_ce: 0.1650  decode.acc_seg: 94.7890\n",
      "05/09 12:00:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32800/57000]  base_lr: 4.8152e-05 lr: 4.8152e-05  eta: 3:56:04  time: 0.5497  data_time: 0.1470  memory: 5238  loss: 0.1111  decode.loss_ce: 0.1111  decode.acc_seg: 93.4294\n",
      "05/09 12:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [32900/57000]  base_lr: 4.8114e-05 lr: 4.8114e-05  eta: 3:55:05  time: 0.5791  data_time: 0.1728  memory: 5238  loss: 0.1641  decode.loss_ce: 0.1641  decode.acc_seg: 92.1847\n",
      "05/09 12:01:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 12:01:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33000/57000]  base_lr: 4.8076e-05 lr: 4.8076e-05  eta: 3:54:05  time: 0.5814  data_time: 0.1743  memory: 5238  loss: 0.0801  decode.loss_ce: 0.0801  decode.acc_seg: 96.5593\n",
      "05/09 12:02:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:15  time: 0.3703  data_time: 0.1973  memory: 2585  \n",
      "05/09 12:03:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4375  data_time: 0.2660  memory: 2590  \n",
      "05/09 12:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3609  data_time: 0.1703  memory: 2577  \n",
      "05/09 12:04:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3649  data_time: 0.1805  memory: 2410  \n",
      "05/09 12:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 12:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 49.09 | 62.04 | 65.85 | 65.85  |   70.16   | 62.04  |\n",
      "| BuildingFlooded | 73.48 | 87.52 | 84.71 | 84.71  |   82.07   | 87.52  |\n",
      "|   BNonFlooded   | 76.23 | 88.27 | 86.51 | 86.51  |   84.82   | 88.27  |\n",
      "|   RoadFlooded   | 57.82 | 75.46 | 73.27 | 73.27  |   71.21   | 75.46  |\n",
      "|   RNonFlooded   | 82.45 | 91.41 | 90.38 | 90.38  |   89.37   | 91.41  |\n",
      "|      Water      | 72.26 | 86.54 |  83.9 |  83.9  |   81.41   | 86.54  |\n",
      "|       Tree      | 84.42 | 90.94 | 91.55 | 91.55  |   92.17   | 90.94  |\n",
      "|      Vecile     | 49.09 | 68.76 | 65.86 | 65.86  |   63.19   | 68.76  |\n",
      "|       Pool      | 62.58 | 75.45 | 76.99 | 76.99  |   78.59   | 75.45  |\n",
      "|      Grass      |  88.8 | 93.41 | 94.07 | 94.07  |   94.73   | 93.41  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 12:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.4900  mIoU: 69.6200  mAcc: 81.9800  mDice: 81.3100  mFscore: 81.3100  mPrecision: 80.7700  mRecall: 81.9800  data_time: 0.2008  time: 0.3806\n",
      "05/09 12:05:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33100/57000]  base_lr: 4.8038e-05 lr: 4.8038e-05  eta: 3:53:06  time: 0.5653  data_time: 0.1610  memory: 5238  loss: 0.1073  decode.loss_ce: 0.1073  decode.acc_seg: 97.8162\n",
      "05/09 12:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33200/57000]  base_lr: 4.8000e-05 lr: 4.8000e-05  eta: 3:52:06  time: 0.5716  data_time: 0.1672  memory: 5238  loss: 0.2351  decode.loss_ce: 0.2351  decode.acc_seg: 94.6686\n",
      "05/09 12:07:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33300/57000]  base_lr: 4.7962e-05 lr: 4.7962e-05  eta: 3:51:06  time: 0.5732  data_time: 0.1695  memory: 5238  loss: 0.1611  decode.loss_ce: 0.1611  decode.acc_seg: 96.1387\n",
      "05/09 12:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33400/57000]  base_lr: 4.7925e-05 lr: 4.7925e-05  eta: 3:50:07  time: 0.5947  data_time: 0.1893  memory: 5238  loss: 0.1125  decode.loss_ce: 0.1125  decode.acc_seg: 92.1592\n",
      "05/09 12:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33500/57000]  base_lr: 4.7887e-05 lr: 4.7887e-05  eta: 3:49:07  time: 0.5726  data_time: 0.1640  memory: 5238  loss: 0.1525  decode.loss_ce: 0.1525  decode.acc_seg: 93.8318\n",
      "05/09 12:10:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33600/57000]  base_lr: 4.7849e-05 lr: 4.7849e-05  eta: 3:48:08  time: 0.5539  data_time: 0.1507  memory: 5238  loss: 0.0708  decode.loss_ce: 0.0708  decode.acc_seg: 98.0924\n",
      "05/09 12:11:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33700/57000]  base_lr: 4.7811e-05 lr: 4.7811e-05  eta: 3:47:09  time: 0.5746  data_time: 0.1709  memory: 5238  loss: 0.0851  decode.loss_ce: 0.0851  decode.acc_seg: 93.7228\n",
      "05/09 12:12:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33800/57000]  base_lr: 4.7773e-05 lr: 4.7773e-05  eta: 3:46:09  time: 0.5753  data_time: 0.1722  memory: 5238  loss: 0.0907  decode.loss_ce: 0.0907  decode.acc_seg: 95.9930\n",
      "05/09 12:13:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [33900/57000]  base_lr: 4.7735e-05 lr: 4.7735e-05  eta: 3:45:09  time: 0.5698  data_time: 0.1664  memory: 5238  loss: 0.1102  decode.loss_ce: 0.1102  decode.acc_seg: 90.9060\n",
      "05/09 12:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 12:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34000/57000]  base_lr: 4.7697e-05 lr: 4.7697e-05  eta: 3:44:10  time: 0.5933  data_time: 0.1870  memory: 5238  loss: 0.1040  decode.loss_ce: 0.1040  decode.acc_seg: 91.0317\n",
      "05/09 12:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34100/57000]  base_lr: 4.7660e-05 lr: 4.7660e-05  eta: 3:43:11  time: 0.5687  data_time: 0.1628  memory: 5238  loss: 0.0666  decode.loss_ce: 0.0666  decode.acc_seg: 93.1389\n",
      "05/09 12:16:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34200/57000]  base_lr: 4.7622e-05 lr: 4.7622e-05  eta: 3:42:12  time: 0.5789  data_time: 0.1745  memory: 5238  loss: 0.1635  decode.loss_ce: 0.1635  decode.acc_seg: 96.3804\n",
      "05/09 12:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34300/57000]  base_lr: 4.7584e-05 lr: 4.7584e-05  eta: 3:41:13  time: 0.5818  data_time: 0.1785  memory: 5238  loss: 0.1017  decode.loss_ce: 0.1017  decode.acc_seg: 95.0710\n",
      "05/09 12:18:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34400/57000]  base_lr: 4.7546e-05 lr: 4.7546e-05  eta: 3:40:14  time: 0.5713  data_time: 0.1678  memory: 5238  loss: 0.1022  decode.loss_ce: 0.1022  decode.acc_seg: 98.5544\n",
      "05/09 12:19:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34500/57000]  base_lr: 4.7508e-05 lr: 4.7508e-05  eta: 3:39:15  time: 0.5761  data_time: 0.1726  memory: 5238  loss: 0.0974  decode.loss_ce: 0.0974  decode.acc_seg: 93.8243\n",
      "05/09 12:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34600/57000]  base_lr: 4.7470e-05 lr: 4.7470e-05  eta: 3:38:16  time: 0.5841  data_time: 0.1783  memory: 5238  loss: 0.1401  decode.loss_ce: 0.1401  decode.acc_seg: 84.4598\n",
      "05/09 12:20:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34700/57000]  base_lr: 4.7432e-05 lr: 4.7432e-05  eta: 3:37:16  time: 0.5862  data_time: 0.1794  memory: 5238  loss: 0.1237  decode.loss_ce: 0.1237  decode.acc_seg: 94.4584\n",
      "05/09 12:21:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34800/57000]  base_lr: 4.7395e-05 lr: 4.7395e-05  eta: 3:36:17  time: 0.5506  data_time: 0.1468  memory: 5238  loss: 0.1069  decode.loss_ce: 0.1069  decode.acc_seg: 92.9618\n",
      "05/09 12:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [34900/57000]  base_lr: 4.7357e-05 lr: 4.7357e-05  eta: 3:35:18  time: 0.5757  data_time: 0.1702  memory: 5238  loss: 0.1541  decode.loss_ce: 0.1541  decode.acc_seg: 96.4324\n",
      "05/09 12:23:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 12:23:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35000/57000]  base_lr: 4.7319e-05 lr: 4.7319e-05  eta: 3:34:20  time: 0.5713  data_time: 0.1662  memory: 5238  loss: 0.1644  decode.loss_ce: 0.1644  decode.acc_seg: 94.7710\n",
      "05/09 12:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35100/57000]  base_lr: 4.7281e-05 lr: 4.7281e-05  eta: 3:33:21  time: 0.5586  data_time: 0.1547  memory: 5238  loss: 0.0941  decode.loss_ce: 0.0941  decode.acc_seg: 97.6141\n",
      "05/09 12:25:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35200/57000]  base_lr: 4.7243e-05 lr: 4.7243e-05  eta: 3:32:22  time: 0.5878  data_time: 0.1823  memory: 5238  loss: 0.1246  decode.loss_ce: 0.1246  decode.acc_seg: 92.0219\n",
      "05/09 12:26:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35300/57000]  base_lr: 4.7205e-05 lr: 4.7205e-05  eta: 3:31:23  time: 0.5768  data_time: 0.1671  memory: 5238  loss: 0.0539  decode.loss_ce: 0.0539  decode.acc_seg: 91.2937\n",
      "05/09 12:27:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35400/57000]  base_lr: 4.7167e-05 lr: 4.7167e-05  eta: 3:30:24  time: 0.5989  data_time: 0.1926  memory: 5238  loss: 0.0983  decode.loss_ce: 0.0983  decode.acc_seg: 96.2939\n",
      "05/09 12:28:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35500/57000]  base_lr: 4.7130e-05 lr: 4.7130e-05  eta: 3:29:25  time: 0.5600  data_time: 0.1561  memory: 5238  loss: 0.1102  decode.loss_ce: 0.1102  decode.acc_seg: 97.3179\n",
      "05/09 12:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35600/57000]  base_lr: 4.7092e-05 lr: 4.7092e-05  eta: 3:28:26  time: 0.5872  data_time: 0.1798  memory: 5238  loss: 0.1520  decode.loss_ce: 0.1520  decode.acc_seg: 98.7939\n",
      "05/09 12:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35700/57000]  base_lr: 4.7054e-05 lr: 4.7054e-05  eta: 3:27:27  time: 0.5603  data_time: 0.1546  memory: 5238  loss: 0.1044  decode.loss_ce: 0.1044  decode.acc_seg: 97.8708\n",
      "05/09 12:31:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35800/57000]  base_lr: 4.7016e-05 lr: 4.7016e-05  eta: 3:26:28  time: 0.5773  data_time: 0.1730  memory: 5238  loss: 0.1315  decode.loss_ce: 0.1315  decode.acc_seg: 98.5625\n",
      "05/09 12:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [35900/57000]  base_lr: 4.6978e-05 lr: 4.6978e-05  eta: 3:25:29  time: 0.5846  data_time: 0.1772  memory: 5238  loss: 0.1127  decode.loss_ce: 0.1127  decode.acc_seg: 94.2209\n",
      "05/09 12:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 12:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36000/57000]  base_lr: 4.6940e-05 lr: 4.6940e-05  eta: 3:24:30  time: 0.5664  data_time: 0.1621  memory: 5238  loss: 0.2711  decode.loss_ce: 0.2711  decode.acc_seg: 96.5159\n",
      "05/09 12:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:15  time: 0.3763  data_time: 0.2034  memory: 2586  \n",
      "05/09 12:34:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4488  data_time: 0.2781  memory: 2589  \n",
      "05/09 12:35:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:57  time: 0.3623  data_time: 0.1717  memory: 2579  \n",
      "05/09 12:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3646  data_time: 0.1804  memory: 2410  \n",
      "05/09 12:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 12:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 37.03 | 47.98 | 54.05 | 54.05  |   61.88   | 47.98  |\n",
      "| BuildingFlooded | 69.63 | 79.84 | 82.09 | 82.09  |   84.48   | 79.84  |\n",
      "|   BNonFlooded   | 74.89 | 91.56 | 85.64 | 85.64  |   80.45   | 91.56  |\n",
      "|   RoadFlooded   | 60.56 | 79.82 | 75.43 | 75.43  |    71.5   | 79.82  |\n",
      "|   RNonFlooded   | 82.79 | 91.64 | 90.58 | 90.58  |   89.55   | 91.64  |\n",
      "|      Water      | 70.44 | 82.34 | 82.66 | 82.66  |   82.97   | 82.34  |\n",
      "|       Tree      | 84.25 | 93.67 | 91.45 | 91.45  |   89.34   | 93.67  |\n",
      "|      Vecile     | 52.09 | 72.32 |  68.5 |  68.5  |   65.06   | 72.32  |\n",
      "|       Pool      | 62.89 | 80.36 | 77.22 | 77.22  |   74.31   | 80.36  |\n",
      "|      Grass      | 88.18 | 92.78 | 93.72 | 93.72  |   94.69   | 92.78  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 12:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 89.9500  mIoU: 68.2700  mAcc: 81.2300  mDice: 80.1300  mFscore: 80.1300  mPrecision: 79.4200  mRecall: 81.2300  data_time: 0.2008  time: 0.3804\n",
      "05/09 12:37:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36100/57000]  base_lr: 4.6903e-05 lr: 4.6903e-05  eta: 3:23:30  time: 0.5751  data_time: 0.1675  memory: 5238  loss: 0.0947  decode.loss_ce: 0.0947  decode.acc_seg: 94.0483\n",
      "05/09 12:38:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36200/57000]  base_lr: 4.6865e-05 lr: 4.6865e-05  eta: 3:22:31  time: 0.5671  data_time: 0.1640  memory: 5238  loss: 0.2288  decode.loss_ce: 0.2288  decode.acc_seg: 96.8251\n",
      "05/09 12:39:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36300/57000]  base_lr: 4.6827e-05 lr: 4.6827e-05  eta: 3:21:32  time: 0.5743  data_time: 0.1679  memory: 5238  loss: 0.1012  decode.loss_ce: 0.1012  decode.acc_seg: 98.9564\n",
      "05/09 12:40:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36400/57000]  base_lr: 4.6789e-05 lr: 4.6789e-05  eta: 3:20:32  time: 0.5539  data_time: 0.1500  memory: 5238  loss: 0.1427  decode.loss_ce: 0.1427  decode.acc_seg: 76.8098\n",
      "05/09 12:41:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36500/57000]  base_lr: 4.6751e-05 lr: 4.6751e-05  eta: 3:19:33  time: 0.5710  data_time: 0.1679  memory: 5238  loss: 0.1970  decode.loss_ce: 0.1970  decode.acc_seg: 90.3662\n",
      "05/09 12:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36600/57000]  base_lr: 4.6713e-05 lr: 4.6713e-05  eta: 3:18:34  time: 0.5838  data_time: 0.1805  memory: 5238  loss: 0.1044  decode.loss_ce: 0.1044  decode.acc_seg: 96.4231\n",
      "05/09 12:42:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36700/57000]  base_lr: 4.6675e-05 lr: 4.6675e-05  eta: 3:17:35  time: 0.6057  data_time: 0.1973  memory: 5238  loss: 0.1621  decode.loss_ce: 0.1621  decode.acc_seg: 97.0719\n",
      "05/09 12:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36800/57000]  base_lr: 4.6638e-05 lr: 4.6638e-05  eta: 3:16:36  time: 0.5643  data_time: 0.1609  memory: 5238  loss: 0.1404  decode.loss_ce: 0.1404  decode.acc_seg: 98.0753\n",
      "05/09 12:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [36900/57000]  base_lr: 4.6600e-05 lr: 4.6600e-05  eta: 3:15:37  time: 0.5637  data_time: 0.1561  memory: 5238  loss: 0.0945  decode.loss_ce: 0.0945  decode.acc_seg: 94.1322\n",
      "05/09 12:45:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 12:45:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37000/57000]  base_lr: 4.6562e-05 lr: 4.6562e-05  eta: 3:14:38  time: 0.5713  data_time: 0.1675  memory: 5238  loss: 0.1054  decode.loss_ce: 0.1054  decode.acc_seg: 86.7453\n",
      "05/09 12:46:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37100/57000]  base_lr: 4.6524e-05 lr: 4.6524e-05  eta: 3:13:39  time: 0.5669  data_time: 0.1627  memory: 5238  loss: 0.1597  decode.loss_ce: 0.1597  decode.acc_seg: 96.9560\n",
      "05/09 12:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37200/57000]  base_lr: 4.6486e-05 lr: 4.6486e-05  eta: 3:12:40  time: 0.5616  data_time: 0.1576  memory: 5238  loss: 0.1347  decode.loss_ce: 0.1347  decode.acc_seg: 94.7593\n",
      "05/09 12:48:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37300/57000]  base_lr: 4.6448e-05 lr: 4.6448e-05  eta: 3:11:42  time: 0.5906  data_time: 0.1792  memory: 5238  loss: 0.1396  decode.loss_ce: 0.1396  decode.acc_seg: 94.7376\n",
      "05/09 12:49:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37400/57000]  base_lr: 4.6410e-05 lr: 4.6410e-05  eta: 3:10:44  time: 0.5784  data_time: 0.1709  memory: 5238  loss: 0.1641  decode.loss_ce: 0.1641  decode.acc_seg: 95.0366\n",
      "05/09 12:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37500/57000]  base_lr: 4.6373e-05 lr: 4.6373e-05  eta: 3:09:46  time: 0.6332  data_time: 0.2258  memory: 5238  loss: 0.1032  decode.loss_ce: 0.1032  decode.acc_seg: 99.0000\n",
      "05/09 12:51:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37600/57000]  base_lr: 4.6335e-05 lr: 4.6335e-05  eta: 3:08:48  time: 0.5572  data_time: 0.1542  memory: 5238  loss: 0.1228  decode.loss_ce: 0.1228  decode.acc_seg: 95.5878\n",
      "05/09 12:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37700/57000]  base_lr: 4.6297e-05 lr: 4.6297e-05  eta: 3:07:49  time: 0.5524  data_time: 0.1477  memory: 5238  loss: 0.1204  decode.loss_ce: 0.1204  decode.acc_seg: 97.3923\n",
      "05/09 12:53:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37800/57000]  base_lr: 4.6259e-05 lr: 4.6259e-05  eta: 3:06:49  time: 0.5489  data_time: 0.1467  memory: 5238  loss: 0.1188  decode.loss_ce: 0.1188  decode.acc_seg: 92.0122\n",
      "05/09 12:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [37900/57000]  base_lr: 4.6221e-05 lr: 4.6221e-05  eta: 3:05:50  time: 0.5738  data_time: 0.1719  memory: 5238  loss: 0.1092  decode.loss_ce: 0.1092  decode.acc_seg: 94.7944\n",
      "05/09 12:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 12:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38000/57000]  base_lr: 4.6183e-05 lr: 4.6183e-05  eta: 3:04:51  time: 0.5634  data_time: 0.1581  memory: 5238  loss: 0.1045  decode.loss_ce: 0.1045  decode.acc_seg: 96.8878\n",
      "05/09 12:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38100/57000]  base_lr: 4.6145e-05 lr: 4.6145e-05  eta: 3:03:51  time: 0.5574  data_time: 0.1547  memory: 5238  loss: 0.1025  decode.loss_ce: 0.1025  decode.acc_seg: 94.1685\n",
      "05/09 12:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38200/57000]  base_lr: 4.6108e-05 lr: 4.6108e-05  eta: 3:02:52  time: 0.5524  data_time: 0.1493  memory: 5238  loss: 0.1115  decode.loss_ce: 0.1115  decode.acc_seg: 93.0709\n",
      "05/09 12:58:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38300/57000]  base_lr: 4.6070e-05 lr: 4.6070e-05  eta: 3:01:54  time: 0.5669  data_time: 0.1635  memory: 5238  loss: 0.1037  decode.loss_ce: 0.1037  decode.acc_seg: 94.4568\n",
      "05/09 12:59:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38400/57000]  base_lr: 4.6032e-05 lr: 4.6032e-05  eta: 3:00:55  time: 0.5681  data_time: 0.1659  memory: 5238  loss: 0.1252  decode.loss_ce: 0.1252  decode.acc_seg: 93.7366\n",
      "05/09 13:00:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38500/57000]  base_lr: 4.5994e-05 lr: 4.5994e-05  eta: 2:59:56  time: 0.5940  data_time: 0.1872  memory: 5238  loss: 0.1218  decode.loss_ce: 0.1218  decode.acc_seg: 95.4531\n",
      "05/09 13:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38600/57000]  base_lr: 4.5956e-05 lr: 4.5956e-05  eta: 2:58:57  time: 0.5644  data_time: 0.1610  memory: 5238  loss: 0.2038  decode.loss_ce: 0.2038  decode.acc_seg: 95.4972\n",
      "05/09 13:02:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38700/57000]  base_lr: 4.5918e-05 lr: 4.5918e-05  eta: 2:57:58  time: 0.5685  data_time: 0.1652  memory: 5238  loss: 0.1329  decode.loss_ce: 0.1329  decode.acc_seg: 88.9906\n",
      "05/09 13:03:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38800/57000]  base_lr: 4.5880e-05 lr: 4.5880e-05  eta: 2:56:59  time: 0.5674  data_time: 0.1641  memory: 5238  loss: 0.1136  decode.loss_ce: 0.1136  decode.acc_seg: 97.8096\n",
      "05/09 13:04:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [38900/57000]  base_lr: 4.5843e-05 lr: 4.5843e-05  eta: 2:56:00  time: 0.5851  data_time: 0.1781  memory: 5238  loss: 0.0785  decode.loss_ce: 0.0785  decode.acc_seg: 98.2327\n",
      "05/09 13:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 13:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39000/57000]  base_lr: 4.5805e-05 lr: 4.5805e-05  eta: 2:55:02  time: 0.5652  data_time: 0.1594  memory: 5238  loss: 0.1241  decode.loss_ce: 0.1241  decode.acc_seg: 95.2795\n",
      "05/09 13:05:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:15  time: 0.3707  data_time: 0.1983  memory: 2588  \n",
      "05/09 13:06:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4368  data_time: 0.2648  memory: 2590  \n",
      "05/09 13:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3846  data_time: 0.1921  memory: 2577  \n",
      "05/09 13:07:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3681  data_time: 0.1843  memory: 2410  \n",
      "05/09 13:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 13:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 49.67 | 63.53 | 66.38 | 66.38  |   69.49   | 63.53  |\n",
      "| BuildingFlooded | 77.47 | 91.52 | 87.31 | 87.31  |   83.46   | 91.52  |\n",
      "|   BNonFlooded   | 79.58 |  89.4 | 88.63 | 88.63  |   87.86   |  89.4  |\n",
      "|   RoadFlooded   | 60.37 | 80.87 | 75.29 | 75.29  |   70.43   | 80.87  |\n",
      "|   RNonFlooded   | 82.93 | 91.71 | 90.67 | 90.67  |   89.65   | 91.71  |\n",
      "|      Water      | 72.78 |  86.0 | 84.25 | 84.25  |   82.57   |  86.0  |\n",
      "|       Tree      | 84.63 | 90.02 | 91.68 | 91.68  |   93.39   | 90.02  |\n",
      "|      Vecile     | 53.21 | 70.96 | 69.46 | 69.46  |   68.02   | 70.96  |\n",
      "|       Pool      | 64.31 | 73.72 | 78.28 | 78.28  |   83.44   | 73.72  |\n",
      "|      Grass      |  88.6 | 93.63 | 93.96 | 93.96  |   94.29   | 93.63  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 13:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.6900  mIoU: 71.3600  mAcc: 83.1400  mDice: 82.5900  mFscore: 82.5900  mPrecision: 82.2600  mRecall: 83.1400  data_time: 0.2016  time: 0.3814\n",
      "05/09 13:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_27000.pth is removed\n",
      "05/09 13:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 71.3600 mIoU at 39000 iter is saved to best_mIoU_iter_39000.pth.\n",
      "05/09 13:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39100/57000]  base_lr: 4.5767e-05 lr: 4.5767e-05  eta: 2:54:06  time: 0.5710  data_time: 0.1652  memory: 5238  loss: 0.1104  decode.loss_ce: 0.1104  decode.acc_seg: 93.6242\n",
      "05/09 13:09:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39200/57000]  base_lr: 4.5729e-05 lr: 4.5729e-05  eta: 2:53:08  time: 0.5905  data_time: 0.1827  memory: 5238  loss: 0.1136  decode.loss_ce: 0.1136  decode.acc_seg: 95.9026\n",
      "05/09 13:10:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39300/57000]  base_lr: 4.5691e-05 lr: 4.5691e-05  eta: 2:52:09  time: 0.5525  data_time: 0.1487  memory: 5238  loss: 0.0895  decode.loss_ce: 0.0895  decode.acc_seg: 94.6880\n",
      "05/09 13:11:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39400/57000]  base_lr: 4.5653e-05 lr: 4.5653e-05  eta: 2:51:11  time: 0.5760  data_time: 0.1736  memory: 5238  loss: 0.2130  decode.loss_ce: 0.2130  decode.acc_seg: 96.6781\n",
      "05/09 13:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39500/57000]  base_lr: 4.5615e-05 lr: 4.5615e-05  eta: 2:50:12  time: 0.5717  data_time: 0.1686  memory: 5238  loss: 0.0856  decode.loss_ce: 0.0856  decode.acc_seg: 90.9804\n",
      "05/09 13:13:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39600/57000]  base_lr: 4.5578e-05 lr: 4.5578e-05  eta: 2:49:13  time: 0.5786  data_time: 0.1719  memory: 5238  loss: 0.1032  decode.loss_ce: 0.1032  decode.acc_seg: 92.6628\n",
      "05/09 13:14:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39700/57000]  base_lr: 4.5540e-05 lr: 4.5540e-05  eta: 2:48:13  time: 0.5709  data_time: 0.1675  memory: 5238  loss: 0.1285  decode.loss_ce: 0.1285  decode.acc_seg: 95.9511\n",
      "05/09 13:15:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39800/57000]  base_lr: 4.5502e-05 lr: 4.5502e-05  eta: 2:47:15  time: 0.5608  data_time: 0.1568  memory: 5238  loss: 0.0932  decode.loss_ce: 0.0932  decode.acc_seg: 99.2816\n",
      "05/09 13:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [39900/57000]  base_lr: 4.5464e-05 lr: 4.5464e-05  eta: 2:46:15  time: 0.5555  data_time: 0.1533  memory: 5238  loss: 0.0732  decode.loss_ce: 0.0732  decode.acc_seg: 96.5141\n",
      "05/09 13:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 13:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40000/57000]  base_lr: 4.5426e-05 lr: 4.5426e-05  eta: 2:45:16  time: 0.5577  data_time: 0.1543  memory: 5238  loss: 0.1183  decode.loss_ce: 0.1183  decode.acc_seg: 96.6261\n",
      "05/09 13:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40100/57000]  base_lr: 4.5388e-05 lr: 4.5388e-05  eta: 2:44:17  time: 0.5866  data_time: 0.1794  memory: 5238  loss: 0.1103  decode.loss_ce: 0.1103  decode.acc_seg: 83.3547\n",
      "05/09 13:19:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40200/57000]  base_lr: 4.5350e-05 lr: 4.5350e-05  eta: 2:43:18  time: 0.5802  data_time: 0.1777  memory: 5238  loss: 0.1418  decode.loss_ce: 0.1418  decode.acc_seg: 92.0026\n",
      "05/09 13:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40300/57000]  base_lr: 4.5313e-05 lr: 4.5313e-05  eta: 2:42:19  time: 0.5580  data_time: 0.1557  memory: 5238  loss: 0.0979  decode.loss_ce: 0.0979  decode.acc_seg: 91.7554\n",
      "05/09 13:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40400/57000]  base_lr: 4.5275e-05 lr: 4.5275e-05  eta: 2:41:20  time: 0.5564  data_time: 0.1542  memory: 5238  loss: 0.2868  decode.loss_ce: 0.2868  decode.acc_seg: 95.2576\n",
      "05/09 13:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40500/57000]  base_lr: 4.5237e-05 lr: 4.5237e-05  eta: 2:40:22  time: 0.5666  data_time: 0.1640  memory: 5238  loss: 0.1909  decode.loss_ce: 0.1909  decode.acc_seg: 95.9452\n",
      "05/09 13:23:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40600/57000]  base_lr: 4.5199e-05 lr: 4.5199e-05  eta: 2:39:23  time: 0.6027  data_time: 0.1972  memory: 5238  loss: 0.1025  decode.loss_ce: 0.1025  decode.acc_seg: 96.2458\n",
      "05/09 13:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40700/57000]  base_lr: 4.5161e-05 lr: 4.5161e-05  eta: 2:38:24  time: 0.5532  data_time: 0.1473  memory: 5238  loss: 0.1451  decode.loss_ce: 0.1451  decode.acc_seg: 94.7115\n",
      "05/09 13:25:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40800/57000]  base_lr: 4.5123e-05 lr: 4.5123e-05  eta: 2:37:25  time: 0.5553  data_time: 0.1522  memory: 5238  loss: 0.3339  decode.loss_ce: 0.3339  decode.acc_seg: 96.5466\n",
      "05/09 13:26:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [40900/57000]  base_lr: 4.5085e-05 lr: 4.5085e-05  eta: 2:36:26  time: 0.5767  data_time: 0.1739  memory: 5238  loss: 0.1189  decode.loss_ce: 0.1189  decode.acc_seg: 72.5834\n",
      "05/09 13:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 13:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41000/57000]  base_lr: 4.5048e-05 lr: 4.5048e-05  eta: 2:35:27  time: 0.5581  data_time: 0.1532  memory: 5238  loss: 0.1089  decode.loss_ce: 0.1089  decode.acc_seg: 93.7075\n",
      "05/09 13:27:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41100/57000]  base_lr: 4.5010e-05 lr: 4.5010e-05  eta: 2:34:28  time: 0.5560  data_time: 0.1538  memory: 5238  loss: 0.1133  decode.loss_ce: 0.1133  decode.acc_seg: 97.1035\n",
      "05/09 13:28:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41200/57000]  base_lr: 4.4972e-05 lr: 4.4972e-05  eta: 2:33:29  time: 0.5901  data_time: 0.1854  memory: 5238  loss: 0.2627  decode.loss_ce: 0.2627  decode.acc_seg: 74.3092\n",
      "05/09 13:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41300/57000]  base_lr: 4.4934e-05 lr: 4.4934e-05  eta: 2:32:31  time: 0.5580  data_time: 0.1559  memory: 5238  loss: 0.0957  decode.loss_ce: 0.0957  decode.acc_seg: 99.1505\n",
      "05/09 13:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41400/57000]  base_lr: 4.4896e-05 lr: 4.4896e-05  eta: 2:31:32  time: 0.5483  data_time: 0.1448  memory: 5238  loss: 0.0696  decode.loss_ce: 0.0696  decode.acc_seg: 92.8458\n",
      "05/09 13:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41500/57000]  base_lr: 4.4858e-05 lr: 4.4858e-05  eta: 2:30:33  time: 0.5887  data_time: 0.1849  memory: 5238  loss: 0.1877  decode.loss_ce: 0.1877  decode.acc_seg: 98.4140\n",
      "05/09 13:32:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41600/57000]  base_lr: 4.4820e-05 lr: 4.4820e-05  eta: 2:29:34  time: 0.5539  data_time: 0.1495  memory: 5238  loss: 0.0699  decode.loss_ce: 0.0699  decode.acc_seg: 95.5581\n",
      "05/09 13:33:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41700/57000]  base_lr: 4.4783e-05 lr: 4.4783e-05  eta: 2:28:35  time: 0.5826  data_time: 0.1758  memory: 5238  loss: 0.0904  decode.loss_ce: 0.0904  decode.acc_seg: 95.0117\n",
      "05/09 13:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41800/57000]  base_lr: 4.4745e-05 lr: 4.4745e-05  eta: 2:27:37  time: 0.5733  data_time: 0.1688  memory: 5238  loss: 0.1095  decode.loss_ce: 0.1095  decode.acc_seg: 94.6866\n",
      "05/09 13:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [41900/57000]  base_lr: 4.4707e-05 lr: 4.4707e-05  eta: 2:26:38  time: 0.5829  data_time: 0.1793  memory: 5238  loss: 0.1312  decode.loss_ce: 0.1312  decode.acc_seg: 89.3661\n",
      "05/09 13:36:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 13:36:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42000/57000]  base_lr: 4.4669e-05 lr: 4.4669e-05  eta: 2:25:39  time: 0.5662  data_time: 0.1633  memory: 5238  loss: 0.1180  decode.loss_ce: 0.1180  decode.acc_seg: 89.5622\n",
      "05/09 13:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:14  time: 0.3669  data_time: 0.1951  memory: 2588  \n",
      "05/09 13:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4522  data_time: 0.2802  memory: 2590  \n",
      "05/09 13:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:57  time: 0.3623  data_time: 0.1715  memory: 2577  \n",
      "05/09 13:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3693  data_time: 0.1847  memory: 2410  \n",
      "05/09 13:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 13:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 42.32 | 52.62 | 59.47 | 59.47  |   68.36   | 52.62  |\n",
      "| BuildingFlooded |  77.1 | 90.13 | 87.07 | 87.07  |   84.21   | 90.13  |\n",
      "|   BNonFlooded   | 78.71 | 89.67 | 88.09 | 88.09  |   86.56   | 89.67  |\n",
      "|   RoadFlooded   | 58.84 | 83.08 | 74.09 | 74.09  |   66.86   | 83.08  |\n",
      "|   RNonFlooded   | 83.13 | 91.34 | 90.79 | 90.79  |   90.25   | 91.34  |\n",
      "|      Water      | 71.52 | 85.57 |  83.4 |  83.4  |   81.34   | 85.57  |\n",
      "|       Tree      | 84.31 | 91.07 | 91.49 | 91.49  |   91.91   | 91.07  |\n",
      "|      Vecile     | 49.85 | 62.27 | 66.53 | 66.53  |   71.43   | 62.27  |\n",
      "|       Pool      | 63.56 | 78.63 | 77.72 | 77.72  |   76.84   | 78.63  |\n",
      "|      Grass      | 88.75 | 93.28 | 94.04 | 94.04  |   94.81   | 93.28  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 13:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.4100  mIoU: 69.8100  mAcc: 81.7600  mDice: 81.2700  mFscore: 81.2700  mPrecision: 81.2600  mRecall: 81.7600  data_time: 0.2005  time: 0.3804\n",
      "05/09 13:40:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42100/57000]  base_lr: 4.4631e-05 lr: 4.4631e-05  eta: 2:24:40  time: 0.5485  data_time: 0.1457  memory: 5238  loss: 0.0821  decode.loss_ce: 0.0821  decode.acc_seg: 99.5675\n",
      "05/09 13:41:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42200/57000]  base_lr: 4.4593e-05 lr: 4.4593e-05  eta: 2:23:42  time: 0.5771  data_time: 0.1754  memory: 5238  loss: 0.1413  decode.loss_ce: 0.1413  decode.acc_seg: 93.1507\n",
      "05/09 13:42:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42300/57000]  base_lr: 4.4555e-05 lr: 4.4555e-05  eta: 2:22:43  time: 0.5604  data_time: 0.1564  memory: 5238  loss: 0.1010  decode.loss_ce: 0.1010  decode.acc_seg: 94.7179\n",
      "05/09 13:43:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42400/57000]  base_lr: 4.4518e-05 lr: 4.4518e-05  eta: 2:21:44  time: 0.5521  data_time: 0.1475  memory: 5238  loss: 0.0815  decode.loss_ce: 0.0815  decode.acc_seg: 93.5164\n",
      "05/09 13:44:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42500/57000]  base_lr: 4.4480e-05 lr: 4.4480e-05  eta: 2:20:46  time: 0.5758  data_time: 0.1728  memory: 5238  loss: 0.0832  decode.loss_ce: 0.0832  decode.acc_seg: 97.2630\n",
      "05/09 13:45:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42600/57000]  base_lr: 4.4442e-05 lr: 4.4442e-05  eta: 2:19:47  time: 0.5978  data_time: 0.1932  memory: 5238  loss: 0.1621  decode.loss_ce: 0.1621  decode.acc_seg: 81.1668\n",
      "05/09 13:45:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42700/57000]  base_lr: 4.4404e-05 lr: 4.4404e-05  eta: 2:18:48  time: 0.5707  data_time: 0.1649  memory: 5238  loss: 0.1520  decode.loss_ce: 0.1520  decode.acc_seg: 92.8274\n",
      "05/09 13:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42800/57000]  base_lr: 4.4366e-05 lr: 4.4366e-05  eta: 2:17:50  time: 0.5594  data_time: 0.1548  memory: 5238  loss: 0.0868  decode.loss_ce: 0.0868  decode.acc_seg: 94.0922\n",
      "05/09 13:47:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [42900/57000]  base_lr: 4.4328e-05 lr: 4.4328e-05  eta: 2:16:51  time: 0.5695  data_time: 0.1666  memory: 5238  loss: 0.1104  decode.loss_ce: 0.1104  decode.acc_seg: 94.6934\n",
      "05/09 13:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 13:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43000/57000]  base_lr: 4.4291e-05 lr: 4.4291e-05  eta: 2:15:52  time: 0.5767  data_time: 0.1735  memory: 5238  loss: 0.1120  decode.loss_ce: 0.1120  decode.acc_seg: 98.4783\n",
      "05/09 13:49:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43100/57000]  base_lr: 4.4253e-05 lr: 4.4253e-05  eta: 2:14:54  time: 0.5939  data_time: 0.1866  memory: 5238  loss: 0.1306  decode.loss_ce: 0.1306  decode.acc_seg: 95.5773\n",
      "05/09 13:50:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43200/57000]  base_lr: 4.4215e-05 lr: 4.4215e-05  eta: 2:13:55  time: 0.5592  data_time: 0.1559  memory: 5238  loss: 0.1168  decode.loss_ce: 0.1168  decode.acc_seg: 96.0070\n",
      "05/09 13:51:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43300/57000]  base_lr: 4.4177e-05 lr: 4.4177e-05  eta: 2:12:56  time: 0.5838  data_time: 0.1804  memory: 5238  loss: 0.1344  decode.loss_ce: 0.1344  decode.acc_seg: 95.2237\n",
      "05/09 13:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43400/57000]  base_lr: 4.4139e-05 lr: 4.4139e-05  eta: 2:11:58  time: 0.5714  data_time: 0.1690  memory: 5238  loss: 0.1228  decode.loss_ce: 0.1228  decode.acc_seg: 94.1790\n",
      "05/09 13:53:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43500/57000]  base_lr: 4.4101e-05 lr: 4.4101e-05  eta: 2:10:59  time: 0.5601  data_time: 0.1579  memory: 5238  loss: 0.1771  decode.loss_ce: 0.1771  decode.acc_seg: 96.4774\n",
      "05/09 13:54:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43600/57000]  base_lr: 4.4063e-05 lr: 4.4063e-05  eta: 2:10:01  time: 0.5742  data_time: 0.1720  memory: 5238  loss: 0.0903  decode.loss_ce: 0.0903  decode.acc_seg: 91.5399\n",
      "05/09 13:55:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43700/57000]  base_lr: 4.4026e-05 lr: 4.4026e-05  eta: 2:09:02  time: 0.6034  data_time: 0.1955  memory: 5238  loss: 0.1158  decode.loss_ce: 0.1158  decode.acc_seg: 93.3542\n",
      "05/09 13:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43800/57000]  base_lr: 4.3988e-05 lr: 4.3988e-05  eta: 2:08:03  time: 0.5444  data_time: 0.1408  memory: 5238  loss: 0.0669  decode.loss_ce: 0.0669  decode.acc_seg: 95.8589\n",
      "05/09 13:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [43900/57000]  base_lr: 4.3950e-05 lr: 4.3950e-05  eta: 2:07:04  time: 0.5710  data_time: 0.1688  memory: 5238  loss: 0.1189  decode.loss_ce: 0.1189  decode.acc_seg: 93.7124\n",
      "05/09 13:58:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 13:58:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44000/57000]  base_lr: 4.3912e-05 lr: 4.3912e-05  eta: 2:06:06  time: 0.5697  data_time: 0.1626  memory: 5238  loss: 0.0860  decode.loss_ce: 0.0860  decode.acc_seg: 96.5229\n",
      "05/09 13:59:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44100/57000]  base_lr: 4.3874e-05 lr: 4.3874e-05  eta: 2:05:08  time: 0.5768  data_time: 0.1738  memory: 5238  loss: 0.1313  decode.loss_ce: 0.1313  decode.acc_seg: 98.4292\n",
      "05/09 14:00:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44200/57000]  base_lr: 4.3836e-05 lr: 4.3836e-05  eta: 2:04:09  time: 0.5837  data_time: 0.1769  memory: 5238  loss: 0.1761  decode.loss_ce: 0.1761  decode.acc_seg: 93.1088\n",
      "05/09 14:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44300/57000]  base_lr: 4.3798e-05 lr: 4.3798e-05  eta: 2:03:11  time: 0.5816  data_time: 0.1754  memory: 5238  loss: 0.0828  decode.loss_ce: 0.0828  decode.acc_seg: 99.1291\n",
      "05/09 14:02:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44400/57000]  base_lr: 4.3761e-05 lr: 4.3761e-05  eta: 2:02:12  time: 0.5751  data_time: 0.1730  memory: 5238  loss: 0.0950  decode.loss_ce: 0.0950  decode.acc_seg: 95.7282\n",
      "05/09 14:03:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44500/57000]  base_lr: 4.3723e-05 lr: 4.3723e-05  eta: 2:01:14  time: 0.5565  data_time: 0.1548  memory: 5238  loss: 0.0925  decode.loss_ce: 0.0925  decode.acc_seg: 97.3511\n",
      "05/09 14:04:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44600/57000]  base_lr: 4.3685e-05 lr: 4.3685e-05  eta: 2:00:15  time: 0.5494  data_time: 0.1468  memory: 5238  loss: 0.1034  decode.loss_ce: 0.1034  decode.acc_seg: 93.3613\n",
      "05/09 14:04:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44700/57000]  base_lr: 4.3647e-05 lr: 4.3647e-05  eta: 1:59:16  time: 0.5716  data_time: 0.1693  memory: 5238  loss: 0.1029  decode.loss_ce: 0.1029  decode.acc_seg: 99.2267\n",
      "05/09 14:05:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44800/57000]  base_lr: 4.3609e-05 lr: 4.3609e-05  eta: 1:58:18  time: 0.5993  data_time: 0.1924  memory: 5238  loss: 0.1216  decode.loss_ce: 0.1216  decode.acc_seg: 93.7515\n",
      "05/09 14:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [44900/57000]  base_lr: 4.3571e-05 lr: 4.3571e-05  eta: 1:57:19  time: 0.5618  data_time: 0.1597  memory: 5238  loss: 0.1085  decode.loss_ce: 0.1085  decode.acc_seg: 94.9120\n",
      "05/09 14:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 14:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45000/57000]  base_lr: 4.3533e-05 lr: 4.3533e-05  eta: 1:56:21  time: 0.5747  data_time: 0.1697  memory: 5238  loss: 0.1344  decode.loss_ce: 0.1344  decode.acc_seg: 96.1887\n",
      "05/09 14:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:15  time: 0.3692  data_time: 0.1963  memory: 2587  \n",
      "05/09 14:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4418  data_time: 0.2706  memory: 2590  \n",
      "05/09 14:09:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:57  time: 0.3648  data_time: 0.1738  memory: 2578  \n",
      "05/09 14:10:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3614  data_time: 0.1772  memory: 2410  \n",
      "05/09 14:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 14:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 52.14 | 61.54 | 68.55 | 68.55  |   77.36   | 61.54  |\n",
      "| BuildingFlooded | 78.03 | 89.52 | 87.66 | 87.66  |   85.87   | 89.52  |\n",
      "|   BNonFlooded   | 79.83 |  90.0 | 88.78 | 88.78  |    87.6   |  90.0  |\n",
      "|   RoadFlooded   |  63.1 | 84.53 | 77.38 | 77.38  |   71.34   | 84.53  |\n",
      "|   RNonFlooded   | 83.44 | 89.39 | 90.97 | 90.97  |   92.62   | 89.39  |\n",
      "|      Water      | 72.94 | 84.02 | 84.35 | 84.35  |   84.69   | 84.02  |\n",
      "|       Tree      | 84.45 | 91.51 | 91.57 | 91.57  |   91.64   | 91.51  |\n",
      "|      Vecile     | 49.18 | 57.28 | 65.93 | 65.93  |   77.66   | 57.28  |\n",
      "|       Pool      | 64.92 | 73.34 | 78.73 | 78.73  |   84.98   | 73.34  |\n",
      "|      Grass      | 89.26 | 94.48 | 94.33 | 94.33  |   94.18   | 94.48  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 14:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 91.0800  mIoU: 71.7300  mAcc: 81.5600  mDice: 82.8200  mFscore: 82.8200  mPrecision: 84.7900  mRecall: 81.5600  data_time: 0.2004  time: 0.3804\n",
      "05/09 14:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/checkpoint/best_mIoU_iter_39000.pth is removed\n",
      "05/09 14:10:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 71.7300 mIoU at 45000 iter is saved to best_mIoU_iter_45000.pth.\n",
      "05/09 14:11:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45100/57000]  base_lr: 4.3496e-05 lr: 4.3496e-05  eta: 1:55:27  time: 0.6672  data_time: 0.2607  memory: 5238  loss: 0.0780  decode.loss_ce: 0.0780  decode.acc_seg: 89.9928\n",
      "05/09 14:13:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45200/57000]  base_lr: 4.3458e-05 lr: 4.3458e-05  eta: 1:54:32  time: 0.6783  data_time: 0.2702  memory: 5238  loss: 0.0813  decode.loss_ce: 0.0813  decode.acc_seg: 97.1565\n",
      "05/09 14:14:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45300/57000]  base_lr: 4.3420e-05 lr: 4.3420e-05  eta: 1:53:36  time: 0.7017  data_time: 0.2934  memory: 5238  loss: 0.0838  decode.loss_ce: 0.0838  decode.acc_seg: 96.6058\n",
      "05/09 14:15:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45400/57000]  base_lr: 4.3382e-05 lr: 4.3382e-05  eta: 1:52:41  time: 0.7536  data_time: 0.3414  memory: 5238  loss: 0.1030  decode.loss_ce: 0.1030  decode.acc_seg: 92.6095\n",
      "05/09 14:16:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45500/57000]  base_lr: 4.3344e-05 lr: 4.3344e-05  eta: 1:51:45  time: 0.6841  data_time: 0.2766  memory: 5238  loss: 0.1003  decode.loss_ce: 0.1003  decode.acc_seg: 94.1052\n",
      "05/09 14:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45600/57000]  base_lr: 4.3306e-05 lr: 4.3306e-05  eta: 1:50:48  time: 0.5999  data_time: 0.1938  memory: 5238  loss: 0.0698  decode.loss_ce: 0.0698  decode.acc_seg: 97.5556\n",
      "05/09 14:18:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45700/57000]  base_lr: 4.3268e-05 lr: 4.3268e-05  eta: 1:49:51  time: 0.6091  data_time: 0.2047  memory: 5238  loss: 0.1226  decode.loss_ce: 0.1226  decode.acc_seg: 87.7025\n",
      "05/09 14:19:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45800/57000]  base_lr: 4.3231e-05 lr: 4.3231e-05  eta: 1:48:53  time: 0.6339  data_time: 0.2289  memory: 5238  loss: 0.1180  decode.loss_ce: 0.1180  decode.acc_seg: 91.6416\n",
      "05/09 14:20:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [45900/57000]  base_lr: 4.3193e-05 lr: 4.3193e-05  eta: 1:47:55  time: 0.6028  data_time: 0.1964  memory: 5238  loss: 0.0864  decode.loss_ce: 0.0864  decode.acc_seg: 96.3553\n",
      "05/09 14:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 14:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46000/57000]  base_lr: 4.3155e-05 lr: 4.3155e-05  eta: 1:46:57  time: 0.5983  data_time: 0.1945  memory: 5238  loss: 0.1072  decode.loss_ce: 0.1072  decode.acc_seg: 99.2358\n",
      "05/09 14:22:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46100/57000]  base_lr: 4.3117e-05 lr: 4.3117e-05  eta: 1:46:00  time: 0.6395  data_time: 0.2344  memory: 5238  loss: 0.1152  decode.loss_ce: 0.1152  decode.acc_seg: 84.0284\n",
      "05/09 14:23:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46200/57000]  base_lr: 4.3079e-05 lr: 4.3079e-05  eta: 1:45:02  time: 0.6174  data_time: 0.2128  memory: 5238  loss: 0.0878  decode.loss_ce: 0.0878  decode.acc_seg: 96.4021\n",
      "05/09 14:24:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46300/57000]  base_lr: 4.3041e-05 lr: 4.3041e-05  eta: 1:44:04  time: 0.6065  data_time: 0.1986  memory: 5238  loss: 0.1358  decode.loss_ce: 0.1358  decode.acc_seg: 89.5404\n",
      "05/09 14:25:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46400/57000]  base_lr: 4.3003e-05 lr: 4.3003e-05  eta: 1:43:05  time: 0.5764  data_time: 0.1713  memory: 5238  loss: 0.0814  decode.loss_ce: 0.0814  decode.acc_seg: 95.3898\n",
      "05/09 14:26:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46500/57000]  base_lr: 4.2966e-05 lr: 4.2966e-05  eta: 1:42:06  time: 0.6004  data_time: 0.1963  memory: 5238  loss: 0.1919  decode.loss_ce: 0.1919  decode.acc_seg: 97.9637\n",
      "05/09 14:27:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46600/57000]  base_lr: 4.2928e-05 lr: 4.2928e-05  eta: 1:41:08  time: 0.5668  data_time: 0.1636  memory: 5238  loss: 0.1026  decode.loss_ce: 0.1026  decode.acc_seg: 96.6180\n",
      "05/09 14:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46700/57000]  base_lr: 4.2890e-05 lr: 4.2890e-05  eta: 1:40:09  time: 0.5617  data_time: 0.1579  memory: 5238  loss: 0.1275  decode.loss_ce: 0.1275  decode.acc_seg: 84.4596\n",
      "05/09 14:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46800/57000]  base_lr: 4.2852e-05 lr: 4.2852e-05  eta: 1:39:11  time: 0.5781  data_time: 0.1743  memory: 5238  loss: 0.1241  decode.loss_ce: 0.1241  decode.acc_seg: 98.0488\n",
      "05/09 14:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [46900/57000]  base_lr: 4.2814e-05 lr: 4.2814e-05  eta: 1:38:13  time: 0.6182  data_time: 0.2126  memory: 5238  loss: 0.1080  decode.loss_ce: 0.1080  decode.acc_seg: 97.1973\n",
      "05/09 14:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 14:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47000/57000]  base_lr: 4.2776e-05 lr: 4.2776e-05  eta: 1:37:14  time: 0.5682  data_time: 0.1651  memory: 5238  loss: 0.0831  decode.loss_ce: 0.0831  decode.acc_seg: 95.5376\n",
      "05/09 14:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47100/57000]  base_lr: 4.2738e-05 lr: 4.2738e-05  eta: 1:36:16  time: 0.5672  data_time: 0.1627  memory: 5238  loss: 0.0982  decode.loss_ce: 0.0982  decode.acc_seg: 93.0675\n",
      "05/09 14:33:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47200/57000]  base_lr: 4.2701e-05 lr: 4.2701e-05  eta: 1:35:17  time: 0.5723  data_time: 0.1695  memory: 5238  loss: 0.1239  decode.loss_ce: 0.1239  decode.acc_seg: 92.5670\n",
      "05/09 14:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47300/57000]  base_lr: 4.2663e-05 lr: 4.2663e-05  eta: 1:34:19  time: 0.5825  data_time: 0.1776  memory: 5238  loss: 0.0835  decode.loss_ce: 0.0835  decode.acc_seg: 97.8991\n",
      "05/09 14:35:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47400/57000]  base_lr: 4.2625e-05 lr: 4.2625e-05  eta: 1:33:20  time: 0.5574  data_time: 0.1529  memory: 5238  loss: 0.2187  decode.loss_ce: 0.2187  decode.acc_seg: 99.6972\n",
      "05/09 14:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47500/57000]  base_lr: 4.2587e-05 lr: 4.2587e-05  eta: 1:32:21  time: 0.5983  data_time: 0.1909  memory: 5238  loss: 0.2086  decode.loss_ce: 0.2086  decode.acc_seg: 88.1778\n",
      "05/09 14:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47600/57000]  base_lr: 4.2549e-05 lr: 4.2549e-05  eta: 1:31:23  time: 0.5635  data_time: 0.1586  memory: 5238  loss: 0.2198  decode.loss_ce: 0.2198  decode.acc_seg: 89.2579\n",
      "05/09 14:38:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47700/57000]  base_lr: 4.2511e-05 lr: 4.2511e-05  eta: 1:30:25  time: 0.5789  data_time: 0.1750  memory: 5238  loss: 0.1372  decode.loss_ce: 0.1372  decode.acc_seg: 91.6658\n",
      "05/09 14:39:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47800/57000]  base_lr: 4.2473e-05 lr: 4.2473e-05  eta: 1:29:26  time: 0.5785  data_time: 0.1734  memory: 5238  loss: 0.0678  decode.loss_ce: 0.0678  decode.acc_seg: 95.2260\n",
      "05/09 14:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [47900/57000]  base_lr: 4.2436e-05 lr: 4.2436e-05  eta: 1:28:28  time: 0.5592  data_time: 0.1555  memory: 5238  loss: 0.0884  decode.loss_ce: 0.0884  decode.acc_seg: 96.8208\n",
      "05/09 14:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 14:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48000/57000]  base_lr: 4.2398e-05 lr: 4.2398e-05  eta: 1:27:29  time: 0.5653  data_time: 0.1585  memory: 5238  loss: 0.0713  decode.loss_ce: 0.0713  decode.acc_seg: 99.2112\n",
      "05/09 14:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48000 iterations\n",
      "05/09 14:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:34  time: 0.4246  data_time: 0.2502  memory: 2589  \n",
      "05/09 14:42:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:51  time: 0.5234  data_time: 0.3513  memory: 2589  \n",
      "05/09 14:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:01:06  time: 0.4098  data_time: 0.2170  memory: 2578  \n",
      "05/09 14:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:21  time: 0.4394  data_time: 0.2510  memory: 2410  \n",
      "05/09 14:44:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 14:44:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 57.46 | 67.96 | 72.98 | 72.98  |    78.8   | 67.96  |\n",
      "| BuildingFlooded | 74.63 | 85.69 | 85.47 | 85.47  |   85.25   | 85.69  |\n",
      "|   BNonFlooded   | 76.94 | 90.96 | 86.97 | 86.97  |   83.32   | 90.96  |\n",
      "|   RoadFlooded   | 60.59 | 79.39 | 75.46 | 75.46  |    71.9   | 79.39  |\n",
      "|   RNonFlooded   | 80.87 | 89.45 | 89.42 | 89.42  |    89.4   | 89.45  |\n",
      "|      Water      |  69.5 | 80.47 | 82.01 | 82.01  |    83.6   | 80.47  |\n",
      "|       Tree      | 84.21 | 91.63 | 91.43 | 91.43  |   91.23   | 91.63  |\n",
      "|      Vecile     | 53.42 | 70.05 | 69.64 | 69.64  |   69.24   | 70.05  |\n",
      "|       Pool      | 64.17 | 77.73 | 78.17 | 78.17  |   78.63   | 77.73  |\n",
      "|      Grass      | 88.37 |  93.9 | 93.83 | 93.83  |   93.75   |  93.9  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 14:44:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.3800  mIoU: 71.0200  mAcc: 82.7200  mDice: 82.5400  mFscore: 82.5400  mPrecision: 82.5100  mRecall: 82.7200  data_time: 0.2527  time: 0.4341\n",
      "05/09 14:45:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48100/57000]  base_lr: 4.2360e-05 lr: 4.2360e-05  eta: 1:26:30  time: 0.5593  data_time: 0.1573  memory: 5238  loss: 0.0746  decode.loss_ce: 0.0746  decode.acc_seg: 95.8468\n",
      "05/09 14:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48200/57000]  base_lr: 4.2322e-05 lr: 4.2322e-05  eta: 1:25:32  time: 0.5713  data_time: 0.1685  memory: 5238  loss: 0.0783  decode.loss_ce: 0.0783  decode.acc_seg: 96.6923\n",
      "05/09 14:47:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48300/57000]  base_lr: 4.2284e-05 lr: 4.2284e-05  eta: 1:24:33  time: 0.5818  data_time: 0.1749  memory: 5238  loss: 0.0849  decode.loss_ce: 0.0849  decode.acc_seg: 99.1495\n",
      "05/09 14:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48400/57000]  base_lr: 4.2246e-05 lr: 4.2246e-05  eta: 1:23:35  time: 0.5972  data_time: 0.1922  memory: 5238  loss: 0.1141  decode.loss_ce: 0.1141  decode.acc_seg: 96.4579\n",
      "05/09 14:49:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48500/57000]  base_lr: 4.2208e-05 lr: 4.2208e-05  eta: 1:22:36  time: 0.5472  data_time: 0.1452  memory: 5238  loss: 0.1172  decode.loss_ce: 0.1172  decode.acc_seg: 96.2593\n",
      "05/09 14:50:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48600/57000]  base_lr: 4.2171e-05 lr: 4.2171e-05  eta: 1:21:38  time: 0.5664  data_time: 0.1636  memory: 5238  loss: 0.0728  decode.loss_ce: 0.0728  decode.acc_seg: 91.4885\n",
      "05/09 14:50:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48700/57000]  base_lr: 4.2133e-05 lr: 4.2133e-05  eta: 1:20:39  time: 0.5746  data_time: 0.1720  memory: 5238  loss: 0.4144  decode.loss_ce: 0.4144  decode.acc_seg: 92.3870\n",
      "05/09 14:51:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48800/57000]  base_lr: 4.2095e-05 lr: 4.2095e-05  eta: 1:19:41  time: 0.5836  data_time: 0.1772  memory: 5238  loss: 0.1353  decode.loss_ce: 0.1353  decode.acc_seg: 90.4223\n",
      "05/09 14:52:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [48900/57000]  base_lr: 4.2057e-05 lr: 4.2057e-05  eta: 1:18:42  time: 0.5858  data_time: 0.1785  memory: 5238  loss: 0.1117  decode.loss_ce: 0.1117  decode.acc_seg: 97.6183\n",
      "05/09 14:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 14:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49000/57000]  base_lr: 4.2019e-05 lr: 4.2019e-05  eta: 1:17:44  time: 0.5779  data_time: 0.1743  memory: 5238  loss: 0.2108  decode.loss_ce: 0.2108  decode.acc_seg: 82.5838\n",
      "05/09 14:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49100/57000]  base_lr: 4.1981e-05 lr: 4.1981e-05  eta: 1:16:45  time: 0.5644  data_time: 0.1594  memory: 5238  loss: 0.1315  decode.loss_ce: 0.1315  decode.acc_seg: 88.7974\n",
      "05/09 14:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49200/57000]  base_lr: 4.1943e-05 lr: 4.1943e-05  eta: 1:15:47  time: 0.5521  data_time: 0.1499  memory: 5238  loss: 0.0891  decode.loss_ce: 0.0891  decode.acc_seg: 93.8748\n",
      "05/09 14:56:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49300/57000]  base_lr: 4.1906e-05 lr: 4.1906e-05  eta: 1:14:48  time: 0.5942  data_time: 0.1912  memory: 5238  loss: 0.0914  decode.loss_ce: 0.0914  decode.acc_seg: 97.8363\n",
      "05/09 14:57:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49400/57000]  base_lr: 4.1868e-05 lr: 4.1868e-05  eta: 1:13:49  time: 0.5617  data_time: 0.1591  memory: 5238  loss: 0.0806  decode.loss_ce: 0.0806  decode.acc_seg: 96.0370\n",
      "05/09 14:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49500/57000]  base_lr: 4.1830e-05 lr: 4.1830e-05  eta: 1:12:51  time: 0.5719  data_time: 0.1656  memory: 5238  loss: 0.1417  decode.loss_ce: 0.1417  decode.acc_seg: 99.7648\n",
      "05/09 14:59:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49600/57000]  base_lr: 4.1792e-05 lr: 4.1792e-05  eta: 1:11:52  time: 0.5731  data_time: 0.1706  memory: 5238  loss: 0.1806  decode.loss_ce: 0.1806  decode.acc_seg: 94.1316\n",
      "05/09 15:00:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49700/57000]  base_lr: 4.1754e-05 lr: 4.1754e-05  eta: 1:10:54  time: 0.5826  data_time: 0.1791  memory: 5238  loss: 0.1642  decode.loss_ce: 0.1642  decode.acc_seg: 96.0566\n",
      "05/09 15:01:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49800/57000]  base_lr: 4.1716e-05 lr: 4.1716e-05  eta: 1:09:56  time: 0.5820  data_time: 0.1762  memory: 5238  loss: 0.0809  decode.loss_ce: 0.0809  decode.acc_seg: 96.5371\n",
      "05/09 15:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [49900/57000]  base_lr: 4.1678e-05 lr: 4.1678e-05  eta: 1:08:57  time: 0.5685  data_time: 0.1666  memory: 5238  loss: 0.0578  decode.loss_ce: 0.0578  decode.acc_seg: 100.0000\n",
      "05/09 15:03:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 15:03:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50000/57000]  base_lr: 4.1641e-05 lr: 4.1641e-05  eta: 1:07:59  time: 0.5960  data_time: 0.1902  memory: 5238  loss: 0.1061  decode.loss_ce: 0.1061  decode.acc_seg: 95.8593\n",
      "05/09 15:04:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50100/57000]  base_lr: 4.1603e-05 lr: 4.1603e-05  eta: 1:07:00  time: 0.5699  data_time: 0.1628  memory: 5238  loss: 0.1338  decode.loss_ce: 0.1338  decode.acc_seg: 92.2104\n",
      "05/09 15:05:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50200/57000]  base_lr: 4.1565e-05 lr: 4.1565e-05  eta: 1:06:02  time: 0.5559  data_time: 0.1539  memory: 5238  loss: 0.0770  decode.loss_ce: 0.0770  decode.acc_seg: 97.2668\n",
      "05/09 15:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50300/57000]  base_lr: 4.1527e-05 lr: 4.1527e-05  eta: 1:05:04  time: 0.5708  data_time: 0.1689  memory: 5238  loss: 0.0970  decode.loss_ce: 0.0970  decode.acc_seg: 98.0680\n",
      "05/09 15:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50400/57000]  base_lr: 4.1489e-05 lr: 4.1489e-05  eta: 1:04:05  time: 0.5614  data_time: 0.1577  memory: 5238  loss: 0.1023  decode.loss_ce: 0.1023  decode.acc_seg: 98.2237\n",
      "05/09 15:08:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50500/57000]  base_lr: 4.1451e-05 lr: 4.1451e-05  eta: 1:03:07  time: 0.5514  data_time: 0.1483  memory: 5238  loss: 0.0782  decode.loss_ce: 0.0782  decode.acc_seg: 98.8652\n",
      "05/09 15:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50600/57000]  base_lr: 4.1414e-05 lr: 4.1414e-05  eta: 1:02:08  time: 0.5792  data_time: 0.1754  memory: 5238  loss: 0.0848  decode.loss_ce: 0.0848  decode.acc_seg: 95.2274\n",
      "05/09 15:09:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50700/57000]  base_lr: 4.1376e-05 lr: 4.1376e-05  eta: 1:01:10  time: 0.5778  data_time: 0.1747  memory: 5238  loss: 0.0632  decode.loss_ce: 0.0632  decode.acc_seg: 92.8883\n",
      "05/09 15:10:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50800/57000]  base_lr: 4.1338e-05 lr: 4.1338e-05  eta: 1:00:11  time: 0.5832  data_time: 0.1799  memory: 5238  loss: 0.0972  decode.loss_ce: 0.0972  decode.acc_seg: 97.8925\n",
      "05/09 15:11:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [50900/57000]  base_lr: 4.1300e-05 lr: 4.1300e-05  eta: 0:59:13  time: 0.5630  data_time: 0.1604  memory: 5238  loss: 0.1011  decode.loss_ce: 0.1011  decode.acc_seg: 95.2399\n",
      "05/09 15:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 15:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51000/57000]  base_lr: 4.1262e-05 lr: 4.1262e-05  eta: 0:58:15  time: 0.5755  data_time: 0.1712  memory: 5238  loss: 0.1213  decode.loss_ce: 0.1213  decode.acc_seg: 93.1240\n",
      "05/09 15:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:16  time: 0.3759  data_time: 0.2027  memory: 2588  \n",
      "05/09 15:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:37  time: 0.4407  data_time: 0.2704  memory: 2588  \n",
      "05/09 15:14:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3739  data_time: 0.1829  memory: 2577  \n",
      "05/09 15:15:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3645  data_time: 0.1799  memory: 2410  \n",
      "05/09 15:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 15:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 42.36 | 49.72 | 59.52 | 59.52  |   74.11   | 49.72  |\n",
      "| BuildingFlooded | 73.99 | 85.33 | 85.05 | 85.05  |   84.77   | 85.33  |\n",
      "|   BNonFlooded   | 74.42 | 92.75 | 85.34 | 85.34  |   79.02   | 92.75  |\n",
      "|   RoadFlooded   | 63.82 | 84.15 | 77.91 | 77.91  |   72.53   | 84.15  |\n",
      "|   RNonFlooded   | 80.56 | 91.64 | 89.23 | 89.23  |   86.95   | 91.64  |\n",
      "|      Water      | 69.62 | 79.82 | 82.09 | 82.09  |    84.5   | 79.82  |\n",
      "|       Tree      | 83.69 |  92.4 | 91.12 | 91.12  |   89.88   |  92.4  |\n",
      "|      Vecile     | 50.28 |  61.8 | 66.92 | 66.92  |   72.97   |  61.8  |\n",
      "|       Pool      | 62.57 |  76.6 | 76.98 | 76.98  |   77.36   |  76.6  |\n",
      "|      Grass      | 87.81 | 93.17 | 93.51 | 93.51  |   93.85   | 93.17  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 15:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 89.9300  mIoU: 68.9100  mAcc: 80.7400  mDice: 80.7700  mFscore: 80.7700  mPrecision: 81.5900  mRecall: 80.7400  data_time: 0.2021  time: 0.3819\n",
      "05/09 15:16:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51100/57000]  base_lr: 4.1224e-05 lr: 4.1224e-05  eta: 0:57:16  time: 0.5714  data_time: 0.1669  memory: 5238  loss: 0.1443  decode.loss_ce: 0.1443  decode.acc_seg: 93.9803\n",
      "05/09 15:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51200/57000]  base_lr: 4.1186e-05 lr: 4.1186e-05  eta: 0:56:18  time: 0.5800  data_time: 0.1752  memory: 5238  loss: 0.1322  decode.loss_ce: 0.1322  decode.acc_seg: 94.4447\n",
      "05/09 15:18:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51300/57000]  base_lr: 4.1149e-05 lr: 4.1149e-05  eta: 0:55:20  time: 0.5869  data_time: 0.1831  memory: 5238  loss: 0.0963  decode.loss_ce: 0.0963  decode.acc_seg: 99.9813\n",
      "05/09 15:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51400/57000]  base_lr: 4.1111e-05 lr: 4.1111e-05  eta: 0:54:22  time: 0.5631  data_time: 0.1586  memory: 5238  loss: 0.0851  decode.loss_ce: 0.0851  decode.acc_seg: 94.2057\n",
      "05/09 15:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51500/57000]  base_lr: 4.1073e-05 lr: 4.1073e-05  eta: 0:53:23  time: 0.6021  data_time: 0.1927  memory: 5238  loss: 0.1348  decode.loss_ce: 0.1348  decode.acc_seg: 86.0384\n",
      "05/09 15:21:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51600/57000]  base_lr: 4.1035e-05 lr: 4.1035e-05  eta: 0:52:25  time: 0.6060  data_time: 0.1988  memory: 5238  loss: 0.1502  decode.loss_ce: 0.1502  decode.acc_seg: 96.6402\n",
      "05/09 15:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51700/57000]  base_lr: 4.0997e-05 lr: 4.0997e-05  eta: 0:51:27  time: 0.5805  data_time: 0.1750  memory: 5238  loss: 0.0788  decode.loss_ce: 0.0788  decode.acc_seg: 98.6623\n",
      "05/09 15:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51800/57000]  base_lr: 4.0959e-05 lr: 4.0959e-05  eta: 0:50:29  time: 0.5754  data_time: 0.1707  memory: 5238  loss: 0.0835  decode.loss_ce: 0.0835  decode.acc_seg: 94.8088\n",
      "05/09 15:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [51900/57000]  base_lr: 4.0921e-05 lr: 4.0921e-05  eta: 0:49:30  time: 0.5930  data_time: 0.1845  memory: 5238  loss: 0.1438  decode.loss_ce: 0.1438  decode.acc_seg: 79.2367\n",
      "05/09 15:25:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 15:25:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52000/57000]  base_lr: 4.0884e-05 lr: 4.0884e-05  eta: 0:48:32  time: 0.5659  data_time: 0.1606  memory: 5238  loss: 0.0996  decode.loss_ce: 0.0996  decode.acc_seg: 96.3819\n",
      "05/09 15:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52100/57000]  base_lr: 4.0846e-05 lr: 4.0846e-05  eta: 0:47:34  time: 0.6081  data_time: 0.1969  memory: 5238  loss: 0.1563  decode.loss_ce: 0.1563  decode.acc_seg: 96.4515\n",
      "05/09 15:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52200/57000]  base_lr: 4.0808e-05 lr: 4.0808e-05  eta: 0:46:36  time: 0.5901  data_time: 0.1839  memory: 5238  loss: 0.1109  decode.loss_ce: 0.1109  decode.acc_seg: 92.5003\n",
      "05/09 15:28:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52300/57000]  base_lr: 4.0770e-05 lr: 4.0770e-05  eta: 0:45:38  time: 0.5999  data_time: 0.1888  memory: 5238  loss: 0.1137  decode.loss_ce: 0.1137  decode.acc_seg: 93.5480\n",
      "05/09 15:29:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52400/57000]  base_lr: 4.0732e-05 lr: 4.0732e-05  eta: 0:44:39  time: 0.5944  data_time: 0.1862  memory: 5238  loss: 0.1306  decode.loss_ce: 0.1306  decode.acc_seg: 90.7277\n",
      "05/09 15:30:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52500/57000]  base_lr: 4.0694e-05 lr: 4.0694e-05  eta: 0:43:41  time: 0.5859  data_time: 0.1786  memory: 5238  loss: 0.1046  decode.loss_ce: 0.1046  decode.acc_seg: 93.5484\n",
      "05/09 15:31:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52600/57000]  base_lr: 4.0656e-05 lr: 4.0656e-05  eta: 0:42:43  time: 0.5872  data_time: 0.1820  memory: 5238  loss: 0.0875  decode.loss_ce: 0.0875  decode.acc_seg: 94.4611\n",
      "05/09 15:32:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52700/57000]  base_lr: 4.0619e-05 lr: 4.0619e-05  eta: 0:41:45  time: 0.5890  data_time: 0.1807  memory: 5238  loss: 0.1054  decode.loss_ce: 0.1054  decode.acc_seg: 97.4623\n",
      "05/09 15:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52800/57000]  base_lr: 4.0581e-05 lr: 4.0581e-05  eta: 0:40:46  time: 0.5799  data_time: 0.1745  memory: 5238  loss: 0.1095  decode.loss_ce: 0.1095  decode.acc_seg: 96.0979\n",
      "05/09 15:34:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [52900/57000]  base_lr: 4.0543e-05 lr: 4.0543e-05  eta: 0:39:48  time: 0.5839  data_time: 0.1788  memory: 5238  loss: 0.0770  decode.loss_ce: 0.0770  decode.acc_seg: 98.4209\n",
      "05/09 15:35:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 15:35:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53000/57000]  base_lr: 4.0505e-05 lr: 4.0505e-05  eta: 0:38:50  time: 0.5800  data_time: 0.1736  memory: 5238  loss: 0.0888  decode.loss_ce: 0.0888  decode.acc_seg: 95.5293\n",
      "05/09 15:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53100/57000]  base_lr: 4.0467e-05 lr: 4.0467e-05  eta: 0:37:52  time: 0.5938  data_time: 0.1844  memory: 5238  loss: 0.1067  decode.loss_ce: 0.1067  decode.acc_seg: 95.1855\n",
      "05/09 15:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53200/57000]  base_lr: 4.0429e-05 lr: 4.0429e-05  eta: 0:36:53  time: 0.5690  data_time: 0.1621  memory: 5238  loss: 0.1698  decode.loss_ce: 0.1698  decode.acc_seg: 92.2605\n",
      "05/09 15:38:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53300/57000]  base_lr: 4.0391e-05 lr: 4.0391e-05  eta: 0:35:55  time: 0.5871  data_time: 0.1828  memory: 5238  loss: 0.1298  decode.loss_ce: 0.1298  decode.acc_seg: 96.6609\n",
      "05/09 15:39:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53400/57000]  base_lr: 4.0354e-05 lr: 4.0354e-05  eta: 0:34:57  time: 0.5611  data_time: 0.1569  memory: 5238  loss: 0.0802  decode.loss_ce: 0.0802  decode.acc_seg: 97.6624\n",
      "05/09 15:40:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53500/57000]  base_lr: 4.0316e-05 lr: 4.0316e-05  eta: 0:33:59  time: 0.5746  data_time: 0.1666  memory: 5238  loss: 0.0736  decode.loss_ce: 0.0736  decode.acc_seg: 95.7220\n",
      "05/09 15:41:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53600/57000]  base_lr: 4.0278e-05 lr: 4.0278e-05  eta: 0:33:00  time: 0.5622  data_time: 0.1578  memory: 5238  loss: 0.0718  decode.loss_ce: 0.0718  decode.acc_seg: 93.9732\n",
      "05/09 15:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53700/57000]  base_lr: 4.0240e-05 lr: 4.0240e-05  eta: 0:32:02  time: 0.5798  data_time: 0.1757  memory: 5238  loss: 0.1301  decode.loss_ce: 0.1301  decode.acc_seg: 99.0362\n",
      "05/09 15:42:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53800/57000]  base_lr: 4.0202e-05 lr: 4.0202e-05  eta: 0:31:04  time: 0.5942  data_time: 0.1819  memory: 5238  loss: 0.0939  decode.loss_ce: 0.0939  decode.acc_seg: 97.8258\n",
      "05/09 15:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [53900/57000]  base_lr: 4.0164e-05 lr: 4.0164e-05  eta: 0:30:05  time: 0.5791  data_time: 0.1743  memory: 5238  loss: 0.0831  decode.loss_ce: 0.0831  decode.acc_seg: 94.0639\n",
      "05/09 15:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 15:44:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54000/57000]  base_lr: 4.0126e-05 lr: 4.0126e-05  eta: 0:29:07  time: 0.5655  data_time: 0.1608  memory: 5238  loss: 0.1175  decode.loss_ce: 0.1175  decode.acc_seg: 94.1387\n",
      "05/09 15:45:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:18  time: 0.3959  data_time: 0.2223  memory: 2589  \n",
      "05/09 15:46:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:38  time: 0.4488  data_time: 0.2772  memory: 2589  \n",
      "05/09 15:46:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:58  time: 0.3707  data_time: 0.1795  memory: 2578  \n",
      "05/09 15:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:19  time: 0.3725  data_time: 0.1869  memory: 2410  \n",
      "05/09 15:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 15:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 43.63 | 52.99 | 60.75 | 60.75  |   71.17   | 52.99  |\n",
      "| BuildingFlooded | 77.73 | 91.01 | 87.47 | 87.47  |    84.2   | 91.01  |\n",
      "|   BNonFlooded   | 78.68 | 89.75 | 88.07 | 88.07  |   86.46   | 89.75  |\n",
      "|   RoadFlooded   | 63.53 |  80.9 | 77.69 | 77.69  |   74.74   |  80.9  |\n",
      "|   RNonFlooded   | 82.54 | 92.88 | 90.44 | 90.44  |   88.12   | 92.88  |\n",
      "|      Water      | 72.07 | 84.31 | 83.77 | 83.77  |   83.24   | 84.31  |\n",
      "|       Tree      | 85.17 | 91.89 | 91.99 | 91.99  |    92.1   | 91.89  |\n",
      "|      Vecile     | 52.29 |  64.9 | 68.67 | 68.67  |   72.91   |  64.9  |\n",
      "|       Pool      | 65.58 | 82.03 | 79.21 | 79.21  |   76.58   | 82.03  |\n",
      "|      Grass      | 89.14 | 93.97 | 94.26 | 94.26  |   94.55   | 93.97  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 15:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.8700  mIoU: 71.0400  mAcc: 82.4600  mDice: 82.2300  mFscore: 82.2300  mPrecision: 82.4000  mRecall: 82.4600  data_time: 0.2062  time: 0.3867\n",
      "05/09 15:48:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54100/57000]  base_lr: 4.0089e-05 lr: 4.0089e-05  eta: 0:28:09  time: 0.5836  data_time: 0.1789  memory: 5238  loss: 0.1566  decode.loss_ce: 0.1566  decode.acc_seg: 93.5185\n",
      "05/09 15:49:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54200/57000]  base_lr: 4.0051e-05 lr: 4.0051e-05  eta: 0:27:11  time: 0.6020  data_time: 0.1936  memory: 5238  loss: 0.1214  decode.loss_ce: 0.1214  decode.acc_seg: 93.6090\n",
      "05/09 15:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54300/57000]  base_lr: 4.0013e-05 lr: 4.0013e-05  eta: 0:26:12  time: 0.5720  data_time: 0.1687  memory: 5238  loss: 0.1012  decode.loss_ce: 0.1012  decode.acc_seg: 74.4312\n",
      "05/09 15:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54400/57000]  base_lr: 3.9975e-05 lr: 3.9975e-05  eta: 0:25:14  time: 0.5721  data_time: 0.1685  memory: 5238  loss: 0.1039  decode.loss_ce: 0.1039  decode.acc_seg: 94.7536\n",
      "05/09 15:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54500/57000]  base_lr: 3.9937e-05 lr: 3.9937e-05  eta: 0:24:16  time: 0.5739  data_time: 0.1702  memory: 5238  loss: 0.1174  decode.loss_ce: 0.1174  decode.acc_seg: 95.3193\n",
      "05/09 15:53:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54600/57000]  base_lr: 3.9899e-05 lr: 3.9899e-05  eta: 0:23:18  time: 0.5835  data_time: 0.1790  memory: 5238  loss: 0.0940  decode.loss_ce: 0.0940  decode.acc_seg: 97.3642\n",
      "05/09 15:54:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54700/57000]  base_lr: 3.9861e-05 lr: 3.9861e-05  eta: 0:22:19  time: 0.5712  data_time: 0.1674  memory: 5238  loss: 0.0820  decode.loss_ce: 0.0820  decode.acc_seg: 97.6695\n",
      "05/09 15:55:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54800/57000]  base_lr: 3.9824e-05 lr: 3.9824e-05  eta: 0:21:21  time: 0.6044  data_time: 0.1962  memory: 5238  loss: 0.0990  decode.loss_ce: 0.0990  decode.acc_seg: 97.2893\n",
      "05/09 15:56:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [54900/57000]  base_lr: 3.9786e-05 lr: 3.9786e-05  eta: 0:20:23  time: 0.5977  data_time: 0.1915  memory: 5238  loss: 0.0869  decode.loss_ce: 0.0869  decode.acc_seg: 95.6450\n",
      "05/09 15:57:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 15:57:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55000/57000]  base_lr: 3.9748e-05 lr: 3.9748e-05  eta: 0:19:25  time: 0.5722  data_time: 0.1685  memory: 5238  loss: 0.1448  decode.loss_ce: 0.1448  decode.acc_seg: 92.2658\n",
      "05/09 15:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55100/57000]  base_lr: 3.9710e-05 lr: 3.9710e-05  eta: 0:18:26  time: 0.5578  data_time: 0.1537  memory: 5238  loss: 0.1156  decode.loss_ce: 0.1156  decode.acc_seg: 93.5130\n",
      "05/09 15:59:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55200/57000]  base_lr: 3.9672e-05 lr: 3.9672e-05  eta: 0:17:28  time: 0.5882  data_time: 0.1790  memory: 5238  loss: 0.0740  decode.loss_ce: 0.0740  decode.acc_seg: 92.8359\n",
      "05/09 16:00:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55300/57000]  base_lr: 3.9634e-05 lr: 3.9634e-05  eta: 0:16:30  time: 0.5638  data_time: 0.1601  memory: 5238  loss: 0.2364  decode.loss_ce: 0.2364  decode.acc_seg: 96.4438\n",
      "05/09 16:01:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55400/57000]  base_lr: 3.9596e-05 lr: 3.9596e-05  eta: 0:15:32  time: 0.5733  data_time: 0.1695  memory: 5238  loss: 0.1349  decode.loss_ce: 0.1349  decode.acc_seg: 95.0091\n",
      "05/09 16:02:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55500/57000]  base_lr: 3.9559e-05 lr: 3.9559e-05  eta: 0:14:33  time: 0.5695  data_time: 0.1659  memory: 5238  loss: 0.1100  decode.loss_ce: 0.1100  decode.acc_seg: 97.2923\n",
      "05/09 16:03:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55600/57000]  base_lr: 3.9521e-05 lr: 3.9521e-05  eta: 0:13:35  time: 0.5784  data_time: 0.1703  memory: 5238  loss: 0.1205  decode.loss_ce: 0.1205  decode.acc_seg: 95.0955\n",
      "05/09 16:04:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55700/57000]  base_lr: 3.9483e-05 lr: 3.9483e-05  eta: 0:12:37  time: 0.5716  data_time: 0.1660  memory: 5238  loss: 0.1043  decode.loss_ce: 0.1043  decode.acc_seg: 96.9130\n",
      "05/09 16:05:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55800/57000]  base_lr: 3.9445e-05 lr: 3.9445e-05  eta: 0:11:39  time: 0.5627  data_time: 0.1593  memory: 5238  loss: 0.0889  decode.loss_ce: 0.0889  decode.acc_seg: 97.5459\n",
      "05/09 16:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [55900/57000]  base_lr: 3.9407e-05 lr: 3.9407e-05  eta: 0:10:40  time: 0.5843  data_time: 0.1808  memory: 5238  loss: 0.0710  decode.loss_ce: 0.0710  decode.acc_seg: 96.0295\n",
      "05/09 16:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 16:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56000/57000]  base_lr: 3.9369e-05 lr: 3.9369e-05  eta: 0:09:42  time: 0.5837  data_time: 0.1801  memory: 5238  loss: 0.1106  decode.loss_ce: 0.1106  decode.acc_seg: 97.8360\n",
      "05/09 16:08:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56100/57000]  base_lr: 3.9331e-05 lr: 3.9331e-05  eta: 0:08:44  time: 0.5785  data_time: 0.1753  memory: 5238  loss: 0.0915  decode.loss_ce: 0.0915  decode.acc_seg: 97.4031\n",
      "05/09 16:09:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56200/57000]  base_lr: 3.9294e-05 lr: 3.9294e-05  eta: 0:07:45  time: 0.6049  data_time: 0.1973  memory: 5238  loss: 0.1063  decode.loss_ce: 0.1063  decode.acc_seg: 96.6736\n",
      "05/09 16:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56300/57000]  base_lr: 3.9256e-05 lr: 3.9256e-05  eta: 0:06:47  time: 0.5685  data_time: 0.1630  memory: 5238  loss: 0.1616  decode.loss_ce: 0.1616  decode.acc_seg: 84.3140\n",
      "05/09 16:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56400/57000]  base_lr: 3.9218e-05 lr: 3.9218e-05  eta: 0:05:49  time: 0.5760  data_time: 0.1717  memory: 5238  loss: 0.0860  decode.loss_ce: 0.0860  decode.acc_seg: 94.2208\n",
      "05/09 16:11:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56500/57000]  base_lr: 3.9180e-05 lr: 3.9180e-05  eta: 0:04:51  time: 0.5710  data_time: 0.1676  memory: 5238  loss: 0.0855  decode.loss_ce: 0.0855  decode.acc_seg: 97.0498\n",
      "05/09 16:12:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56600/57000]  base_lr: 3.9142e-05 lr: 3.9142e-05  eta: 0:03:52  time: 0.5849  data_time: 0.1814  memory: 5238  loss: 0.0947  decode.loss_ce: 0.0947  decode.acc_seg: 95.7007\n",
      "05/09 16:13:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56700/57000]  base_lr: 3.9104e-05 lr: 3.9104e-05  eta: 0:02:54  time: 0.5783  data_time: 0.1750  memory: 5238  loss: 0.0817  decode.loss_ce: 0.0817  decode.acc_seg: 99.5275\n",
      "05/09 16:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56800/57000]  base_lr: 3.9066e-05 lr: 3.9066e-05  eta: 0:01:56  time: 0.5660  data_time: 0.1621  memory: 5238  loss: 0.0966  decode.loss_ce: 0.0966  decode.acc_seg: 98.2679\n",
      "05/09 16:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [56900/57000]  base_lr: 3.9029e-05 lr: 3.9029e-05  eta: 0:00:58  time: 0.6011  data_time: 0.1908  memory: 5238  loss: 0.0740  decode.loss_ce: 0.0740  decode.acc_seg: 98.1710\n",
      "05/09 16:16:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: swin-base-patch4-window12-in1k-384x384-pre_upernet_8xb2-160k_ade20k-512x512_20240509_060815\n",
      "05/09 16:16:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(train) [57000/57000]  base_lr: 3.8991e-05 lr: 3.8991e-05  eta: 0:00:00  time: 0.5856  data_time: 0.1814  memory: 5238  loss: 0.0722  decode.loss_ce: 0.0722  decode.acc_seg: 99.0308\n",
      "05/09 16:16:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 57000 iterations\n",
      "05/09 16:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [100/450]    eta: 0:02:11  time: 0.3572  data_time: 0.1831  memory: 2588  \n",
      "05/09 16:18:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [200/450]    eta: 0:01:34  time: 0.4275  data_time: 0.2558  memory: 2588  \n",
      "05/09 16:18:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [300/450]    eta: 0:00:56  time: 0.3553  data_time: 0.1635  memory: 2578  \n",
      "05/09 16:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [400/450]    eta: 0:00:18  time: 0.3656  data_time: 0.1807  memory: 2410  \n",
      "05/09 16:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 16:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 47.02 | 56.39 | 63.97 | 63.97  |    73.9   | 56.39  |\n",
      "| BuildingFlooded | 77.73 | 92.21 | 87.47 | 87.47  |    83.2   | 92.21  |\n",
      "|   BNonFlooded   |  80.0 | 88.32 | 88.89 | 88.89  |   89.47   | 88.32  |\n",
      "|   RoadFlooded   | 63.24 | 84.67 | 77.48 | 77.48  |   71.42   | 84.67  |\n",
      "|   RNonFlooded   |  83.2 | 90.22 | 90.83 | 90.83  |   91.45   | 90.22  |\n",
      "|      Water      | 70.17 | 81.45 | 82.47 | 82.47  |   83.52   | 81.45  |\n",
      "|       Tree      | 84.49 | 92.72 | 91.59 | 91.59  |   90.49   | 92.72  |\n",
      "|      Vecile     | 54.79 | 75.58 | 70.79 | 70.79  |   66.57   | 75.58  |\n",
      "|       Pool      | 65.23 | 82.98 | 78.96 | 78.96  |   75.31   | 82.98  |\n",
      "|      Grass      |  88.5 | 93.63 |  93.9 |  93.9  |   94.17   | 93.63  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 16:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(val) [450/450]    aAcc: 90.5500  mIoU: 71.4400  mAcc: 83.8200  mDice: 82.6400  mFscore: 82.6400  mPrecision: 81.9500  mRecall: 83.8200  data_time: 0.1883  time: 0.3694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (data_preprocessor): SegDataPreProcessor()\n",
       "  (backbone): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (adap_padding): AdaptivePadding()\n",
       "      (projection): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
       "    (stages): ModuleList(\n",
       "      (0): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (2): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (4): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (5): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (6): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (7): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (8): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (9): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (10): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (11): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (12): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (13): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (14): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (15): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (16): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (17): SwinBlock(\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (adap_padding): AdaptivePadding()\n",
       "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
       "          (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinBlockSequence(\n",
       "        (blocks): ModuleList(\n",
       "          (0): SwinBlock(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): SwinBlock(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): ShiftWindowMSA(\n",
       "              (w_msa): WindowMSA(\n",
       "                (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "                (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "                (softmax): Softmax(dim=-1)\n",
       "              )\n",
       "              (drop): DropPath()\n",
       "            )\n",
       "            (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (layers): Sequential(\n",
       "                (0): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                  (1): GELU(approximate=none)\n",
       "                  (2): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (dropout_layer): DropPath()\n",
       "              (gamma2): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm0): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/swin/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K/upernet_swin_base_patch4_window12_512x512_160k_ade20k_pretrain_384x384_1K_20210531_132020-05b22ea4.pth'}\n",
       "  (decode_head): SegformerHead(\n",
       "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
       "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
       "    (conv_seg): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (convs): ModuleList(\n",
       "      (0): ConvModule(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvModule(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvModule(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvModule(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activate): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fusion_conv): ConvModule(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/segformer/segformer_mit-b5_512x512_160k_ade20k/segformer_mit-b5_512x512_160k_ade20k_20210726_145235-94cedf59.pth'}\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9b6b55c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T16:19:39.705219Z",
     "iopub.status.busy": "2024-05-09T16:19:39.704195Z",
     "iopub.status.idle": "2024-05-09T16:22:36.307081Z",
     "shell.execute_reply": "2024-05-09T16:22:36.306017Z"
    },
    "papermill": {
     "duration": 176.755129,
     "end_time": "2024-05-09T16:22:36.309066",
     "exception": false,
     "start_time": "2024-05-09T16:19:39.553937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/mmsegmentation/mmseg/datasets/transforms/loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05/09 16:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [100/450]    eta: 0:02:17  time: 0.3779  data_time: 0.2034  memory: 2588  \n",
      "05/09 16:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [200/450]    eta: 0:01:39  time: 0.4665  data_time: 0.2943  memory: 2588  \n",
      "05/09 16:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [300/450]    eta: 0:00:59  time: 0.3705  data_time: 0.1781  memory: 2578  \n",
      "05/09 16:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [400/450]    eta: 0:00:19  time: 0.3774  data_time: 0.1924  memory: 2410  \n",
      "05/09 16:22:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/09 16:22:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|      Class      |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "|    Background   | 47.02 | 56.39 | 63.97 | 63.97  |    73.9   | 56.39  |\n",
      "| BuildingFlooded | 77.73 | 92.21 | 87.47 | 87.47  |    83.2   | 92.21  |\n",
      "|   BNonFlooded   |  80.0 | 88.32 | 88.89 | 88.89  |   89.47   | 88.32  |\n",
      "|   RoadFlooded   | 63.24 | 84.67 | 77.48 | 77.48  |   71.42   | 84.67  |\n",
      "|   RNonFlooded   |  83.2 | 90.22 | 90.83 | 90.83  |   91.45   | 90.22  |\n",
      "|      Water      | 70.17 | 81.45 | 82.47 | 82.47  |   83.52   | 81.45  |\n",
      "|       Tree      | 84.49 | 92.72 | 91.59 | 91.59  |   90.49   | 92.72  |\n",
      "|      Vecile     | 54.79 | 75.58 | 70.79 | 70.79  |   66.57   | 75.58  |\n",
      "|       Pool      | 65.23 | 82.98 | 78.96 | 78.96  |   75.31   | 82.98  |\n",
      "|      Grass      |  88.5 | 93.63 |  93.9 |  93.9  |   94.17   | 93.63  |\n",
      "+-----------------+-------+-------+-------+--------+-----------+--------+\n",
      "05/09 16:22:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [450/450]    aAcc: 90.5500  mIoU: 71.4400  mAcc: 83.8200  mDice: 82.6400  mFscore: 82.6400  mPrecision: 81.9500  mRecall: 83.8200  data_time: 0.2067  time: 0.3882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'aAcc': 90.55,\n",
       " 'mIoU': 71.44,\n",
       " 'mAcc': 83.82,\n",
       " 'mDice': 82.64,\n",
       " 'mFscore': 82.64,\n",
       " 'mPrecision': 81.95,\n",
       " 'mRecall': 83.82}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "runner.test()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2963587,
     "sourceId": 5104516,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37062.32115,
   "end_time": "2024-05-09T16:22:39.848889",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-09T06:04:57.527739",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
